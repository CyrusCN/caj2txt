分类号：TP391

10710-2018224075

专业硕士学位论文

基于改进 MTCNN 网络的多特征疲劳驾驶
检测研究

薛丽

导师姓名职称

申请学位类别

工程硕士

马祥 教授

专业学位类别

及领域名称

交通运输工程

论文提交日期 2021 年 4 月 3 日 论文答辩日期 2021 年 6 月 5 日

学位授予单位

长安大学

Research on Multi-feature Fatigue Driving Detection

Based on Improved MTCNN Network

A Thesis Submitted for the Degree of Master

Candidate：Xue Li

Supervisor：Prof. Ma Xiang

Chang’an University, Xi’an, China

摘

要

随着国民水平的提高以及交通行业的发展，私家车越发普及，致使交通事故频繁发

生，人们的生命和财产安全也因此受到了非常大的影响。相关报道显示，疲劳驾驶是造

成交通事故的重要原因，若我们可以检测到驾驶员的驾驶状态并在疲劳时及时给出提

醒，就能够在一定意义上降低交通事故率。在目前的疲劳驾驶检测方法中，基于驾驶员

生理特征的检测法因需随身佩戴相关的检测仪器，其成本较高且会影响驾驶状态。基于

机动车行为特征的检测方法因易受天气、路况、驾驶环境等因素的影响，其鲁棒性较低。

相较于以上两种方法，基于面部特征的疲劳检测方法具有不接触、不干扰、检测精度高

等优点，所以本文围绕此方法进行研究，研究内容主要有以下几个方面：

（1）人脸检测和特征点定位。本文采用基于多任务级联框架的 MTCNN 算法来实

现人脸检测以及 5 个特征点的粗定位，首先选择 WIDER FACE 和 CelebA 两个数据集对

MTCNN 网络进行训练。实验表明，MTCNN 经三个子网络 P-Net、R-Net 以及 O-Net 训

练后，准确率从 95.8%提高至 97.3%。其次，本文在原有网络的基础上，对三个子网络

的参数进行了优化：针对 P-Net 网络，增加了 1 个卷积核为 3×3 的卷积层；针对 R-Net

网络，用均值池化替换了全连接层，且将最后一层的卷积核从 128 改为 196；针对 O-Net

网络，改变第 1、2、4 层卷积核参数，且将最大池化层的大小全部设置成 2×2。经优化

后，MTCNN 网络的准确率从 97.3%达到了 98.92%，提高了 1.62 个百分点。获得人脸候

选框后，本文选择 300-W 人脸数据库对级联回归算法 ERT 进行训练，最后实现了人脸

的 68 个关键点精定位，为后续疲劳检测奠定了扎实基础。

（2）面部跟踪。本文设计了基于 DSST 和 TLD 相结合的人脸跟踪算法，由于 DSST

算法缺少对于跟踪失败案例的检测机制，TLD 算法容易受到诸如光照等外界因素的影

响，而这两种算法可以互补，所以本文融合了两种人脸跟踪算法：将 TLD 算法中的跟

踪模块用 DSST 算法和适用于此算法的跟踪失败检测方法取代，且在 TLD 算法的检测

模块中加入 HOG 特征。模拟了驾驶员在裸眼、佩戴眼镜以及局部遮挡情况下的各种面

部姿态，使用 MTCNN 网络和 DSST+TLD 的人脸跟踪算法进行实验，结果显示，在这

些复杂环境下，本文设计的算法表现出了优异的性能。

（3）疲劳特征提取。获得人脸特征点位置后，分别对驾驶员的眼部、嘴部和头部

i

姿态这三种特征进行分析。针对眼部特征提取，选用眼睛纵横比 EAR 算法，提出了利

用两只眼睛求平均值的方式计算 EAR 值，通过此算法来获取 PERCLOS 值和眨眼频率

并将其作为判断疲劳的依据；针对嘴部特征提取，使用 MAR 算法，鉴于每个人的嘴唇

厚度不同，本文提出了利用嘴巴的内轮廓来计算 MAR 值，并将打哈欠作为判断疲劳的

依据；针对头部特征提取，选取三维空间欧拉角中的俯仰角 Pitch 来判断疲劳状态。采

集 5 个人的视频模拟疲劳驾驶状态，对以上几种疲劳特征进行实验，最终得出疲劳阈值：

P80 为 0.25，EAR 为 0.23，MAR 为 0.6，Pitch 的偏移量为 20%。

（4）多特征疲劳检测。因目前大多数单一疲劳特征提取的准确率较低，本文设计

了多特征疲劳检测。首先利用分辨率为 1080p HD、视频帧率为 30fps 的设备采集了 10

个实验人员的清醒状态和疲劳状态视频，截取各两分钟的 5 段疲劳和非疲劳视频，随机

选取 250 组样本训练支持向量机 SVM，并在剩下的数据集上测试，在相同的实验条件

下对比不同的检测算法。通过实验分析，本文采用的方法准确率可达 96.42%，对于疲

劳驾驶检测具有更好的可行性。最后使用 Python 语言、Tensorflow 框架对本文的算法进

行编程，完成疲劳驾驶检测系统。

关键词：疲劳驾驶，MTCNN，目标跟踪，多特征疲劳检测

ii

Abstract

With the improvement of the national standard and the development of the transportation

industry, private cars are becoming more and more popular, accompanying it is the frequent

occurrence of traffic accidents, which in turn has a big impact on safety of human life and

property. Related reports show that fatigue driving is an important cause of traffic accidents. If

we can detect the driver's fatigue state in real time and give prompt reminders, can we reduce

the traffic accident rate in a certain sense. Among current detection fatigue driving detection

methods, the detection method based on the physiological characteristics of the driver needs

to wear related detection equipment, which has a high cost and will affect the driving state.

The detection method based on the behavior characteristics of the motor vehicle is vulnerable

to weather, road conditions, driving environment and other factors, it has low robustness.

Compared with the above two methods, the fatigue detection method based on facial features

has the advantages of non-contact, non-interference and high detection accuracy. Therefore,

this article focuses on this method for research. The content mainly includes the following

aspects:

(1) Face detection and feature point positioning. This paper uses the MTCNN algorithm

based on the multi-task cascade framework in order to accomplish face detection and coarse

positioning of five feature points. First, select the WIDER FACE and CelebA data sets to train

the MTCNN network. Experiments show that after MTCNN is trained by the three

sub-networks P-Net, R-Net and O-Net, the accuracy rate has reached 97.3% from 95.8%.

Secondly, this article optimizes the parameters of the three sub-networks on the basis of the

original network: For the P-Net network, a convolutional layer with a 3×3 convolution kernel

is added; For the R-Net network, the fully connected layer is replaced with mean pooling, and

the convolutional kernel of the last layer is changed from 128 to 196; For the O-Net network,

change the parameters of the first, second, and fourth convolutional layers, and set the size of

the maximum pooling layer to 2×2. After optimization, the accuracy of the MTCNN network

has increased from 97.3% to 98.92%, an increase of 1.62%. After obtaining the face candidate

iii

frame, this paper selects the 300-W face database to train the cascade regression algorithm

ERT, finally, the 68 key points of the face are accurately positioned.

(2) Face tracking. This paper designs a face tracking algorithm based on the

combination of DSST and TLD, Because DSST lacks a detection mechanism for tracking

failure cases, TLD is susceptible to external factors such as light. These two methods can

complement each other, so this article merges two face tracking algorithms: Replace the

tracking module in the TLD with DSST and a tracking failure detection method suitable for

this algorithm, and add the HOG feature to the detection module of the TLD algorithm.

Through experiments, various facial postures of the driver with naked eyes, glasses and partial

occlusion are simulated, experiment with the MTCNN network and the face tracking

algorithm of DSST+TLD. The results show that in these complex environments, the algorithm

designed in this paper shows excellent performance.

(3) Fatigue feature extraction. After obtaining the position of the facial feature points,

analyze the three features of the driver's eyes, mouth, and head posture. Aiming at the

extraction of eye features, this article selects the eye aspect ratio EAR algorithm, and its value

is calculated by averaging two eyes. The PERCLOS and blinking frequency are obtained by

this algorithm, we use it as the basis for judging fatigue; For the extraction of mouth features,

the MAR algorithm is used. In view of the different thickness of the lips of each person, this

paper proposes to use the inner contour of the mouth to calculate the MAR value, and yawn as

the basis for judging fatigue; For the head feature extraction, the pitch angle in the Euler

angles in the three-dimensional space is selected to judge the fatigue state. Select 5 people to

simulate the fatigue state, conduct experiments on the above fatigue characteristics, and

obtain the fatigue threshold: P80 is 0.25, EAR is 0.23, MAR is 0.6, and the pitch offset is

20%.

(4) Multi-feature fatigue detection. Due to the low accuracy of most single fatigue

feature extraction at present, this paper designs a multi-feature fatigue detection. First, the

device with a resolution of 1080p HD and a video frame rate of 30fps is used to collect videos

of the awake and fatigue states of 10 experimenters, intercept 5 fatigue and non-fatigue videos

iv

of two minutes each, randomly select 250 groups of samples to train the support vector

machine, and test on the remaining data set, compare different detection algorithms under the

same experimental conditions. Experimental analysis shows that the accuracy of the method

used in this paper can reach 96.42%, which is more feasible for fatigue driving detection.

Finally, use Python language and Tensorflow framework to program the algorithm of this

article to complete the fatigue driving detection system.

Keywords: Fatigue driving, MTCNN, Target tracking, Multi-feature fatigure detection

v

目 录

第一章 绪论...............................................................................................................................1
1.1 课题的研究背景及意义..............................................................................................1

1.2 疲劳驾驶研究方法和现状..........................................................................................3
1.2.1 基于驾驶员生理特征的检测方法...................................................................4
1.2.2 基于机动车行为特征的检测方法...................................................................5
1.2.3 基于驾驶员面部特征的检测方法...................................................................6
1.3 本文的研究内容和方法..............................................................................................7

1.4 本文章节安排..............................................................................................................8

第二章 基本理论与技术基础.................................................................................................11

2.1 深度学习理论............................................................................................................11

2.2 卷积神经网络结构....................................................................................................12
2.2.1 卷积层.............................................................................................................12
2.2.2 池化层.............................................................................................................14
2.2.3 全连接层.........................................................................................................15
2.2.4 激活函数.........................................................................................................16
2.3 卷积神经网络特性....................................................................................................19
2.3.1 局部连接.........................................................................................................19
2.3.2 权值共享.........................................................................................................20
2.4 人脸检测与特征点定位............................................................................................20
2.4.1 人脸检测概述.................................................................................................20
2.4.2 人脸特征点定位.............................................................................................23
2.5 本章小结....................................................................................................................24

第三章 基于改进 MTCNN 网络的人脸检测、跟踪和定位方法........................................ 25

3.1 引言............................................................................................................................25

3.2 基于 MTCNN 网络的人脸检测算法....................................................................... 25
3.2.1 数据与处理.....................................................................................................25
3.2.2 网络结构.........................................................................................................26
3.2.3 损失函数.........................................................................................................29
3.3 实验设计分析与 MTCNN 网络的改进................................................................... 31
3.3.1 数据集.............................................................................................................31
3.3.2 网络训练过程.................................................................................................33
3.3.3 实验结果分析及改进.....................................................................................34

vii

3.4 基于 DSST 与 TLD 相结合的人脸跟踪算法.......................................................... 37
3.4.1 DSST 人脸跟踪算法.......................................................................................37
3.4.2 TLD 人脸跟踪算法......................................................................................... 39
3.4.3 基于 DSST 与 TLD 相结合的人脸跟踪算法............................................... 41

3.5 基于级联回归树 ERT 的特征点定位算法.............................................................. 44
3.5.1 建立模型.........................................................................................................44
3.5.2 模型拟合.........................................................................................................46
3.5.3 训练模型.........................................................................................................47
3.6 本章小结....................................................................................................................47

第四章 疲劳驾驶特征提取.....................................................................................................49

4.1 引言............................................................................................................................49

4.2 基于 EAR 算法的眼部疲劳特征提取......................................................................49
4.2.1 PERCLOS 准则............................................................................................... 50
4.2.2 眨眼频率.........................................................................................................51
4.3 基于嘴巴内轮廓的嘴部疲劳特征提取....................................................................52

4.4 基于欧拉角的头部疲劳特征提取............................................................................53
4.4.1 欧拉角.............................................................................................................53
4.4.2 相机标定及其实现.........................................................................................54
4.5 实验及结果分析........................................................................................................57

4.6 本章小结....................................................................................................................60

第五章 多特征疲劳驾驶检测.................................................................................................61

5.1 相关算法....................................................................................................................61
5.1.1 理论基础及推导公式.....................................................................................61
5.1.2 松弛变量和惩罚因子.....................................................................................63
5.1.3 核函数.............................................................................................................64

5.2 多特征疲劳驾驶检测算法........................................................................................65
5.2.1 疲劳驾驶检测算法设计.................................................................................65
5.2.2 实验及结果分析.............................................................................................66
5.3 疲劳驾驶检测系统的实现........................................................................................68
5.3.1 开发环境.........................................................................................................68
5.3.2 工作流程.........................................................................................................69
5.4 实验平台工作页面....................................................................................................70

5.5 本章小结....................................................................................................................71

viii

第六章 总结与展望.................................................................................................................73
6.1 总结............................................................................................................................73
6.2 展望............................................................................................................................74

参考文献...................................................................................................................................75

攻读学位期间取得的研究成果...............................................................................................81

致谢...........................................................................................................................................83

ix

第一章 绪论

第一章 绪论

1.1 课题的研究背景及意义

随着科技的持续进步，人民的生活水平质量也在不断提升，更多的市民开始将私家

车作为他们的代步工具，因此其保有量和驾驶人的数量也在不断增加。在《2021-2027

年中国交通事故现场勘查救援设备行业市场运行格局及战略咨询研究报告》这篇报告

中，相关数据显示：2020 年中国汽车保有量达 2.81 亿辆，较 2019 年增加了 0.19 亿辆，

同比增长 7.50%，而中国汽车驾驶人数量达 4.56 亿人，较 2019 年增加了 0.34 亿人，同

比增长 8.10%，具体数据如图 1.1 和 1.2 所示。汽车给我们带来了诸多便利，但与此同

时也导致了道路交通安全事故的发生，安全问题成为人们关注的重点话题。在中国，由

交通事故导致的死亡人数已经接连 10 年排于世界的第 1 位，造成交通事故的客观因素

有路况环境以及糟糕的极端天气等，而其主观因素则是因驾驶员的驾驶行为和精神状态

不佳等引起的，主要有疲劳驾驶、超速驾驶、酒后驾驶等等，其中疲劳驾驶在经济损失

以及人员伤亡等方面所占的比例最高，而美国有一个调查显示，高达 28%的重卡司机在

驾驶期间有过打盹或者睡眠行为。

图 1.1

2014-2020 年中国机动车及汽车保有量

1

长安大学硕士学位论文

图 1.2

2016-2020 年机动车驾驶人及新领证人数

疲劳驾驶是指在长时间的驾车过程中，驾驶员因连续驾车或缺乏睡眠而呈现出精神

疲惫的状态，使得生理及心理相关机能失去平衡，致使其不能正常驾车或驾车能力下降。

疲劳驾驶时，驾驶员通常会有如下反应：记忆力、决策力下降，不能及时礼让行人，遗

忘交通规则，忽视指示牌和信号灯，无法对路况做出适当的应急措施。这一系列行为可

能导致交通事故的发生。根据相关统计显示，在我国疲劳驾驶引发的交通事故数目占到

了总量的 20%，而占特大交通事故数目的比例已经达到了 40%以上，每年有 9 万余人致

死或重伤，在高速公路上，20%的事故也是因疲劳驾驶所致。综上所述，疲劳驾驶已经

给我们的生活带来了巨大的隐患，《中华人民共和国道路交通安全法实施条例》中的第

62 条第 7 款作出了相关约束，即司机不得“持续驾驶机动车超过 4h 而未停车休息或者

休息的时间低于 20min”。此规定虽然能够适当性地减少交通事故的发生，但导致疲劳

驾驶的原因有很多，主要有以下几个方面：（1）驾驶员身体状况不佳，比如感冒等症

状喝药导致产生困意；（2）驾驶员在开车前就未能得到充分的休息，使得在驾驶过程

中精神不佳；（3）夜间行驶时，受生活作息规律影响，容易进入疲惫状态；（4）在高

速公路上，因道路畅通，障碍少，行驶速度快，致使驾驶员注意力不集中等。每个驾驶

员的心理、身体素质各不相同，而疲劳驾驶的规定时间是 4 个小时，这就使得单单依据

驾驶员的驾驶时间自觉性并不能做到预防事故的发生。

2

第一章 绪论

由以上分析可知，研究驾驶员在行车过程中的疲劳状况，开发出一套实时的检测系

统，有特别重要的价值。若能检测到驾驶员的疲劳状态并给出提醒，就能够在一定意义

上降低疲劳驾驶导致的交通事故率，这对于保障人民的生命安全有重大的意义，也比较

符合当代生活中汽车智能化和安全化的发展理念。因此，在不影响驾驶员正常驾驶的前

提下，怎样能够准确高效地检测出驾驶员的疲劳驾驶状态，是防止疲劳驾驶的重大任务。

1.2 疲劳驾驶研究方法和现状

疲劳驾驶严重威胁着人们的财产和生命安全，其检测也一直是国内外相关研究人员

的热点。近年来，专家从多种角度出发，对疲劳驾驶进行了相关研究，主要有以下几个

方面：最开始从医学的角度对疲劳状态的产生规律和如何预防进行了理论分析及实验研

究；在改善道路交通环境上，以对路况和交通辅助设施的合理优化来预防疲劳驾驶；在

人机工程设计上，也对通过改善驾驶环境来预防疲劳驾驶进行了相关研究，这些研究为

检测驾驶员疲劳状态提供了设计思路以及理论上的依据。计算机行业的快速发展，带动

了计算机视觉、深度学习等领域的迅速崛起，国内外研究人员把计算机视觉应用到了此

领域，取得了卓越成果，也因此使得疲劳驾驶检测技术更加进步。根据研究方式，我们

把疲劳驾驶检测方法大致划分成以下两类：主观检测法、客观检测法。

主观检测法顾名思义，就是询问驾驶人员对自我睡眠的评价，或者通过査询、填写

记录表来对他们是否存在疲劳驾驶状态进行判断，其中最常用的方法有 Stanford 嗜睡量

表、chalder-14 疲劳量表（船舵表）、Borg 疲劳量表，睡眠习惯调查表以及卡洛琳斯卡

睡眠尺度表 KSS，这些方法简便常用、方便实施，但是因为其主观性强，个体之间存在

着一定的差异，每个人对疲劳的评判标准并不统一，无法有效对疲劳驾驶进行精准的评

估，且一般用于事后分析，所以不具备实时性，主观检测法一般只作为研究疲劳驾驶的

辅助手段。

客观检测法消除了人的意识对于判断带来的妨碍，使用相机、传感器等相关检测设

备探测驾驶员的生理特征、车辆的行驶轨迹等，通过这些特征判断是否存在疲劳驾驶现

象，它是一种客观且科学的检测方法。目前，国内外研究人员从多个方向开展研究，陆

陆续续推出了一些非常有效的检测方法，取得了不错成果。本文在准确性、实用性和可

拓展性上对客观检测的三种方法作了比较，见表 1.1。

3

长安大学硕士学位论文

表 1.1 不同模型预测结果分析

客观法

检测技术描述

准确性

实用性 可拓展性

驾驶员生理特征

很好

很差

一般

检测司机的生理信号，如心电

图、血压、肌电等

检测机动车的行驶状态，如驾驶

机动车行为特征

一般

好

很好

方向、驾驶速度等

检测人脸特征，如嘴部、眼部、

驾驶员面部特征

很好

很好

很好

头部等

1.2.1 基于驾驶员生理特征的检测方法

在早先的驾驶员疲劳检测研究中，研究人员主要通过运用生物学相关知识分析疲劳

驾驶状态。驾驶员产生疲劳时，生理状态参数会发生明显变化，驾驶员通过佩戴可以采

集到其心电、眼电、肌电、脑电和呼吸频率等信息的传感器设备，对获得的数据进行分

析，当处于疲劳状态时，驾驶员的各种生理参数会与正常状态下的参数存在差异，以此

来判断是否属于疲劳驾驶，该方法是接触式的检测方法。

（1）基于脑电信号的检测

相关研究表明，人的脑电信号可以在某种程度上明显表现出人体的疲劳程度，在疲

劳加深的过程中，脑电信号的θ波和δ波的能量会提升，而α波和β波的能量会降低[1]。王

爱芹等人通过观察脑电图（EEG）的变化，实现了由脑电信号采集模块、报警模块、模

拟驾驶模块、控制中心模块以及实时驾驶模块五部分组成的疲劳驾驶检测系统，实验表

明，相较于主观检测法，此系统的疲劳驾驶检测准确率较高[2]。在 2010 年，Sibsambh u

Kar 等学者采用 32 导联采集装置，并选用 8 导联采用 Fp1、Fp2、F3、F4、Fz、Cz、O1、

O2 通道采集 EEG 信号，提出了利用 5 类熵来判别疲劳驾驶状态，它们分别是 2 阶雷尼

熵、3 阶雷尼熵、小波熵、广义 Tsallis 熵以及香农熵，结果显示这五种熵也能够反映出

人脑的疲劳程度[3]。2014 年，东北大学的王福旺采用 Emotive 便携式脑电采集装置，使

用二导联采用 F7 和 F8 通道采集脑电信号，通过小波包转化的方式提取出α波，然后求

得相对功率谱，结果证明通过采集脑电信号的方式可以判断出驾驶员在驾驶过程中的疲

劳状态变化[4]。脑电信号与其他生理信号对比，其优点在于可以更准确、直接地反映出

4

第一章 绪论

驾驶员大脑本身的状态。

（2）基于心电信号的检测

心电图（ECG）也是一种非常重要的生理信号，它是采用心电仪器来记录心脏每一

心跳周期所产生的微弱电流规律性变化的图形，可以通过检测心率的变化反映出司机的

身体状况。一般而言，心率（HR）以及心率变异性（HRV）是表征疲劳的心电指标。

Calcagnini 等人发现，通过 ECG 信号的相关特性，比如低频、超低频、高频还有低频

与高频能量的比值，能够判断驾驶员是否处于疲劳驾驶状态[5]。杨渝书、李增勇等人模

拟驾驶员疲劳驾驶，通过采集人的心电信号来研究驾驶员的心电在时域和频域上的数据

变化规律，实验结果显示：在心率变异性中，随着行驶时间的不断增加，其标准差（SD）、

心电低频功率（LF）以及 RR 间期呈正相关的关系，相反地，高频功率（HF）呈负相关，

高频与低频功率比明显增大[6]。Jung Sj 等人将具有嵌入式特点的心电传感器置于驾驶员

车辆的方向盘上，利用心电传感器获取驾驶员的心电信号，通过心率变异性的时域和频

域变化结果反映出较高的精确率[7]。ECG 检测容易操作、快捷方便，但其灵敏度低、误

差大。

（3）基于其他信号的检测

还有诸如肌电图（EMG）和眼电图（EOG）等生理信号的检测方法。肌电图是检测

肌肉的活动状况，而眼电图则是利用眼电仪器来检测眼睛静电位。Katsis 等人将电极放

置在驾驶员的身体部位，通过与肌肉接触的方式测量其肌电信号，然后把测得的肌电信

号发送至肌电图的记录仪上，研究结果显示：当驾驶员处于疲劳驾驶状态且随着疲劳的

不断增加，肌电图的频率会越来越低，相反地，肌电图的幅值会越来越高[8]。Mieko 等

人分析驾驶员的眼电图，并对其峰尖的上升与下降时间以及幅值作了相关实验，得到了

不同驾驶状态下的眼电波形图，通过波形图来判断驾驶员的疲劳程度[9]。

这些方法虽然有诸多理论支撑，且检测度高，但是需要驾驶人员随身佩戴相关的测

试仪器，所以基于驾驶员生理特征的检测方法在现实生活中应用不广泛。

1.2.2 基于机动车行为特征的检测方法

基于机动车行为特征的检测是一种非直接的疲劳驾驶检测方法，主要依据是判别人

对机动车的操控行为。相较于正常状态，疲劳驾驶时人对车辆的操作会发生相应的改变，

5

长安大学硕士学位论文

比如驾驶方向、驾驶速度、短时加速度、驾驶路线、方向盘角度、车身的横向偏移距离

等，因此可以通过车辆的传感器来获取这类参数，分析这些变化特征并判断驾驶员是否

处于疲劳状态。

美国的 I-teris 公司研发出了一套 AutoVue 系统，将摄像头安置在车辆面对公路的位

置上，当检测到车辆偏离正常车道时，会提示驾驶员并发起警告[10]。Sandberg 等人选择

基于前馈神经网络（feedforward neural network，FFNN）的方法划分疲劳所获得的数据，

其中包括机动车速度、方向盘转动角度、机动车横向位置和空气的动力角等，通过这些

数据判断驾驶员的驾驶状态[11]。B cheng 等人在机动车内部安装了车载摄像头，通过摄

像头采集了驾驶员驾驶过程中车道和车辆之间的相对距离，利用车道轨迹判断其驾驶状

态[12]。MS Wang 等人采用基于随机森林的算法，通过把不同时间点的机动车纵向加速

度、横向加速度以及车辆方向盘转动相结合，对这些参数进行分析对比，得出检测疲劳

驾驶状态的最佳指标是车辆的侧向加速度[13]。

相较于基于生理信号的检测，这种方法不与驾驶员产生身体上的直接接触，不会影

响驾驶员的驾驶行为，且获取参数的传感器设备很容易部署。但这类方法容易受到诸如

天气、路况、车辆类型、驾驶环境等客观因素的影响，因此会对检测结果造成干扰，鲁

棒性较低。

1.2.3 基于驾驶员面部特征的检测方法

对于驾驶员而言，在从正常驾驶到疲劳的过渡过程中，一般都会出现一些诸如眨眼

频率增加、频繁点头、打哈欠等现象，这些症状可以反映出一个人的驾驶状态。而基于

面部特征的检测方法，就是利用摄像头来获取司机面部的相关视觉信息，然后结合图像

处理和计算机视觉等技术，对他们的眼睛、嘴巴以及头部状态进行分析处理，继而判断

其疲劳状态。

针对一些大型车辆比如公交车、货车等，Mandal 等人研发出一套由人脸检测、头

部检测、眼睛检测、PERCLOS 准则以及疲劳等级划分等模块构成的疲劳驾驶检测系统，

其中，针对眼睛检测，提出了基于谱回归的方法判断其开合度，在眼睛状态检测上采用

基于自适应的积分模型，该系统对于驾驶员面部倾斜等难点问题作了相关处理，结果表

明其鲁棒性好且准确率高[14]。周云鹏等人设计了一种多特征的疲劳检测技术，在人脸检

6

第一章 绪论

测上选择具有 harr 特征的 Adaboost 算法，在眼部提取上选择 Gabor 滤波器进行边缘检

测并利用 LBP 算法获取眼部特征，通过 SVM 分类眼睛状态，在嘴部提取上使用图像二

值化以及嘴巴纵横比获取嘴部特征，并对驾驶员面部表情进行分类，融合以上三种特征

获取驾驶员的疲劳程度[15]。邹昕彤等人对驾驶员佩戴眼镜的情况进行了分析并提出了针

对这类问题的检测方法，同样也是利用 Adaboost 的人脸检测算法，在佩戴眼镜上设计

了垂直积分投影法，最后利用灰度直方图以及 PERCLOS 准则对眼部疲劳特征进行提取

进而判断疲劳状态[16]。Dong 等人使用方向梯度直方图（HOG）来提取眼部区域，在眼

睛的睁开闭合状态上选用了随机森林算法，最后实现了驾驶员疲劳驾驶检测预警[17]。

Vicente 等人对驾驶员的头部进行三维建模，将驾驶员的面部分为 18 个区域，利用驾驶

员的脸部定点位置获取头部姿态变化角度，并通过这些区域对眼睛的瞳孔以及眼睑位置

的距离进行计算[18]。沈英超等人在人脸检测与定位上选用 MTCNN 网络，在眼部区域获

取上设计了基于多任务学习的人眼定位网络，通过改进的 LeNet-5 模型对驾驶员的疲劳

驾驶状态进行判断[19]。

与前面两种疲劳检测方法相比，此类方法具有检测精度高、不接触、不干扰等优点，

且近年来计算机的迅速发展也使得机器学习、深度学习、计算机视觉等技术取得了很大

的突破，因此这种检测方法也成为了目前应用最为广泛的一种。

1.3 本文的研究内容和方法

综合目前国内外的疲劳驾驶研究现状，本文选择基于面部特征的驾驶员疲劳检测方

法，主要的研究内容如下：

（1）人脸检测和特征点定位。对目前存在的人脸检测和特征点定位方法进行分析阐

述后，本文采用基于深度学习的人脸检测方法，选择 WIDER FACE 和 CelebA 两种数据

集训练多任务卷积神经网络 MTCNN 完成驾驶员面部检测及特征点粗定位，并在原有网

络基础上，对 3 个子网络的参数进行了优化。获得人脸候选框和 5 个特征点位置后，选

择 300-W 人脸数据库训练 ERT 算法完成驾驶员面部 68 个特征点的精确定位。

（2）在面部跟踪上，采用基于 DSST 和 TLD 相结合的人脸跟踪算法。首先介绍了

DSST 和 TLD 目标跟踪算法，其次分析了两种算法的优缺点，由于 DSST 缺少跟踪失败

的检测机制，TLD 容易受到光照等因素的影响，而这两种算法具有互补的作用，所以本

7

长安大学硕士学位论文

文将两种人脸跟踪算法结合到了一起，并对驾驶员在复杂环境下的驾驶状态进行模拟实

验。在 MTCNN 算法检测到驾驶员面部之后，利用 DSST+TLD 的目标跟踪算法实现面

部的实时稳定跟踪。

（3）疲劳特征提取。目前存在的疲劳驾驶检测研究大多都是基于单一特征的提取

方法，本文在获得人脸特征点定位后，对驾驶员的眼部、嘴部以及头部姿态这三种特征

分别进行分析。在眼睛疲劳特征提取上，本文采用 EAR 算法，且通过两只眼睛求平均

值的方法来实现，选择 PERCLOS 准则和眨眼频率来判断疲劳状态；在嘴部疲劳特征提

取上，本文采用与之类似的 MAR 算法，提出通过嘴巴内轮廓的开合度来计算 MAR，

选择打哈欠来判别疲劳状态；在头部疲劳特征提取上，本文选择欧拉角中的俯仰角 Pitch

来判断疲劳状态。

（4）多特征疲劳检测。本文采集了 10 个人的视频数据集训练支持向量机，在得到

疲劳驾驶分类模型后，在数据集上进行测试，检测准确率达到 96.42%。

（5）通过 Python 语言编程实现疲劳驾驶检测系统，验证算法的可行性。

1.4 本文章节安排

本论文总计六章，下面简要介绍这六章的内容。

第一章：绪论。本章主要介绍了课题的研究背景和意义，对目前国内外存在的疲劳

驾驶检测方法进行阐述分析。通过分析各种疲劳驾驶研究方法的优缺点，选择基于驾驶

员面部特征的疲劳驾驶检测作为本文的研究方法，并对研究内容及章节安排作了简单介

绍。

第二章：基本理论与技术基础。本章主要介绍了深度学习的理论知识，卷积神经网

络的结构及其特性，还有目前主要的人脸检测与特征点定位方法。

第三章：人脸检测、跟踪和定位算法。本章主要研究基于 MTCNN 的人脸检测算法，

对 MTCNN 数据的处理、网络结构、损失函数及其训练作了详细的介绍，并对 MTCNN

网络进行了改进。然后提出了基于 DSST 和 TLD 相结合的面部跟踪算法，分别对 DSST

算法和 TLD 算法的原理和优缺点作了描述，利用此目标跟踪算法实现对面部的稳定跟

踪。最后提出了基于级联回归树的特征点定位算法，对于其模型建立、模型拟合、模型

训练作了详细阐明。

8

第一章 绪论

第四章：疲劳驾驶特征提取。本章主要介绍了基于驾驶员眼部、嘴部以及头部的驾

相关疲劳特征提取，并对实验结果进行分析。

第五章：多特征疲劳驾驶检测。本章主要介绍了 SVM 相关理论知识并将其应用到

疲劳检测中，对采集到的数据进行分类测试，对比几种疲劳驾驶检测方法且设计疲劳驾

驶检测系统进而得出本文方法的可行性。

第六章：对本文的主要研究内容进行了总结，并提出不足之处以及对未来的展望。

9

第二章 基本理论与技术基础

第二章 基本理论与技术基础

2.1 深度学习理论

作为机器学习领域的一部分，近年来深度学习取得了巨大突破。建立一个模型来模

拟人的大脑神经连接结构，使机器能够跟人一样，对语音、文本、图像等进行分析处理

并学习是深度学习的目的所在。在计算单元和样本数量上，浅层学习并不多，这就使得

复杂函数的表达能力产生了一定的局限性，在某种程度上导致对于一些分类问题的泛化

能力大大降低。而深度学习的本质就是使用大量的数据，构造多隐层的人工神经网络，

通过训练后把原始信号逐层特征转换，然后将样本的特征表示映射到新的特征空间上

来，进行无监督学习，最后获得层次化特征表达。

2006 年，Hinton 教授在《science》上发表了一篇介绍深度学习的理论的文章，突破

了传统的机器学习。2010 年起，深度学习开始得到了纽约、斯坦福大学的资助并重视起

来。2011 年时，在语音识别方面，深度学习也取得了很大的进步。2013 年，百度首席

执行官李彦宏建立了百度研究院，将深度学习作为首个重点研究对象。而在 2017 年，

AlphaGo Zero（AlphaGo 升级版）横空出现在世人面前，于是人们把这一年视为深度学

习甚至于人工智能发展最为一鸣惊人的一年。

图 2.1 传统机器学习与深度学习算法流程对比

深度学习算法是一种复杂的机器学习算法，它与传统机器学习在流程上的差异如图

2.1 所示，不同之处在于：（1）注重无监督学习；（2）机器模型结构一般有 5 层且包

括多层节点。相较于传统机器学习，深度学习算法的本质区别在于它是从大数据中自动

11

长安大学硕士学位论文

地学习特征，不需要人工设计，所以深度学习算法的表达能力更好。典型的深度学习模

型有堆栈自编码网络(AE)、卷积神经网络(CNN)、深度置信网络（DBN）和递归神经网

络（RNN）等,本文采用的是 CNN 模型。

2.2 卷积神经网络结构

当下应用最普遍的深度学习模型就是卷积神经网络，其计算速度之快、参数之少使

得在训练的过程中不会因为参数问题而产生过拟合现象。卷积神经网络的结构如图 2.2

所示，主要由卷积层、池化层、全连接层和激活函数四部分组成。

2.2.1 卷积层

图 2.2 卷积神经网络结构

卷积层（Convolutional Layer）是卷积神经网络中至关重要的一层，其作用是获取

图像特征，准备后续识别工作。与传统全连接的神经网络层不同，因为卷积层具有权值

共享机制和局部感受野的网络特点（下一节会介绍到），这就使得卷积运算的计算量大

大缩减。它实际上就是利用两个大小不同的矩阵作的一种数学运算，我们以二维卷积核

为例[20]，计算公式如下式（2.1）：

l


1


i

,



j

Z

l



[

Z



w

l


1

),](
j
i


b

l

K

f

f



k


1

x


1

y


1

l

[

(
isZ
0

K



,
jsx
0




1
l
)
yxwy
k

,(

)]



b


i
,...1,0{),(

j

L
l

},

L
l


1


1



L
l



2
s

p



f



1

0

(2.1)

其中， 1lZ 是特征图，即第 1l 层的卷积输入以及输出， 

j

iZ , 表示的是特征图的像素，

1lL 是 1lZ 的尺寸，假设特征图长和宽相等，b 为偏差，通道数量用 K 来表示， f 为卷

积核大小， 0s 是卷积步长， p 为填充层数[21]。

12

第二章 基本理论与技术基础

如图 2.3 所示，假设输入图像为 5×5 大小的矩阵，卷积核大小为 3×3，卷积步长是

1，也就是说，在完成每个卷积操作之后，卷积核将向右移动 1 个像素位置。卷积运算

一共有三个步骤：

1

0

1

0

1

0

0

0

1

2

0

3

2

1

0

1

3

1

0

0

2

1

0

2

1

3

2

0

0

1

2

0

1

1

（a）卷积核

（b）输入数据

图 2.3 卷积核和输入数据

（1）求点积：如图 2.4 所示，将卷积核 3×3 矩阵中的每个元素（红色数字）与其

在输入数据 5×5 矩阵中的 3×3 灰色区域的对应像素相乘，然后累加，3×3 输出矩阵的第

一个元素也就是该值。

2×1

0×0

0×0

0×0

1×1

2×0

3×1

3×0

1×1

2

1

1

0

0

2

1

3

2

0

0

1

2

0

1

1

7

图 2.4 第一次卷积操作结果

（2）滑动窗口：如图 2.5 所示，将卷积核向右移动一格，即第二次卷积操作。

7

7

2

0

3

2

1

0×1

0×0

1×0

1×0

2×1

3×0

3×1

1×0

2×1

1

0

0

2

0

0

1

2

0

1

1

13

长安大学硕士学位论文

图 2.5 第二次卷积操作结果

（3）重复（1）和（2）的“求点积和滑动窗口”操作，直到我们计算出输出矩阵

的所有值，如图 2.6 所示。

2

0

3

2

1

0

1

3

1

0

0

2

1

3

1

2

1×1

2×0

0×0

0×0

0×1

1×0

2×1

0×0

1×1

7

5

7

7

3

3

4

5

4

图 2.6 第九次卷积操作结果

2.2.2 池化层

在卷积神经网络结构中，卷积层进行特征提取后，紧随其后会有一个池化层（Pooling

Layer），也被叫做下采样层。一幅图像中可能包含很多信息，但有些是冗余的，池化

层的作用就是保留特征不变性与此同时降低每组特征映射的特征维数，这样就可以减少

参数和计算量，同时对过拟合现象有较好的缓解作用，并且提高模型的泛化能力。与卷

积操作类似，池化层也需要卷积核与上一层的特征映射组进行卷积操作，以获得当前组

相对应的特征映射组。不过池化层的卷积核是通过最基本的最大值或平均值来计算的，

而不是相应位置的加权和，它的卷积核是固定的，一般是每个参数值都为 2 的大小是 2×2

的卷积核。

卷积神经网络 CNN 中最常用的池化方法有两种，它们分别是均值池化以及最大值

池化。均值池化的意思是对池化范围中的所有像素点求平均值，该方法通常用来提取背

景信息。而最大值池化即对池化范围中的所有像素点求最大值，该方法通常用来提取纹

理信息。计算公式如下式（2.2）：







pool

max



max(

Ri

a
i

)

pool

avg



1
R

|




Ri

|

a
i

（2.2）

其中，卷积核中的参数个数用 R 来表示， ia 代表的是在每组特征映射里，对应于卷积核

14

第二章 基本理论与技术基础

的相同大小窗户内的特征值。假设原始的图像尺寸是 4×4，卷积核尺寸为 2×2，窗口滑

动步长是 2，如图 2.7 所示为最大池化和均值池化的操作过程：

2

5

1

4

4

1

3

5

5

3

4

7

8

4

2

1

最大池化

均值池化

5

5

8

7

3

5

3.25

3.5

图 2.7 最大池化和均值池化操作

2.2.3 全连接层

卷积神经网络 CNN 的隐藏层之后，通常会有一个全连接层（Fully Connected Layer），

其承接了神经元的连接，也就是说上一层网络中全部的神经元都跟下一层中的神经元互

相连接，如图 2.8 所示为全连接层的示意图。对于 CNN 来说，全连接层扮演着“分类

器”的角色，也就是说通过 CNN 的卷积层、池化层以及激活函数等结构，全连接层把

学习到的特征表示映射到样本的标记空间，紧接着利用损失函数去操控学习过程，最终

在输出层得到对象的分类预测结果。

全连接层的运算公式如下式（2.3）：

图 2.8 全连接层示意图

15

长安大学硕士学位论文


T
bxWf



(

y



）

（2.3）

其中，x 表示输入向量，y 表示输出激活向量，W 为层间各单元之间连接权重的矩阵，b

为偏置项。

由上式可知，全连接层对提取的特征进行了非线性运算，因此它没有提取特征的性

能。全连接层通常位于 CNN 的尾部，但是因为它的参数数量相对较多，使得其在总模

型中的占有量也很高，进而更容易产生网络的过拟合现象，且网络的泛化能力也有所降

低。因此，在某些 CNN 网络中，选择用全局均值池化代替全连接层的作用[22]。

2.2.4 激活函数

在卷积神经网络中，利用卷积层对输入进行卷积运算后，我们还需要引入非线性函

数作为激活函数（Activation Function），激活函数层也被称作非线性映射层，它可以通

过激活函数表示输入输出间非线性的任意函数映射，进而在稀疏特征线性可分上获得更

大的可能性。多个线性操作层叠加仅仅可以充当简单的线性映射效果，而通过激活函数

能够提高非线性，也就是网络的表达能力，进而更好地完成识别分类任务，也能够更好

地解决复杂性问题。

一般地，激活函数所必备的条件是：非线性（拟合复杂学习任务）、单调性（凸函

数，收敛到最优解）、连续可微性（网络参数基于梯度更新）。常见的激活函数有 Sigmoid、

tanh 以及 ReLu 函数等[23]。

（1）Sigmoid 函数

Sigmoid 函数又被叫做 Logistic 函数，其表达式如下（2.4）：

对应的导数表达式为：

)(
xF



1

xe

1

'
xF
)(





e

e

1(

x



x

2

)

（2.4）

（2.5）

其曲线图如图 2.9 所示，由图可知，Sigmoid 函数可以将输入值变换成（0，1)之间

的输出值，如果是非常大的正树，输出为 1；相反地，如果是非常大的负数，输出则为

0，所以此激活函数常用在二分类神经网络中。但是，当输入值小于-5 或者大于 5 时，

16

第二章 基本理论与技术基础

输出就会到达饱和状态，而此时导数无限接近于 0，这就导致梯度弥散现象，使得训练

不收敛，进而训练效果差。Sigmoid 激活函数的反函数以及一阶导数比较简单，所以也

得到了广泛的应用，它一般适用于输入图像的相关特征差别不大的情况。

图 2.9 Sigmoid 函数示意图

（2）Tanh 函数

双曲正切函数 Tanh 函数的表达式为：

xF

)(

x

x

e
e



x



x




e
e

对应的导数表达式为：

'
xF
)(



sinh
cosh

x
x


1





x

x

e
e



x



x




e
e

2





其曲线图如图 2.10 所示：

（2.6）

（2.7）

图 2.10 Tanh 函数示意图

17

长安大学硕士学位论文

Tanh 函数能够用 sinh 函数和 cosh 函数表示，如公式 2.7 所示，它与 Sigmoid 函数

的形式相似，但不同的是，它的输出结果区间在（-1，1）之间，函数以 0 为中心，均

值也是 0，其收敛速度更迅速，因此对输出有更好的控制。而 tanh 函数的导数取值位于

（0，1）区间，优于 sigmoid 函数的（0，1/4），在某种意义上减少了梯度弥散现象。

在一些应用中 tanh 函数的性能优于 sigmoid 函数，tanh 函数一般适用于输入图像的相关

特征差异比较明显的情况。

（2）ReLu 函数

ReLu 函数的表达式如下（2.8）：

xF
)(







x

0

x

x





0

0

)('
xF




1

0


x

x





0

0

对应的导数表达式为：

其图像如 2.11 所示：

（2.8）

（2.9）

图 2.11 ReLu 函数示意图

由上图很容易看出 ReLu 函数的优点，即当输入为正数时，其一阶导数为 1，反之

为 0，所以在输入值大于 0 的时候，它有效防止了神经网络在训练过程中出现的梯度饱

和问题，但是在输入为负的情况下，ReLu 函数将输出简单置 0，会导致部分输入对应的

特征丢失掉，进而使得神经元“死亡”。在随机梯度下降的收敛速度上，ReLU 函数要

比 Sigmoid 函数快大约 6 倍[24]，所以在激活函数中，此函数也是现如今应用最广泛的。

18

第二章 基本理论与技术基础

2.3 卷积神经网络特性

相 较 于 传 统 神 经 网 络 ， CNN 具 有 局 部 连 接 （ Local Connectivity ） 和 权 值 共 享

（Parameter Sharing）两大核心思想，这两个特性的关键作用在于优化网络结构，减少

网络训练过程中的参数数量，使其运算变得更加简洁高效，下面对这两种特性分别进行

介绍。

2.3.1 局部连接

局部连接也被叫作稀疏连接，其定义是卷积层的节点只跟上一层的一部分节点连接

起来，形成局部感受野，局部连接的作用是对局部特征进行学习。动物视觉的皮层成分

是局部感知的想法来源，它是指动物在感知外界物质时，它们的神经元只有某一部分在

起作用[25]。基于机器视觉的图像处理也可采用局部相关性理论，因为在机器视觉领域中，

像素在某个图像范围内的相关性与其距离呈正相关，即像素与像素间距离差距比较大时

相关性弱，而距离差距小时相关性则比较强。局部连接通过部分神经元来获取图像信息，

然后将所有信息综合在一起达到增强图像信息的目的。在局部连接结构中，每个神经元

只与其连接的神经元互相作用，所以参数数量较少，进而训练之后的网络模型变小，降

低了训练难度，提高了学习速度，在某种程度上减少了过拟合的现象。如图 2.12 所示为

卷积神经网络在全连接和局部连接下的相连方式，其中图（a）为全连接，图（b）为局

部连接。

（a）全连接

（b）局部连接

图 2.12 全连接和局部连接示意图

我们以一张具有 1000×1000 个像素点的输入图像为例，隐藏层中神经元的个数是

1000000 个，如果选择全连接网络，就会有 1000×1000×1000000=1012 个权值，这是一个

19

长安大学硕士学位论文

相当巨大的数量级，此时网络的训练时间变长，收敛困难。而如果选择局部连接的方式，

过滤器尺寸设置为 10×10，则需要 10×10×1000000=108 个权值，与全连接方式相比，局

部连接缩减了 104 倍，网络泛化能力大大提高。

2.3.2 权值共享

权值共享最开始由 LeNet5 模型提出来，也被称为参数共享。传统神经网络结构输

入输出交互采用的是全连接、通过矩阵乘法实现的，参数数量的巨大导致网络很容易产

生过拟合现象，为了降低参数数量，出现了权值共享。卷积核又被称为特征过滤器，是

对图像的角、边、颜色等特征进行特征提取的权值参数，卷积操作面向的是整个图像，

且图像特征分布不均匀，进而在使用卷积核特征提取时，需要反复使用卷积核，在各区

域的卷积中，采用同一滤波器，支持相同的卷积核共享。

在局部连接下的卷积神经网络中，下一隐藏层中的神经元连接的是上层中 10×10 尺

寸的窗口，在进行卷积运算操作时，每个神经元有 100 个相同的参数，它们共享权值，

不一样的滤波器就能够获取不一样的特征图，所以 100 种卷积核就会有 100 种特征图，

由上可知，权值共享的作用可总结为：（1）权值共享的卷积操作确保了每一个像素皆

有一个权系数，而所有的图片共享这些系数，所以在某种程度上缩减了卷积核中的参数

量，网络的复杂度也随之下降；（2）传统的神经网络及机器学习在提取图像特征方面

需要先进行复杂的预处理操作，然后在神经网络中输入获得的特征，而加入卷积操作之

后就能够通过图片空间上的局部相关这一特性将特征自动地提取出来。

2.4 人脸检测与特征点定位

通过驾驶员面部特征判断疲劳驾驶，首要工作是人脸检测和特征点定位，所以人脸

检测与定位算法的好坏直接影响着后续疲劳驾驶检测的准确率。

2.4.1 人脸检测概述

人脸检测就是在给定的输入图像中找出人脸的位置，并用一个矩形框将其表示出

来，它是计算机视觉中最常用的方法之一。一般来说，人脸检测分为以下三个步骤：首

先从图像中选取待检测区域，其次对所选区域提取一些特征来表征此区域，最后把这些

特征输入分类器中，根据特征确定该区域中是否有人脸的存在。目前，主要有 3 类人脸

20

第二章 基本理论与技术基础

检测算法，如图 2.13 所示，它们分别是基于图像特征的方法、基于模板匹配的方法以及

基于统计模型的方法。

（1）基于图像特征的方法

基于图像特征的方法是依据人脸面部特征不变性来实现检测的，无论在何种环境何

种光线下都可以看到人脸和其他的物体。基于图像特征的检测方法有肤色、纹理、轮廓

规则等。①肤色规则：在自然环境中，皮肤颜色是辨别人脸和非人脸的一个明显特点，

它集中在颜色空间中的一个小区域内，所以能够通过此规则有效地将人脸和其他背景颜

色区分开来。这种方法相对简单，但准确率低，可以实现系统对于人脸的粗定位，便于

后面的精细化处理。②纹理规则：纹理是所有事物都具备的属性，纹理的区域性可以映

射局部像素间的相关性，由于人脸的纹理特性跟其他背景不同，所以易于区分。Dai 等

人[26]将纹理特征用空间灰度共生矩阵的参数特征表征，通过一组不等式构造面部纹理特

征模型，这种方法能够用来检测一些分辨率比较低的面部。③轮廓规则：人脸的轮廓以

及面部特征是固定的，每个人的五官只有细微的差别，对人脸进行轮廓提取时，Hough

变换是一种效果比较出色的边缘连接算法。基于图像特征的人脸检测方法简单易实现，

但这种方法容易收到诸如光线、遮挡、噪声等因素的影响，因此检测率相对较低。

（2）基于模板匹配的方法

基于模板匹配的人脸检测方法的核心思想是设定的模板和待检测图像之间存在着

一定的自相关系数，其与固定的阈值之间的大小决定了待检测的图片是否含有人脸图像

[27]。该方法主要分为以下三个步骤：首先以人脸器官为依据构建一个模板，其次将输入

图像与其比较并计算相关值，最后将相关值和与预先设定的阈值作对比进而判断是否存

在人脸。该方法主要有以下两种：①固定模板匹配：将人脸的面部轮廓比例作为不变的

模板，然后设立一个阈值，通过这个模板对输入图像中的人脸逐点式扫描，最后将该模

板与人脸候选区域的相关度计算出来，如果相关度大于设定的阈值，则说明检测到了人

脸，否则为非人脸[28]。此方法容易实现，但易受到模板的尺度和形状等因素影响，所以

存在诸多不足，不利于实际中人脸的检测。②可变模板匹配：设定一个参数可调的模板，

不断调整参数使得损失函数最小化，此时得到的模板即可表示该几何特征[29]。由于只能

依靠人为经验调整参数，且损失函数优化需要大量时间，所以此方法不利于应用到实际

中。

21

长安大学硕士学位论文

（3）基于统计模型的方法

上述所提到的两种方法均需人工参与，但是受面部复杂性等因素的影响，将全部人

脸特征表示出来极具挑战性。而基于统计模型的人脸检测方法主要是利用机器学习或者

深度学习的理念，将人脸检测当成模式识别，通过训练大批人脸及非人脸图像的方法来

构造分类器，判断图像属于哪类模式进而实现人脸的检测，这就避免了人为带来的误差

影响。该方法主要有以下几种：①支持向量机（SVM）：此方法是由 Vapnik 等人提出

来的，在高维模式识别、小型样本以及非线性等方面有很好的处理能力[30]，SVM 关键

在于超平面的有效建立，在最优超平面中正负样本的分隔边界使得最大化,它有效整合

了复杂的模型、较少的样本信息以及较强的学习能力。②Adaboost 算法：此算法是在经

典的 Boosting 算法基础上由 viola[31]等人提出来的，运用了“积分图像”的表示方法来

加快计算速度。它是一种迭代算法，通过训练集来训练不同的弱分类器，接着级联这些

弱分类器，组成一个最终的决策分类器[32]。Adaboost 算法能够消去一些多余的训练数据

特征，将重心放在关键技术上[33]，虽然该方法较于传统检测方法准确率有所提高，但需

要花费的时间成本以及误检率也相对较高。③神经网络：Rowley 等人最先提出了此方

法，其主要思想是针对待检测图片生成图像金字塔，紧接着在上面进行滑动窗口，最终

将获得的图片传送到神经网络中，进而判断是否存在人脸。相较于传统人脸检测算法，

神经网络算法的优点在于它能够自适应地提取特征，这就避免了人工参与，使得复杂的

模式识别能够进行很好的处理。

图 2.13 人脸检测方法

22

第二章 基本理论与技术基础

2.4.2 人脸特征点定位

人脸特征点定位就是在给出的输入人脸图像中，检测出眼睛、嘴巴、鼻子等关键点

坐标，根据方法不同可以定位出 5 个、68 个、甚至 108 个关键点，目前主要分为以下三

类方法，如图 2.14 所示。

（1）基于参数化模型的方法

主动形状模型（ASM）[34]由 Cootes 等人提出，方法原理是选取人脸训练样本，用

一组有序特征点描述物体形状并归一化，利用 PCA（主成分分析法）建立人脸形状模型，

通过建立好的模型进行模板匹配。ASM 算法模型简单，对人脸边缘轮廓有较强的约束，

但其效率低下且鲁棒性差，主要原因是人脸表情、姿态等会导致几何形状发生变化。于

是在 ASM 的基础上提出了主动外观模型（AAM），此方法的主要思想是将纹理及形状

信息结合在一起，通过人脸全部像素点的灰度值来进行关键点的定位，它的运算速度快

于 ASM，检测也更加准确，但是 AAM 的优化难度更大、对人脸关键点的初始化要求高

且定位精度低。

（2）基于回归模型的方法

Dollar 等人于 2010 年提出了级联姿态回归模型（CPR）[35]，它的主要思想是定义初

始预测值，根据回归器一步步迭代估计形状，全部回归器加权组合后得到了最后的输出。

后来 Dollar 在 CPR 的原型上，又提出了鲁棒级联姿态回归模型（RCPR）,RCPR 模型

增加了对于一些遮挡变化问题的处理，避免了在人脸检测过程中遮挡带来的干扰。Cao

等人[36]提出了显式形状回归模型（ESR），此模型可以直接学习向量回归函数进而降低

人脸模型的复杂程度。2014 年，Vahid Kazemi 和 Josephin Sullivan 提出了一种基于回归

树集合的面部特征点定位算法[37]，也就是 ERT 算法，相较于其他回归模型，其运行速

度快，准确率高，所以本文采用了此算法，详细介绍在第三章第四节，所以此处不作过

多阐述。

（3）基于深度学习的方法

2013 年，香港中文大学汤晓鸥教授首次提出了级联卷积神经网络（DCNN）[38]的概

念，并利用 DCNN 网络进行人脸特征点定位，它的主要思想是通过三层子网络对人脸

的 5 个特征点进行检测。在 2014 年和 2016 年，Zhang 等人[39]依次提出了 TCDCN 网络

以及 MTCNN 模型，本文采用的也是基于 MTCNN 模型的方法，详细介绍在第三章第二

23

长安大学硕士学位论文

节，此处将不再讲述。

图 2.14 人脸特征点定位方法

2.5 本章小结

本章主要介绍了深度学习理论相关知识，对比了传统机器学习与深度学习的算法流

程，紧接着介绍了卷积神经网络的结构：卷积层、池化层、全连接层以及激活函数，对

卷积神经网络 CNN 的两大特性：局部连接和权值共享作了详细介绍。且概述了目前的

人脸检测与特征点定位方法，本文最终选择基于 MTCNN 的人脸检测算法和基于 ERT

的特征点定位算法。

24

第三章 基于卷积神经网络的人脸检测和定位方法

第三章 基于改进 MTCNN 网络的人脸检测、跟踪和定位方法

3.1 引言

2006 年深度学习理论被 Geoffrey E.Hinton 教授提出后，其在计算机视觉方面应用也

越来越广泛，而基于驾驶员面部特征的人脸检测以及定位一直以来都是应用于疲劳驾驶

中的重点研究对象。Viola 等人采用 harr + Adaboost 算法来训练不同的弱分类器，然后

级联成最终的决策分类器[40]。Taigman Y 等人在 2014 年提出了 DeepFace，这也是人脸

识别的基石，DeepFace 方法在 LFW（Labeled Faces in the Wild）人脸数据集上的准确率

高达 97.35%[41]。Google 于 2015 年提出了 FaceNet，此算法在 YouTube Faces DB 数据集

中的精确度为 95.12％，而在 LFW 数据集上甚至达到了 99.63%，比 DeepFace 提高了 2.28

个百分点[42]。但是在实际应用过程中，由于受到驾驶员脸部姿态、光照、遮挡等因素的

影响，上述网络模型计算较为复杂且速度较慢，使其具有一定的难度。2016 年，Zhang

等 人 提 出 了 一 种 基 于 级 联 的 多 任 务 学 习 算 法 （ Multi-task Cascaded Convolutional

Networks，MTCNN)[39]，这种方法能够较好地避免以上所提及到的影响，所以本文采用

MTCNN 算法进行人脸检测。

3.2 基于 MTCNN 网络的人脸检测算法

在传统的人脸检测算法中，一般都是先对输入图像进行检测，当检测出人脸时再进

行特征点对齐，进而获取人脸，然而这些方法忽视了人脸检测与特征点定位两者之间的

联系，使得检测时间大大增加。MTCNN 是一个多任务卷积神经网络，它可以同时完成

人脸检测和关键点的粗定位，最终的输出为人脸框以及五个关键点坐标，分别是左右眼、

鼻子以及嘴唇的左右角，该模型的主要任务是人脸检测，而特征点定位在本文中起到了

辅助作用。

3.2.1 数据与处理

由于在人脸检测过程中，人脸的大小不固定，所以我们可以通过构造图像金字塔来

解决目标多尺度问题，即将原始人脸图像进行尺度变换得到不同尺寸的图像，然后按照

从大到小的顺序往上堆叠，组成形似金字塔状，通过这种方法能够更好得检测出不同大

25

长安大学硕士学位论文

小的人脸。图像尺寸主要受两个因素的影响：①minisize（此处设为 40），即图像中需

要识别人脸的最小检测尺寸，其作用是过滤掉人脸得分过低的候选框，minisize 与阶层

呈负相关，即 minisize 的值越小则表示阶层越多；②factor（其取值范围在 0 和 1 之间，

此处设为 0.709），表示生成图像金字塔的缩放系数，其作用是使得阶层变多，进而得

到更加准确的结果，factor 与阶层呈负相关，即 factor 的值越大则阶层越多。下式（3.1）

即为生成金字塔的缩放公式：

isize
其中，dst 表示缩放之后的图片结果， src 表示输入的任意一张原图片，n 表示最后得到

min

dst



src





factor

n 
,
n

,...,1,0{

N

}

（3.1）

12

的全部结果的图片数量。

3.2.2 网络结构

MTCNN 主要包括 P-Net（Proposal Network）网络、R-Net（Refine Network）网络

和 O-Net（Output Network）这三层网结构[43]，它们以一种级联的结构，按照由粗到精

的方式实现人脸检测，整体框架如图 3.1 所示：

图 3.1 MTCNN 网络的整体框架

26

第三章 基于卷积神经网络的人脸检测和定位方法

（1）P-Net 网络

在数据与处理过程中构建图片金字塔获得不同尺寸的图像之后，将其输入到 P-Net

中。如图 3.2 所示，P-Net 网络的输入是一个三通道的、宽高为 12×12 的 RGB 图像，第

1 个卷积层为 10 个 3×3 的卷积核，最大池化尺寸为 2×2，生成了 10 个 5×5 的特征图；

第 2 个卷积层是 16 个 3×3 的卷积核，生成了 16 个 3×3 的特征图；第 3 层采用的是 32

个大小为 3×3 的卷积核，生成了 32 个 1×1 的特征图；最后一层的卷积核为 1×1，实现

人脸分类、人脸候选框回归以及关键点定位这三大任务。

P-Net 由全卷积神经网络构成，由于参数少、网络浅所以这一阶段的运算量也低，

P-Net 网络的工作是获取候选人脸框以及边界框回归向量，通过边界框回归向量校验候

选窗口，将得分低于阈值的滑框去除，最后通过非极大抑制算法（NMS）[44]来合并高重

叠率的人脸候选框。P-Net 网络只是比较粗略地筛选出一些候选人脸框，然后把候选框

尺寸调整成 24×24 送入 R-Net 网络中。

图 3.2 P-Net 网络结构

（2）R-Net 网络

R-Net 网络也是一个卷积网络，其结构与 P-Net 网络大致相同，如图 3.3 所示。R-Net

网络的输入是一个三通道的、宽高为 24×24 的 RGB 图像，第 1 个卷积层为 28 个 3×3

的卷积核，最大池化尺寸为 3×3，生成了 28 个 11×11 的特征图；第 2 个卷积层是 48 个

3×3 的卷积核，第 2 个池化层同样也采用了 3×3 的最大池化，生成了 48 个 4×4 的特征

图；第 3 层采用的是 64 个 2×2 的卷积核，生成了 64 个 3×3 的特征图；全连接层与最后

一层卷积层相连接，进而得到一个 128 维向量，最终完成对人脸的分类、边界框回归以

及关键点定位的任务。

相对于上一阶段，R-Net 网络其实是一个提纯的过程，由于它比 P-Net 网络多了一

27

长安大学硕士学位论文

个全连接层，使得其能够更好地排除掉假正(false-positive)样本，人脸检测精度更高，即

它对 P-Net 所得到的人脸候选框进一步进行筛选，进而剔除掉被误判为人脸的非人脸框。

首先将 P-Net 网络计算出来的人脸候选框从原图上截取出来，调整尺寸大小为 24×24，

输入到 R-Net 之中，然后经过前向传播获得人脸候选框的得分以及边界框回归向量，放

弃人脸得分低于阈值的候选框，通过非极大抑制算法合并剩余人脸候选框，最后根据得

到的边框回归结果反向映射到原始图像的坐标上进而获得人脸框具体位置，R-Net 网络

的最终输出是 P-Net 网络中精筛出来的人脸候选框。

图 3.3 R-Net 网络结构

（3）O-Net 网络

O-Net 网络结构与 R-Net 大致相同，如图 3.4 所示。O-Net 网络的输入是一个三通道

的、宽高为 48×48 的 RGB 图像，第 1 个卷积层为 32 个 3×3 的卷积核，最大池化尺寸

为 3×3，生成了 32 个 23×23 的特征图；第 2 个卷积层是 64 个 3×3 的卷积核，第 2 个池

化层同样也采用了 3×3 的最大池化，生成了 64 个 10×10 的特征图；第 3 层采用的是 64

个 3×3 的卷积核，第 3 个池化层采用 2×2 的最大池化，生成了 128 个 3×3 的特征图；全

连接层与最后一层卷积层相连接得到一个 256 维向量，最终实现人脸的分类、边界框回

归以及关键点定位。

图 3.4 O-Net 网络结构

相较于 R-Net 网络，O-Net 网络是一个稍微繁杂的网络，它比 R-Net 多了 1 个卷积

28

第三章 基于卷积神经网络的人脸检测和定位方法

层，所以其关键点定位结果更准确，性能更佳。该网络对上一网络结果作了进一步的筛

选，将 R-Net 网络输出的人脸候选框从原图中截取出来，调整尺寸增大至 48×48，输入

到 O-Net 网络中，然后经过前向传播获取人脸得分以及边界框回归向量，排除掉得分不

高于阈值的人脸候选框，利用 NMS 去除重合度非常高的候选框，经过合并筛选后，最

终输出的就是我们所需要的人脸框以及五个人脸关键点（左右眼、鼻子和左右嘴角）。

在上述 MTCNN 网络中，卷积核步长为 1，池化步长为 2，在卷积层与全连接层之

后还有激励层，这里激励函数选择 PReLu（Parametric Rectified Liner Unit），表达式如

3.2 所示：

P

Re

Lu







x

ax

x

x





0

0

（3.2）

由表达式可知，当 a = 0 时，PReLu 即 ReLu 函数。a 是可调节参数，当 x≤0 时保

留部分信息。

3.2.3 损失函数

对于 MTCNN 来说，它主要完成三个任务的学习[45]：一是人脸/非人脸分类，二是

边界框回归，三是人脸关键点定位，因此它的损失函数也分为三部分，接下来分别介绍

各部分的损失函数。

（1）人脸分类

人脸分类是一个二分类问题，利用人脸分类器我们可以获得输入图片是人脸图像的

概率输出值，而损失函数越小则代表模型越稳定、抗干扰能力越强。在训练过程中利用

交叉熵来计算训练损失函数，其公式如式（3.3）所示：





det

L
i
det
i

y



(

y

det
i
}1,0{



log(

p
i

)


1(

y

det
i

1)(



log(

p
i

)))

（3.3）

其中， det

iL 表示分类的损失函数， det

iy 表示类别的真实标签（值为 0 是非人脸，值为 1

是人脸）， ip 表示输入图像中存在人脸的概率。

（2）边界框（bounding box）回归

由于在候选框计算过程中，输入的数据是连续量，所以边界框回归被定义成回归问

题，此部分的主要任务是得到候选人脸框的坐标位置（候选框的宽和高以及左上角位置

29

长安大学硕士学位论文

上的横坐标和纵坐标）。在这里使用欧氏距离损失函数（Euclidean）来度量边界框回归

误差，其公式如（3.4）所示：







box
L
i


||


y

box

i



y

box
i

2
2||

y

box
i

4



R

（3.4）

其中， box

iL 表示边界框回归的损失函数， box

iy 是四元组，包括人脸框的宽和高以及左上

角横纵坐标，有箭头的是经过网络输出后校正得出的边界框坐标，而没有箭头的表示的

是真实的边界框坐标。

（3）人脸关键点定位

人脸五个关键点的定位与上面边界框回归相似，皆可归于回归问题，它们都是计算

模型产生的回归值和真实值之间的偏移量，进而确定两者之间的差距，使训练效果更优。

所以人脸特征点定位同样可以采用欧氏距离作为损失函数，公式如下（3-5）所示：







landmark
L
i


||


y

landmark

i



y

landmark
i

2
2||

y

lanmark
i

10



R

(3.5)

其中， landmark

iL

表示人脸特征点定位的损失函数，

landmark

iy

表示通过网络训练后我们得到

的面部特征点坐标， landmark

iy

表示真实的人脸特征点坐标，其中人脸关键点主要包括左眼

和右眼的中心、嘴巴左右角横纵坐标以及鼻子这五个点，是一个十元组。

由于 MTCNN 中每个网络层功能各不相同，在训练过程中存在不同类型的图像，而

他们使用不同的损失函数。因此，为了表示样本是否需要计算某一类损失函数，我们在

这引入一个指示值，所有网络整体的目标函数即多任务损失函数，其公式如下（3.6）所

示：

min






i

j

N

 
i
1

}1,0{


j

(det,

box

,

landmark

)


i
j

j

j
L
i

（3-6）

其中， N 表示训练样本的总个数， j 表示任务的优先级，即子网络占整体损失函数的

权重值， j

i 表示对应的样本标签， j

iL 表示上面 3 个公式中的损失函数。

训练过程中：P-Net 和 R-Net 网络只对人脸检测起作用，而特征点的输出位置在 O-Net

30

第三章 基于卷积神经网络的人脸检测和定位方法

网络中；P-Net 和 R-Net 网络更关注准确度，而 O-Net 网络更注重人脸关键点定位。由

上可知，在 MTCNN 网络中，上面提及到的三部分损失在 P-Net、R-Net 以及 O-Net 网

络的所占权值不同，在 P-Net 和 R-Net 网络中占比 1:0.5:0.5，而在 O-Net 网络中为 1:0.5:1，

三个网络的代价函数参数设置如下表 3.1 所示：

表 3.1 MTCNN 网络训练参数

P-Net

R-Net

O-Net

det

box

landmark

1

0.5

0.5

1

0.5

0.5

1

0.5

1

为了 MTCNN 算法在面部检测上具有更好的性能，在训练过程中，我们将所有样本

的前向传播所计算的损失值采取降序的排序顺序，然后把有效样本定位到前百分之七

十，省去一些对分类器没有改进作用的普通样本，这种方法也被称为在线困难样本挖掘

（Online Hard Example Mining，OHEM），它能够自动地选择样本，进而获得更好的性

能，使人脸分类器地泛化能力大大提高。

3.3 实验设计分析与 MTCNN 网络的改进

3.3.1 数据集

训练 MTCNN 网络时选择 WIDER FACE 和 CelebA 这两种数据集。WIDER FACE[46]

主要用来检测人脸，它是由香港中文大学公开的，截取部分图片如图 3.5 所示，其中有

32203 张图片以及 393703 个人脸图像，里面有 61 个事件在表情、尺寸、姿势、亮度等

方面的复杂变化。

如图 3.6 所示的文件为注解文件，其中第一行是第一张图片的名称，第二行表示该

图片中有一个人脸，第三行是人脸边框定位数据。CelebA（CelebFaces Attributes Dataset）

[47]用于人脸关键点的定位，它是一个开源的大型人脸属性数据库，覆盖了一些大的姿态

变化和背景干扰，截取部分图片如图 3.7 所示，其中有 10177 个名人、202599 个人脸图

像、5 个地标位置（左右眼、左右嘴角和鼻子）以及 40 个二进制属性注释。如图 3.8 所

示的文件标注了每一张图所对应的 bbox 标注框的起点位置和它们的宽高，如图 3.9 所示

31

长安大学硕士学位论文

的文件标注了五个关键点的横纵坐标。

图 3.5 WIDER FACE 数据库

图 3.6 wider_face_train_bbx.txt 格式

图 3.7 CelebA 数据库

32

第三章 基于卷积神经网络的人脸检测和定位方法

图 3.8 list_bbox_celeba.txt

图 3.9

list_landmarks_align_celeba.txt

3.3.2 网络训练过程

图 3.10 候选框与真实边界框重叠图（IOU）

以训练任务的不同为依据，我们将训练数据分成以下四类：人脸、非人脸、部分人

脸以及关键点人脸。以候选框和原标记框的交并比（IOU）为依据，将数据样本按照负

33

长安大学硕士学位论文

样本：正样本：部分样本：关键点样本=3：1：1：2 的比例划分为四个子集来进行模型

的训练。其中，正样本和负样本用来训练人脸和非人脸，正样本和部分样本用来训练人

脸边界框的回归，关键点样本用来训练人脸关键点的定位。交并比指的是候选人脸框和

真实的人脸边界框的重叠率，通过 IOU 可以判断候选框精度，如图 3.10 所示。

A 候选框的左上角和右下角坐标用坐标(Ax1,Ay1) 和(Ax2,Ay2)表示,宽和高的公式

如下（3.7）：


WA



HA


|

|

Ax

2



Ax

|1

Ay

1



Ay

|2

（3.7）

A 框面积：area(A)=WA*HA，B 候选框的左上角和右下角坐标用坐标(Bx1,By1) 和

(Bx2,By2)表示，宽和高的公式如下（3.8）：


WB



HB


|

|

Bx

2



Bx

|1

By
1



By

|2

（3.8）

B 框面积：area(B)=WB*HB，A 和 B 的交集区域宽和高的公式如下（3.9）：


W



H


|

|

WA



WB



(

Bx

2



Ax

|)1

HA



HB



(

Ay

1



By

|)2

（3.9）

A 与 B 交集区域的面积为：

area

(

HWBA


)

*

A 与 B 并集区域的面积为：

area

(

BA


)

WA

*

HA



WB

*

由上可以推导出 IOU 的计算公式，如下（3.10）：

HWHB

*



IOU



area
area

(
(


BA

BA

)
)

（3.10）

将数据集根据 IOU 进行分类：候选框与原标记人脸框的 IOU 小于 0.3 的是不包含

人脸的负样本，候选框与原标记人脸框的 IOU 大于 0.65 的为包含人脸的正样本，候选

框与原标记人脸框的 IOU 大于 0.4 且小于 0.65 的是局部样本，CelebA 数据集为关键点

样本。由于 IOU 处于 0.3 到 0.4 之间时，数据库标定过程具有一定误差，训练准确度不

高，所以这部分不参与整个训练。

3.3.3 实验结果分析及改进

由于本文在此基础上设计了目标跟踪算法，所以多任务卷积神经网络 MTCNN 的人

34

第三章 基于卷积神经网络的人脸检测和定位方法

脸检测和 5 个特征点定位与此算法结合在一起，详细检测结果示意图见第 3.4.3 节。

MTCNN 三个子网络在训练过程中人脸检测的准确率如图 3.11 所示，P-Net 网络接近

95.8%，R-Net 网络接近 96.8%，而 O-Net 网络达到了 97.3%左右，其准确率在 MTCNN

由粗到精的训练过程中逐步递增。我们也可以从中看出迭代次数的变化，P-Net 网络在

训练到 112000 个 epoch 时基本稳定，R-Net 网络在 94000 个 epoch 时趋于稳定，而 O-Net

网络在 30000 个 epoch 左右已基本稳定，由此可知在人脸检测过程中它们三个子网络的

迭代次数也在不断地减少。

图 3.11 P-Net、P-Net、O-Net 网络的准确率

如图 3.12 所示为 MTCNN 的三个子网络在训练过程中的特征点损失对比图，P-Net

网络的特征点损失率为 4.3%左右，R-Net 网络为 2.8%左右，而 O-Net 网络最终降到了

1.5%，其特征点损失在 MTCNN 训练过程中逐步减少。

图 3.12 P-Net、P-Net、O-Net 网络的特征点损失

35

长安大学硕士学位论文

为了提高 MTCNN 算法在人脸检测和定位上的准确率，本文在原网络的基础上对其

进行了改进。针对 P-Net 网络，增加了 1 个卷积层，其卷积核为 3×3；针对 R-Net 网络，

因平均池化可以减少参数量，所以将全连接层用均值池化替换，且把末尾的卷积层改为

192；针对 O-Net 网络，将第 1 个卷积层改为 16 个 5×5 的卷积核，第 2 个改为 48 个 3×3

的卷积核，第 3 个不变，第 4 个改为 64 个 3×3 的卷积核，将最大池化层的大小从原来

的 3×3 和 2×2 全部设为 2×2，图 3.13、3.14、3.15 为各个网络结构示意图，其中红色部

分为修改点。实验结果显示，经过优化网络参数后，MTCNN 最终人脸检测的准确率达

到了 98.92%，证明了实验优化的有效性。

图 3.13 改进后的 P-Net 网络

图 3.14 改进后的 R-Net 网络

36

第三章 基于卷积神经网络的人脸检测和定位方法

图 3.15 改进后的 O-Net 网络

3.4 基于 DSST 与 TLD 相结合的人脸跟踪算法

在驾驶员车辆驾驶过程中，由于驾驶背景容易变化，且驾驶员的人脸部位有时会检

测不到，这对于之后的疲劳驾驶检测研究造成了很大的困扰。MTCNN 网络虽然在准确

性以及实时性方面具备很大的优点，但是它对于图像处理单元的系统硬件设备的要求特

别高，所以本文提出了一种 DSST 与 TLD 相结合的目标跟踪算法对驾驶员人脸进行实

时的跟踪，这样就可以减少在人脸检测这一环节的时间且提高准确率。

3.4.1 DSST 人脸跟踪算法

该算法的跟踪任务包括位置变化及尺度变化两部分。在目标跟踪时，DSST 算法设

计了 2 个相关滤波器[48]，第一个的主要作用是确定目标位置，被称为位置滤波器，第二

个的主要作用是估计目标尺度，被称为尺度滤波器。

（1）位置滤波器

DSST 算法采用了 HOG 特征，我们假设从输入的某矩形图像块 f 中获得了维度为 d

t ：
的特征向量，构造最小的代价函数 )
( f


t

o
)(



k

d

 
||

t


1

l


1

l

h

*

f

l



2

g

||



d



l


1

l

||

h

2

||

（3.11）

其中，l 表示 k 维特征的某一维，h 表示滤波器， g 表示输入滤波器后得到的响应值，

37

长安大学硕士学位论文

表示正则项权值。

通过 Parseval 定理把上式（3.11）变换至频域上求解，更新滤波器 h ：


FG
_
l
FF

l

l



l
A
t
l
B
t





（3.12）

l

H



d



l


1

其中，


G 表示 G 的共轭转置，对分子和分母进行更新来加速计算过程，公式如下：


1(

l
 1
 
)
A
t




FG
t
t

l

l
A
t

l
B
t


1(


)

l
 
B
1
t

k




t


1


l
FF
t
t

l

（3.13）

（3.14）

其中，代表学习速率。在下一帧的图像区域里，可以利用位置滤波器输出的最大响应

值来计算目标的位置：

y

t



F


1









K



t


1
B
t

l

ZA

1
t

l
t

1












（3.15）

（2）尺度滤波器

在位置滤波器获得位置坐标后，我们将候选位置中心当作基础进而得到不同的候选

尺寸，并计算最为匹配的并将其当成目标当前的尺度更新值。尺度选择原则如下：

n


nRaPa

,


{[

n

S



1

S



1

]}

],...,

[

（3.16）

2
其中，P 和 R 表示目标区域上尺度大小，即长和宽， a 表示尺度因子，值为 1.02，S 表

2

示尺度数量，值为 33，图 3.16 为此算法的原理图。

DSST 算法的优势是有 2 个独立的滤波器，速度和效果都比较理想，但是它也存在

以下几个方面的劣势：

① DSST 没有跟踪失败的检测机制；

② DSST 无法处理一些完全遮挡的问题；

③ 对于一些搜索框外面的目标，DSST 也不能处理。

38

第三章 基于卷积神经网络的人脸检测和定位方法

（a）位置定位

（b）尺度更新

图 3.16 DSST 算法流程

3.4.2 TLD 人脸跟踪算法

如图 3.17 所示为 TLD 算法的框架，其主要分为四个模块，分别是跟踪模块、学习

模块、检测模块以及集成模块。

图 3.17 TLD 算法框架图

（1）跟踪模块

跟踪模块[49]采用的是中值光流法，其基础是金字塔 LK 光流法。首先在时刻 t，利

用金字塔 LK 光流跟踪法获得前向轨迹，记录时刻 t+1 的位置；其次进行反向跟踪，求

出前后向的误差值，将误差中值设为阈值，如果误差大于该阈值，则剔除，如果误差小

39

长安大学硕士学位论文

于该阈值，则表示跟踪有效；最后通过余下的特征点估算所有目标的位置进而更新目标

框，如果找不到目标框则模块无输出结果，如果能找到则将其作为输出结果。

（2）学习模块

学习模块的主要作用是更新检测器，它包括正样本及负样本处理，正样本的处理指

的是把本应为正却判为负的样本添加至正样本集里，负样本的处理指的是把本应为负却

判为正的样本添加至负样本集里，这两种处理方法是互相独立的。P-N 学习框架如图如

图 3.18 所示。

（3）检测模块

图 3.18 P-N 学习框架

如图 3.19 所示为 TLD 算法的检测模块示意图，其包含方差分类器、集成分类器和

最近邻分类器，且它们是级联的。这一模块通过滑动窗口依次扫描每一帧图像，它们都

经过三层分类器，然后判断每一个可能的图像元，进而确定是否含有目标。

图 3.19 TLD 算法检测模块

40

第三章 基于卷积神经网络的人脸检测和定位方法

（4）集成模块

集成模块顾名思义，就是将前面的几个模块结合输出为一个最终结果，这里不作详

细阐述。

TLD 算法的优势是它有全局检测模块，且拥有 DSST 算法没有的跟踪失败检测机制。

但是在跟踪模块，它也存在一些方面的不足，比如在驾驶员车辆驾驶过程中，驾驶员面

部很容易收到光照、人脸快速移动等现象的影响进而导致目标跟踪失败。

3.4.3 基于 DSST 与 TLD 相结合的人脸跟踪算法

在上面两节中，介绍了 DSST 算法和 TLD 算法，为了避免人脸跟踪中的一些常见

问题，本文提出了两种算法相结合的方法，也就是把 TLD 中的跟踪模块用 DSST 和适

用于此算法的跟踪失败检测方法取代，且在 TLD 算法的检测模块中加入 HOG 特征。

由于两种算法的输入输出一样，所以把跟踪算法视为一个黑箱，用 DSST 算法直接

替换 TLD 算法的金字塔 LK 光流跟踪法，将峰值旁瓣比 psr 当作描述两个信号相关性的

指标，就可以设计适用于 DSST 算法的跟踪失败检测方法， psr 计算公式如式（3.17）

所示：

psr


sl

g
 max

sl

（3.17）

其中， maxg 表示峰值， sl 表示旁瓣的均值， sl 表示旁瓣的标准差。

TLD 算法中，在对图像进行扫描分类时，因计算量太大致使其实用性较低。而在此

算法的几个模块中，最近邻分类器起最关键的作用，最近邻分类就是利用图像单元的灰

度像素值计算其与模板库正负样本的相似程度，灰度像素值并不算上好的图像特征，所

以在这里提出了 HOG 特征替换灰度像素值。具体框架如图 3.20 所示，其中红色区域为

替换之后的方法。

如图 3.21 所示，本文模拟了在正常情况和佩戴眼镜时驾驶员的正脸、侧脸、俯视以

及仰视姿态，还有局部遮挡状态下总共 12 种驾驶情况，在 MTCNN 检测到人脸后，运

用 DSST 和 TLD 相结合的人脸跟踪算法对其进行实时跟踪。结果显示，本文使用的

MTCNN 人脸检测和 DSST+TLD 人脸跟踪在驾驶员面部遮挡、佩戴眼镜以及头部转动

41

长安大学硕士学位论文

等较为复杂的情况下表现出很好的性能，可以满足大多数场景需求。

图 3.20 DSST+TLD 跟踪算法框架图

42

第三章 基于卷积神经网络的人脸检测和定位方法

（a）裸眼时的人脸检测与定位

（b）戴眼镜时的人脸检测与定位

43

长安大学硕士学位论文

（c）局部遮挡时的人脸检测与定位

图 3.21 人脸检测与定位图

3.5 基于级联回归树 ERT 的特征点定位算法

上文中利用 MTCNN 网络完成了人脸检测以及 5 个关键点的粗定位，为了后续能够

更加准确地提取面部疲劳特征，我们在此基础上采用了一种基于级联回归树（Ensemble

of Regression Trees，ERT）的人脸关键点定位算法，此算法的核心是使用两层回归来建

立数学模型[50]，其主要包括训练建立模型和模型拟合这两个过程。相比于其他算法，ERT

算法运行速度快、准确率高，以下将介绍此算法。

3.5.1 建立模型

ERT 算法通过梯度提升策略树（Gradient Boosting Decision Tree,GBDT）来更新策略，

当前形状与真实形状之间的差值即为此算法每次的回归学习。第一层采用级联回归的方

法来建立模型，其迭代公式如式（3.18）所示：


t
)1(
S


S



t
)(

t
)(


SI
,(

)




t

44

（3.18）

第三章 基于卷积神经网络的人脸检测和定位方法

其中，t 代表级联的层数级，

)(t


S

表示对形状 S 的第 t 级回器预测，它是由坐标组成的向

量，

)1(  t
S 表示 t+1 次迭代的预测结果， t 表示当前需要的训练量，也就是所在级数的回

归器， I 表示当前输入的人脸图像，


SI
,(


t

)(t

)

是当前层计算出的残差形状或者坐标，它

的输入是当前图片和形状向量，输出是更新后的特征点位置，在第一层回归器中，每次

通过一级，就会更新一次特征点的位置，进而可以回归更加准确的坐标结果。

回归模型的训练中假设存在 n 组数据：（I1,S1),（I2,S2),...,（In,Sn)，其中 iI 代表当

前的人脸图像， iS 表示的是人脸特征点向量。第二层训练主要是回归器 t 的迭代，我们

创建人脸图像的三元胞数组

t
)(


S

i

(

I

i

,

,


S

)(
t
i

)

，其中

I 为数据集中的人脸图像，预测特征

i

点向量用

)(t


iS

来表示， )(t

iS 表示真实值和预测值之间的差值，迭代公式如下：

i 

,...,3,2,1{

n
}

)0(

i


S



,{
SS
1

2

,...
S

n

\}
S

i



S

)0(
i



S
i



S


)0(
i


t
)1(
S

i

t
)(

i


S






(
I
t

i

,


S

t
)(

)

i



S


)1(
t
i



S
i




t
)1(
S

i

（3.19）

（3.20）

（3.21）

（3.22）

（3.23）

将上式（3.19）至（3.23）不断迭代，直至学习了 t 级回归的级联。然后我们使用梯

度提升策略树的方法训练 t ，学习率 v 的取值范围在 0 和 1 之间，具体流程如下：

对其中一棵回归树

)(t


SI
,(

f

k

)

进行初始化，表达式如式（3.24）：

t
)(


SI
,(

f

0

)



min

arg



min
R

p

2

N



i


1

||



S

t
)(
i





||

（3.24）

每次迭代更新回归树 ikr 的值，如式（3.25）：

r
ik


S

)(
t
i


f
1
k

(

I

i

,


S

t
)(

)

i

（3.25）

通过上式我们得到弱回归方程

)(t


SIg
,(

k

，更新

)


SI
,(

f

k

)(t

)

，如下：

45

长安大学硕士学位论文

t
)(


SI
,(

f

k

)



f

k


1

t
)(


SI
,(



)

vg

k

t
)(


SI
,(

)

重复以上步骤至设定迭代次数或收敛状态，得到最后的回归函数

式如式（3.27）：

t
)(


SIr
,(
t

)



f

k

t
)(


SI
,(

)

本文的损失函数采用平方误差：



1
2

[

y 
i

xf
(
i

2)]

（3.26）


S

)(t

)

i


I
(
t

i

,

，表达

（3.27）

（3.28）

对损失函数求导，得

y 
i

xf
( i

)

，在每一轮的迭代过程中，我们将此梯度视为拟合对

象，进而得到构造模型。

3.5.2 模型拟合

上一节通过 k 次迭代后得到了一个回归模型，这一节将介绍模型拟合的具体步骤。

（1）将每一张人脸图像上的关键点向量进行初始化，使得初始形状一样。

（2）根据检测结果，构造特征池并随机选择其中两点，由于每张人脸图像都不同，

进而提取出来的特征不同，将像素差作为特征，并在这两个点计算每张人脸图像的像素

差。

（3）构造 GBDT 中的回归树，构造函数如下：
  

QE
(


)
,

||


s

rl
},{


Qi

,

s

r
i




,

s

||

（3.29）

其中， E 代表目标函数，代表候选节点， l 代表左子树， s 代表右子树， s, 表示根据

当前所划分产生的结果。随机产生一个分裂阈值，当阈值大于像素差时往左分裂，相反

则往右分裂。根据这种方法把人脸图像分裂成左边和右边两部分，重复上述过程的得到

最优节点，然后保存分裂阈值以及坐标值。

（4）利用全部的决策树来计算残差。首先算出每个叶子节点的残差，然后将全部

子树的残差求和，最后就可以获得全局残差。

重复（2）、（3）、（4）步骤，直至迭代完成，也就是真实形状可以用关键点形

向量来表示。

46

第三章 基于卷积神经网络的人脸检测和定位方法

3.5.3 训练模型

训练 ERT 算法时选用 300-W（300 Face in Wild）人脸数据库，该数据集总共有 3148

张训练集+689 张测试集（554+135），其中包含了 afw（337）、helen（train 2000+test 330）、

ibug（135）和 lfpw（train 811+test 224）等目录，此数据库每个图像上可能不止一个人

脸，但只标注出了一张人脸。模型训练参数如下表 3.2 所示：

表 3.2 ERT 模型训练参数

参数名

级联级数

树的深度

正则项

样本数扩大倍数

每层级联树的数量

回归树节点分裂个数

特征池的大小

设置

10

5

0.1

20

500

20

400

ERT 算法流程图如下所示：

图 3.22 ERT 算法流程图

其中，T 代表级联级数，当级联数为 0 时，人脸关键点向量是初始值，通过不断地级联

回归，人脸关键点的坐标位置与实际位置越来越接近，而当级联级数为 T 为 10 时，我

们可以看到误差越来越小，基本接近真实坐标。

3.6 本章小结

本章采用了一种基于级联的多任务学习算法 MTCNN 来进行驾驶员面部检测和五

47

长安大学硕士学位论文

个关键点定位。首先介绍了金字塔尺寸变换的数据预处理，然后详细阐述了 MTCNN 三

个子网络 P-Net、R-Net、O-Net 的结构及算法原理，在 WIDER FACE 和 CelebA 这两个

数据集上训练与测试，并分析实验结果，发现 MTCNN 网络经三个子网络训练后准确率

逐步提高，迭代次数逐步下降，能够较准确检测出人脸并且定位出五个特征点。紧接着，

在原有网络的基础上，对其参数进行优化，实验结果在准确率上提升了 1.62%的准确率。

然后提出了基于 DSST 和 TLD 相结合的面部跟踪算法，分别对 DSST 算法和 TLD 算法

的原理和优缺点作了描述，对驾驶员在复杂环境下的驾驶情况进行模拟实验，结果显示

这两种相结合的目标跟踪算法能够实现对面部的实时稳定跟踪。为了使其检测更加精

准，在 MTCNN 基础上又选取了基于级联回归树 ERT 算法的特征点定位方法，此算法

主要包括训练建立模型和模型拟合这两个过程，文中对其进行详细的说明，ERT 算法可

以精准地定位出人脸的眼睛、鼻子、嘴巴、轮廓等 68 个点。

48

第四章 疲劳驾驶特征提取

第四章 疲劳驾驶特征提取

4.1 引言

在上面几个章节介绍了人脸检测和特征点定位的相关算法流程，接下来的这一章将

在此基础上提取相关疲劳特征。当驾驶员疲劳驾驶时，其面部会有明显的疲劳特征，比

如打哈欠、眨眼的频率提高、眼睛的张开程度减小、点头频率增加等，传统机器学习检

测方法一般都是基于单一的眼部状态，比如 PERCLOS 准则来判断疲劳状态，这就导致

检测结果可能不理想，出现误判的概率。本章主要对驾驶员的眼部、嘴部以及头部姿态

进行分析，分别研究这三个部位的疲劳特征。

4.2 基于 EAR 算法的眼部疲劳特征提取

上一章通过 MTCNN 检测到人脸框后，利用 ERT 算法得到了 68 个人脸关键点，简

易模型如图 4.1 所示：

图 4.1

68 个面部特征点分布图

49

长安大学硕士学位论文

人脸各部位坐标总结如表 4.1 所示：

表 4.1 人脸器官与关键点分布关系

关键点坐标分布

1~17

18~22

23~27

28~31

32~36

37~42

43~48

49~60

61~68

人脸器官

脸颊

左边眉毛

右边眉毛

鼻梁

鼻翼

左边眼睛

右边眼睛

外嘴唇轮廓

内嘴唇轮廓

4.2.1 PERCLOS 准则

Wierwille[51]实验发现眼睛的闭合时间在某种意义上能够反映出驾驶员的驾驶状态，

于是卡内基梅隆研究所提出了 PERCLOS 准则，其定义是单位时间（1min/30s）眼睛闭

合时间占总时间的比例，有以下 3 种判断准则：

（1）EM：以瞳孔被眼睑遮住的面积超过 50%为指标；

（2）P70：以瞳孔被眼睑遮住的面积超过 70%为指标；

（3）P80：以瞳孔被眼睑遮住的面积超过 80%为指标。

在模拟驾驶过程中，美国国家公路交通安全管理局和美国联邦公路管理局[52]对九种

疲劳检测的指标进行了对比，发现它们都可以判断疲劳状态，但是预测的相关性不一样，

PERCLOS 的关联性更高，且 P80 的指标判断结果更佳，因此本文选用了 P80。

PERCLOS 原理图如图 4.2 所示，它显示了驾驶员眼睛从睁开到闭合的一个状态， 1t

到 4t 是一个眼睛闭合周期，其中 1t 表示第一次眼睛的张开度从最大达到 80%的时刻，2t 表

示第一次瞳孔剩余被遮挡的面积达到 20%的时刻， 3t 表示第二次瞳孔露出面积达到 20%

50

第四章 疲劳驾驶特征提取

的时刻， 4t 表示第二次眼睛的张开度从最大达到 80%的时刻。

PERCLOS 的计算公式如下（4.1）所示：

图 4.2 PERCLOS 原理图

P
80



t
3
t

4




t
2
t
1



%100

（4.1）

为了便于计算，上式也可等价为：

P
80



frame
frame

wink

sum



%100

（4.2）

其中，

frame 指的是视频中的闭眼帧数，

wink

frame 指的是视频中的总帧数。表 4.1

sum

显示了左眼的特征点分布在 37 至 42，右眼的特征点分布在 43 至 48，我们可以通过这

些特征点坐标来计算眼睛的纵横比，进而准确计算出 80P 的值，眼睛纵横比将在下一小

节介绍。

4.2.2 眨眼频率

驾驶员在正常驾驶时，通常情况下的眨眼频率[53]（Blink Frequence，BF）为 100ms

到 400ms 之间，每分钟眨眼 15 次左右，但当他们疲劳驾驶时，某段时间内其眨眼频率

会降低。2016 年，Tereza Soukupova 和 Jan Cech 提出了一种基于眼睛纵横比(Eye Aspect

Ration，EAR)[54] 的方法，它可以在时间序列上反映驾驶者的状态特征。如图 4.3 所示为

截取的一次眨眼过程，其眼睛纵横比随时间的变化关系见图 4.4，当驾驶员的人眼处于

51

长安大学硕士学位论文

正常睁开状态时，EAR 在某个值的上下浮动，变化不大，而当驾驶员的人眼接近闭合时，

EAR 的值会迅速下降到 0 附近，当其返回到之前的稳定范围内时，表示完成了一次眨眼

过程。

图 4.3 眨眼过程

图 4.4 眼睛纵横比随时间的变化

一些研究人员采用一只眼睛来计算眼睛的纵横比，但是为了提高算法的鲁棒性，本

文选用两只眼睛的平均值来计算 EAR，计算公式如（4.3）所示：

EARaverage



||

P
38



P
||
42
||4
P
37


||
P
39

P
40



P
41

||

||

||

P
44





P
48
||4

||
P
43


||
P
45

P
46



P
47

||

||

（4.3）

基于眼睛纵横比的 EAR 算法计算量和耗时都比较少，且很难受到外界一些因素的

影响，所以准确率比较高。

4.3 基于嘴巴内轮廓的嘴部疲劳特征提取

当驾驶员处于疲劳驾驶状态时，嘴部也会发生变化，嘴巴的三种状态如图 4.5 所示，

从左到右依次为打哈欠、非打哈欠以及嘴巴闭合状态。疲劳时，打哈欠的频率会随着疲

劳程度的加深而明显增加，打哈欠一般持续在 4s 左右，嘴巴张开度要比正常情况下大。

在非打哈欠且张嘴时，一次的张嘴持续时间和嘴巴张开程度明显小于打哈欠的时候，所

以我们可以通过计算嘴巴的纵横比（MAR）来进行疲劳判断。

52

第四章 疲劳驾驶特征提取

图 4.5 嘴巴的三种状态

嘴巴的特征点分布在 49 至 68，由于每个人的嘴巴厚度各不相同，所以本文提出了

采用嘴巴的内轮廓来计算嘴巴纵横比 MAR[55]的计算公式如下：

||

P
62

MAR





P
68
||2

||
P
55


||
P
64

P
49



P
66

||

||

（4.4）

嘴巴纵横比 MAR 超过某个阈值并持续一段时间则被认为是打哈欠，研究发现，驾

驶员处于疲劳驾驶打哈欠时，MAR 值一般大于 0.5，而正常闭合情况下 MAR 值在 0 与

0.2 之间。基于嘴巴纵横比的 MAR 算法计算量小，在一定程度上简化了驾驶员疲劳驾驶

检测流程。

4.4 基于欧拉角的头部疲劳特征提取

当驾驶员处于疲劳驾驶状态时，很难保持正常的头部姿态，其点头频率增加，且会

出现头部前后运动及左右倾斜等反应，所以我们可以通过检测三维空间中的坐标角度变

化 来 判 断 驾 驶 员 的 驾 驶 状 态 。 三 维 空 间 旋 转 有 欧 拉 角 （ Euler Angle ） 、 四 元 数

（Quaternion）、旋转矩阵（Rotation）以及旋转向量（Rotation Vector）等，由于欧拉角

具有直接简单等特点，本文用它来表示三维空间。

4.4.1 欧拉角

将人脸的头部视为刚体，如图 4.6 所示为头部姿态欧拉角示意图，设水平方向为 x

轴，垂直方向为 y 轴，依据 x/y 轴方向向量构造的向量平面的法向量为 z 轴，则俯仰角

（pitch）、偏航角（yaw）以及滚转角（roll）表示的是绕 x 轴、y 轴和 z 轴旋转的角度，

即前后转动、水平转动还有正面横向弯曲。经实验研究，成年人的头部运动始终在一个

比较固定的范围之内[56]，pitch 的范围是[-60.4，69.6], yaw 的范围是[-79.8，75.3], roll 的

范围是[-40.9，36.3]。

53

长安大学硕士学位论文

图 4.6 头部姿态欧拉角

4.4.2 相机标定及其实现

相机标定是一个二次转换的过程[57]：第一次是三维向二维的转化，也就是说把世界

坐标系转化为相机坐标系；第二次是二维到二维的一个映射，即将相机坐标系转化成图

像坐标系。

如图 4.7 所示，o 表示相机中心，世界坐标系中，点 P 的坐标为（U，V，W），图

像坐标系中，点 P 的坐标为（x，y）,相机坐标系中，点 O 的坐标为（X，Y，Z）。

图 4.7 三大坐标系的对应关系

利用 ERT 算法定位驾驶员面部特征点，然后反向映射获取三维的特征点，公式（4.5）

表示它们之间的映射关系：

b

[

BtRA

]

（4.5）

其中，b 是图像平面 p 的坐标向量，是比例因子，A 是相机的参数矩阵，t 表示映射变

54

第四章 疲劳驾驶特征提取

换的平移矩阵（3×1 的矢量），旋转矩阵（3×3）用 R 来表示， xf 、

yf 、 xc 、

yc 是相机

的标定参数。带入坐标，得：

x

y

1






















f

x
0

0

0

f

y
0

c

x

c

y
1













r
00
r
10
r
20

r
01
r
11
r
21

r
02
r
12
r
22

t

t

t

x

y

z







V


U



W



1








三维坐标和图像坐标的转化公式如下：

X

Y

Z















R

V


U



W









t

X

Y

Z















[


U

]|
tR


W


V







展开成

X

Y

Z





















r
00
r
10
r
20

r
01
r
11
r
21

r
02
r
12
r
22







（4.6）

（4.7）








V


U



W



1

本文通过张正友法[58]，使用格数为 7×5 的棋盘图片采集不同角度和位置的图像，通

过 opencv 库自带的相机校正函数来获得相机的内部参数和畸变参数。其中，棋盘格内

角 点 的 检 测 通 过 cv2.findChessboardCorners() 函 数 实 现 ， 亚 像 素 角 点 信 息 通 过

cv2.cornerSubPix()获得，而 cv2.calibrateCamera()函数则用来相机的标定。经计算我们求

得了相机的内参矩阵 A 和畸变系数，如表 4.2 所示：

表 4.2 相机标定结果

类型

内参矩阵

畸变系数

6.53×102

0

0

参数

0

6.53×102

0

7.08×10-2

6.91×10-2

0

-1.31

3.19×102

2.39×102

1

0

表 4.3 为三维模型对应的二维模型特征点。因为比例因子、二维坐标和三维坐标

目前已经是已知的，所以可以求出旋转矩阵 R。接下来，利用罗德里格斯公式来计算欧

拉角。

55

长安大学硕士学位论文

表 4.3 三维模型与二维模型的特征点对应表

面部关键点

二维点序号

三维点坐标

三维点序号

左眉左上角

左眉右角

右眉左脚

右眉右上角

左眼左上角

左眼右上角

右眼左上角

右眼右上角

鼻子左上角

鼻子右上角

嘴巴左上角

嘴巴右上角

嘴中央下角

下巴底部角

17

21

22

26

36

39

42

45

31

35

48

54

57

8

（6.825897，6.760612，4.402142）

（1.330353，7.122144，6.903745）

（-1.330353，7.122144，6.903745）

（-6.825897，6.760612，4.402142）

（5.311432，5.485328，3.987654）

（1.789930，5.393625，4.413414）

（-1.789930，5.393625，4.413414）

（-5.311432，5.485328，3.987654）

（2.005628，1.409845，6.165652）

（-2.005628，1.409845，6.165652）

（2.774015，-2.080775，5.048531）

（-2.774015，-2.080775，5.048531）

（0.000000，-3.116408，6.097667）

（0.000000，-7.415691，4.070434）

欧拉角可以用旋转矩阵 R 来表示，公式如下：


RR


)
(



R


)
(



R

z


)(

y

x

R

x


)
(



1

0

0







0



cos


sin




0







,

R

y


(
)



cos



0

sin









0

1

0

sin

cos

联立式（4.8）与（4.9），得



sin

0

cos










,

R

z


)(








cos



sin



sin



cos



0

0

R









cos

cos



cos

sin


sin

sin



cos

sin



cos

sin



sin



sin
sin

cos

sin


sin

sin

cos

cos



cos

sin



sin



sin



sin
sin

cos

cos



sin


cos




已知旋转矩阵 R 的参数，联立式（4.10）可得欧拉角的计算公式为：

56

33

29

34

38

13

17

25

21

55

49

43

39

45

6

（4.8）

（4.9）

0

0

1







（4.10）

第四章 疲劳驾驶特征提取



arctan(



arctan(

r
21
r
22

)



2
r
21

r
20
2

r
22

)

（4.11）
















arctan(

r
10
r
00

)

通过欧拉角的方法统计头部姿态信息，可以实时且比较准确地判断驾驶员是否疲劳

驾驶，而且针对面部遮挡问题具有较好的鲁棒性。

4.5 实验及结果分析

实验选取了 5 个人模拟疲劳状态，分别录制正常以及疲劳视频，部分图像帧如图 4.8

所示，其中（a）是正常状态，（b）是疲劳状态。

图 4.8（a） 清醒状态

图 4.8（b） 疲劳状态

将视频转化为帧图像，计算帧序列的 PERCLOS 值，发现当 PERCLOS 为 0.25 时，

人处于长时间的闭眼状态，可视为疲劳。根据分析可知，在正常情况下眨眼时，眼睛的

57

长安大学硕士学位论文

纵横比 EAR 会突然下降到 0.1 附近，而当五个实验者出现眨眼行为时，其 EAR 会变低

且都在 0.23 以下，即 0.23 是从正常转为疲劳的一个界限，所以将眼睛纵横比 EAR 的阈

值设定为 0.23。在眨眼过程中，EAR 的变化会呈现出波谷状，这个波谷其实就是通过闭

眼时间长度反映出来的，将其设定为 3，即 3 个连续帧 EAR 的值小于 0.23 就认为是疲

劳状态，相反为正常状态。

眼部疲劳检测如图 4.9 所示，其中 Faces 表示人脸数，Blinks 表示眨眼数，COUNTER

表示帧计数器，sleep 表示疲劳。左图中，EAR 的值为 0.34，表示正常状态；右图中，

EAR 的值为 0.10，COUNTER 为 74，Blinks 为 52，表示疲劳状态。

图 4.9 眨眼检测

通过对五个实验员嘴巴的分析，发现在正常说话的时候，嘴巴纵横比 MAR 的值会

出现上浮或者下跌的小范围波动，而当他们出现打哈欠行为时，其 MAR 值会迅速上升

达到 0.6 以上，所以我们将 MAR 的阈值设定为 0.6，当驾驶员在 3 个连续帧的 MAR 值

大于 0.6 就认为处于疲劳状态，相反为正常状态。

图 4.10 打哈欠检测

58

第四章 疲劳驾驶特征提取

如图 4.10 所示为嘴部疲劳检测，其中 Yawning 表示打哈欠。左图中，MAR 的值为

0.56，是正常的张嘴状态；右图中，MAR 的值为 0.85，超过了阈值，显示 Yawing，属

于疲劳状态。

Pitch、Yaw、Row 三个角度中，俯仰角 Pitch 与疲劳状态下的点头最为相关，所以

我们选取 Pitch 对驾驶员疲劳进行判断。图 4.11 为欧拉角建模图，其中左图表示正常姿

态三维坐标，右图表示疲劳状态三维坐标，由图可知，正常状态下，Pitch 的变化范围

在 5°到 7°之间，而疲劳状态下的变化范围是在 10°～25°之间。我们选择偏移量超

过 20%作为疲劳指标，也就是说三个连续帧头部俯仰角 Pitch 变化 25°。

图 4.11 头部姿态在正常状态与疲劳状态下的三维坐标图[59]

头部姿态检测如图 4.12 所示，其中 Nod 表示点头，我们只观察 pitch。左图中，俯

仰角为 4.02，未出现点头现象，属于正常头部运动；右图中，俯仰角 pitch 为 21.73，超

出了变化范围，点头次数为 9，则被视为疲劳状态。

图 4.12 头部姿态检测

59

长安大学硕士学位论文

4.6 本章小结

本章主要介绍了一些相关性高的疲劳特征及其提取，对眼部、嘴部以及头部特征进

行了分析。在眼部疲劳提取中，采用了眼睛纵横比 EAR 算法，利用 EAR 可以计算出

PERCLOS 值和眨眼频率；在嘴部疲劳提取中，选择与之类似的嘴巴纵横比 MAR 算法，

并提出用嘴巴内轮廓开合度的特征计算 MAR；在头部疲劳特征提取中，介绍了欧拉角

的定义和相机标定及其实现过程，并用罗德里格斯公式计算欧拉角。最后采集了五个人

正常状态和疲劳状态下的视频数据集对疲劳特征进行分析，给定 P80 的值为 0.25，EAR

的阈值为 0.23，MAR 的值为 0.6，Pitch 的偏移量为 20%。

60

第五章 多特征疲劳驾驶检测

第五章 多特征疲劳驾驶检测

5.1 相关算法

支持向量机(SVM)是机器学习中的一类算法，最早应用于数据的分类，Vapnik[60]等

人引入了不敏感损失函数，把分类问题引申为回归问题，因此也可以用于预测，其应

用非常广泛，比如文本分类、人像识别、手写字符识别等。支持向量机 SVM 没有任何

前提假设，且不涉及概率测度，它适合处理一些非线性、非平稳的数据且可以避免高维

模型构造带来的问题，能够利用较少的数据样本来训练数据。

5.1.1 理论基础及推导公式

支持向量机 SVM 的主要目的是通过训练样本来构建分类结果最佳的超平面，其求

解思路如图 5.1 所示。

图 5.1 最佳分割超平面

假设输入的数据集为

C



{(

,
yx
i

i

:)

x
i



n
,
yR

i



1}}1,1{


l
i

， ix 表示输入的多个数据， iy

表示学习目标，即分类标签。H：

 bxw

*

0

表示把正样本和负样本划分开的最优超平

面，H1：

 bxw

*

1

和 H2：

 bxw

*

1

分别表示正样本和负样本距离 H 最近的样本点，

它们与 H 的关系是平行的。超平面和最近样本点的距离公式如下：

|

T
xw k
||
w



b

|

||



1
w

||

||

（5.1）

Margin 表示分类间隔，公式如下：

61

长安大学硕士学位论文

m

arg

in



2
w

||

||

把最优超平面问题转变成求解最优化的问题：

约束条件公式如下：

wD
)
(



||

w

2||

1
2

xwy
*(
i
i

 b


01)

（5.2）

（5.3）

（5.4）

采用拉格朗日乘数法[61]把最优超平面问题转化成二次凸优化的求解，如下式：

,
abwL
i

(

,

)





1
2

1
2

2

||

w

||



2

||

w

||



l



i


1


(
xwya
i
i
i

(

b


)1)

l



i


1


(
xwya
i
i
i

(

b

)



l



i


1

（5.5）

a
i

)

（5.6）

（5.7）

（5.8）

（5.9）

（5.10）

其中， ia 表示拉格朗日乘子，其值≥0，接下来求解：

min
bw
,

max

a
0
i

abwL
,(
i

,

)



max

a
0
i

首先要计算 w 和 b 的偏导，如下式：

,(min

abwL
i

,

,

(


,
abwL
i

w

)


w

l



i


1

,

(


,
abwL
i

w

)



l



i


1

xya
i
i
i

ya
i

i

令式（5.7）、（5.8）等于 0，使 w 和 b 的值最小：

w 


xya
i
i
i

l

i


1


i ya

i

0

l

i


1

将其带入式（5.5），得：

62

第五章 多特征疲劳驾驶检测

min
bw
,

abwL
,
i

(

,

)



1
2

2

||

w

||


w

l



i


1

xya
i
i
i


b

l



i


1

1
2
l







2

||

w

||



bww

0

l



i


1

a
i



i


1

l



i


1

a
i



a
i



1
2

1
2

2

||

w

||

l

l



i


1

j


1

xxyyaa
i
j

(

i

i

j



l



i


1

a
i

（5.11）

ya
i

i



)

j

x
ma

a
0

i

min
bw
,

abwL
,
i

(

,

)



max{

l



i


1

a
i



1
2

l

l



i


1

j


1

xxyyaa
i
j

(

i

i

j



)}

j

（5.12）

条件极值转成凸规划，如下式：

1
2

||

w

||

2



{max

a
0

i

1
2

2

||

w

||



l



i


1



1
2

2

||

w

||



{min

a
0

i

l



i


1


xwya
(
i
i
i

(

b


}1)


xwya
(
i
i
i

(

b


}1)

（5.13）

即

{min

ai
0

l



i


1


xwya
(
i
i
i

(

b


)}1)



0

，又公式（5-4）中的约束条件≥0，所以可以得到


xwya
(
i
i
i

(

b


0)1)

。也就是说，若拉格朗日系数等于 0，意味着这个样本不是支持向

量，相反的，如果其值不为 0，则代表这个样本是支持向量。

确定了法向量 w 和分割阈值 b，那么最优超平面 H 也就确定了，则分类决策函数可

以表示为：

xf
)(



sign

(

5.1.2 松弛变量和惩罚因子

N



i


1

xxya
(
i
i

i



*



)

b

)

（5.14）

如果数据集中有一些离群的点，那么就会导致超平面移动，所以我们引入了松弛变

量 i ，其值大于零，式（5.15）表示了样本为正例和负例的约束，其中第一行是正例，

第二行是负例：





xw
*
i

xw
*
i


i

i

,

,

y

i

y

i



1


1

（5.15）



1

b



b

1

63

长安大学硕士学位论文

引入惩罚因子 C，即离群点的权重，目标函数的公式如下：

,
bwf

(


),



||

w

2||



C

1
2

N



i


1


i

（5.16）

这时，分类间隔可以小于 1， 

C

N

i


1

 意味着离群的点越多，目标函数越大，通过调

i

整 C 我们可以实现更好地分类样本。

5.1.3 核函数

以上我们说的是线性可分的情况，但是在解决实际问题的过程中，我们经常会遇到

很多线性不可分的情况，为了可以利用 SVM 原理，我们需要把线性不可分转为可分，

一个比较好的方法就是利用非线性映射

:

R

n



R

D

，把数据从低维空间映射到高维上

去，也就是核函数理论,如图 5.2 所示。

定义支持向量机 SVM 的核函数为：

图 5.2 核函数

yxK
(
i
i

,

)



 
(
x
)
i

(

y
i

)

（5.17）

最大化目标函数可以表示为：

aL
)(



最终决策函数表示为：

N



i


1

a

i



1
2

N

N



i


1

j


1

yyaa
j

i

i

xf
)(



sgn[




x
)(



b

]



sgn[

目前比较常用的核函数有以下几种：

64

l



i


1

 
)
x
((
(
i

x

j

j

))

（5.18）


xxKy
),
(
i
i

i



b

]

（5.19）

第五章 多特征疲劳驾驶检测

xxK
(
i

,

j

)



(


xx
i

j

)

（5.20）

(
xxK
),
i



((

,
xx
i


)1)

d

（ d 为正整数）

（5.21）

①线性核函数：

②多项式核函数：

③高斯核函数：

xxK
),
(
i



exp(



||

x



2 i
x
/
||

2

)

（为核宽度）

（5.22）

④Sigmoid 核函数：

xxK
),
(
i



tanh((

xx
,
i

)



c

)

（5.23）

5.2 多特征疲劳驾驶检测算法

疲劳驾驶会严重危害交通安全，所以研究出一种疲劳驾驶检测方法有非常重要的意

义。在文献[62]中，作者提取眼部特征，利用 PERCLOS 准则和眨眼频率判断驾驶员是

否处于疲劳状态；在文献[63]中，作者提取嘴部特征，通过打哈欠行为来判断驾驶员的

疲劳状态。由于单一的疲劳检测方法出现的误判概率比较高，本文提出了一种基于支持

向量机 SVM 的多特征疲劳驾驶检测方法来判断疲劳状态，并对其可靠性进行分析。

5.2.1 疲劳驾驶检测算法设计

由上一章我们得到了眼睛纵横比 EAR 的阈值为 0.23，嘴巴纵横比 MAR 的阈值为

0.6，俯仰角 Pitch 的偏移量为 20%，本章使用这三个疲劳特征（眼睛、嘴巴以及头部姿

态）来进行疲劳驾驶判断。首先我们区分开非疲劳和疲劳状态，选取 1 分钟 EAR 小于

0.23、MAR 大于 0.6、Pitch 的偏移量大于 0.2 为疲劳状态，学习标签为 1；选取与之相

反的 1 分钟 EAR 大于 0.23、MAR 小于 0.6、Pitch 的变化小于 0.2 为非疲劳状态，学习

标签为 0。紧接着我们把非疲劳状态和疲劳状态这两类数据作为训练集，对支持向量机

进行训练，这样我们就得到了能够检测出疲劳驾驶的分类模型。

利用设备采集 10 个实验人员录制他们的疲劳状态和非疲劳状态，用来模拟疲劳驾

驶状态，其中设备的分辨率为 1080p HD,视频帧率为 30fps。我们截取 2 分钟的 5 段疲劳

视频和 2 分钟的 5 段非疲劳视频。由于帧与帧间的变化非常微小且出于计算简单化的目

65

长安大学硕士学位论文

的，我们对帧图像进行采样，每 5 帧选择 1 帧，然后计算这些帧的 EAR 值、MAR 值以

及 Pitch 值，其中帧的数量为：10×2×5×120×30÷5=7200 帧。

这类问题是支持向量机中的非线性问题，因为眼部特征、嘴部特征及头部特征不规

律，我们选取高斯核函数

xxK
),
(
i



exp(



||

x



2 i
x
/
||

2

)

作为其训练模型，因为数据中有

一些离群点，所以我们设置松弛变量 i 和惩罚因子的值分别为 6 和 7。

5.2.2 实验及结果分析

我们从数据集中随机选取 250 组样本训练支持向量机，然后选取剩下的 250 组进行

测试，表 5.1 为 SVM 的分类识别结果。

表 5.1 SVM 分类识别结果

样本个数

学习标签

疲劳状态

非疲劳状态

识别率

125

125

1

0

123

3

2

122

98.4%

97.6%

训练好分类模型之后，我们对 10 段数据集（各 5 段疲劳和非疲劳的视频）进行测

试，表 5.2 为最后的测试结果。

视频编号

疲劳帧数

非疲劳帧数

正确帧数

表 5.2 疲劳检测结果

10

11

20

21

30

31

40

41

50

51

717

11

688

5

659

24

708

54

632

19

687

702

642

691

638

682

699

615

614

676

3

709

32

715

61

696

19

666

88

701

66

准确率

95.80%

99.01%

93.31%

96.64%

96.81%

97.98%

98.72%

92.34%

97.15%

96.43%

第五章 多特征疲劳驾驶检测

通过上表可以计算出平均检测准确率为 96.42%。分析表中数据，我们发现视频编

号为 20 和 41 的两组数据准确率分别为 93.31%和 92.34%，远远低于综合准确率，其中

两组都是因为实验人员头部左右过度摇晃，使得偏航角 yaw 超出了变化范围且人脸不在

框内，进而导致不能准确识别出人脸。综上所述，在正常情况下，本文给出的疲劳驾驶

检测准确率比较高，然而由于在头部姿态提取上，本文只选取了 pitch 作为特征，未将

偏航角 yaw 考虑进去，导致当驾驶员头部左右严重晃动时出现误判。我们对不同文献在

相同的实验条件下作了对比，见表 5.3。

文献

文献[62]

文献[63]

文献[64]

文献[65]

文献[66]

本文

表 5.3 不同方法对比

算法

Cascade + PERCLOS

卷积神经网络 + Softmax

Adaboost + PERCLOS

VGG-16 + EAR、MAR + SVM

MTCNN + EAR、MAR + SVM

MTCNN + EAR、MAR、Pitch + SVM

准确率

92.87%

94.28%

93.91%

94.38%

95.52%

96.42%

在文献[62]中，毛须伟等人采用 Cascade 的人脸检测算法，通过 Otsu 阈值分割以及

形态学运算获取人眼特征，然后利用眼睛宽高比来判断闭合程度，最后将 PERCLOS 准

则和眨眼频率作为疲劳判断依据，其准确率为 92.87%。

在文献[63]中，马素刚等人采用卷积神经网络，利用 Softmax 分类器对嘴部特征进

行分类，判断是否属于打哈欠行为，进而判定疲劳状态，其准确率为 94.28%。

在文献[64]中，刘朝涛等人利用 Adaboost 人脸检测算法对人脸进行定位，然后采用

PERCLOS 准则和人眼变化曲线对驾驶员的疲劳状态进行判断，其准确率为 93.91%。

在文献[65]中，刘梦佳利用卷积神经网络 VGG-16 提取人脸特征点，然后通过眼睛

纵横比 EAR 和嘴巴纵横比 MAR 来判断疲劳状态，其准确率为 94.38%。

在文献[66]中，冯晓锋等人采用多任务卷积神经网络 MTCNN 进行人脸特征定位，

然后对眼部和嘴部特征通过 EAR 和 MAR 值进行提取，最后利用支持向量机 SVM 对疲

劳状态进行判断，其准确率为 95.52%。

在上述[62]到[66]的文献中，它们采用不同的方法来实现人脸特征点定位，我们发

67

长安大学硕士学位论文

现基于深度学习的人脸检测及定位比传统检测算法更佳，且采用多种疲劳特征提取要比

单一的更加准确，在文献[65]和[66]中，作者仅对眼部和嘴部特征进行了提取，而本文

在其基础上，对头部姿态也进行了分析，结果显示本文所用的方法准确率更高，对于疲

劳驾驶检测有更好的可行性。

图 5.3 不同方法准确率对比

5.3 疲劳驾驶检测系统的实现

5.3.1 开发环境

本文使用的开发平台为 Pycharm，深度学习框架为 Tensorflow，使用基于深度学习

的人脸检测算法，所以运用 Python 语言进行编程，具体环境参数见下表。

参数名称

操作系统

内存

处理器

显卡

开发语言

IDE

表 5.4 开发环境

参数值

Windows 10

16.0GB

Inter(R) Core(TM) i5-10400F CPU @ 2.0GHz 2.90GHz

NVIDIA GeForce GTX 1660

Python 3.6

JetBrains PyCharm Community Edition 2019.2.4 x64

深度学习框架

Tensorflow 1.2.1

68

第五章 多特征疲劳驾驶检测

5.3.2 工作流程

本文工作流程如图 5.4 所示，各个模块研究内容如下：

开始

视频采集

WIDER FACE 和

CelebA 数据集

MTCNN 人脸检测

DSST+TLD 面部追踪

ERT 人脸特征点定位

疲劳特征融合训

练集

训练检测分类模

型

眼部疲劳特征提取

嘴部疲劳特征提取

头部疲劳特征提取

疲劳驾驶检测

结束

图 5.4 工作流程图

（1）人脸检测及特征点定位：本文选择 MTCNN 算法检测驾驶员的面部区域，视

频帧通过 MTCNN 的三个子网络之后得到了人脸检测框和 5 个关键点，将其输入到级联

69

长安大学硕士学位论文

回归树 ERT 中，然后通过 ERT 算法进行人脸 68 个特征点的精确定位。

（2）面部追踪：本文选择基于 DSST 算法与 TLD 算法相结合的人脸追踪方法，避

免了单一算法带来的弊端，使得在比较复杂的驾驶环境也能具有较好的性能。

（3）面部特征提取：本文选择眼部、嘴部以及头部姿态作为疲劳驾驶的特征提取，

针对眼部区域，选择 EAR 计算其眨眼频率，针对嘴部区域，选择 MAR 判断打哈欠行为，

针对头部区域，选择 pitch 作为判断依据。

（4）疲劳融合：本文选择支持向量机 SVM 对提取到的眼部、嘴部以及头部信息特

征融合，进而判断驾驶员的疲劳状态。

5.4 实验平台工作页面

本文使用 Python 语言进行系统开发，并选用 wxPython 来绘制图形界面，疲劳驾驶

平台检测界面如图 5.5 所示。

图 5.5 疲劳驾驶平台检测系统页面

其中，摄像头 1 表示本地摄像头，摄像头 2 表示外置摄像头，点击开始检测按钮就

会进入检测。疲劳检测有打哈欠检测、闭眼检测以及点头检测，目标丢失表示连续帧内

没有检测到人脸，这时我们需要重新通过检测算法来定位驾驶员的人脸位置。疲劳驾驶

检测过程如图 5.6 和图 5.7 所示（图片中的详细说明见第四章第五小节，这里不再作重

复叙述），其中图 5.6 为清醒状态，图 5.7 为疲劳状态。

70

第五章 多特征疲劳驾驶检测

图 5.6 清醒状态

5.5 本章小结

图 5.7 疲劳状态

本章引入了支持向量机 SVM 的算法进行多特征疲劳驾驶检测，首先介绍了 SVM 的

理论基础和推导公式，并且列出了几种常见的核函数。采集 10 个人的视频数据集，设

清醒状态的学习标签为 0，疲劳状态为 1，对支持向量机进行训练，进而得到疲劳驾驶

分类模型，在数据集上进行测试，发现检测准确率可达 96.42%。接着列出了五个其他

71

长安大学硕士学位论文

算法并与本文算法进行对比，实验发现多特征疲劳驾驶检测更加准确。最后介绍了疲劳

驾驶检测系统的实现，包括开发环境、工作流程以及实验平台工作页面。

72

第六章 总结与展望

第六章 总结与展望

6.1 总结

随着科技的迅速发展，人民生活水平质量的不断提升，私家车遍及各地，且人们的

平均上班时间也在逐渐增加，这就致使出现疲劳驾驶现象进而引发诸多交通事故。目前，

疲劳驾驶已然在某种程度上损害到了人们的健康和财产安全，因此其检测也成为了当下

非常热门的研究领域。在阅读了大量有关疲劳驾驶检测的文献后，本文对现有方法进行

了分析并发现其中的不足之处，提出了将多任务卷积神经网络应用于疲劳检测中并设计

出比较可行的疲劳驾驶检测系统，本文的主要研究工作包括以下几点：

（1）分析本课题研究背景及意义，从基于机动车行为特征、驾驶员生理特征以及

面部特征的检测方法对国内外的研究方法和现状进行了分析阐述，通过对比这几种方

法，最后选择驾驶员面部特征作为本文疲劳驾驶的研究方法。

（2）介绍卷积神经网络的结构和特性，对目前的人脸检测和特征点定位方法进行

概述并选择了基于深度学习的多任务算法 MTCNN，对 MTCNN 网络的结构、损失函数

及其训练作了详细的说明，分析实验结果，然后对 MTCNN 网络的三个子网络进行了优

化。在此基础上设计了 ERT 算法进行更精确的 68 个人脸特征点定位，详细介绍了 ERT

算法的模型建立、模型拟合并对其进行训练。

（3）设计了基于 DSST 和 TLD 相结合的人脸跟踪算法。由于 DSST 算法没有跟踪

失败的检测机制，TLD 算法对于一些外界环境（比如光照等）容易受到影响，而两种算

法正好可以互补，所以本文结合了这两种目标跟踪算法，在利用 MTCNN 算法检测到人

脸之后，通过 DSST+TLD 的目标跟踪算法实现对驾驶员人脸部位的稳定跟踪。

（4）设计了多特征疲劳驾驶检测方法。分析驾驶员眼部、头部及嘴部的疲劳特征，

针对眼部，通过 ERT 算法选择 PERCLOS 准则和眨眼频率作为判断疲劳的依据，针对嘴

部，通过 MAR 算法选择打哈欠作为疲劳判断的依据，针对头部，介绍了欧拉角、相机

标定及其实现，并将俯仰角 pitch 的偏移量作为疲劳判断依据。对于目前比较单一的疲

劳驾驶致使其准确率不高的问题，选择支持向量机 SVM 并将其应用到多特征疲劳驾驶

检测中，最后设计了疲劳驾驶检测系统对驾驶员的状态进行检测。

73

长安大学硕士学位论文

6.2 展望

本文研究了基于改进 MTCNN 网络的多特征疲劳驾驶检测方法，并通过实验设计和

分析取得了比较好的检测效果。但是在实际应用场合由于环境复杂性等因素导致存在一

些不足之处。回顾本文的研究方法和成果，发现仍有以下一些可以改进的内容，这也是

我们未来研究的重点：

（1）有些驾驶员的眼睛非常小，这就使得眼睛纵横比 EAR 值波动不大，无法明显

区别睁闭眼进而导致疲劳驾驶检测失效，因此我们可以研究出一套基于驾驶员眼睛自动

调节阈值的方法来进行眼部特征提取；

（2）本文仅仅采集了 10 个人的疲劳和非疲劳状态作为研究对象，样本数量相对较

少，在统计分析时存在一定的误差，因此在以后的研究中，可以扩充一些数据来提高疲

劳驾驶检测系统的准确率；

（3）本文未对驾驶员戴墨镜以及夜间驾驶情况讨论分析，事实证明在这两种情况

下都会对疲劳检测造成一定的干扰。因此在未来的研究中，我们需要设计出更加完善的

图像采集系统；

（4）本文所使用的网络结构模型相对比较复杂，为了减少检测时间，在未来的研

究中我们可以尝试对网络模型进行更好的优化。

74

参考文献

参考文献

[1] Fortino G, Gravina R. Fall-MobileGuard: a Smart Real-Time Fall Detection System[C].

Proceedings

of

the

10th EAI

International Conference

on Body Area

Networks(BodyNet’15), 2015:44-50

[2] 王 爱 芹 , 孟 明 珠 . 一 种 基 于 脑 电 图 识 别 的 疲 劳 驾 驶 检 测 系 统 [P]. 中 国 专 利 ：

CN104586388A, 2015:05-06

[3] Rao Songhui, Li Kairui,Wu Jun, Mu Zhendong. Application of Ensemble Learning in

EEG Signal Analysis of Fatigue Driving[J]. Journal of Physics: Conference Series,

2021,1744(4)

[4] Shangguan P, Qiu T, Liu T, et al. Feature extraction of EEG signals based on functional

data analysis and its application to recognition of driver fatigue state[J]. Physiological

Measurement, 2020, 41(12):125004

[5] Pelter M M, Sukardi S, Cass S, et al. Actionable Ventricular Tachycardia During

In-hospital ECG Monitoring and its Impact on Alarm Fatigue[J]. Cardiology in Review,

2020, 19(2):79-86

[6] Hu J, Liu F, Wang P. EEG-Based Multiple Entropy Analysis for Assessing Driver

Fatigue[C]. 2019 5th International Conference on Transportation Information and Safety

(ICTIS). Liverpool, United Kingdom, United Kingdom, 2019:1290-1294

[7] Jung S j, Shin H s, Chung W y. Driver fatigue and drowsiness monitoring

system with

embedded electrocardiogram sensor on steering wheel[J]. IET Intelligent Transport

Systems, 2014, 8(1):43-50

[8] Bhardwaj R, Parameswaran S, Balasubramanian V. Comparison of Driver Fatigue Trend

on simulator and on-road driving based on EMG correlation[C]//2018 IEEE 13th

International Conference on Industrial and Information Systems (ICIIS). IEEE, 2018:

94-97

[9] Weizhe Zhang, Shuohan Wang, Nan Bao,Wenbin Li. A Wearable Cervical Fatigue

Monitoring System Based On Multi-sensor Data[J]. Frontiers in Medical Science

Research, 2020,2(1)

[10]Zhang F, Dai F. Research and Application of Fatigue Driving Monitoring and Emergency

Treatment[C]//2017 International Conference on Computer Technology, Electronics and

Communication (ICCTEC). IEEE, 2017:1072-1075

[11] Li R, Chen Y V, Zhang L. A method for fatigue detection based on Driver's steering wheel

grip[J]. International Journal of Industrial Ergonomics, 2021, 82:103083

75

长安大学硕士学位论文

[12]Cheng B, Zhang W, Lin Y, et al. Driver drowsiness detection based on multisource

information[J]. Human Factors and Ergonomics in Manufacturing & Service Industries,

2012, 22(5):450-467

[13]Wang M S, Jeong N T, Kim K S, et al. Drowsy behavior detection based on driving

information[J]. International journal of automotive technology, 2016, 17(1):165-173

[14]Ma J, Zhang J, Gong Z, et al. Study on fatigue driving detection model based on steering

operation features and eye movement

features[C]//2018 IEEE 4th International

Conference on Control Science and Systems Engineering (ICCSSE). IEEE, 2018:

472-475

[15]周云鹏. 基于面部视觉多特征融合的驾驶员疲劳检测方法研究[D]. 湖南大学, 2015

[16]邹昕彤, 王世刚, 赵文婷. 基于眼睛与嘴部状态识别的疲劳驾驶检测[J]. 吉林大学

学报(信息科学版), 2017 (02):204-11

[17]Dong Y, Zhang Y, Yue J, et al. Comparison of random forest, random ferns and support

vector machine for eye state classification[J]. Multimedia Tools and Applications, 2016,

75(19):11763-11783

[18]Li Z, Nianqiang L. Fatigue Driving Detection System Based on Face Feature[C]//2019

IEEE 2nd International Conference on Electronics Technology (ICET). IEEE, 2019:

525-529

[19]沈英超. 基于眼部特征的疲劳驾驶检测系统的研究与实现[D]. 桂林电子科技大学,

2019

[20]Devi N, Borah B. Cascaded pooling for Convolutional Neural Networks[C]//2018

Fourteenth International Conference on Information Processing (ICINPRO). IEEE, 2018:

1-5

[21]Loke K S. Texture recognition using a novel input layer for deep convolutional neural

network[C]//2018 IEEE 3rd International Conference on Communication and Information

Systems (ICCIS). IEEE, 2018:14-17

[22]Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions[C]//Proceedings of the

IEEE conference on computer vision and pattern recognition, 2015:1-9

[23]Nair V, Hinton G E. Rectified linear units improve restricted boltzmann machines vinod

nair[C]. International Conference on Machine Learning, 2010:807–814

[24]Guo Y, Sun L, Zhang Z, et al. Algorithm Research on Improving Activation Function of

Convolutional Neural Networks[C]//2019 Chinese Control And Decision Conference

(CCDC). IEEE, 2019:3582-3586

76

参考文献

[25]Xiaowei W, Xiong J, Wang R, et al. Fs-net: Medical image denoising via local receptive

field smoothing network[C]//2019 IEEE Fourth International Conference on Data Science

in Cyberspace (DSC). IEEE, 2019:70-76

[26]Caldelli Roberto, Galteri Leonardo,Amerini Irene,Del Bimbo Alberto. Optical Flow

based CNN for detection of unlearnt deepfake manipulations[J]. Pattern Recognition

Letters, 2021, 146

[27]Zarkasi A, Nurmaini S, Stiawan D, et al. Face movement detection using template

matching[C]//2018 International Conference on Electrical Engineering and Computer

Science (ICECOS). IEEE, 2018:333-338

[28]Huang J, Lin Z. Multi-feature

fatigue driving detection based on computer

vision[C]//Journal of Physics: Conference Series. IOP Publishing, 2020, 1651(1):012188

[29]Xiaoying Yang,Nannan Liang,Wei Zhou,Hongmei Lu. A Face Detection Method Based

on Skin Color Model and Improved AdaBoost Algorithm[J]. Traitement du Signal, 2020,

37(6)

[30]Wankun H. Experimental Results of Maritime Target Detection Based on SVM

Classifier[C]//2020 IEEE 3rd International Conference on Information Communication

and Signal Processing (ICICSP). IEEE, 2020:179-182

[31]Hu X, Zhang P, Zhang Q. A Novel Framework of CNN Integrated with Adaboost for

Remote Sensing Scene Classification[C]//IGARSS 2020-2020 IEEE International

Geoscience and Remote Sensing Symposium. IEEE, 2643-2646

[32]Yan H, Liu Y, Wang X, et al. A Face Detection Method Based on Skin Color Features and

AdaBoost Algorithm[C]//Journal of Physics: Conference Series. IOP Publishing, 2021,

1748(4):042015

[33]Lin Y N, Hsieh T Y, Huang J J, et al. Fast Iris localization using Haar-like features and

AdaBoost algorithm[J]. Multimedia Tools and Applications, 2020, 79(45):34339-34362

[34]Cootes T F, Taylor C J, Cooper D H, et al. Active Shape Models-Their Training and

Application[J]. Computer Vision and Image Understanding, 1995, 61(1):38-59

[35]DOLLAR P, WELINDER P, PERONA P. Cascaded pose regression[C]//2010 IEEE

Computer Society Conference on Computer Vision and Pattern Recognition. IEEE, 2010:

1078-1085

[36]Fan X, Liu R, Luo Z, et al. Explicit shape regression with characteristic number for facial

landmark localization[J]. IEEE Transactions on Multimedia, 2017, 20(3):567-579

[37]Gaol L, Li W, Huang Z, et al. Automatic Facial Attractiveness Prediction by Deep

Multi-Task Learning[C]// International Conference on Pattern Recognition. IEEE, 2018

77

长安大学硕士学位论文

[38]Rastogi A, Singh R, Sharma R, et al. The Survey of Digital Image Analysis with Artificial

Intelligence-DCNN Technique[C]//2020 9th International Conference System Modeling

and Advancement in Research Trends (SMART). IEEE, 2020:209-211

[39]Zhang K, Zhang Z, Li Z, et al. Joint face detection and alignment using multitask

cascaded convolutional networks[J].IEEE Signal Processing Letters, 2016,23(10):

1499-1503

[40]Schroff F, Kalenichenko D, Philbin J. Facenet: A unified embedding for face recognition

and clustering[C]. The IEEE Conference on Computer Vision and Pattern Recognition.

Boston:IEEE, 2015:815-823

[41]Taigman Y, Yang M, Ranzato M A, et al. Deepface: Closing the gap to human-level

performance in face verification[C]. The IEEE Conference on Computer Vision and

Pattern Recognition. Columbus: IEEE, 2014:1701-1708

[42]Cahyono F, Wirawan W, Rachmadi R F. Face Recognition System using Facenet

Algorithm for Employee Presence[C]//2020 4th International Conference on Vocational

Education and Training (ICOVET). IEEE, 2020:57-62

[43]Du Juan. High-Precision Portrait Classification Based on MTCNN and Its Application on

Similarity Judgement[J]. Journal of Physics: Conference Series,2020, 1518(1)

[44]Zhang Z, Wang Y, Jiang H, et al. Strict NMS: Pedestrian Detection in Crowd

Scenes[C]//2020 IEEE 3rd International Conference on Information Systems and

Computer Aided Education (ICISCAE). IEEE, 2020:225-230

[45]Hongchang Ku, Wei Dong. Face Recognition Based on MTCNN and Convolutional

Neural Network[J]. Frontiers in Signal Processing, 2020, 4(1)

[46]Chauhan A, Varghese B K, Rahman L M A, et al. WIDER Face Challenge using

Multi-Task Cascading Neural Network[C]//2019 IEEE 9th International Conference on

Advanced Computing (IACC). IEEE, 2019:188-192

[47]Yang S, Luo P, Loy C, et al. Wider face: A face detection benchmark[C]. The IEEE

Conference on Computer Vision and Pattern Recognition. Las Vegas: IEEE,2016:

5525-5533

[48]杜奇. 移动机器人的视觉目标跟踪方法研究与实现[D]. 哈尔滨工业大学, 2016

[49]黄浩淼, 张江, 张晶, 保峻嵘. 融合 TLD 框架的 DSST 实时目标跟踪改进算法[J]. 计

算机工程与科学, 2020, 42(09):1587-1598

[50]Tao Shifan, Li Yufeng,Huang Yufeng, Lan Xiaoyu. Face Detection Algorithm Based on

Deep Residual Network[J]. Journal of Physics: Conference Series, 2021, 1802(3)

78

参考文献

[51]Yang S, Song X, Zhang L , et al. The anti-fatigue driving system design based on the eye

blink detect[C]// Seventh International Conference on Electronics and Information

Engineering, 2017

[52]Soares G, Lima D D, Neto A M. A Mobile Application for Driver's Drowsiness

Monitoring based on PERCLOS Estimation[J]. Latin America Transactions,

IEEE

(Revista IEEE America Latina), 2019

[53]FYou F, Gong Y, Tu H, et al. A fatigue driving detection algorithm based on facial motion

information entropy[J]. Journal of advanced transportation, 2020, 2020

[54]梁元辉, 吴清乐, 曹立佳. 基于多特征融合的眼睛状态检测算法研究[J]. 计算机技

术与发展, 2021, 31(02):97-100

[55]Cech J, Soukupova T. Real-time eye blink detection using facial landmarks[J]. Cent.

Mach. Perception, Dep. Cybern. Fac. Electr. Eng. Czech Tech. Univ. Prague, 2016:1-8

[56]王迪. 基于人眼状态的疲劳检测算法研究与应用[D]. 电子科技大学, 2020

[57]Kroeger O, Huegle J, Niebuhr C A. An automatic calibration approach for a

multi-camera-robot system[C]//2019 24th IEEE International Conference on Emerging

Technologies and Factory Automation (ETFA). IEEE, 2019:1515-1518

[58]Ferrario V F, Sforza C, Serrao G, et al. Active range of motion of the head and cervical

spine:

a

three-dimensional

investigation in healthy young adults[J].Journal of

Orthopaedic Research, 2002, 20(1):122-129

[59]武昆亮. 基于面部特征与头部姿态的疲劳驾驶检测[D]. 东华大学, 2020

[60]Vapnik V N. An Overview of Statistical Learning Theory[J]. IEEE Transactions on

Neural Networks, 1999, 10(5):988–999

[61]Dong Shi. Multi class SVM algorithm with active learning for network traffic

classification[J]. Expert Systems With Applications, 2021, 176

[62]毛须伟, 景文博, 王晓曼, 等. 一种基于眼部状态的疲劳驾驶检测方法[J]. 长春理工

大学学报 (自然科学版), 2016 (2016 年 02): 125-130, 136

[63]马素刚, 赵琛, 孙韩林, 等. 一种基于卷积神经网络的哈欠检测算法[J]. 计算机科学,

2018, 45(S1):227-229+241

[64]刘朝涛, 张雪佼 . 基于图像处理的疲劳驾驶预警研究 [J]. 电子技术应用 , 2019,

45(08):104-108

[65]刘梦佳. 基于卷积神经网络的疲劳驾驶检测系统设计[D]. 郑州大学, 2020

[66]冯晓锋, 方斌. 融合面部特征的机动车驾驶人疲劳检测[J/OL]. 机械科学与技术

79

长安大学硕士学位论文

术:1-7[2021-04-04]

80

攻读学位期间取得的研究成果

攻读学位期间取得的研究成果

发表论文：

[1] 王晓莉, 薛丽. 标签噪声学习算法综述[J]. 计算机系统应用, 2021, 30(01):10-18

软件著作权：

[1] 薛丽, 韩肖. 智能违法疲劳驾驶行为检测软件 V1.0.No.06136954,2020SR0856114

[2] 王佳婧, 薛丽. 金融微信服务平台软件 V1.0.No.06376934,2020SR1053125

81

致谢

致谢

行文至此，百感交集，意味着我三年的研究生生涯即将拉上帷幕，追梦长大，终有

一别。时光荏苒，岁月如梭，始于2018年金秋，终于2021年盛夏，这三年时光，目光所

及，皆是回忆。在这座充满智慧与包容的校园里，留下的是汗水和青春，带走的是沉甸

甸的收获，纵有万般不舍，依旧心存感激。

我想把我最深的谢意给我的导师马祥教授。至今仍能记得三年前研究生复试与老师

的面谈，马老师面带微笑，和蔼可亲。原本我只是一个普通二本的学生，在人才济济的

复试梯队里，并不及他人优秀，感谢我的导师接纳了我，给予我成为“长大人”的机会，

并且制定我的研究方向，在论文撰写过程中提出了很多宝贵的建议。这三年我深深感受

到了导师学术造诣的高深，马老师治学严谨、工作拼搏的精神也不断激励着我奋勇向前。

其次，感谢我的父母躬耕陇亩、不辞劳苦换来了我二十余载暖衣饱食、无忧无虑的

生活。我的求学路步步坚定不移主要源于他们对我无私的爱和淳淳教导，无以为报，只

想全力以赴，带着他们这份深沉的爱继续前行。另外，还有我二十几年相爱相杀的哥哥，

感谢在我每一个人生关键路口给予我超越任何人的指导和帮助。

另外，还要感谢我的室友这三年来对我的包容，感谢在研究生期间遇到了崔恩杰，

陪我一起学习、一起吃饭、一起逛街，因为有她这个知心大姐我的生活也变得更加丰富

多彩。感谢我的同门王晓丽在学习上互相交流共同进步、生活上互帮互助，同时在找工

作的时候积极为我出谋划策。另外，感谢我的闺蜜王佳茹在研究生期间给予我精神上的

支持和鼓励，让我面对困难时无所畏惧。

以梦为马，不负韶华。2020年的疫情让我看到了中国的力量和担当，感谢在疫情期

间始终守在前线的抗疫人员，这次疫情也让我懂得珍惜身边的人。感谢那个努力奋斗的

自己，感谢在长大这片热土收获成长的自己，每一次的成长都是未来奋力拼搏的力量。

最后，感谢在百忙之中评审本论文以及参加答辩的各位老师、专家及学者们，感谢

你们提出宝贵的建议和意见！

83

