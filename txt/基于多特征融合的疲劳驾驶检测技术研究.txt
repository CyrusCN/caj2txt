硕士学位论文 

基于多特征融合的疲劳驾驶检测技术研究 

作者姓名：                 杜莹                      

指导教师:                周祚峰 研究员               

             中国科学院西安光学精密机械研究所   

学位类别:                 工程硕士 

学科专业:              电子与通信工程  

培养单位:       中国科学院西安光学精密机械研究所 

2021 年  6  月 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Research on Fatigue Driving Detection Technology  

Based on Multi-feature Fusion 

A thesis submitted to 

University of Chinese Academy of Sciences 

in partial fulfillment of the requirement 

for the degree of 

Master of Engineering 

in Electronics and Communications Engineering 

By 

Du Ying 

Supervisor :  Professor Zhou Zuofeng  

Xi’an Institute of Optics & Precision Mechanics, 

Chinese Academy of Sciences 

June 2021 

 
 
 
 
 
 
                                        
 
 
 
 
 
 
 
摘    要 

摘  要 

近年来，我国由疲劳驾驶所导致的汽车交通事故高发，且数量逐年增多，这

已经严重威胁到了人们的生命健康和财产安全。预判驾驶员的疲劳状态并预警，

能从根本上控制交通事故的发生，由于汽车驾驶员的疲劳状态可以直接反映在视

觉特征、生理指标和车辆行为上，现已逐渐成为国内外的学术领域和汽车行业的

重要技术研究热点。本文针对目前汽车驾驶员疲劳评估方法费时、准确率低、硬

件要求高的缺陷，提出一种基于多特征融合进行疲劳驾驶检测的方法。主要研究

工作为： 

1.  对视频图像进行预处理。视频图像历经采集、传输、存储，在此过程中其质

量会因受到噪声干扰而降低，而且在行车过程中驾驶员的面部区域会被不同

光线条件所影响，因此本文预先对视频图像进行下述两种处理，保证能够准

确检测人脸：（1）基于双邻域中值滤波去除图像噪声；（2）结合直方图均

衡化算法和对数变换均匀图像光照。 

2.  实时人脸检测。综合考虑速度和准确性这两个指标，本文选用 HOG 特征检

测视频图像中的人脸，即在人脸图像上按照不同大小的窗口进行滑动扫描，

同时提取该块的 FHOG 特征，并用 SVM 训练出的人脸分类器判定当前块是

否属于人脸，结束对整幅图像的扫描后，存在同一人脸区域被多次检出的情

况，用非极大值抑制对此现象进行处理，然后得到人脸检测的最终结果。经

实验，该方法对遮挡、人脸变化具有鲁棒性。根据实际应用需要，本文只进

行最大人脸检测。 

3.  高精度面部特征点定位。在正确检出人脸的基础上，本文基于级联的残差回

归树标注 68 个人脸特征点，这些点的坐标信息将用于计算疲劳特征参数。

实验表明该方法既方便又有高识别率，可以为后续的头部姿态估计提供准确

的人脸特征点坐标值。为了排除其他人脸信息的干扰，本文只对检测出的最

大人脸唯一定位人脸特征点。 

4.  眼部和嘴部疲劳检测。基于 PERCLOS 准则由人眼的 12 个特征点计算眼睛

纵横比 EAR，根据 EAR 阈值来识别眼部睁闭状态，进而实现眨眼检测，然

后统计在单位时间内发生眨眼的次数，从而求出眨眼频率；对于嘴部疲劳状

I 

基于多特征融合的疲劳驾驶检测技术研究 

态的识别，首先根据嘴巴的 10 个特征点计算嘴部高宽比 MAR，找寻合理的

MAR 阈值进行哈欠初判，再结合嘴巴张开持续时间来二次验证是否打哈欠，

同样地，对单位时间内的打哈欠次数进行统计，求出打哈欠频率。 

5.  头部姿态角计算。头部姿态估计是从二维视频图像映射到三维空间的过程，

本文从定位出的 68 个 2D 人脸关键点中选择了 14 个具有代表性的点，通过

用这些点去匹配 3D 标准人脸模型，求解出 3D 模型点和对应 2D 图像点之间

存在的转换关系，则头部姿态角可由旋转矩阵求得，从而实现头部姿态估计。 

6.  多特征融合进行疲劳状态判断。提取出眼睑开合度、眨眼频率、嘴巴张开度、

打哈欠频率和头部姿态角五种疲劳特征，得到七个特征参数，选定了采用

RBF 核函数的支持向量机将上述特征融合起来建立疲劳检测模型，然后在自

制的疲劳驾驶检测视频数据集上开展对比实验，一方面证明本文所提出的方

法具有较快的运行速度，可以用于进行实时检测；另一方面实验结果表明本

文基于多特征融合的疲劳驾驶检测算法正确识别疲劳状态的能力明显高于

传统的基于单疲劳特征的方法，并且同另外两种现有方法的疲劳驾驶检测准

确率进行比较，进一步体现出了所提方法的优良性能。 

关键词：疲劳识别，眨眼检测，哈欠判断，头部姿态估计，特征融合 

II 

 
 
 
Abstract 

Abstract 

In  recent  years,  my  country  has  seen  a  high  incidence  of  automobile  traffic 

accidents caused by fatigue driving, and the number has increased year by year, which 

has seriously threatened people's life, health and property safety. Predicting the fatigue 

state of the driver and warning it can fundamentally control the occurrence of traffic 

accidents. Whether the driver is fatigued or not can be directly reflected in the visual 

characteristics, physiological indicators and vehicle behavior/due to the fatigue state of 

the car driver. Reflected in visual characteristics, physiological indicators and vehicle 

behavior,  it  has  gradually  become  an  important  technical  research  hotspot  in  the 

academic  field  and  the  automotive  industry  at  home  and  abroad.  Aiming  at  the 

shortcomings of current automobile driver fatigue assessment methods that are time-

consuming,  low  accuracy,  and  high  hardware  requirements,  this  paper  proposes  a 

method for fatigue driving detection based on multi-feature fusion. The main research 

work is: 

1.  Preprocess the video image. The video image is collected, transmitted, and stored. 

During this process, its quality will be reduced due to noise interference, and the 

driver’s facial area will be affected by different light conditions during driving. 

Therefore,  this  article  preliminarily  performs  the  following  on  the  video  image 

Two kinds of processing ensure accurate face detection: (1) Remove image noise 

based on dual-neighborhood median filtering; (2) Combine histogram equalization 

algorithm and logarithmic transformation to uniform image illumination. 

2.  Real-time face detection. Considering the two indicators of speed and accuracy, 

this article selects HOG feature inspection measure the face in the video image, 

that  is,  perform  sliding  scanning  on  the  face  image  according  to  windows  of 

different sizes, and at the same time extract the FHOG feature of the block, and 

use  the  face  classifier  trained  by  SVM  to  determine  whether  the  current  block 

belongs to a face, and the end of the After scanning the entire image, there is a 

situation where the same face area is detected multiple times. This phenomenon is 

processed  with  non-maximum  suppression,  and  then  the  final  result  of  face 

detection is obtained. Through experiments, this method is robust to occlusion and 

face  changes.  According  to  actual  application  needs,  this  article  only  performs 

maximum face detection. 

III 

基于多特征融合的疲劳驾驶检测技术研究 

3.  High-precision facial feature point positioning. Based on the correct detection of 

the  face,  this  paper  is  based  on  the  cascaded  residual  regression  tree  marks  68 

facial feature points, and the coordinate information of these points will be used 

to calculate the fatigue feature parameters. Experiments show that this method is 

convenient and has a high recognition rate, and can provide accurate facial feature 

point coordinates for subsequent head pose estimation. In order to eliminate the 

interference  of other face information, this  paper only  locates  the facial  feature 

points uniquely for the largest face detected. 

4.  Eye and mouth fatigue detection. Calculate the eyes from the 12 feature points of 

the human eye based on the PERCLOS criterion aspect ratio EAR, according to 

the EAR threshold to identify the eye open and closed state, and then achieve blink 

detection, and then count the number of blinks in a unit time, so as to find the blink 

frequency;  for  the  recognition  of  the  mouth  fatigue  state,  first  according  to  the 

mouth 10 Calculate the mouth height-to-width ratio MAR, find a reasonable MAR 

threshold for the initial judgment of yawning, and then combine the mouth opening 

duration to verify whether you are yawning again. Similarly, the number of yawns 

per unit time is counted to find the frequency of yawning. 

5.  Calculation of head attitude angle. Head pose estimation is the process of mapping 

from  a  two-dimensional  video  image  to  a  three-dimensional  space.  This  paper 

selects 14 representative points from the 68 2D face key points located, and uses 

these  points  to  match  the  3D  standard  face  Model,  the  conversion  relationship 

between the 3D model points and the corresponding 2D image points is solved, 

then  the  head  posture  angle  can  be  obtained  from  the  rotation  matrix,  so  as  to 

realize the head posture estimation. 

6.  Multi-feature fusion to judge fatigue state. Extract five fatigue features, such as 

the  degree of eyelid opening, blinking frequency,  mouth  opening  degree,  yawn 

frequency,  and  head  posture  angle,  from  which  seven  feature  parameters  are 

obtained.  The  support  vector  machine  using  RBF  kernel  function  is  selected  to 

fuse  the above  features  to establish a fatigue  detection  model,  and then use  the 

self-made fatigue driving detection video A comparative experiment on the data 

set proves that the method proposed in this paper has a faster running speed and 

can be  used for  real-time  detection; on the other  hand,  the  experimental  results 

show  that  the  fatigue  driving  detection  algorithm  based  on  multi-feature  fusion 

correctly recognizes the fatigue state. The ability is significantly higher than the 

IV 

Abstract 

traditional method based on single fatigue feature, and compared with the other 

two existing methods of fatigue driving detection accuracy, it further demonstrates 

the excellent performance of the proposed method. 

Key  Words:  Fatigue  recognition,  Blink  detection,  Yawn  judgment,  Head  posture 

estimation, Feature fusion 

V 

目   录 

目    录 
第 1 章  绪论 .............................................................................................................. 1 
1.1  研究背景与意义................................................................................................. 1 

1.2  国内外研究现状................................................................................................. 2 

1.3  本文主要内容及组织结构................................................................................. 5 

1.3.1  主要研究内容.............................................................................................. 5 

1.3.2  本文组织结构.............................................................................................. 6 

第 2 章  疲劳驾驶检测相关技术介绍 ............................................................... 9 
2.1  视频图像预处理算法介绍................................................................................. 9 

2.1.1  图像去噪算法.............................................................................................. 9 

2.1.2  光照均衡算法............................................................................................ 12 

2.2  人脸检测及特征点定位................................................................................... 14 

2.2.1  人脸检测算法概述.................................................................................... 14 

2.2.2  人脸特征点定位算法概述........................................................................ 16 

2.3  疲劳检测原理................................................................................................... 18 

2.3.1  眼部疲劳检测原理.................................................................................... 18 

2.3.2  嘴部疲劳检测原理.................................................................................... 19 

2.3.3  头部疲劳检测原理.................................................................................... 20 

2.4  支持向量机理论............................................................................................... 21 

2.5  本章小结........................................................................................................... 24 

第 3 章  基于多特征融合的疲劳驾驶检测 .................................................... 25 
3.1  图像预处理....................................................................................................... 25 

3.1.1  基于双邻域中值滤波的图像去噪............................................................ 25 

3.1.2  结合直方图均衡化和对数变换的图像光照均衡.................................... 25 

3.2  基于 HOG 特征的人脸检测 ............................................................................ 28 

3.2.1  HOG 特征介绍 .......................................................................................... 29 

3.2.2  HOG 特征提取 .......................................................................................... 29 

3.2.3  人脸检测实现原理.................................................................................... 32 

3.3  基于级联的残差回归树定位人脸特征点....................................................... 33 

3.4  疲劳特征参数提取........................................................................................... 36 

3.4.1  人眼特征疲劳判断.................................................................................... 37 

VII 

基于多特征融合的疲劳驾驶检测技术研究 

3.4.2  嘴部疲劳状态检测.................................................................................... 42 

3.4.3  头部姿态信息提取.................................................................................... 44 

3.5  基于特征融合的疲劳驾驶检测....................................................................... 49 

3.5.1  基于核学习的特征融合............................................................................ 49 

3.5.2  疲劳检测模型的搭建................................................................................ 51 

3.6  本章小结........................................................................................................... 52 

第 4 章  疲劳驾驶检测的实现 ........................................................................... 53 
4.1  图像预处理....................................................................................................... 54 

4.1.1  图像去噪.................................................................................................... 54 

4.1.2  图像光照均衡............................................................................................ 56 

4.2  多特征提取的实现........................................................................................... 57 

4.2.1  人脸检测.................................................................................................... 57 

4.2.2  人脸特征点定位........................................................................................ 58 

4.2.3  疲劳特征提取............................................................................................ 61 

4.3  疲劳驾驶检测的实现....................................................................................... 69 

4.4  本章小结........................................................................................................... 72 

第 5 章  总结与展望 .............................................................................................. 73 
5.1  总结................................................................................................................... 73 

5.2  展望................................................................................................................... 74 

参考文献 ................................................................................................................... 77 

致  谢 .......................................................................................................................... 81 
作者简历及攻读学位期间发表的学术论文与研究成果 .......................... 83 

VIII 

图目录 

图目录 

图 1.1 2010-2019 年我国汽车交通事故统计图 .......................................................... 1 

图 1.2 疲劳驾驶检测的主要方法................................................................................. 3 

图 2.1 中值滤波示意图............................................................................................... 10 

图 2.2 两个 3x3 均值滤波器模板 ............................................................................... 11 

图 2.3 光照不均图像................................................................................................... 12 

图 2.4 同态滤波的基本步骤....................................................................................... 13 

图 2.5 反射图............................................................................................................... 13 

图 2.6 常用的人脸检测方法....................................................................................... 16 

图 2.7 人脸特征点定位............................................................................................... 16 

图 2.8 人脸特征点定位方法汇总............................................................................... 17 

图 2.9 最优分类超平面............................................................................................... 23 

图 2.10 低维映射到高维............................................................................................. 23 

图 3.1 自适应非线性变换函数曲线........................................................................... 27 

图 3.2 输入输出灰度对比........................................................................................... 28 

图 3.3 人脸图像及其 HOG 特征 ................................................................................ 29 

图 3.4 HOG 特征提取基本流程 ................................................................................. 30 

图 3.5 HOG 特征提取中图像的划分 ......................................................................... 30 

图 3.6 梯度直方图....................................................................................................... 32 

图 3.7 人脸检测的实现原理....................................................................................... 32 

图 3.8 FHOG 特征 ....................................................................................................... 33 

图 3.9 人脸特征点模型............................................................................................... 34 

图 3.10 PERCLOS 的测量原理 .................................................................................. 37 

图 3.11 标定出的人眼区域坐标................................................................................. 39 

图 3.12 眼睛 EAR 值变化 ........................................................................................... 40 

图 3.13 眨眼对应的 EAR............................................................................................ 40 

图 3.14 左右眼 EAR 变化曲线 ................................................................................... 41 

图 3.15 嘴唇轮廓结构示意图..................................................................................... 43 

IX 

基于多特征融合的疲劳驾驶检测技术研究 

图 3.16 嘴唇区域坐标标示......................................................................................... 43 

图 3.17 头部姿势......................................................................................................... 44 

图 3.18 头部姿态信息的提取步骤............................................................................. 45 

图 3.19 2D 和 3D 人脸特征点的对应 ........................................................................ 45 

图 3.20 各个坐标系展示............................................................................................. 46 

图 3.21 图像坐标系..................................................................................................... 46 

图 3.22 成像原理......................................................................................................... 47 

图 3.23 信息融合处理过程及层次划分..................................................................... 50 

图 4.1 疲劳驾驶检测算法的实现流程....................................................................... 53 

图 4.2 AR 人脸数据库部分样本数据 ........................................................................ 54 

图 4.3 加噪后的图像................................................................................................... 54 

图 4.4 图像去噪效果对比........................................................................................... 55 

图 4.5 彩色图像匀光前后的对比............................................................................... 57 

图 4.6 模拟驾驶情形下的人脸检测结果................................................................... 58 

图 4.7 人脸 68 个关键点 ............................................................................................. 59 

图 4.8 模拟驾驶情形下的人脸特征点定位结果....................................................... 59 

图 4.9 唯一定位人脸................................................................................................... 60 

图 4.10 一段时间内人眼 EAR 的变化图示 ............................................................... 61 

图 4.11 EAR 数据的筛选 ............................................................................................ 62 

图 4.12 EAR 均值的变化曲线 .................................................................................... 62 

图 4.13 睁闭眼测试图片............................................................................................. 63 

图 4.14 EAR 阈值寻优结果图 .................................................................................... 63 

图 4.15 眨眼波形......................................................................................................... 64 

图 4.16 张口度曲线..................................................................................................... 65 

图 4.17 YawDD 数据集示例 ...................................................................................... 66 

图 4.18 两种方法准确度比较..................................................................................... 67 

图 4.19 人脸模型......................................................................................................... 68 

图 4.20 头部姿态检测结果......................................................................................... 69 

X 

表目录 

表目录 

表 3.1 人脸检测中 Haar Cascade 和 HOG 方法对比 ................................................ 28 

表 3.2 疲劳特征汇总................................................................................................... 49 

表 3.3 各特征的基本统计学信息............................................................................... 49 

表 3.4 常用特征级信息融合算法及其特点............................................................... 50 

表 3.5 常用核函数....................................................................................................... 51 

表 4.2 两种方法实验结果统计................................................................................... 67 

表 4.3 3D 和 2D 人脸模型特征点对应表 .................................................................. 68 

表 4.4 视频数据集介绍............................................................................................... 70 

表 4.5 疲劳检测耗时情况........................................................................................... 71 

表 4.6 不同疲劳特征下检测准确率对比................................................................... 71 

表 4.7 不同疲劳驾驶检测方法准确率对比............................................................... 72 

XI 

缩写列表 

缩写列表 

BF (Blink Frequency) 

眨眼频率 

PERCLOS (Percentage of Eyelid Closure over the Pupil 

眼睑闭合度 

over Time) 

EAR (Eye Aspect Ratio) 

ASM (Active Shape Model) 

AAM (Active Appearance Model) 

CLM (Constrained Local Model) 

CPR(Cascaded Pose Regression) 

CNN (Convolutional Neural Network) 

眼睛纵横比 

主动形状模型 

主动外观模型 

约束局部模型 

级联姿态回归 

卷积神经网络 

DCNN (Deep Convolutional Neural Network) 

深度卷积神经网络 

MTCCN (Multi-task Cascaded Convolutional Networks)  多任务级联卷积网络 

HOG (Histogram of Oriented Gradient) 

SVM (Support Vector Machine) 

NMS (Non-Maximum Suppression) 

ERT (Ensemble of Regression Trees) 

MAR (Mouth Aspect Ratio) 

YF (Yawn Frequency) 

3D (Three-Dimension) 

PnP (Perspective-n-Point) 

DLT (Direct Linear Transform) 

PSNR (Peak Signal to Noise Ratio) 

梯度方向直方图 

支持向量机 

非极大值抑制 

级联回归树 

嘴唇纵横比 

打哈欠频率 

三维 

多点透视成像 

直接线性变换 

峰值信噪比 

XIII 

 
 
 
 
第 1 章 绪论 

第 1 章  绪论 

1.1  研究背景与意义 

根据国家统计局官网公布的数据，截止 2019 年底，我国民用汽车的数量达

25376.38 万辆，同比增长 9.23%；汽车驾驶员人数达 39752.86 万人，同比增长

7.66%。汽车极大地便利了人们的出行，在交通运输中，它的作用更是无可替代，

然而汽车的普及也不可避免地造成道路交通事故频频发生。我国是世界上道路交

通事故最多的国家之一[1]，这不仅导致伤亡人员数量巨大，给个人、家庭以及国

家都带来了不可挽回的损失，而且严重阻碍了我国发展经济、保障社会稳定。由

下图显示的我国近 10 年汽车交通事故相关数据可以看出，自 2010 年以来，事故

发生数和受伤人数基本同步变化，死亡人数起伏波动较小，但是仍旧不容乐观，

因事故而直接损失的财产金额巨大，且整体呈现出上升的趋势。 

180000

160000

140000

120000

100000

80000

60000

40000

20000

0

汽车交通事故发生数（起）

汽车交通事故死亡人数
（人）

汽车交通事故受伤人数
（人）

汽车交通事故直接财产损失
（万元）

图 1.1 2010-2019 年我国汽车交通事故统计图 

Figure 1.1 Statistics of our country motor traffic accidents from 2010 to 2019 

作为直接操纵车辆的人以及参与道路交通的重要人员，汽车司机的驾驶行为

是影响交通安全的关键[2]。调查结果表明，疲劳驾驶是目前造成交通事故的最主

要原因之一，由它所引发的交通事故数逐年上升。疲劳在驾驶场景中被划分为两

种类型，分别是身体疲劳、精神疲劳，它们都会降低驾驶员执行驾驶职责的能力：

身体疲劳是由于进行了体育活动，体力消耗过大引起的；精神疲劳是由使精神状

态变差的生理因素，如：连续几个小时保持清醒、睡眠障碍、工作过量、压力和

1 

 
 
基于多特征融合的疲劳驾驶检测技术研究 

药物等引起的，它会影响驾驶员的注意力、警觉性、反应速度，以及判断和决策

的能力。驾驶员微微疲劳时，不能在合适时机换挡，或是错误换挡；疲劳程度较

深时，操纵车辆的动作变得呆滞，甚至于忘记进行操作；严重疲劳时，很容易无

意识地驾车，或产生间断性的短时间入睡现象，随着疲劳程度的不断加深，则会

直接丧失对车辆的控制意识和能力——这些都大大增加了发生道路交通事故的

概率。研究发现，若能在感知驾驶员变得疲劳时，立即制止其继续驾车，就可以

在很大程度上避免许多交通事故的发生，保障车内人员的生命、财产安全。然而，

疲劳驾驶具有很强的隐蔽性，通常情况下只有驾驶员自身能察觉到，所以如果可

以对驾驶员进行及时、准确的疲劳驾驶检测，并在确定驾驶员的疲劳状态后给予

其某种警告，以对其进行提醒，就可以大大减少疲劳驾驶的伤害。因此，疲劳驾

驶检测和预警作为减少交通事故的重要手段，现已逐渐成为国内外的学术领域和

汽车行业的重要技术研究热点。 

国内外关于疲劳驾驶检测的研究主要包含三大关键技术，它们分别是驾驶疲

劳判断、监测预警、辅助控制，覆盖了多个学科领域，如：医学、行为学、生理

科学、车辆工程、自动控制、计算机视觉等，任何一处疲劳驾驶检测技术研究上

的进展都能反作用于上述某一方面，并产生积极的推动作用。另外，疲劳驾驶检

测技术具有极其广阔的应用前景，除了面向汽车驾驶员外，类似地也可以对飞行

员、火车司机、轮船驾驶员等进行疲劳检测；还可以将疲劳检测应用于车间操作

工人，提高生产一线的安全性，营造良好的工作环境，保障工人的生命健康权[3]。

由此可见，对疲劳驾驶检测技术进行研究具有重大而深远的意义。 

1.2  国内外研究现状 

疲劳驾驶检测在早期主要着眼于医学角度，其相关研究的开展借助了许多医

疗设备。20 世纪 90 年代，疲劳驾驶的检测有了巨大突破，许多车载疲劳驾驶电

子检测装置纷纷涌现，其中尤以美国科学家研发的 DDDS（The  Drowsy  Driver 

Detection System）最具代表性，它获取的驾驶员疲劳数据有情绪特征、眨眼频率

（Blink Frequency, BF）、眨眼持续时间等[4]。我国研究疲劳驾驶的起始时间是上

世纪 60 年代，较晚于国外，最初的研究对象是飞行员，并且在 2003 年前主要是

由国内的少数几个高等院校进行理论上的钻研与探索[5]。2003 年以后，虽然我国

2 

 
第 1 章 绪论 

有越来越多的单位纷纷着手此项研究，也有了一定的成果，但总体上，我国在此

领域还稍微落后于欧美发达国家。 

图 1.2 展示了目前疲劳驾驶检测采用的主要方法，这些方法可以分为两大类： 

图 1.2 疲劳驾驶检测的主要方法 

Figure 1.2 Main methods of fatigue driving detection 
（1）非接触式检测，即不需要驾驶员佩戴任何接触身体的传感器的检测方式。

它又可以进一步划分为基于计算机视觉的检测方式和基于人车交互特性的检测

方式： 

1）在基于计算机视觉的检测方式中，作用对象可以是驾驶员也可以是车辆

本身。 

当作用于驾驶员时，研究表明表征疲劳的信号大多会在驾驶员的脸部显著体

现，一旦感到疲劳，眼睛睁闭、嘴巴张合以及头部朝向等均会出现不同于清醒时

的行为特征，因此目前基本都是以人脸特征变化为基础，检测疲劳的相关指标。

一般将摄像头固定在汽车前挡风玻璃上，对驾驶员的面部进行实时监控，并由拍

摄画面监测驾驶员的面部特征[6]，如眨眼频率（人疲劳时眨眼频率一般会降低）、

眼睑闭合度（Percentage of Eyelid Closure over the Pupil over Time, PERCLOS）、

3 

 
 
基于多特征融合的疲劳驾驶检测技术研究 

眼球跟踪（观察驾驶员是否正视前方，是否主动检查后视镜和侧视镜）、头部姿

态（人打瞌睡时通常头会垂得更低，点头会更频繁）、打哈欠频率（人疲劳时打

哈欠频率一般会升高）等，从而判断驾驶员是否疲劳。这种方法无法顾及到驾驶

员面部特征的个体差异性，并且由于光线直接关系到所拍画面的效果，进而也会

影响检测性能；另外，驾驶员面部的遮挡物（如墨镜、口罩等）会对检测造成极

大的干扰。 

当作用于车辆本身时，一般将摄像头安置在车头部，拍摄车道中车辆所处的

实时位置，从而获得车道偏移数据，据此来判断驾驶员的疲劳状态。这种方法对

道路条件的要求比较严苛，比如当没有道路标识或道路标识不清晰时就很难进行

分析；而且由于天气和照明因素直接关系到所拍画面的效果，进而也会影响检测

性能。 

2）在基于人车交互特性的检测方式中，先通过传感器获取车辆在行驶过程

中的参数，包括状态参数（行驶速度、加速度和车身横摆角等）和驾驶员打方向

盘、踩踏板、踩离合等的行为参数，从而判断车辆是否超速、车距是否太近、驾

驶员是否及时刹车、方向盘是否及时调整等，来进一步判断驾驶员是否疲劳。这

种方法容易被司机个体行为差异、车辆本身特点和路况等因素所干扰[7]。 

（2）接触式检测，即需要在驾驶员身上安装相应检测生理信号的装置的检测方

式。这些生理信号包括脑电图（人疲劳时 8-13 赫兹的 alpha 波活动减少，4-8 赫

兹的 theta 波活动增加）、心电图（人疲劳时心率变化会变慢）、肌电图（肌电

的频率和疲劳程度成负相关，肌电的幅值和疲劳程度成正相关）、眼电图（检测

眼球运动方向和速度）、呼吸、皮肤电传导等。虽然这种方法准确、可靠，且受

外界影响较小，但是由于它要求驾驶员佩戴接触身体的传感器以采集生理信号，

在一定程度上会对驾驶员产生干扰。 

综上所述，主要从视觉特征、生理特征和车辆行为特征三个方面来检测疲劳

驾驶[8]。采用单一的疲劳特征信息判别驾驶员的疲劳状态存在局限性，容易造成

误判或漏判，因此多信息融合的疲劳检测方法逐渐成为研究的热点——结合多个

疲劳特征参数对克服光照、遮挡、天气、路标等的影响，提高检测的实时性、准

确度和鲁棒性，降低误报率具有重大意义。目前主要在以下四个方面对驾驶员疲

劳信息融合进行研究，分别是：融合多个不同的生理特征、视觉特征或融合生理

4 

 
第 1 章 绪论 

特征、视觉特征以及融合视觉特征、车辆行为特征，其中广受青睐的是视觉特征

之间的融合和视觉特征与其他特征之间的融合，这也是今后的发展趋势。 

1.3  本文主要内容及组织结构 

本文提出了一种基于多特征融合的疲劳驾驶检测技术，其实现过程为首先利

用车载摄像头实时采集驾驶员开车时的人脸视频，然后在人脸检测和特征点定位

的基础上提取出视频图像中驾驶员的眼睑闭合度、眨眼频率、嘴巴张开度、打哈

欠频率和头部姿态作为疲劳特征参数，并基于使用 RBF 核函数的支持向量机对

融合后的上述特征数据训练并测试，从而检测驾驶员的疲劳状态。 

1.3.1  主要研究内容 

（1） 视频图像预处理 

本文预先基于双邻域中值滤波对图像进行平滑去噪，以及结合直方图均衡化

和对数变换对图像进行光照均衡。 

（2） 人脸检测及面部特征点定位 

人脸检测：本文利用 HOG 特征检测视频图像中驾驶员的面部区域。 

面部特征点定位：在人脸检测的基础上，本文建立一个级联的残差回归树来

标注 68 个面部特征点。 

（3） 疲劳特征提取 

利用定位出的人脸关键点之间的几何关系进行下述三种疲劳特征的提取。 

1）眼部特征提取：根据人眼纵横比 EAR 识别眼部睁闭状态，进而进行眨眼

检测，再提取出眨眼频率这一眼部疲劳特征。 

2）嘴部特征提取：结合嘴部高宽比 MAR 和嘴巴张开持续时间进行双阈值

法哈欠检测，再提取出打哈欠频率这一嘴部疲劳特征。 

3）头部特征提取：用标准 3D 人脸模型匹配检测出的 2D 人脸关键点，然后

选择 14 个具有代表性的 2D 点，求解出它们和对应的 3D 点之间的转换关系，最

后由旋转矩阵计算欧拉角，由欧拉角可以知道头部相对于 x, y, z 轴的角度，根据

角度来估计对应的头部姿态。 

（4） 多特征融合进行疲劳状态判断 

5 

 
基于多特征融合的疲劳驾驶检测技术研究 

融合提取出的眼睑闭合度、眨眼频率、嘴巴张开度、打哈欠频率以及表示头

部姿态的三个欧拉角这七个特征参数，然后利用支持向量机训练融合特征得到疲

劳检测模型。 

1.3.2  本文组织结构 

本文主要围绕基于多特征融合的疲劳驾驶检测技术展开研究，分为以下 5 个

章节。 

第一章  绪论。先对疲劳驾驶检测的研究背景及意义进行了说明，然后简述

了疲劳驾驶检测在国内外的研究现状。 

第二章  相关技术背景。本章主要对疲劳驾驶检测的过程中用到的相关算法

进行综述。首先介绍了常用的图像去噪和光照均衡算法；接着描述了国内外人脸

检测和人脸特征点定位算法的发展历程，并对不同算法的实现过程和优缺点进行

了简要概括；然后解释了通过驾驶员眼部、嘴部和头部检测疲劳的原理，分别为

人眼状态识别、哈欠特征检测和头部姿态估计，同时对应介绍了具有代表性的实

现方法；最后概述了支持向量机理论的基本思想、数学推导和分类优点。 

第三章  基于多特征融合的疲劳驾驶检测。本章主要讲述了基于多特征融合

的疲劳驾驶检测的相关原理，包括人脸检测、人脸特征点定位以及疲劳特征参数

提取的理论基础。首先介绍了本文实现图像预处理所使用的算法，包括基于双邻

域中值滤波的图像去噪和结合直方图均衡化和对数变换的图像光照均衡；接着详

细描述了图像的 HOG 特征及其提取步骤，并阐释了利用 HOG 特征检测人脸的

实现思路；再从应用优势和算法流程两方面对基于级联的残差回归树的人脸特征

点定位模型进行了简明扼要的说明；然后介绍了本文判断是否疲劳所选取的眼部、

嘴部和头部的特征指标，分别是：①基于 PERCLOS 的眼睛纵横比和眨眼频率；

②基于 EAR 的嘴唇纵横比、张口持续时间和打哈欠频率；③利用头部的姿态角

检测抬头仰头和左右偏头状态；最后选定了采用 RBF 核函数的支持向量机建立

基于特征融合的疲劳检测模型。 

第四章  疲劳驾驶检测的实现。本章主要对基于多特征融合的疲劳驾驶检测

方法进行实验测试和结果分析。首先利用 3.1 节中所提到的图像预处理算法实现

了图像去噪和图像光照均衡，并对比分析了处理前后的图像效果；然后对本文人

脸检测和人脸特征点定位方法进行实验测试，并作结果展示，经分析，这两种方

6 

 
第 1 章 绪论 

法都满足常见疲劳驾驶场景的应用需要；接着分别阐述了本文提取眼部、嘴部和

头部特征的五个疲劳指标的过程，这五个指标分别是：眼睑闭合度、眨眼频率、

嘴巴张开度、打哈欠频率和头部姿态信息；最后利用 SVM 训练多特征融合的疲

劳驾驶检测模型，并利用自制的驾驶员疲劳检测视频数据集开展实验。 

第五章  总结与展望。本章先从四个方面对本文研究内容做出高度概括，然

后指出其中有待改进或完善的地方，并提供了相应的解决思路。 

7 

 
 
基于多特征融合的疲劳驾驶检测技术研究 

8 

 
 
 
 
第 2 章 疲劳驾驶检测相关技术介绍 

第 2 章  疲劳驾驶检测相关技术介绍 

2.1  视频图像预处理算法介绍 

图像由采集到传输再到存储的过程中难免被噪声污染，其质量受到影响，会

有不同程度的下降，另外拍摄时外界光线的变化会使图像过暗、过亮或光照分布

不均衡，在本文疲劳驾驶检测的应用场景下，上述现象都会对检测人脸、提取特

征信息和识别疲劳状态的准确性产生一定影响。因此对于采集到的视频，有必要

先进行图像序列的预处理操作，以尽可能消除图像中影响检测效果的信息，如噪

声、光照不均等，以及对检测无用的信息，保证后续提取、分析感兴趣区域的准

确性[9]。本文中涉及到的视频图像预处理算法主要包括图像去噪算法和光照均衡

算法。 

2.1.1  图像去噪算法 

在采集图像信号过程中，通常会存在诸如传感器缺陷、环境光线暗淡或光照

不均匀等问题，从而导致图像噪声的产生[10]。作为干扰信息，噪声会严重破坏图

像的边缘、纹理等特征，而图像细节的丢失会降低其空间分辨率，引起图像退化

[11]，因此必须先予以去除。对图像进行去噪处理一方面提升了图像的可视性，另

一方面尽可能地保留了原始图像中的有用信息。 

图像去噪问题可以简化为下述模型[12]： 

y

= +  
x n

… (2.1) 

式中 y  表示观察到的有噪点的图像，x 表示未知的高质量图像，n 表示加性

噪声，往往假设 n 是加性高斯白噪声。对图像的去噪处理的主要挑战为：图像平

坦区域应光滑；去模糊以保持图像边缘、角点和纹理；不应产生伪影。由于从等

式(2.1)中解出清晰的图像 x 是一个不适定问题，因此我们无法从带有噪声的图像

模型中取得唯一解。 

通常，图像去噪方法分为两大类[13]：空间域方法、变换域方法。 

（1）空间域方法。该方法去噪的原理为，按照源图像中图像块之间的相关程度，

重新为每个像素定义灰度值[14]。它分为空间域滤波和变分去噪方法，其中空间域

滤波应用空间滤波器、在任一像素和以该像素为中心的窗口内的其他所有像素之

间实施某种数学操作，用得到的新值替换该像素的原值，即完成了对该像素的滤

9 

 
 
基于多特征融合的疲劳驾驶检测技术研究 

波。空间域滤波会在一定程度上消除噪声，但代价是图像变得模糊，导致锐利边

缘丢失。 

（2）变换域方法。该方法起源于傅里叶变换，之后又逐渐衍生出许多其他的变

种，如余弦变换、小波域方法[15]和 BM3D（Block-Matching and 3D Filtering）[16]。

在变换域中，图像信息和噪声的特征有所区别，该方法利用这一特点，先在变换

域处理图像，然后将结果图像恢复至空域，从而实现去噪。 

上述方法中，空间域滤波的算法易于实现、效率高，常常被用于处理图像，

下面介绍几种经典的空间域滤波处理方法。 

（1）中值滤波：在图 2.1 中，选择一个 3x3 的窗口，里面包含了 9 个像素，按顺

序排列它们的灰度值，找出中值 ( ,

g x y ，用该值替换中心像素 ( ,

x y 原本的像素

)

)

值 ( ,

f x y ，如公式(2.2)所示，这即为中值滤波过程。 

)

g x y median f x

( ,

)

[

(

=

−

1,

y

−

1),

( ,
f x y

−

1),

(
f x

+

1,

y

−

1),

(
f x

−

1,

y

),

( ,
f x y

),

(
f x

+

1,

y

),

(
f x

−

1,

y

+

1),

( ,
f x y

+ +
1)

(
f x

+

1,

y

+

1)]

  … (2.2) 

图 2.1 中值滤波示意图 

Figure 2.1 Graph of median filtering 

（2）均值滤波：对于待处理的像素 ( ,

x y ，以 ( ,

x y 为中心，其相邻的周边像素

)

)

构成一个矩阵 I ，求 I 中所有像素值的均值，用该值替代 ( ,

x y 的灰度值 ( ,

g x y ，

)

)

则对 ( ,

x y 进行了均值滤波处理，即： 

)

10 

 
 
 
 
 
 
第 2 章 疲劳驾驶检测相关技术介绍 

( ,
g x y

)

=

1
n ∈

∑
I Neighbour

( ,
I x y

)

… (2.3) 

下面展示了常见的 3x3 均值滤波器模板，左边采用标准像素平均，右边采用

加权平均。 

图 2.2 两个 3x3 均值滤波器模板 

Figure 2.2 Two 3x3 mean filters 
（3）高斯滤波：高斯滤波的具体操作是：根据高斯分布得到高斯模板，用此滤

波模板遍历图像中的每个像素，然后按不同权重计算模板窗口内像素值的均值，

将该值作为滤波后窗口中心点的灰度值。由于图像都是二维的，所以在滤波处理

中需要二维高斯函数，公式如下： 

( ,
f x y

)

=

2

2
+
y
x
−
22
e σ

1

2
πσ
2

… (2.4) 

高斯滤波器对于抑制高斯噪声非常有效，但对图像的细节有较大的损坏。 

上面所介绍的传统的图像去噪算法对所有待处理图像都按照固定的滤波模

板进行相同的操作，何凯明等人对此作出改进，于 2010 年提出引导滤波，该滤

波器的权值能够自适应改变。引导滤波具有优越的边缘保持特性，其公式为： 

q
i

= ∑

j

W I p
( )

ij

j

… (2.5) 

其中 I 为引导图像， p 是待滤波的图像，q 是滤波后的输出图像，W 是用于滤波

的自适应模板，它与 I 有关，W 的计算如公式(2.6)所示。 

公式(2.6)中，

kw 表示以像素 k 为中心的窗口，|

|w 是

kw 中的像素个数，i ,  j

表示两个相邻像素点，它们的像素值分别为

iI 和

jI ，

kµ , 

kσ 分别代表 I 在

kw 中的

均值和方差，ε是惩罚项。 

11 

 
 
 
 
 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

W I
( )
ij

=

1
w

2
|

|

2.1.2  光照均衡算法 

(

I

i

−

(1

+

−

µ
k

I
)(
j
2
+
σ ε
k

µ
k

)

)

… (2.6) 

∑

k i j w
:( , )
k

∈

采集图像时，光照会产生影响，尤其在室外动态场景下，如图 2.3 所示。本

文进行疲劳驾驶检测技术的研究需要摄像头实时采集驾驶员的面部视频，由于自

然界光线变化无法控制，加之车内环境提供的光源有限，使得获取的人脸图像上

光照分布不均衡，在一定程度上，这会对后续操作产生消极影响[17]。 

图像光照不均匀的具体表现有以下三种： 

（1）整体灰度低：环境光弱、或设备问题均可导致具有较低灰度值、较弱对比

度的图像的产生，从而难以识别图像中的感兴趣区域。常见于红外图像[18]、夜间

拍摄的图像[19]； 

（2）局部灰度低：环境光分布不均时，所采集的图像也不具有均匀照度，往往

表现为，一部分光线明亮，一部分则较暗。在光线明亮的部分，前景和背景之间

明暗程度差异大、易于区分，而在光线较暗部分，整体灰度值偏低，目标与背景

混淆在一起，图像动态范围大，使得从原始图像中提取出这部分的有用信息变得

困难[20]； 

（3）图像出现反光现象：当所采集的图像中包含具有反光特性的物体时会出现

反光现象（亮度很大）[21]，从而导致该部分像素信息的损失。 

图 2.3 光照不均图像 

Figure 2.3 Uneven illumination image 

为了抑制一般图像中非均匀光照的影响，主要有 4 种经典的光照均衡算法：

灰度变换法、同态滤波法、感知理论法和梯度域法。 

（1）灰度变换法：它利用函数改变原始图像中每个像素的灰度值，从而改变图

像的动态范围。此方法以直方图均衡化法为典型，它可达到图像对比度整体增强

12 

 
 
 
 
第 2 章 疲劳驾驶检测相关技术介绍 

的效果，但是在图像细节信息的处理上比较粗糙，而且忽略了图像的频率信息，

甚至容易产生过增强现象，使图像部分关键信息丢失。 

（2）同态滤波法：图像 ( ,

f x y 可表示为 ( ,

f x y

)

)

=

)
f x y f x y
i

( ,

( ,

r

)

，其中 if 代表光

强分量，它和空间位置有关； rf 代表反射分量。同态滤波过程如图 2.4 所示： 

1）对原图作对数变换： 

ln ( ,

f x y

)

=

f x y
ln ( ,
i

)

+

ln

f x y
( ,
r

)

… (2.7) 

2）对对数图像作傅里叶变换： 

DFT[ln ( ,

f x y

=

)] DFT[ln ( ,

f x y
i

)] DFT ln[

+

f x y
( ,
r

)]

… (2.8) 

3）设计一个频域滤波器 ( , )

H u v ，用于对对数图像进行操作； 

4）逆变换，将对数图像转换回空域； 

5）取指数，得到空域滤波结果。 

图 2.4 同态滤波的基本步骤 

Figure 2.4 The basic steps of homomorphic filtering 
（3）感知理论法：该方法认为源图像 S 可表示为光照图像 L 和反射率图像 R 相

乘，如图 2.5 所示， S 为人眼所看到的物体图像， L 为入射光，则 S 由物体表面

对 L 反射得到，即： 

S x y
( ,

)

=

⋅
R x y L x y
)

( ,

( ,

)

… (2.9) 

S=R*L 图像

入射光

L

R

物体

图 2.5 反射图 

Figure 2.5 Graph of perception theory 

13 

 
 
 
 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

感知理论法适合处理受照射光影响较大的图像。该算法不但能使图像颜色保

持不变，还能兼顾压缩图像动态范围和增强图像边缘的效果[22]，但是该算法滤除

了图像低频部分包含的信息[23]，忽略了图像梯度的变化。 

（4）梯度域法：对灰度求导数，得到图像梯度[24]，该方法最先由  Fattal  等人提

出[25]，虽然它对图像的细微之处，以及图像的颜色层级分布情况，能在一定程度

上进行保护，但是该方法容易导致图像失真，并且算法实现上较为复杂，因而不

具有实时性。 

2.2  人脸检测及特征点定位 

2.2.1  人脸检测算法概述 

人脸检测是指，找寻和定位出图像中的人脸，并返回人脸的相关信息，如位

置、大小和姿态等。现如今，该技术被广泛应用，不再囿于人脸识别领域，而逐

渐扩展至内容检索、视觉检测和数字视频处理等方面[26]，标志着它向独立的研究

方向的转变，且技术趋于成熟。 

目前国内外普遍应用的人脸检测方法主要分为三大类[27]，如图 2.6 所示。 

（1）基于图像特征的方法：这种方法解析出人脸图像中恒定的特征，如生理结

构特征（如双眼大致对称，鼻、嘴关于轴对称分布[28]）、皮肤纹理特征、形状轮

廓特征、直方图特征（如双眼、嘴和鼻的亮度一般低于背景区域）、肤色特征等

[29]，对人脸位置、大小进行判定，人脸图像在此方法中被视作高维向量，那么检

测人脸就相当于检测信号在高维空间中的分布[30]。 

这种检测方法符合人类的认知规律，容易理解、方便实现，而且除了使用单

个特征，也可以将若干相互独立的面部特征组合起来，提高检测的准确率和鲁棒

性。由于此类方法所采用的很多特征都是人为观察总结得来，这就导致一些特征

不具有普适性，难以保证适用于开放环境下的各种情况；另外，人面部特征容易

受到外部因素的干扰，如：光照、遮挡、图像采集等，所以方法的稳定性较差[29]。 

该方法常利用灰度分布特性和肤色特性来进行人脸检测：通过灰度特征检测

人脸的方法中，具有代表性的是 Yang 和 Huang[31]提出的镶嵌图法；在彩色人脸

图像中，肤色是最为显著的特征之一[32]，常被用于人脸检测，然而在实际检测人

脸时，一般不唯一依赖于该特征，而是将它作为其他人脸检测方法的辅助[30]。 

14 

 
第 2 章 疲劳驾驶检测相关技术介绍 

（2）基于模板匹配的方法：此方法的提出是为了解决人脸姿态变化带来的对检

测率的影响问题。该方法分为通用模板匹配和可变形模板匹配[33]： 

1）通用模板匹配：五官位置在比例上有一定关系，对这种关系设定阈值，

得到固定的人脸模板，用该模板按照一定顺序、一个点接一个点扫描待测图像，

计算各点上待测图像与标准模板之间的相似度，若此相似度大小比阈值大，则认

为检测到人脸，否则认为该输入图像中不存在人脸。这种方法简单、直观，容易

实现，但是由于它使用一个模板应对所有的情形，不能顾及到需求的差异性，所

以在大多数实际应用中，往往不会考虑采用此方法[34]。 

2）可变形模板匹配：该方法根据人脸的先验知识，即形状信息，定义一个

形状模型，其中包含反映形状可变性的参数[35]。常用的为二元可变形模板[36]。和

通用模板相比，可变形模板能主动进行调整，以匹配不同的待测对象，这在很大

程度上提高了检测精度。 

梁路宏等人[37]提出了多模板匹配的方法，检测时，首先使用双眼模板进行初

判，然后通过对人脸模板长和宽的比例取不同值，找到人脸的位置和范围，最后

结合面部器官的边缘特征，确认最终的人脸区域；Govindaraju[38]采用变形模板法，

通过匹配头部轮廓线和左右两条面颊轮廓线，检测并定位出人脸。 

（3）基于统计模型的方法：该方法中常用的有三种，分别是基于特征空间、基

于神经网络[32]和基于 AdaBoost[30]的方法： 

1）基于特征空间：该方法对人脸图像进行变换，将其映射到某一特征空间，

在该特征空间中，人脸图像的分布呈现出规律性，据此区分“人脸”和“非人脸”。

其中具有代表性的方法是主成分(PCA)分析法。 

2）基于神经网络：该方法用神经网络对大量的样本，包括人脸图像和非人

脸图像进行训练，期间不断改变网络的权值和层数，以提升网络性能，训练完成

后，该网络会搜索包含人脸的图像的背景，最终确定人脸。 

3）基于 AdaBoost：该方法由 Viola 和 Jones 提出，实现过程为：寻找人脸图

像和其他图像不同的 Harr 特征，然后训练多个分类器，再采用级联结构，得到

最终的人脸检测器。时至今日，人们仍在不断地使用此方法并对它进行改进[33]。 

15 

 
基于多特征融合的疲劳驾驶检测技术研究 

基于图像特征的方法

人脸检测

基于模板匹配的方法

生理结构

灰度分布

肤色

...

通用模板匹配

可变形模板匹配

基于特征空间

基于统计模型的方法

基于神经网络

基于AdaBoost

图 2.6 常用的人脸检测方法 

Figure 2.6 Common face detection methods 

2.2.2  人脸特征点定位算法概述 

人脸特征点定位是指，自动识别出给定的面部图像或视频中眼睛、鼻子、嘴

巴等一些具有特殊语意信息的面部关键点的位置，如图 2.7 所示。 

图 2.7 人脸特征点定位 

Figure 2.7 Facial feature points localization 

16 

 
 
 
第 2 章 疲劳驾驶检测相关技术介绍 

这些关键点包括描述人脸器官标志性位置（如眼角、鼻尖、嘴角）的优势点，

以及连接这些优势点和人脸器官及面部轮廓的插值点[29,39]。 

人脸特征点定位的研究主要经历了如下几个阶段：（1）基于统计模型的方

法，（2）基于级联回归的方法，（3）基于深度学习的方法，如下图所示： 

主动形状模型（ASM）

基于统计模型

主动外观模型（AAM）

人脸关键点定位

基于级联回归

基于深度学习

约束局部模型（CLM）

级联姿态回归（CPR）

级联回归树（ERT）

深度卷积神经网络
（DCNN）

多任务级联卷积网络
（MTCCN）

任务约束深度卷积网络
（TCDCN）

图 2.8 人脸特征点定位方法汇总 

Figure 2.8 Summary of facial feature points localization methods 
（1）基于统计模型的方法。该方法起源于主动形状模型（Active  Shape  Model, 

ASM）[40]算法，ASM 算法由 Cootes 等人在 1995 年提出；后来，Cootes 等人在

ASM 方法基础之上进行完善，在 1998 年提出主动外观模型（Active Appearance 

Model, AAM）[41]算法，该算法建立两个模型：一个是形状模型，一个是表观纹

理模型。AAM 方法原理简单直接、易于理解，但是计算量仍然特别大，效率不

高。2006 年出现了约束局部模型（Constrained Local Model, CLM）[42]算法，它是

一种利用局部外观模型的生成化方法，其目标模型是受约束的形状。 

（2）基于级联回归的方法。级联回归这一概念首次出现在 2010 年，来自于 Dollar

等人提出的级联姿态回归（Cascaded Pose Regression, CPR）[44]方法。级联回归的

思想是，从初始形状开始，迭代逼近真实形状，每一次迭代结束后，估计形状和

真实形状之间存在偏差，通过偏差量对下一次的迭代过程进行优化，直至终止，

得到最终最接近真实形状的估计形状[43]。级联回归算法在人脸关键点检测中得

17 

 
 
基于多特征融合的疲劳驾驶检测技术研究 

到了广泛的研究与应用，但该算法也有一些不足，如占据较大内存、容易受初始

化的影响、在遮挡情形下性能不稳定[45]。 

（3）基于深度学习的方法。2013 年 Sun 等人提出 DCNN[47]，并用它检测人脸关

键点，这是深度学习在该研究领域的首次应用。在如今的深度学习洪流中，对于

人脸外表和形状之间的非线性关系，CNN 模型能够很好地进行建模[46]，因而被

广泛用于检测面部关键点，已成为该领域的主流模型[39]。除了 DCNN 之外，具

有代表性的还有 MTCCN[48]和 TCDCN（Tasks-Constrained  Deep  Convolutional 

Network）[49]。 

2.3  疲劳检测原理 

2.3.1  眼部疲劳检测原理 

由于人眼运动和变化能够很好地反映人的疲劳程度，因此基于眼部识别的疲

劳驾驶检测方法得到了广泛的研究与应用。经分析发现人眼部的疲劳特征都与睁

开和闭合这两种人眼状态有关，所以利用眼部特征对疲劳状态进行判定的首要任

务是进行人眼状态检测。人眼状态检测是指判断指定眼睛区域睁眼和闭眼的情况，

其关键技术就是找出能区分睁眼和闭眼的特征。下面介绍几种常用的人眼状态识

别方法。 

（1）基于虹膜特征的方法 

1）虹膜轮廓点的数量：眼睛在不同状态下虹膜被眼睑遮挡的情况不同，虹

膜的圆形的可见程度也有所不同，故该方法利用 Hough 变换在圆检测方面的优

势，提取出人眼中的虹膜，据此分析眼睛状态。 

2）虹膜暴露面积：虹膜暴露面积的多少能表示眼睛睁闭的程度，常据此来

判断人眼状态。首先获取睁眼图像，检测其中的虹膜部分的边缘；对于图像每列

最顶上和最底下的像素点，用 255 替代其灰度值；连接这些点，即构成了虹膜与

上下眼睑的交界；对于上下边界之间的像素点，也用 255 代替其灰度值；统计白

色点的个数，就得到了当前眼睛状态下虹膜的面积[50]。 

3）虹膜的水平灰度投影：闭上眼睛时，虹膜完全被遮挡，只有眼睑相接处

具有较大灰度值，因此，若对闭眼灰度图像进行水平投影，所得曲线会有一个极

18 

 
第 2 章 疲劳驾驶检测相关技术介绍 

窄的凹峰。眼睛睁闭程度改变时，能够直接反映在眼睑距离上，虹膜面积随之变

化，那么上述曲线中波谷的宽度也同步改变。基于此，可以检测眼睛状态。 

4）虹膜的颜色饱和度：在一种颜色中，混入的白色越多，其饱和度值就越

低，由此可知，虹膜的饱和度值很高，大于皮肤。闭眼时，皮肤会覆盖虹膜区域，

且闭眼程度不同，虹膜被皮肤覆盖的情况也不同，因此可根据眼睛图像中虹膜的

颜色饱和度的大小对人眼状态进行检测。 

（2）基于人眼边缘特征的方法 

1）眼睑曲率：眼睑弯曲程度，即眼睑曲率，可以反映眼睛睁开或闭合的程

度，因此通过对眼睑曲率设定临界值，如果小于该值则判为闭眼，否则为睁眼。

往往提取上眼睑曲率作为特征，对眼睛的睁闭状态进行识别：进行边缘检测，获

得人眼边缘图像，边缘图上部即为上眼睑轮廓，对上眼睑曲线进行拟合，并根据

公式(2.10)计算出该段曲线的平均曲率： 

ρ

=

∆
∆

θ
L

… (2.10) 

式中 θ∆ 表示眼睑曲线段切线的变化角度， L∆ 表示弧长。 

该方法高度依赖于眼角定位情况，而且其检测的准确性易受眼睑曲线拟合误

差的影响。 

2）边缘图像复杂函数：在睁、闭状态下，眼部轮廓复杂程度的不同，据此

提出一个表征复杂度的函数，利用它区分睁、闭眼。 

（3）基于统计的方法 

1）支持向量机法：采集睁眼、闭眼图像，然后进行训练，得到一个二分类

器，它能够对眼睛是睁开还是闭合作出判别。 

2）神经网络法：采集多种眼部状态的样本，制作成数据集，其中每种状态

对应一个标签，然后用神经网络对该数据集进行训练，得到一个分类器，它能够

对多种人眼状态作出检测。 

2.3.2  嘴部疲劳检测原理 

近年来，随着驾驶员疲劳状态检测预警系统的快速发展，嘴部状态检测也成

为判断疲劳驾驶的方法之一，其中打哈欠是嘴部最明显的反映疲劳状态的特征。

常用的对嘴部状态进行判别的方法如下[9]： 

19 

 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

（1）面积法。在张嘴图像中，嘴部区域的亮度较之周围皮肤明显较暗，而且嘴

部张开程度越大，暗区域面积也越大，这种状况在嘴部的二值图像上就体现在黑

色部分面积的变化，可以据此判断嘴部的张合状态。 

（2）距离法。嘴巴张开程度的变化最直观的反映就是两唇之间距离的增减，正

常状态下，人进行说话、唱歌等嘴部动作时，唇间距离会不断发生改变，但基本

维持在一定范围内，而当人因疲劳而打哈欠时，这个距离会显著增大。因此，可

以通过设置距离阈值，来区分是否打哈欠。 

（3）近似张角法。先由嘴部定位的方法检测出嘴部区域的最小外接矩形，从而

得到该矩形的长、宽和中心点坐标。矩形与嘴唇的四个交点对应着左、右嘴角点

和上、下嘴唇的中点，其坐标也相互对应，因此分别连接左右任一嘴角和上、下

嘴唇中点，通过计算两条连线之间的夹角，得到嘴部张开的角度，据此对嘴部状

态进行判断。 

2.3.3  头部疲劳检测原理 

当人处于疲劳状态下时，头会下垂、仰起或产生持续性点头动作。鉴于头部

姿态容纳了人的疲劳信息，通过估计头部姿态来检测疲劳也得到了十分普遍的应

用[51]。 

现有头部姿态估计算法多种多样，依据实现方式及原理不同，可分为以下几

种： 

（1）基于外观模板的头部姿态估计。该方法依托足够多的样本作为模板，即建

立了头部姿态估计数据集，其中每个样本的姿态已知，然后将待测头部图像和样

本逐一比对，并将匹配程度最高的样本对应的姿态输出为当前姿态。 

（2）基于检测器阵列的头部姿态估计。对于多个头部姿态，该方法为其中的每

个单独训练分类器，往往采用支持向量机，或 Adaboost 级联的方法进行，从而

能够检测出头部的不同姿态。相比于（1）中的方法，该方法不考虑外观因素变

化的影响，如图像的像素等，因为这种因素和姿态变化没有关联，这是该方法作

出的巨大改进。但是由于该方法为每一种姿态单独训练检测器，需要提供庞大的

正负样本，操作过程繁杂冗余，工作量巨大。 

20 

 
第 2 章 疲劳驾驶检测相关技术介绍 

（3）基于非线性回归的头部姿态估计。通过训练的过程，实际上，该方法找到

了一个非线性函数，让此函数作用于头部图像空间，则它被映射至头部姿态空间。

该方法需要人工预处理图像，并且容易受头部定位的影响。 

（4）基于流形学习的头部姿态估计。该方法即是对于待测头部姿态图像，通过

嵌入技术，或利用数学建模，在流形空间中进行表示。该方法实现简单，但是分

类复杂，准确率不是很高，有待进一步的研究与发展。 

（5）基于弹性模型的头部姿态估计。该方法对头部姿态信息作如下处理：向其

中加入面部特征点之间的空间约束，作非刚性建模，然后匹配已得到的模型。 

（6）基于几何特征的头部姿态估计。该方法先提取面部的若干特征点，由这些

点所构成的几何关系可以间接估计出头部姿态。该方法简单、运行效率高，估计

结果连续，但是由于过分依赖面部关键特征点的定位，其准确性容易受光照变化、

表情变化以及遮挡等影响，而且对图像的分辨率要求较高。 

2.4  支持向量机理论 

20 世纪 90 年代，Cortes 和 Vapnik 提出支持向量机（Support Vector Machine, 

SVM）[52]。SVM 的基本原理为：在二维空间中，对于正负两类样本点，分类的

原则是最大化它们之间的最小间隔，即最近的点、最远的距离，如图 2.9 所示。 

当线性可分时，对于训练样本集

D

=

{(

,
x y
1
1

), (

,
x y
2

2

),



(

,
x y
n

n

)}

，

ix

d

R∈ ，

iy ∈ − ，存在超平面 (

{ 1,1}

⋅
w x

)

+ = ，能够划分两类样本，公式中 w 表示超平面

b

0

的法线，则 SVM 的求解思路为确定最优权重值 w 、偏移量 b ，以最小化目标函

数值： 

min (

φ =
w
)

1
2

w

式中， w 表示范数； 

公式(2.11)满足如下约束条件： 

⋅ +
y w x
(
i
i

b

− ≥
) 1 0,

i

=   
l

1, 2,

,

引入拉格朗日函数，解决上述的二次规划问题： 

… (2.11) 

… (2.12) 

,
, )
L w b a

(

=

2

−

w

1
2

L

∑

i

=
1

α
i

{

y x w b
i
i

(

+

}
−
) 1

… (2.13) 

21 

 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

设 (

L w b a 取最小值时的 w , b 取值分别为

, )

,

w w=
0

,

b b= ，满足： 

0

α
,
0

)

(

∂
L w b
,
0
0
∂
b

= ⇒
0

L

∑

i

=
1

0
α
i

y
i

=

0

… (2.14) 

α
,
0

)

(

∂
L w b
,
0
0
∂
w

由 K-T 条件得知，最优解满足 

= ⇒ =

0

w
0

L

∑

i

=
1

0
α
i

y x
i
i

… (2.15) 

α
i

[

⋅ +
(
y w x
i
i

b

− =
) 1] 0,

i

=

1, 2,



,

l

α
i

≥

0

… (2.16) 

当 (

Tw b 符合 K-T 条件时，便得到全局最小点，因此对超平面的求解可以变换为

, )

对拉格朗日乘数α的求解，α满足 K-T 条件。再将该问题转化成拉格朗日对偶问

题，求解如下式的极大化： 

w
max (

α
)

=

1
2

满足约束： 

l

l

∑∑

i

=
1

j

=
1

αα
i
j

y y x x
i
j
i

⋅

j

… (2.17) 

l

∑

i

=
1

α
y
i
i

=

0

α
i

≥

0,

i

=

1, 2,

l
,
  

… (2.18) 

其中， iα 为拉格朗日乘数，它和每个样本相对应。 

在低维空间中，若样本数据是线性不可分的，可将其向更高维度映射，在高

维空间中，它会变得线性可分，过程如图 2.10 所示。若 x 非线性可分，映射到高

维空间后，其特征向量用 ( )xφ 表示，此时可用 SVM 对 ( )xφ 进行区分，分类超平

面表示为： 

于是需要最小化函数： 

min
w b
,

1
2

2
w   

s t
. .

其对偶问题为： 

f x
( )

T
φ=
w

x
( )

+  
b

… (2.19) 

T
φ +
y w
x
(
i
i

)

(

b

i
) 1, (

≥

= 
1, 2,

,

m

)

… (2.20) 

m

−∑
α
i

i

=
1

1
2

m m

∑∑

i

=
1

j

=
1

αα φ φ
(
j

y y
i

x
i

(

T
)

j

i

x

j

)

… (2.21) 

m

∑

i

=
1

α
i

y
i

=

0,

α
i

≥

0,

i

=

1, 2,

,
m
  

… (2.22) 

max
α

s t
. .

22 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
第 2 章 疲劳驾驶检测相关技术介绍 

利用公式(2.23)进行 (

φ φ 的计算： 
)
j

T
)

x
i

x

(

k x x
,
i

(

j

)

=<

φ φ
), (
x
i

(

x

j

)

>=

T
φ φ
x
(
)
i

(

x

j

)

… (2.23) 

则公式(2.21)可以写成如下形式： 

max
α

m

−∑
α
i

i

=
1

1
2

m m

∑∑

i

=
1

j

=
1

αα
i
j

(
y y k x x
i

,

j

i

)

j

… (2.24) 

求解后得到： 

f x
( )

=

T
φ
w

x
( )

+ =
b

m

∑

i

=
1

α φ φ
x
(
(
i

y
i

T
)

i

x

j

)

+ = =

b

s

m

∑

i

=
1

α
i

y k x x
(
i

,

i

)

+

b

j

  … (2.25) 

类2

类1

图 2.9 最优分类超平面 

Figure 2.9 Optimal separating hyperplane 

分类面

图 2.10 低维映射到高维 

figure 2.10 Mapping from low dimension to high dimension 

支持向量机的优点如下： 

23 

 
 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

（1） 样本容量较小、或样本空间有有限个样本点时，SVM 分类效果理想； 

（2） 对于非线性情形下的分类和回归问题，SVM 具有较好的处理能力； 

（3） SVM 的运算量不受样本维数的影响，保证了该算法对新鲜样本具有较强

的适应性； 

（4） SVM 中提供了强大的模型选择方案，且防止了过拟合的发生，通过改变

核函数，就可以得到适应不同问题的 SVM 算法。 

2.5  本章小结 

本章主要叙述了疲劳驾驶检测研究的技术背景。首先介绍了常用的图像去噪

和光照均衡算法；接着描述了国内外人脸检测和人脸特征点定位算法的发展历程，

并对不同算法的实现过程和优缺点进行了简要概括；然后解释了通过驾驶员眼部、

嘴部和头部检测疲劳的原理，分别为人眼状态识别、哈欠特征检测和头部姿态估

计，同时对应介绍了具有代表性的实现方法；最后概述了支持向量机理论的基本

思想、数学推导和分类优点。

24 

 
 
 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

第 3 章  基于多特征融合的疲劳驾驶检测 

3.1  图像预处理 

3.1.1  基于双邻域中值滤波的图像去噪 

由 2.1.1 节可知，中值滤波算法简单、运行速度快，可以有效去除孤点噪声、

保护图像的边缘信息，并能在一定条件下克服如均值滤波等线性滤波器造成的图

像细节模糊，适合于实验中的人脸图像。但由于它仅仅通过对滤波窗内像素按灰

度排序的结果决定中心像素的灰度，导致当所处理的邻域中噪声较多时滤波效果

下降，因此本文将窗口中数据的内容信息纳入考虑范围，实现了双邻域中值滤波

算法。其基本思想是甄别噪声与图像信息，用邻域中未受噪声干扰的像素点的灰

度值作为该邻域中心像素的输出值，从而进行噪声的滤除。 

选择 5×5 的正方形作为采样窗口，当窗口在图像上滑动时，中心像素的灰

度记为 (

p m n ，则该邻域中像素的灰度平均值为： 

, )

AVG

=

1
25 i

2

2

∑ ∑

=−
2

j

=−
2

+
p m i n

(

,

+

j

)

… (3.1) 

均方根误差为： 

RMSE

=

1
25 i

2

2

∑ ∑

=−
2

j

=−
2

[

+
p m i n

(

,

+

j

)

−

AVG

2

]

… (3.2) 

然 后 在 3 × 3 邻 域 中 对像 素灰 度 值 (

kf k =  按 大 小 排 序： 若

1, 2,

,9)

kf

kf

−

≤
AVG RMSE

， 则 将 对 应像 素 判 为 图 像 信 号， 保 留 该 值； 若

−

>
AVG RMSE

，则判为噪声，将其值舍弃，然后取筛选过后像素灰度值的中

值作为邻域中心像素的值。利用较大邻域区分有用信号与干扰信号，然后在较小

邻域内通过判别为图像的像素进行中值滤波，这样的双邻域中值滤波算法既能有

效滤除掉噪声，又能保证图像清晰度。 

3.1.2  结合直方图均衡化和对数变换的图像光照均衡 

考虑到本文技术的实际应用环境，光照因素对所采集的视频图像的影响不容

小觑，因而有必要针对不均匀光照条件下的图像处理提出解决方法。由于人面部

的立体性，光线的入射角度、强度等都会使人脸图像千差万别——它对于光照变

25 

 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

化的这种敏感性导致 2.1.2 节中提到的四类主流算法无法有效消除其光照不均匀

现象。因此，本文融合了直方图均衡化和对数变换实现图像光照均衡。 

相较于色度信息，人眼对亮度分量更加敏感，因此该方法首先将图像从 RGB

颜色空间转换到 b

r

YC C 颜色空间，依据 ITU.BT-601 标准的转换公式如下： 







Y

C
b
C

r









= −




0.299

0.587

0.169

0.500

−
−

0.331

0.419

0.114

0.500

−

0.081









R

G

B













+

0

128

128













… (3.3) 

然后对 b

r

YC C 图像进行直方图均衡化，以增强图像的对比度；最后分别对光

照过亮、过暗以及中间灰度区域作自适应处理，具体过程如下： 

（1）修正高光和暗调 

设原始图像包含 N 个像素，L 个灰度级，

jg 表示第 j 个灰度级的值、

jn 表示

jg 出现的频数、 (

f g 表示第 j 级灰度出现的概率： 

)j

(
f g

)

j

=

n

j
N

,

0

≤

g

j

≤

1,

j

=   
L

1, 2,

,

… (3.4) 

对图像中全部像素的亮度值按照从小到大的顺序进行排列，对于位于前 5%

和位于后 5%的像素，当其数量多到一定程度时，则将其亮度值重置为 0 和 255。

即令 

a
m

=

m

∑

j

=
1

f g
(

),

j

s
m

=

m

∑  
n

j

j

=
1

… (3.5) 

当

a
m

<

5%,

a +
1
m

> 时，若 100

ms > ，则将相应灰度级范围内包含的所有

5%

像素的亮度值修正为 0； 

当 1
a
m

− <

95%,

a
m

>

95%

时，若 100

ms > ，则将相应灰度级范围内包含的所

有像素的亮度值修正为 255。 

（2）修正中间调 

在观察图像时，设人眼感受到的亮度为 I ，图像的实际亮度为 S ，则韦伯-费

赫涅尔定律可以表示为： 

I

=

k

lg

+  
S r

… (3.6) 

其中 k , r 均为常数，公式表明主观亮度 I 与客观亮度 S 的对数成线性关系。

根据这个感觉特性可知，当图像的直方图与人眼视觉系统对图像亮度的响应变化

26 

 
 
 
 
 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

一致时，可以取得良好的视觉效果。因此对中间灰度区域作对数变换来进行修正，

变换公式如下： 

′
( ,
b x y

)

=

ln

V
V

′
max

max

′−
V
min
−
ln
V

min



ln

)

( ,
b x y
V

min

+

V

′
min

… (3.7) 

式中， ( ,

b x y 和 ( ,
)

b x y

′

)

分别为原图像和修正后图像像素的亮度值， maxV 、 minV

和 maxV ′ 、 minV ′ 表示图像变换前后像素灰度的最大值、最小值。 

进一步计算可得： 

′
( ,
b x y

)

=

0,

255(ln ( ,

b x y

)

−

ln

255,









B

low

max

) / (ln

B

high
B

low

min

max

b x y
( ,

)

≤

B

low

max

),

B

low

max

≤

( ,
b x y

)

≤

B

high

min

  … (3.8) 

( ,
b x y

)

≥

B

high

min

其中，

lowB 为前 m 个灰度级中像素的最高亮度值，

max

highB 为后 (

min

n m− + 个灰度
1)

级中像素的最低亮度值。 

综上，本文实现光照均衡的灰度变换曲线如图所示： 

255

0

图 3.1 自适应非线性变换函数曲线 

Figure 3.1 Curve of self-adaptive nonlinear transformation function 

图 3.2 中，横坐标代表输入灰度级，纵坐标代表输出灰度级，则可以直观看

出输入中范围在[0,

L 的灰度值拉伸为输出中范围为[0,3 / 4]

L 的灰度值，输入

/ 4]

中范围在[0,3 / 4]

L 的灰度值压缩为输出中[0,

L 的灰度值。因而这种变换能够

/ 4]

扩大图像中黑暗区域或者阴影区域的动态范围，同时压缩高亮区域的动态范围，

从而达到光照补偿的目的。 

27 

 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

图 3.2 输入输出灰度对比 

Figure 3.2 Input and output gray scale comparison 

3.2  基于 HOG 特征的人脸检测 

传统的机器学习算法中，Haar-Cascade 和 HOG-SVM 正是代表着人脸检测的

两个时代，下表对比了使用 Haar 级联和 HOG 特征进行人脸检测的优缺点。 

表 3.1 人脸检测中 Haar Cascade 和 HOG 方法对比 

Table 3.1 Comparison of Haar Cascade and HOG methods in face detection 

可以看出，不论是在算法速度、准确性和对遮挡、人脸变化的鲁棒性方面，

人脸检测的 HOG 方法都要优于 Haar Cascade 方法。HOG 人脸检测方法的主要缺

点是它无法检测小脸，但是，可以根据实际需要用较小尺寸的人脸数据自行训练

面部检测器，而且在本文疲劳驾驶检测技术的应用场景中，不会处理非常小的人

脸，因此基于 HOG 特征的人脸检测是更好的选择。 

28 

 
 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

3.2.1  HOG 特征介绍 

HOG(Histograms of Oriented Gradients)全称为方向梯度直方图，由 N.Dalal 和

B.Triggs 于 2005 年提出，它通过计算图像局部区域的梯度来提取特征信息，从

而表示目标的外观和形状，这也是 HOG 特征的关键所在[53]，如图 3.3 所示。 

HOG 特征有如下特点： 

优点： 

（1） 在捕捉局部形状信息上有一定优势； 

（2） 某种程度上，不受平移和旋转的影响，即对几何有不变性； 

（3） 对光照变化具有良好的不变性； 

缺点： 

（4） 生成过程复杂，不具有实时性； 

（5） 没有较好的抵抗遮挡的能力； 

（6） 对噪点相当敏感。 

图 3.3 人脸图像及其 HOG 特征 

Figure 3.1 Face image and its HOG features 

3.2.2  HOG 特征提取 

提取图像 HOG 特征的基本流程如图 3.4 所示，首先生成检测窗口，然后对

其进行 Gamma 校正，以归一化彩色空间，对于窗口内的每个像素，求其梯度，

接着分割窗口成为单元格，称为细胞，在细胞内，通过加权的方式构建梯度直方

图，得到它的特征描述子，多个细胞组合，形成一个块，串接该块内细胞的特征

描述子，便得到块描述子，最后串接窗口内的所有块描述子，便得到窗口的特征

描述子，也即生成了待检测目标的 HOG 特征。 

29 

 
 
基于多特征融合的疲劳驾驶检测技术研究 

生成检测
窗口

归一化图像

计算图像
梯度

构建细胞的
梯度直方图

归一化块

生成HOG特征

图 3.4 HOG 特征提取基本流程 

Figure 3.4 The basic process of HOG feature extraction 

每一步的过程详述如下： 

（1）生成检测窗口 

检测窗口即为图像中待提取 HOG 特征的目标区域。 

提取图像的 HOG 特征的过程中，存在窗口、细胞和块这三个操作单位： 

1）窗口：将图像划分成若干个尺寸相同的网格单元，称为窗口； 

2）细胞：将窗口划分成若干个互不重叠、尺寸相同的网格单元，称为细胞； 

3）块：由若干个细胞组合成的、空间连通的区域，称为块，它主要分为矩

形块和环形块两种。 

下图直观表示了 HOG 特征提取过程中图像的划分情况： 

图 3.5 HOG 特征提取中图像的划分 

Figure 3.5 Image division in HOG feature extraction 

图中，黑线划分窗口，蓝线划分块，黄线划分细胞。 

（2）归一化图像 

提取 HOG 特征时，没有用到图像的色彩信息，因而通常先对图像按公式(3.9)

Gray

=

0.3

∗ +
R

0.59

∗ +
G

0.11

∗  
B

… (3.9) 

进行灰度化： 

30 

 
 
 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

由于目标图像可能会存在光照不均的问题，如过度曝光、局部阴影等，为了

对此作出改善，先标准化图像的伽马颜色空间，即对其灰度值进行非线性转换，

常用开方或取对数的方式。 

（3）计算图像梯度 

用 ( ,

f x y 表示数字图像，则其像素点的梯度采用差分法计算，如下所示： 

)

∇

f x y
( ,

)

=

{
[

f x y
( ,

)

−

f x
(

+

1,

y

2
)]

+

[

f x y
( ,

)

−

f x y
( ,

+

2
1)]

} 1/2

  … (3.10) 

上式计算比较复杂，往往采用一维离散微分模板进行代替，它能高效、准确

地计算出图像的梯度信息，其公式如下： 

=

x

( ,


G x y H x
)

=
G x y H x y
)


( ,

( ,

(

y

+

−

(

−
y H x
)
1,
+ −
1)

H x y
( ,

y
1,
−

1)

)

… (3.11) 

公式中， ( ,

xG x y 表示点 ( ,

x y 在横坐标方向上的梯度， ( ,

yG x y 表示点 ( ,

x y

)

)

)

)

在纵坐标方向上的梯度， ( ,

H x y 表示点 ( ,

x y 的像素值。该点处梯度的幅值及方

)

)

向分别如公式(3.12)和(3.13)所示： 

G x y
( ,

)

=

G x y
( ,

x

)

2

+

G x y
( ,

y

)

2

α

x y
( ,

)

=

tan

1

− 



G x y
( ,

y

)

G x y
( ,

x

)





… (3.12) 

… (3.13) 

（4）构建细胞的梯度直方图 

假设每个细胞为 8×8 像素，并且对细胞的梯度方向在 0~180°范围内均分

为 9 份，分别是 0°~20°，20°~40°，40°~60°，60°~80°，80°~100°，

100°~120°，120°~140°，140°~160°，160°~180°(即 0°)，则这一步是

以细胞中像素的梯度幅值为权值向该像素的梯度方向所属区间内映射。例如：某

像素的梯度方向是 60°，梯度大小是 4，则该点就归为 60°这份，直方图中对

应区间的计数增加 4；某像素的梯度方向是 130°，梯度大小是 4，因为 130 和

120 相差 10、和 140 也相差 10，所以其一半幅值归为 120°这份，另一半则归为

140°这份，直方图中对应区间的计数各增加 2，如图 3.6 所示。 

对细胞内的 64 个像素点分别进行上面的操作，则每份角度区间都会生成一

个权值，从而得到这个细胞的梯度直方图，也就是一个维数为 9 的特征向量。 

31 

 
 
 
 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

图 3.6 梯度直方图 

Figure 3.6 Histogram of gradients 

（5）归一化块 

将组成块的所有细胞的特征向量进行串联，得到该块的描述符，为了减弱光

照对图像梯度的影响，对它进行归一化，即用块中向量的幅值除以向量的模长，

这样便得到了 HOG 描述符。 

（6）生成 HOG 特征 

串联检测窗口中所有块的 HOG 描述符，得到该检测窗口的 HOG 特征。 

3.2.3  人脸检测实现原理 

本文中的人脸检测的实现原理如下图所示： 

图 3.7 人脸检测的实现原理 

Figure 3.7 The realization principle of face detection 

首先采集有人脸图像（正样本）和无人脸图像（负样本），构建数据集，然

后提取每幅图像的 HOG 特征，借助 SVM 进行训练，生成人脸检测模型，接着

使用负样本进行难例挖掘，即对于训练集中的无人脸图像，用分类器展开多尺度

检测，若出现非人脸区域的误检，则在负样本集中添加该部分图像，对所有的负

样本判定完毕后，重新训练模型，循环往复，得到最终的分类模型。检测目标图

像时，取不同尺寸的窗口，在图像上不断滑动扫描，提取其 HOG 特征，再利用

该模型实现分类，若判定为人脸，则对其进行标记，操作结束后，会重复标记某

些人脸区域，采用非极大值抑制（Non-Maximum Suppression，NMS）消除掉重

叠的检出区域即可。 

32 

 
 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

本文检测人脸时提取的 HOG 特征来自于 Felzenszwalb 版本的 HOG(简称

FHOG)，它的细胞尺寸为 8×8 像素，每个细胞中提取的 FHOG 算子是 31 维的，

如图 3.8 所示。其中，31D FHOG=18D+9D+4D（D 代表维数），解释如下： 

（1）18D 由对细胞的梯度方向在 0~360°范围内均分为 18 份得到，从而生成维

度为 18 的 FHOG 梯度，它是有符号的； 

（2）9D 由对细胞的梯度方向在 0~180°范围内均分为 9 份得到，从而生成维度

为 9 的 FHOG 梯度，它是无符号的； 

（3）4D 由当前细胞及其 4 个对角位置上的邻域细胞通过归一化得到。即令 2×

2 个细胞构成一个块，则生成维度为 4×9 的 FHOG 梯度，它是无符号的，将该

FHOG 梯度视作矩阵，进行逐行逐列相加，可得到维度为 1 的特征向量，由于 4

个邻域生成 4 个块，就得到维度为 4 的特征。 

串联上述三个部分的特征向量，最终每个细胞得到 31 维 FHOG 特征。 

图 3.8 FHOG 特征 

Figure 3.8 FHOG feature 

3.3  基于级联的残差回归树定位人脸特征点 

级联回归模型具有精度高、速度快等特点，在人脸配准问题上具有明显的优

势，其主要思想就是通过级联简单的回归器不断拟合配准残差完成人脸配准。因

此，本文以级联的方式处理残差回归树，从而检测人面部特征点并进行标定。 

33 

 
 
基于多特征融合的疲劳驾驶检测技术研究 

级联回归树(Ensemble of Regression Trees, ERT)算法由 Kazemi 和 Sullivan 于

2014 年提出，是一种人脸对齐算法，基于回归树实现。该算法构建了人脸标记的

一个模板，即提取了面部的关键点，共 68 个，如图 3.9 所示。 

该算法包括模型建立和模型拟合两个过程： 

（1）模型建立 

模型的建立通过两层回归实现。第一层为： 

… (3.14) 

上面的迭代式中， S 是用于表征形状的矢量， I 表示图像，用 p 表示面部标

+ 𝑟𝑟𝑡𝑡(𝐼𝐼, 𝑆𝑆̂

= 𝑆𝑆̂

𝑆𝑆̂

)

(𝑡𝑡+1)

(𝑡𝑡)

(𝑡𝑡)

记点的数量，则

S

=

(

T
X X
,
1

T
2

,



,

X

T T
)
p

2

∈

R

为 I 中 p 个点对应的坐标，其中

iX

2

R∈

是第 i 个点的坐标，用 ( ,

x y 进行表示；估计标记点的坐标，并不断迭代此过程，

)

t 次后，得到的坐标集合为 ( )ˆ tS ，其中的点按照坐标相连，便构成了描述当前形状

的向量，同理，经过 1t + 次后，所预测的形状向量为 ( 1)

ˆ tS + ；

tr I S 是回归器，
( ,

( )ˆ
)t

在级联中，它以人脸图像和当前形状为输入，输出新的形状估计。 

在该层中，每级级联回归器会重新计算标记点的坐标，使得其位置更逼近真

实分布。 

图 3.9 人脸特征点模型 

Figure 3.9 Face feature point model 

第二层回归则是回归器 tr 的内部迭代。用 1

{(

I S
,
1

),

I S
, (

,

n

)}

n

表示训练样本集，

它由人脸图像构成，n 为图像的数量， iI 为人脸集合中的第 i 幅图像，它的形状矢

34 

 
 
 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

量用 iS 表示。为了求出用于拟合人脸形状的函数 ir ，创建三维矢量

，

它包含人脸相关的三种元素，其中样本集中的人脸图像表示为

(𝑡𝑡)
Iπ ，在第一层回归
)

(𝐼𝐼𝜋𝜋𝑖𝑖, 𝑆𝑆̂𝑖𝑖

, 𝛥𝛥𝑆𝑆̂𝑖𝑖

(𝑡𝑡)

i

中，迭代 t 次所得到的人脸形状矢量表示为 ( )ˆ t

iS ，当前人脸形状相对于真实人脸形

状的估计偏差表示为 ( )ˆ t

iS∆ 。则有： 

}
{
π ∈   
1, 2,
n

,

i

ˆ
(0)
S
i

∈

{

,
S S
1

2

,



,

S

n

}

\

Sπ

I

∆
S

(0)
i

=

S
π
i

−

(0)ˆ
S
i

(𝑡𝑡+1)
𝑆𝑆̂𝑖𝑖
= 𝑆𝑆̂𝑖𝑖
∆
S

+
( 1)
t
i

(𝑡𝑡)
=

(𝑡𝑡)

+ 𝑟𝑟𝑡𝑡(𝐼𝐼𝜋𝜋𝑖𝑖, 𝑆𝑆̂𝑖𝑖
ˆ
+
( 1)
t
S
S
π
i
i

−

… (3.15) 

… (3.16) 

… (3.17) 

… (3.18) 

… (3.19) 

)

根据上述过程，不断重复计算，当经过 t 级回归，学习到 0

,
r r
1

,

r − 后，则终

, t

1

止。 

对于用于进行训练的样本{
(

I
π
i

,

ˆ
( )
t
S
i

,

∆

ˆ
( )
t
S
i

N

}
)

i

=
1

，学习率 0<v<1，回归函数 tr 学

习的具体算法如下： 

1）初始化函数

kf

I S ，其中 1,...,
( ,

( )ˆ
)t

=

k

K

： 

ˆ
( ,
I S

f

0

( )
t

)

=

arg min
∈
R

γ

p

2

N

∑

i

=
1

∆
S

( )
t
i

−

γ

… (3.20) 

2）N 次迭代，拟合回归树 ikr ，得到弱回归函数

ikr 的表达式如下： 

kg I S ，其中 1,...,

( ,

( )ˆ
)t

=

i

，

N

r
ik

= ∆
S

t
( )
i

−

f

k

−
1

(

ˆ
t
( )
Sπ
I
,
i

i

)

… (3.21) 

3）根据得到的弱回归函数更新

( )ˆ
)t
I S ： 
( ,

kf

ˆ
( ,
I S

t
( )

)

f

k

−=
f

k

1

ˆ
( ,
I S

t
( )

)

+ ∗

ˆ
v g I S
k

( ,

4）重复 K 次操作 2)、3)步骤，得到

( )ˆ
)t
I S ； 
( ,

kf

5）得到回归函数

ˆ
( ,
r I S
t

t
( )

)

=

f

k

ˆ
( ,
I S

t
( )

)

。 

（2）模型拟合 

t
( )

)

… (3.22) 

35 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

通过（1）中的 K 次迭代建立了回归模型，然后对该模型进行拟合，具体步

骤如下： 

1）对于每个人脸样本，提取出其特征点，这些点的坐标构成了向量集合，

表示人脸的形状，对所有得到的向量进行初始化，使每个人脸样本都具有相同的

初始形状。 

2）构建特征集合，它和每幅图像中人脸的形状对应，从中选择任意两点，

在这两点处分别求解每幅图像的像素值，然后求差。 

3）构造回归树。生成一个随机的分割临界值，对 2)中求解的差值和该临界

值进行比较，若差值更小，则对图像的分割向左进行，否则向右进行，按照此方

法，将所有样本分割成两块。不断重复操作上述过程，对于最优临界点θ∗ ，通过

对误差的均方根最小化得到，目标函数如下： 

(
E Q

θ
,
)

=

∑ ∑

{ , }
l r i Q
θ
,

∈

s

∈
s

r
i

−

µ
θ
,

s

… (3.23) 

其中，θ表示待分裂的节点， ,l s 分别为左子树、右子树， ,sθµ 为当前分割结

束后得到的结果。最优节点产生后，记录这两个标记点的坐标以及分割临界值。

之后的每一个节点进行分裂，都需要重复该步骤，直至得到叶子节点。 

4）计算每个叶子节点的残差。计算每个人脸样本的估计形状和实际形状的

偏差，对于相同叶子节点中的每幅图像，计算该差值和，然后作平均，再将求得

的均值存入叶子节点。 

5）对每幅图像的形状进行更新，即用 ( ,
S

S∆ 替换当前形状 S 。 

)

6）重复操作 2）、3）、4）过程，直至最后得到最优的形状估计。 

3.4  疲劳特征参数提取 

人在疲劳时的面部表现并非单一的，而往往会调动眼睛、嘴巴和头等多个器

官来释放一系列的信号，比如眯眼的同时伴有不断眨眼、打哈欠及连续点头等现

象，因此本文融合人眼、嘴和头的多个疲劳特征共同进行疲劳驾驶检测。在本文

3.2 节中定位人脸 68 个关键点的基础之上，提取出能够表示驾驶疲劳的眼部、嘴

部和头部特征，然后借助已知的关键点信息对疲劳特征进行量化。 

36 

 
 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

3.4.1  人眼特征疲劳判断 

眼部特征是最能直观反映驾驶员疲劳状态的面部特征，它衍生出了许多常被

用于检测疲劳驾驶的评价指标，主要包括：瞳孔直径[54]、闭眼持续时间、眨眼频

率、眨眼用时和 PERCLOS 值等。实验研究表明，实时监测驾驶员的眼睛状况所

捕捉到的疲劳信号最为可靠[55]，因此为了提高结果的准确性，本文采用多指标融

合进行眼部疲劳判断。基于眼部特征检测驾驶员是否疲劳的 评判标准中，

PERCLOS 准则广受研究人员认可且发展已经十分成熟[55]，被奉为圭臬。因此本

文选取等效 PERCLOS 准则的眼睛纵横比（Eye Aspect Ratio, EAR）以及眨眼频

率这两个眼部指标作为眼部疲劳特征参数。 

（1）PERCLOS 算法理论 

研究发现，闭眼时间与疲劳程度成正相关，基于此，PERCLOS 作为衡量疲

劳的指标被提出，它表示眼睛在一定时间内闭合指定比例所持续的时间[56]。在

PERCLOS 算法理论中，对 PERCLOS 值的计算存在三种标准，分别是 P70、P80、

和 EM 标准：P70 和 P80 分别指在人眼睑遮住瞳孔的面积超过 70%和 80%的时候

就认为眼睛闭合，而 EM 标准是根据人眼睛闭合速率百分比的均方值来进行判断

[57]。其中 P80 准则与驾驶员标准疲劳值的相关性最好，最能反映驾驶员真实的疲

劳状态。 

图 3.10 示意了一次完整的眨眼过程，假设某一时刻驾驶员的眼睛完全睁开，

1t  表示眼睛从睁开最大到睁开 80%所经历的时间， 2t  表示眼睛从睁开最大到睁

开 20%经过的时间， 3t  表示眼睛从睁开最大到闭合，然后再次睁开到 20%经过的

时间， 4t  表示眼睛开度从最大到闭合再到 80%经过的时间。 

图 3.10 PERCLOS 的测量原理 

Figure 3.10 The measuring principle of PERCLOS 

37 

 
 
基于多特征融合的疲劳驾驶检测技术研究 

根据 P80 准则，可得 PERCLOS 的值 0f 为： 

f

0

=

t
3
t

4

−
−

t
2
t
1

×

100%

… (3.24) 

当 0f 大于某一阈值时，就可以认为检测对象处于闭眼状态。上述公式限定在一次

眨眼过程中，实际应用中常以预设的检测周期为单位时间判断人是否疲劳，这就

需要统计该时间段内的闭眼情况，如下式所示： 

n

i

∑  
t
==
1
i
T

f
1

… (3.25) 

式中

∑ 为时间T 内眼睛睁开度小于 20%的时间和。 

t

i

n

i

=
1

（2）基于 PERCLOS 的眼睛纵横比 

本文的研究对象为人脸视频图像，因此，计算闭眼时间占比可等效为计算闭

眼帧数占比[58]，则 PERCLOS 表示为： 

N

∑  
( )
P i
==
i
N

0

f

2

… (3.26) 

式中 N 为时间 t 内采集的视频帧数，它等于视频帧率和时间的乘积； ( )P i 反

映了闭眼的程度，当闭眼的比例不小于 80%时， ( ) 1

P i = ，否则 ( ) 0

P i = 。比较 2f

和区分正常、疲劳的阈值，就可以检测是否疲劳。无论 PERCLOS 表示成(1)中的

0f 、 1f 还是上面的 2f ，其本质上都体现了一段时间内判定人眼为闭合的占比情

况，其判定标准为眼睛睁开程度。由此可见，根据 PERCLOS 算法进行疲劳驾驶

检测的关键在于找寻合适的方法检测眼睛的开闭状态，在 2.3.1 节中介绍了几种

常用的人眼状态识别方法，但是由于本文会先捕获人脸图像上的大多数特征点，

包括眼角和眼睑，因此采用 EAR 作为表示眼睛睁开程度的指标。 

EAR 由 Tereza Soukupová 等人于 2016 年提出，可以在定位眼睛和眼睑的轮

廓的前提下，快捷地通过面部界标计算，用于评估睁（闭）眼状态，检测效率高。

如图 3.11 所示，从人眼的左角开始，围绕眼廓顺时针标定出 6 个 ( ,

x y 坐标，依

)

次命名为 1p ,

2p ,

3p ,

4p ,

5p 和 6p ，则 EAR 的计算公式如下： 

38 

 
 
 
 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

EAR

=

p
2

−

p
6
p
1

−

p
5

+

−

p
3

p
4

… (3.27) 

2

式中，分子表示上下眼睑上对应的两对眼睛标志点在垂直方向上的距离和，

分母表示左右眼角处的眼睛标志点在水平方向上的距离，由于水平点只有一组，

而垂直点有两组，所以给分母乘上 2，以保证分子分母的权重相同。 

图 3.11 标定出的人眼区域坐标 

Figure 3.11 The calibrated human eye area coordinates 

（3）眨眼频率 

研究表明，当人处于疲劳状态时，眨眼频率 BF 会发生明显的变化，也就是

说眨眼频率能在一定程度上反映人的疲劳程度。因此，可以将眨眼频率用于驾驶

员行车时的疲劳状态判断[52]——实时监控驾驶员的面部，得到其连续的眼部视

频帧，判别每一帧中的眼睛状态，即是否闭眼，综合时间上连续的若干相关数据，

便可计算出眨眼周期，进而求出眨眼频率的大小，据此对驾驶员是否疲劳进行分

析[59]。 

本文基于眼睛纵横比的概念判断是否眨眼，从图 3.12 和 3.13 中可以看到，

EAR 值在某一时刻骤降至 0，又快速恢复至一定大小，并在该值上下作小幅度、

稳定的波动，则说明在这一时刻发生了眨眼活动。因而（2）中得到的 EAR 值有

两个作用，一方面将人眼闭合 80%时的 EAR 取作阈值，用

Thresh 表示，那么

80P

PERCLOS P80 标准就可以等效为： 

≤
EAR Thresh

80P

… (3.28) 

EAR 值满足上式时表明驾驶员处于疲劳状态，并且认为此时人眼是闭合的，

然后计算这段时间在单位时间内所占的比例，即为 PERCLOS 值。实际估量驾驶

员的疲劳程度时，计算闭眼时间占据总时间的百分比将转换为计算闭眼的帧数和

39 

 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

总帧数的比值。另一方面，如果连续几帧图像中人眼经历了从

≥
EAR Thresh

80P

到

≤
EAR Thresh

80P

再到

≥
EAR Thresh

80P

的过程，即视为发生了一次眨眼活动。 

图 3.12 眼睛 EAR 值变化 

Figure 3.12 Changes in eye EAR value 

图 3.13 眨眼对应的 EAR 

Figure 3.13 EAR corresponding to the blink of an eye 

综上所述，本文检测眨眼频率的步骤为： 

（1）计算 EAR。由图 3.14 可以看出，人左右眼的动作高度同步，所以计算两眼

的 EAR 值，然后对它们取算术平均，得到的值作为人眼最终的 EAR 值。68 点人

脸关键点标记中 37-42 为左眼，43-48 为右眼，则通过点 38、39、41、42 和 44、

45、47、48 的纵坐标、点 37、40 和 43、46 的横坐标来计算眼睛的睁开度，公式

(

y

P
38

EAR

Left

=

为： 

40 

y

P
39

−

y

)

P
41

−

y

P
42
x
2(

)

+

(
−

P
40

x

)

P
37

… (3.29) 

 
 
 
 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

EAR

Right

=

(

y

P
44

y

P
45

−

y

)

P
47

−

y

P
48
x
2(

)

+

(
−

P
46

x

)

P
43

EAR

=

EAR

Left

+

EAR

Right

2

… (3.30) 

… (3.31) 

图 3.14 左右眼 EAR 变化曲线 

Figure 3.14 EAR change curve of left and right eyes 
（2）确定 EAR 的阈值。当人眼闭合时，EAR 值迅速下降，理论上会接近于零，

但是由于人脸检测模型定位和实际还存在差距，同时借鉴 PERCLOS 算法理论的

思想，所以本文通过一个阈值判定眼睛是睁开还是闭上。当 EAR 低于该阈值时，

认为眼睛处于闭合状态，并据此进行眨眼检测。 

每个人的眼睛大小比例不同，如果统一设置成固定的阈值，会带来较大的误

差，因此本文采用动态设定阈值的方式：先采集驾驶员在疲劳状态下的眼部 EAR

数据，取其平均值，并根据 PERCLOS 算法的 P80 标准得到自适应阈值，再用根

据经验确定的 EAR 阈值对该自适应阈值进行修正，最后将二者的算术平均值作

为本文人眼识别疲劳驾驶的最终阈值。 

（3）确定发生眨眼的连续帧数。当外界因素，比如大风吹、强光直射等刺激人

眼时，它会出现应激反应，即快速眨眼，然而该情况并不是由驾驶员疲劳引起的，

因而为了避免误判，需要合理设置同一次眨眼的连续帧数来检测眨眼次数。 

本文采用的方法为：以帧数为横坐标，EAR 为纵坐标画出疲劳状态下一段时

间内驾驶员眼部状态变化的波形，然后统计波谷出现的次数 n 以及每次波幅由突

41 

 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

然降低到刚好恢复所经过的视频帧数

if ，则单次眨眼包含的连续帧数为 ：

n

i

∑  
f
==
i
1
n

f

blink

… (3.32) 

3.4.2  嘴部疲劳状态检测 

当人疲劳时，在嘴部活动上的表现就是不断地打哈欠，常见的作为驾驶员嘴

部打哈欠动作疲劳判断的依据有[60]： 

（1）嘴巴开合度 

打哈欠时嘴巴张开程度明显变大，其计算公式如下所示： 

O
i

=

i

H
W
i

… (3.33) 

式中， iH 为嘴巴张开的高度， iW 为嘴巴的宽度。 

（2）嘴巴张开持续时间 

与说话、吃东西等其他嘴部动作相比，打哈欠时张嘴持续时间较长，统计嘴

巴张开持续时间的公式如下： 

0T

nt=

… (3.34) 

式中， n 为嘴巴张开的帧数， t 为每帧的时间。 

（3）打哈欠频率 

F

=

N
T

… (3.35) 

式中， N 为打哈欠次数，T 为单位时间。 

本文基于嘴部动作的驾驶员疲劳判定方法的实质是先检测出嘴部区域，在此

基础之上，计算嘴巴的张开程度，根据该值的大小判断是否打哈欠，进而判断驾

驶员是清醒还是疲劳。因为打哈欠时嘴巴的几何特征变化比较显著，故本文中嘴

部疲劳状态识别的相关研究是基于嘴巴的几何特征进行的[61]。人嘴巴与眼睛的

生理活动变化类似，并且在 3.2 节中已经定位出了嘴部特征点，所以本文参考基

于 EAR 的人眼特征疲劳判断方法，类似地，将其移植到嘴部疲劳状态识别中，

给出嘴唇纵横比（Mouth Aspect Ratio, MAR）的定义，并根据其值进行哈欠检测。 

如图 3.15 所示，嘴唇纵横比有两种计算方式[62]： 

42 

 
 
 
 
 
 
 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

图 3.15 嘴唇轮廓结构示意图 

Figure 3.15 Lip contour structure diagram 

（1）基于嘴巴内轮廓的 MAR： 

α=

H
L

（2）基于嘴巴外轮廓的 MAR： 

β

=

M

H
L
M

=

+
H t

+

t
up
+ +
L t
r

down
t

l

… (3.36) 

… (3.37) 

式(3.37)中的

upt 、 down

t 、 rt 、 lt 是与嘴唇厚度相关的量，因为每个人的嘴唇厚度有

所不同，那么这四个量的值就因人而异，所以即使不同人处于同等程度的疲劳状

态，MAR 值也不统一，因此将该 MAR 作为描述疲劳的嘴部特征时会受嘴唇厚

度影响，导致出现哈欠判别错误；而式(3.36)中的 MAR 则与嘴唇厚度无关，且嘴

巴在活动时内外轮廓的动作高度同步，所以本文提取嘴巴内轮廓的纵横比来消除

嘴唇厚度的干扰。 

图 3.16 嘴唇区域坐标标示 

Figure 3.16 Lip area coordinate marking 

嘴唇区域坐标标示如图 3.16 所示，使用内嘴唇坐标计算 MAR 的公式为： 

43 

 
 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

MAR

=

p
2

−

p
8

+

3

p
3
p
1

−

−

p
7
p
5

+

p
4

−

p
6

… (3.38) 

事实上，此处定义的嘴唇纵横比 MAR 等效于上述依据嘴巴开合度。 

本文结合 MAR 值与上述依据嘴巴张开持续时间进行双阈值法哈欠检测，具

体步骤为： 

（1）根据 MAR 值的大小进行哈欠初判。首先确定一个能够区分打哈欠与其他

嘴部动作的阈值，若张口度超过阈值，则进行步骤（2）； 

（2）根据张口度超过阈值的持续时间进行二次判决。人在大声说话，或感到吃

惊等情形下时，会瞬时张大嘴巴，这时，虽然张口度明显大于初判的阈值，但是

维持这种状态的时间极短，而按照经验，打哈欠时嘴巴大张会持续一定时间，因

此，满足该条件才认为正在打哈欠并计数。 

最后每 30 帧统计一次打哈欠的次数，根据公式（3.35）求出打哈欠频率（Yawn 

Frequency, YF）。 

3.4.3  头部姿态信息提取 

在驾驶过程中，驾驶员脸部区域可能存在被遮挡的情况，如戴墨镜、打电话、

喝水等。因此，若只通过面部特征来对疲劳与否进行判断，经常会导致错误的评

估结果。相比细微复杂的脸部特征，头部姿态估计可以更直观地反映驾驶员的疲

劳状态，故将其纳入疲劳驾驶的判断指标。 

图 3.17 头部姿势 

Figure 3.17 Head posture 

44 

 
 
 
 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

头部姿态估计指通过一幅面部图像来获得头部的姿态角。在三维（Three-

Dimension, 3D）空间中，物体的旋转可以由三个欧拉角来表示： pitch(围绕 X 轴

旋转)，yaw(围绕 Y 轴旋转)和 roll(围绕 Z 轴旋转)，分别称作转动角、平动角和

滚动角，通俗讲就是抬头、转头和偏头，如图 3.17 所示。 

鉴于前面已经获得了面部关键点，且综合考虑准确性以及运行速度的需求，

本文基于人脸几何特征来估计头部姿态，即先提取出面部图像的关键点，在此二

维信息的基础之上，向三维空间进行投影，从而求出表征头部姿势的欧拉角。 

本文头部姿态信息提取的步骤如下图所示： 

2D人脸关键点
检测

3D人脸模型
匹配

求解3D点和
对应2D点的
转换关系

根据旋转矩阵
求解欧拉角

图 3.18 头部姿态信息的提取步骤 

Figure 3.18 Steps to extract head posture information 

其中 2D 图像中的人脸关键点映射到 3D 人脸模型中的对应点的示意图如下所示： 

图 3.19 2D 和 3D 人脸特征点的对应 

Figure 3.19 Correspondence of 2D and 3D face feature points 

首先需要得到摄像头的位姿，即求解多点透视成像（Perspective-n-Point, PnP）

问题。以相机为参照，物体的姿态可以使用两个矩阵来表示，分别是旋转矩阵和

平移矩阵： 

（1）平移矩阵：即以相机为参考，反映了物体在空间中的位置，这种对应关系

用 T 表示； 

（2）旋转矩阵：即以相机为参考，反映了物体在空间中的姿态，这种对应关系

用 R 表示。 

45 

 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

下来进行坐标系转换，分别是：世界坐标系(UVW)、相机坐标系(XYZ)、图

像像素坐标系(xy)，如下图所示： 

U,V,W : 世界坐标系
X,Y,Z  : 相机坐标系
x,y       : 图像坐标系
oc        : 焦距        

W

p

U

世界坐标系

V

x

p

y

c

Z

X

o

Y

相机坐标系

图像平面

图 3.20 各个坐标系展示 

Figure 3.20 Display of various coordinate systems 
（1）图像坐标系：图 3.21 中，从像素角度，它可被分为像素坐标系(xy)，从物

理角度，它可被分为物理坐标系(uv)[63]，直角坐标系的建立以实图的左上顶点为

原点，以像素为单位。 

图 3.21 图像坐标系 

Figure 3.21 Image coordinate system 

（2）世界坐标系：该坐标系用于对物体在真实场景下的位置从三个维度进行描

述。 

（3）相机坐标系：由相机成像的几何关系可知，以相机为参考，向世界坐标系

投影形成了三维空间，因此以摄像机光心为原点，x 轴为平行于图像的水平方向、

y 轴为平行于图像的竖直方向、z 轴为摄像机的光轴，建立三维直角坐标系[63]，

如下图所示： 

46 

 
 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

p(x,y)

(R,T)

u

x

v

y

图 3.22 成像原理 

Figure 3.22 Imaging principle 

各坐标系之间的转换关系如下： 

（1）世界坐标系到相机坐标系： 

X
Y
Z













=


U

R V


W








+ =
T

[

R T
|

]








U
V
W

1








（2）相机坐标系到像素坐标系： 

x



s y




1









= 



f

x
0

0

0

f

y

c

x

c

y

0 1













X

Y

Z







（3）由（1），（2）可得像素坐标系和世界坐标系的关系如下： 


x

s y




1









= 



f

x
0

0

0

f

y

c

x

c

y

0 1







[

R T
|

]








U
V
W

1








… (3.39) 

… (3.40) 

… (3.41) 

上式可综合直接线性变换（Direct  Linear  Transform,  DLT）算法和最小平方

法不断迭代求解，其中最小平方法的目标函数可以表示为

（变量 ˆix , ˆiy 为估计值， ix ,
2

iy 为实测值）。考虑到相机镜头畸变的影响，需要
+ (𝑦𝑦�𝑖𝑖 −

𝐽𝐽 = (𝑥𝑥�𝑖𝑖 − 𝑥𝑥𝑖𝑖)

2

𝑦𝑦𝑖𝑖)
先对相机坐标系进行转换，使它变到图像中心坐标系下： 

47 

 
 
 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

 
u
 
v
 

=





X Z
/

Y Z
/





最后由图像中心坐标系到像素坐标系： 

s





x
y






= 


f

x
0

0

f

y

c

x
c

y

 
u

 
v

 
 
1
 

… (3.42) 

… (3.43) 

确定头部姿态就是确定从 3D 人脸模型到图片中人脸的仿射变换矩阵，它包

含旋转和平移的信息，所以只要知道世界坐标系内点的位置、像素坐标位置和相

机参数就可以求出旋转和平移矩阵，我们利用 OpenCV 内置的求解 PnP 问题的

函数 solvePnp()完成。得到旋转矩阵后，就可以根据下面的公式求出欧拉角： 

R

=







r
00
r
10
r
20

r
01
r
11
r
21

r
02

r
12
r
22







=







φ γ
cos cos
+
ϕ γ
sin
−
ϕ γ

sin sin cos

ϕ φ γ
ϕ φ γ
sin cos

cos

sin sin

cos

φ γ
−
cos sin
+
ϕ γ
cos cos
−
ϕ γ

sin cos

cos

sin sin sin

ϕ φ γ
ϕ φ γ
sin sin

−

φ


sin

ϕ φ
sin sin


ϕ φ
sin


cos

=

ϕ


φ
=

 =
γ


a

tan(

−

r
12

,

r
22

)

a

tan(

a

tan(

,

r
02
−
r
01

,

2
r
12
r
00

+

2
r
22

)

)

… (3.44) 

… (3.45) 

其中 R 是旋转矩阵，ϕ,φ,γ是欧拉角。 

一般通过头部状态判断是否疲劳有两种方式：①利用姿态估计结果（如 Pitch

的读数）来判断是否点头及点头幅度；②用鼻尖处点的前后移动值（或是方差，

方差表示一个单位时间数据的偏离程度，程度越大，则表示发生点头动作的概率

越大、点头幅度越大）作为判断标准。本文采用方法①，通过点头进行疲劳分析。

当驾驶员疲劳时，颈部肌肉乏力、松弛，很难保持正常的驾驶姿势，最直接的表

现为驾驶员头部的后仰、低垂、左右倾斜或者这些动作的组合，对应到头部姿态

上就是 Roll 旋转角以及 Pitch 旋转角的变化[56]。 

48 

 
 
 
 
 
 
 
 
 
 
 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

3.5  基于特征融合的疲劳驾驶检测 

3.5.1  基于核学习的特征融合 

本文从驾驶员面部提取了眼睑闭合度、眨眼频率、嘴巴张开度、打哈欠频率

和三个头部姿态角共七个能够表征驾驶疲劳的特征，汇总如下： 

表 3.2 疲劳特征汇总 

Table 3.2 Summary of fatigue characteristics 

特征 

特征说明 

信息源 

眼睛 

嘴巴 

头 

眼睑闭合度 

眼睛纵横比 

图像信息 

眨眼频率 

单位时间内的眨眼次数 

图像信息 

嘴巴张开度 

嘴巴内轮廓的纵横比 

图像信息 

打哈欠频率 

单位时间内的打哈欠次数 

图像信息 

转动角 

平动角 

滚动角 

抬头、点头的角度 

转头的角度 

偏头的角度 

图像信息 

图像信息 

图像信息 

表 3.3 各特征的基本统计学信息 

Table 3.3 Basic statistical information of each feature 

特征 

眼睑闭合度 

眨眼频率（/s） 

嘴巴张开度 

打哈欠频率（/s) 

转动角（°） 

平动角（°） 

疲劳样本数据 

非疲劳样本数据 

均值 

标准差 

均值 

标准差 

0.213 

0.327 

0.755 

0.017 

17.490 

9.580 

0.091 

0.184 

0.108 

0.013 

5.826 

4.375 

0.458 

0.295 

0.524 

0.002 

1.480 

0.176 

0.053 

0.362 

0.001 

1.063 

32.610 

13.949 

滚动角（°） 
计算 4.3 节中提取各个特征所用到的数据集或所采集的视频中对应特征参数

21.330 

0.027 

0.090 

3.319 

（其中非疲劳样本数据和疲劳样本数据约各占一半）的基本统计量，如表 3.2 所

示。通过横向、纵向对比可知：（1）疲劳和非疲劳状态下同一特征数据的分布

情况存在一定程度的差异；（2）不同特征数据的分布情况有明显的差异；（3）

采集的特征数据的分布不具有规律性，疲劳状态判断属于非线性分类问题。这说

49 

 
基于多特征融合的疲劳驾驶检测技术研究 

明多种信息都能从不同角度反映出驾驶员的疲劳情况，但单模态的疲劳驾驶检测

方法并不能准确地判断驾驶员是否疲劳，因此本文应用信息融合来识别疲劳状态。 

信息融合指综合处理多种数据，以实现决策和估计，这些数据从单个或多个

信息源处获取，图 3.23 展示了信息融合的步骤和 3 个层次。在数据层融合中，直

接处理原始数据，其中不仅包含冗余信息，还存在噪声；在决策层融合中，数据

信息缺失，这会降低结果的精度；相比之下，在特征层融合中，对原始数据进行

提取，降低了数据量，同时保留了有效信息，因此本文在特征层级上进行疲劳信

息融合。 

图 3.23 信息融合处理过程及层次划分 

Figure 3.23 Information fusion processing process and level division 

表 3.4 介绍了特征级融合常用的算法，鉴于本文检测驾驶疲劳所提取的特征

具有以下特点：（1）维度较低/维数不多；（2）物理意义明确；（3）不具有规

律性，经过对比分析，基于核学习的特征级融合更适用于本文的研究。支持向量

机为核方法的典型代表，故利用它来构建疲劳分类模型。 

表 3.4 常用特征级信息融合算法及其特点 

Table 3.4 Common feature-level information fusion algorithms and their characteristics 

特征级融合算法 

特点 

核学习（KL） 

可解决特征不规则问题 

主成分分析（PCA） 

适用于高维特征融合 

典型相关性分析（CCA） 

适用于特征之间具有内在联系的场景 

神经网络 

适应能力强，适用于输入输出关系 
不明确的信息融合 

50 

 
 
第 3 章 基于多特征融合的疲劳驾驶检测 

3.5.2  疲劳检测模型的搭建 

（1）模型输入。如表 3.2 和表 3.3 所示，本文要融合的多类特征参数在物理含义、

量纲和数量级上或多或少存在差异，因此训练这些特征之前需要对其数据进行归

一化处理。样本集合用 X 表示， X 中每个元素


jX

是一个样本的特征集合，其中

j

P∈
[1,

]

， P 为 样 本总 数 ， 假 设样 本 有 D 种 特 征 ， 其特 征 集 合


X
j

i
X
j

 
1
2
{
X X
,
,
j

j

=



,


}D
X
j

=

{

x

i
1

j

,

x

j

2

i

,



,

x

i

}

∈

jn
i

公式为： 

， 第 i 种 特 征有 in 维 ， 样 本特 征 向 量

X
j

，则对样本第 i 种特征的一个维度

jnx 进行归一化的

i

i

i

′ =

x

jn
i

i

−

x

jn
i

max{
i
1

x

j

x

,

i
j
1
x

j

,

2

x
i

,

max{

i

,



,

j

2



,

x

jn
i

i

−

x
i

} min{
i
1

jn
i
−
} min{

x

j

x

,

i
j
1
x

j

,

2

x
i

,

i

,



,

j

2



,

x

jn
i

i

}

x
i

jn
i
}

  … (3.46) 

i

′ 为归一化后的特征值。 

jnx

i

（2）模型训练。利用 SVM 训练疲劳检测模型时，通过引入核函数使得输入的特

征样本线性可分，常用核函数如表 3.5 所示。 

表 3.5 常用核函数 

Table 3.5 Common kernel functions 

本文选用 RBF 核函数，理由如下： 

1）适用于特征与分类标签之间的关系为非线性的情况。线性核函数是它的

一个特例；在某些参数设定下 Sigmoid 核函数和 RBF 的功能相似。 

2）参数较少，模型复杂度较低/模型简单。多项式核函数的参数较多，调参

困难。 

3）RBF 核有更少的数值复杂度。 

51 

 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

OpenCV 内置的机器学习模块(Machine Learning, ML)下的 CvSVM 类中集成

了 SVM 算法，包括其代码实现和用于展开模型训练及测试的接口函数。本文基

于该工具展开驾驶疲劳检测模型的训练。 

用径向基（RBF）内核训练 SVM 时，模型的性能由惩罚因子 C 和核参数γ 

决定，对于本文疲劳驾驶检测模型的小样本训练，使用网格搜索和 k 折交叉验证

（K-fold cross-validation, k-CV）进行参数调优。做法是将数据集分成 k 个互斥子

集，限定参数的变化范围与变化步长，然后选择 k-1 个子集作为训练集穷举所有

的(C, γ)对值，剩下的一个子集作为测试集，这视为一次交叉验证，重复 k 次该

过程，将每一对参数组合下 k 次的平均交叉验证识别率作为该模型的最终精确

度，找出使交叉验证精确度最高的(C, γ)对，从而得到最优参数。 

3.6  本章小结 

本章主要讲述了基于多特征融合的疲劳驾驶检测的相关原理，包括人脸检测、

人脸特征点定位、疲劳特征参数提取以及疲劳检测的理论基础。首先介绍了本文

实现图像预处理所使用的算法，包括基于双邻域中值滤波的图像去噪和结合直方

图均衡化和对数变换的图像光照均衡；接着详细描述了图像的 HOG 特征及其提

取步骤，并阐释了利用 HOG 特征检测人脸的实现思路；再从应用优势和算法流

程两方面对基于级联的残差回归树的人脸特征点定位模型进行了简明扼要的说

明；然后介绍了本文判断是否疲劳所选取的眼部、嘴部和头部的特征指标，分别

是：①基于 PERCLOS 的眼睛纵横比和眨眼频率；②基于 EAR 的嘴唇纵横比、

张口持续时间和打哈欠频率；③利用头部的姿态角检测抬头仰头和左右偏头状态；

最后选定了采用 RBF 核函数的支持向量机建立基于特征融合的疲劳检测模型。

52 

 
 
第 4 章  疲劳驾驶检测的实现 

第 4 章  疲劳驾驶检测的实现 

本章介绍了疲劳驾驶检测的实现流程，算法的整体框架如下所示： 

开始

输入视频图像帧

图像去噪与光照补偿

HOG人脸检测

检测到人脸

基于ERT的人脸特征点
定位

眼部疲劳特征提取

嘴部疲劳特征提取

头部姿态信息提取

眼睑闭合度、眨眼频率

嘴巴张开度、打哈欠频率

头部姿态角
（pitch,yaw,roll）

SVM疲劳检测模型

疲劳状态分类

结束当前帧

图 4.1 疲劳驾驶检测算法的实现流程 

Figure 4.1 Implementation process of fatigue driving detection algorithm 

53 

 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

4.1  图像预处理 

4.1.1  图像去噪 

（1）人脸图像去噪实验结果 

本文在 AR 人脸数据库上对上述双邻域中值滤波算法进行实验测试。该人脸

库由 Aleix  M.  Martinez 和 Robert  Benavente 在 UAB 计算机视觉中心创建，文中

用到的是其中的一个子集，包含 50 位男性和 50 位女性的 2600 张分辨率为

120*165 像素的面部灰度图像，每人 26 张，具有不同的面部表情，照明条件和遮

挡(墨镜和围巾)，部分展示如下： 

图 4.2 AR 人脸数据库部分样本数据 

Figure 4.2 Partial sample data of AR face database 

图 4.3 加噪后的图像 

Figure 4.3 Noised image 

54 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
第 4 章  疲劳驾驶检测的实现 

AR 人脸库中的人脸图像能准确、全面地反映真实驾驶场景中驾驶员的人脸

变化情形，且本文的研究不依赖于图像的颜色信息，因此采用该数据集测试双邻

域中值滤波算法的去噪效果是合理可行的。 

对测试图像均添加噪声密度为 0.05 的椒盐噪声，如图 4.3 所示。 

(a)男性面部图像 

(b)女性面部图像 

图 4.4 图像去噪效果对比 

Figure 4.4 Image denoising effect comparison 

然后分别用本文的双邻域中值滤波算法和标准中值滤波算法进行处理，结果

如图 4.4 所示，(a)和(b)中从上至下依次为原图、改进算法滤波效果图、传统中值

滤波效果图。 

55 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

（2）人脸图像去噪实验结果分析 

由图 4.4 可以看出本文算法的去噪效果明显优于标准中值滤波，同时不损失

图像清晰度。利用峰值信噪比（Peak Signal to Noise Ratio, PSNR）对图像质量进

行客观评价，分别统计测试图像经过中值滤波和双邻域中值滤波处理后的 PSNR

均值，如表 4.1 所示。 PSNR 的数学公式为： 

PSNR

=

10 log

10





(2

n

−
1)
MSE

2





… (4.1) 

其中，n 为每像素的比特数，MSE 是宽为 w 高为 h 的源图像 ( , )

Y i

j 与目标图

像 ( , )
j
Y i

′ 之间的均方误差（Mean Square Error, MSE），其定义为： 

MSE

=

h

−
1

w

−
1

1
× ∑∑
w h

=

=

0

0

i

j

(

Y i

j
( , )

−

′
j
Y i
( , )

2

)

… (4.2) 

MSE 越小，则 PSNR 越大；所以 PSNR 数值越大，表示图像失真越小、质量

越好。 

表 4.1 两种中值滤波算法对比 

Table 4.1 Comparison of two median filtering algorithms 

中值滤波 

双邻域中值滤波 

PSNR（分贝） 

31.9651 

40.2783 

由表 4.1 可以看出，经双邻域中值滤波算法处理后的图像的峰值信噪比较高，

图像去噪能力有所提升。 

4.1.2  图像光照均衡 

（1）人脸图像光照均衡实验结果 

图 4.5 展示了对同一人在相同场景，不同光照环境下的原始彩色图像用本文

方法进行实验的结果。 

（2）人脸图像光照均衡实验结果分析 

图 4.5 中，(a)为非均匀光照条件下的人脸彩色图像，经光照均衡处理后由(d)

中可以看出消除了脸上 T 区周围的阴影；(b)中人脸处于暗光下，处理后的(e)图

像整体亮度增加，同时较好地呈现出了人脸的细节；(c)图像拍摄于亮光环境中，

与之相比，(f)图像的对比度增强，细节变得更清晰。因此，基于直方图均衡化和

56 

 
 
 
 
 
 
 
第 4 章  疲劳驾驶检测的实现 

对数变换的光照均衡方法在消除光照影响的同时能较好地保持图像细节，有利于

图像的后续处理。 

(a) 

(b) 

(c) 

(d) 

(e) 
(a)~(c)原始彩色图像，(d)~(f)光照均衡处理后的图像 

(f) 

图 4.5 彩色图像匀光前后的对比 

Figure 4.5 Contrast of color image before and after homogenization 

4.2 多特征提取的实现 

4.2.1  人脸检测 

（1）实验测试 

本文基于 HOG 特征实现人脸检测，考虑到驾驶员实际行车过程中面部常常

会出现朝向、角度和遮挡的变化，而且会受到环境光照改变的影响，因此模拟一

般驾驶情形下的人脸状况进行人脸检测实验测试。人脸左右偏转、头前后左右倾

斜、面部存在常见局部遮挡以及处于不同光线条件下时的检测结果如图 4.6 所示。 

（2）实验结果分析 

图 4.6 所对应的原始人脸图像反映了驾驶员疲劳状态下的人脸异常姿态，

比如打哈欠时仰头和 瞌睡时点头。由图中可以看出，大部分时候检测框不会完

整包括前额和下颌，但这对于本文的后续研究没有影响。综上所述，本文基于

HOG 特征的方法适用于驾驶场景下不同偏转角度、不同倾斜方向、不同程度

遮挡以及不同光照条件下的人脸检测 。 

57 

 
 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

正脸 

头向前倾 

戴眼镜 

光线较暗 

向左侧脸 

头向后倾 

戴口罩 

光线较亮 

向右侧脸 

头向左倾 

戴眼镜和口罩 

光线不均 

头向右倾 

手挡住人脸 

(a)偏转角度 

(b)倾斜方向 

(c)存在遮挡 
图 4.6 模拟驾驶情形下的人脸检测结果 

(d)光照变化 

Figure 4.6 Face detection results in simulated driving situations 

4.2.2  人脸特征点定位 

（1）实验测试 

本文基于级联的残差回归树进行 68 个人脸关键点标注，这些点的分布情况

和对应坐标如图 4.7 所示。 

为充分展示该方法的效果，参照人脸检测实验测试，模拟驾驶员开车时的人

脸不同偏转角度、倾斜方向、遮挡以及光照进行面部特征点定位，同时被试人

员的表情反映了清醒和疲劳两种状态。实验结果如图 4.8 所示： 

图 4.8 的各图设定的场景为： 

(a)中从上至下依次代表驾驶员正常驾驶时直视前方、向左看、向右看； 

58 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
第 4 章  疲劳驾驶检测的实现 

(b)中第一列从上至下依次代表驾驶员正常驾驶时抬头、向左偏头和疲劳驾驶时

仰头打哈欠，(b)中第二列从上至下依次代表驾驶员疲劳驾驶时向左前、右前偏头

和低头的同时打盹； 

(c)中从上至下依次代表驾驶员正常驾驶时戴眼镜和口罩、用手遮住嘴巴和疲劳

驾驶时手捂嘴仰头打哈欠； 

(d)中从上至下依次代表光线较暗、较亮和不均的环境下驾驶员正常驾驶。 

图 4.7 人脸 68 个关键点 

Figure 4.7 68 key points of the face 

(a)偏转 

(c)遮挡 
图 4.8 模拟驾驶情形下的人脸特征点定位结果 
图 4.8 Location results of facial feature points in simulated driving situations 

(b)倾斜 

(d)光照 

在实际应用场景中，不可避免地会出现摄像头捕捉到多张人脸的情形，为了

排除其他人的干扰，本文做了下面两个工作： 

59 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

1）加入检测最大人脸的功能。由于驾驶员距离摄像头最近，因此对当前帧

中所有的人脸进行大小筛选就可以保证只检测驾驶员的脸； 

2）唯一定位人脸特征点。由于标定出的人脸关键点关系到后续疲劳参数的

提取，如果对定位人脸的操作不加数量限制，就会导致特征指标混淆出错，因此

仅对驾驶员的人脸数据进行处理。 

实验结果如图 4.9 所示： 

图 4.9 唯一定位人脸 

Figure 4.9 Uniquely locate the face 

（2）人脸特征点定位实验结果分析 

由图 4.7 可以看到，人脸特征点分为面部特征点和轮廓特征点，面部特征点

分布在眉毛、眼睛、鼻子、嘴巴处，共计 51 个，轮廓特征点总共有 17 个。其具

体分布情况为：单边眉毛有 5 个特征点，从左边界到右边界均匀采样，共 5×2=10

个；单只眼睛有 6 个特征点，分别在左、右边界和上、下眼睑均匀采样，共 6×2=12

个；嘴唇有 20 个特征点，除了内、外嘴角各 2 个，剩下的分布在上、下嘴唇，

其中上、下嘴唇的外边界，各自均匀采样 5 个点，上、下嘴唇的内边界，各自均

匀采样 3 个点；鼻子上鼻梁部分有 4 个特征点，而鼻尖部分则均匀采集 5 个，共

9 个关键点；脸部轮廓均匀采样了 17 个特征点。 

图 4.8 的实验结果表明，在不同人脸姿态、局部遮挡以及光线条件下，当驾

驶员脸部五官大幅度动作时本文方法均能较好地实现人脸特征点的提取，完全可

以满足实际驾驶的需要。不过，当驾驶员戴口罩时，算法会将口罩表面的褶皱误

60 

 
 
第 4 章  疲劳驾驶检测的实现 

判为嘴巴，由于本文融合了眼睛、嘴巴和头部的多个特征共同进行疲劳驾驶检测，

因而这种情况不会对研究产生实质性影响。 

4.2.3  疲劳特征提取 

本文在 Windows 操作系统下，利用 Visual  Studio  2017 结合开源库 OpenCV

（所用版本为 0penCV  4.1.0）和 Dlib（所用版本为 Dlib  19.19）实现眼睛、嘴巴

和头部的多个面部疲劳特征的提取，下面分别介绍实验过程。 

（1）眼部特征提取 

1）基于 PERCLOS 的眼睛纵横比 

计算人脸视频图像连续 500 多帧的眼睛纵横比并绘制出其随时间变化的曲

线，得到的结果如图 4.10 所示，可以看出，睁眼时 EAR 值在 0.30 上下波动，发

生眨眼动作闭眼时 EAR 值会下降至 0.20 左右，这两种临界状态之间必定存在一

个能够区分眼睛睁闭的阈值。阈值是判断睁闭眼的关键，考虑到人与人之间眼睛

形状的差异性，本文在此处采用了动态设定阈值的方法，预先获取驾驶员 k 个闭

眼时的 EAR 数据，取其平均值，并根据 PERCLOS 算法的 P80 标准得到自适应

阈值 1th ，又人眼纵横比的值在一定程度上存在共性，因此再用根据经验确定的

EAR 阈值 2th 对 1th 进行修正，即将二者的算术平均值作为本文人眼识别疲劳驾驶

的最终阈值 th ，如公式 4.11 所示： 

th
1

th

=

/ 80%
2

+

th
2

=

⋅
(1.25 (

k

∑

i

=
1

n
i

) /

k

+

th
2

) / 2

… (4.3) 

图 4.10 一段时间内人眼 EAR 的变化图示 

Figure 4.10 Diagram of the change of the human eye EAR over a period of time 

61 

 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

为了找寻合理的 k 值，本文做了下述工作：对 5 个人每人采集 50 个闭眼的

EAR 值，这个过程中需要对数据进行筛选，如图 4.11 所示，应舍弃掉标记点对

应的数值，因为它不能真实反映疲劳时的人眼状态。 

图 4.11 EAR 数据的筛选 

Figure 4.11 Screening of EAR data 

鉴于数据量太小时求均值无意义，太大时由于其均值早已趋于稳定，徒增时

间成本，因此本文从求 21 个 EAR 数据的均值逐个增加至求 50 个 EAR 数据的均

值，然后对 5 个人每人 30 个 EAR 均值拟合出如下变化曲线，可以看出从 38 开

始，均值变化波动较小，可以用于反映分布的集中趋势，因此此处 k 取 40。 

图 4.12 EAR 均值的变化曲线 

Figure 4.12 Screening of EAR data 

经实验，本文中被试对象 40 个闭眼 EAR 的均值约为 0.2，故 1

th =

0.25

。 

为了提高检测的准确度，本文在数据集上进行实验，寻找合适的 EAR 经验

阈值 2th 。实验使用了 LFW 和 CEW 两个数据集，选取 LFW 中的 1000 张睁眼图

62 

 
 
 
第 4 章  疲劳驾驶检测的实现 

像、CEW 中的 1000 张闭眼图像，且图像中的人脸均能被正确检测和定位关键点，

部分图像如图 4.13 所示： 

(a)部分睁眼图片 

(a)部分闭眼图片 

图 4.13 睁闭眼测试图片 

Figure 4.13 Eyes open and closed test picture 

使阈值从 0 到 1 变化，步长为 0.05，在数据集上测试，得到了不同 EAR 阈

值和判断睁闭眼准确率之间的对应关系，如图 4.14 所示，结果表明最优阈值为

0.2，因此本文中 2

th = 。 
0.2

图 4.14 EAR 阈值寻优结果图 

Figure 4.14 EAR threshold optimization result graph 

最终,本文中 th 取 0.23。如果 EAR 大于 th ,则认为眼睛是睁开的；如果 EAR

小于 th ,则认为眼睛是闭合的。 

2）眨眼频率 

为检测眨眼频率 BF（即单位时间内的眨眼次数），需要设置同一次眨眼的

连续帧数。令本文被试对象在一段时间内完成正常眨眼和快速眨眼，观测其眼睛

EAR 值变化情况，如图 4.15(a)所示，前 50 帧中发生了一次正常眨眼，为了统计

该次眨眼所包含的视频帧数，对图(a)的水平坐标轴的范围进行两次缩放，依次放

63 

 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

大得到图(b)、图(c)的波形，然后结合 1）中确定的阈值，统计 EAR 由 0.23 先减

小再增大，直至回到 0.23 的耗时，容易看出，3-3.5 帧完成了正常眨眼动作；第

320-340 帧之间接连发生了两次快速眨眼，同样对(a)进行局部放大操作得到图(d)，

可知该动作经历了 1.5-2 帧。 

设 EAR 接连 f 帧小于阈值 th ，则当 f 超过某一值时，可视作发生了眨眼动

作；否则认为是误操作。采集测试人处于正常状态和疲劳状态下的各 5 组、每组

30 秒的眼睛 EAR 波形，根据上述方法对每段视频中正常眨眼的次数 c 和每次眨

眼所用帧数 if 进行统计，根据公式

num

f

i

c

∑
==
i
1
c

计算出单次眨眼包含的连续帧数，

然后对得到的 10 个数值求均值，经实验求得判定眨眼的阈值为 3。本文对视频

流每 30 秒提取一次眨眼频率，即用该段时间内的总眨眼次数除以总帧数得到。 

综上所述，本文将基于 PERCLOS 的眼睛纵横比和眨眼频率结合起来作为疲

劳状态判断的眼部特征参数。 

图 4.15 眨眼波形 

Figure 4.15 Blink waveform 

（2）嘴部特征提取 

1）嘴唇纵横比 

正常驾驶时，驾驶员的嘴部是闭合的，而一般发生以下三种情形时其嘴部会

张开：与人交谈；疲劳打哈欠；由惊讶导致的瞬时嘴巴张大。模拟进行说话、打

哈欠和惊讶张嘴，并对每一帧视频按照 3.4.2 节中的公式(3.36)实时求取张口度，
64 

 
 
第 4 章  疲劳驾驶检测的实现 

得到 MAR 随时间变化的曲线，如图 4.16 所示。从图中可以看出，人在说话的时

候 MAR 值往往不是太高，但该值会在音量提高时显著增大；打哈欠时嘴巴张开

幅度的变化分为两种情况：一种是先变大，而后恢复较低水平，这代表发生了浅

度哈欠，另一种是变大后在较大值上下波动一段时间再下降，视作发生了深度哈

欠；由于惊讶等导致张嘴时 MAR 值会瞬时大幅上升，之后快速回落。因此，MAR

值的大小可以在一定程度上区分常见的嘴部动作，本文通过找寻合适的 MAR 阈

值先进行哈欠初判。 

图 4.16 张口度曲线 

Figure 4.16 Openness curve 

2）嘴巴张开持续时间 

由图 4.16 中可见，若仅用 MAR 阈值进行判别，则大声说话和瞬时张嘴会被

误判为打哈欠，不过，发生前两种嘴部动作时，张口度维持较高值的时间很短，

而打哈欠时嘴巴张开至较大幅度后会停留一定时间，如图 4.16 中红色箭头所示。

因此引入时间条件进行二次验证，即判为打哈欠需要满足以下关系： 

∑

n
( (

α ⋅ ≥
t T
)

)

yawn

… (4.4) 

其中，
n

α
(
)


= 


0,

1,

0

≤

α

≤

mar

yawn

α

≥

mar

yawn

表示嘴巴开合度α连续超过阈值

mar 的

yawn

帧数， t 表示每一帧的时间，

yawnT 表示嘴巴张开持续时间的阈值。 

本文利用 YawDD 数据集检测嘴唇纵横比，根据多次实验的经验值确定上述

哈欠阈值

mar 和

yawn

yawnT 。YawDD 中包含两套 640x480 分辨率、24-bit 真彩色(RGB)、

30 帧/秒、AVI 格式的驾驶员视频数据集：第一套数据集提供了 47 个男驾驶员和
65 

 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

43 个女驾驶员戴或不戴眼镜/墨镜的 322 段视频，每个参与者的若干段视频都分

别体现了①正常驾驶（不说话）、②驾驶时说话或唱歌、③驾驶时打哈欠、④驾

驶时说话和打哈欠这四种情况下的嘴部状态之一；第二套数据集提供了 16 个男

驾驶员和 13 个女驾驶员的 29 段视频，每段视频都包括了驾驶时正常（不说话）、

说话或唱歌和打哈欠的场景。YawDD 数据集中部分样本展示如图 4.17 所示。 

(a)第一套数据集 

(b)第二套数据集 

图 4.17 YawDD 数据集示例 

Figure 4.17 YawDD dataset examples 

常用的阈值法有均值法和中值法，为了对比这两种方法的有效性，首先在第

一套数据集中手动截取 20 个驾驶员每人正常、说话各 10 帧以及打哈欠的连续 50

帧人脸图像。对每个驾驶员的 20 张非打哈欠样本和 50 张打哈欠样本都进行下述

操作： 

①选择任意连续的 30 张打哈欠样本，相应得到 30 个打哈欠时的 MAR 数据，分

别取其均值和中值，并将该值作为此人的 MAR 阈值； 

②使用两种 MAR 阈值对剩余的 40 张图像（包含 20 张非打哈欠样本和 20 张打

哈欠样本）进行哈欠检测； 

③计算检测的准确度。 

两种方法的检测效果如图 4.18 所示，其横轴代表测试对象编号，纵轴代表

对应的准确度，结合表 4.2 可以直观地看出，在绝大多数情况下，选用打哈欠时

66 

 
 
 
 
 
第 4 章  疲劳驾驶检测的实现 

的若干张口度的均值作为阈值更能反映整体情况，具有一定的代表性。因此，本

文采用均值法来确定 MAR 阈值。 

表 4.2 两种方法实验结果统计 

Table 4.2 Statistics of experimental results of two methods 

均值法>中值法  均值法=中值法  均值法<中值法 

数据组数（占比） 

16(80%) 

3(15%) 

1(5%) 

图 4.18 两种方法准确度比较 

Figure 4.19 Comparison of the accuracy of the two methods 

然后在第二套数据集上进行实验，结合前面的结论，本文对每段视频中打哈

欠过程的前、中、后 50 帧分别求取 MAR 均值，最终得出

mar

yawn

=

0.75

；此处嘴

巴张开持续的时间采用一段时间内嘴巴张开持续的帧数来近似表示 ，即用

n α 来等效
(

) yawn

yawnT ，观测 29 段视频中不同嘴部动作下的张嘴持续帧数，结果表

明连续 10 帧 MAR 值高于阈值

3）打哈欠频率 

mar 则可判断为打哈欠，因此 (

n α = 。 

10

)

yawn

yawn

由 1）、2）可知，连续 10 帧

MAR >

0.75

则认为正在打哈欠，每 30 秒统计一

次哈欠的总个数 N ，T 为 30 秒内总帧数，最后根据

F

= 求出打哈欠频率 YF。 

N
T

（3）头部特征提取 

67 

 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

在相机坐标系下定位出人脸 68 个关键点后，需要将其在真实世界里进行描

述，这依赖于 3D 人脸模型来完成。由于普通的人脸模型缺乏通用性和普适性，

所以本文采用标准人脸模型，如图 4.19 所示： 

(a)2D 人脸模型 

(b)3D 标准人脸模型 

图 4.19 人脸模型 

Figure 4.19 Face model 

表 4.3 3D 和 2D 人脸模型特征点对应表 

Table 4.3 3D and 2D face model feature point correspondence table 

角点位置 

序
号 
1  左眉左上角 
2  左眉右角 
3  右眉左角 
4  右眉右上角 
5  左眼左上角 
6  左眼右上角 
7  右眼左上角 
8  右眼右上角 
9  鼻子左上角 
10  鼻子右上角 
11  嘴左上角 
12  嘴右上角 
13  嘴中央下角 
14 

下巴角 

3D 模型点 
序号 
#33 
#29 
#34 
#38 
#13 
#17 
#25 
#21 
#55 
#49 
#43 
#39 
#45 
#6 

3D 模型点世界坐标 

[6.825897, 6.760612, 4.402142] 
[1.330353, 7.122144, 6.903745] 
[-1.330353, 7.122144, 6.903745] 
[-6.825897, 6.760612, 4.402142] 
[5.311432, 5.485328, 3.987654] 
[1.789930, 5.393625, 4.413414] 
[-1.789930, 5.393625, 4.413414] 
[-5.311432, 5.485328, 3.987654] 
[2.005628, 1.409845, 6.165652] 
[-2.005628, 1.409845, 6.165652] 
[2.774015, -2.080775, 5.048531] 
[-2.774015, -2.080775, 5.048531] 
[0.000000, -3.116408, 6.097667] 
[0.000000, -7.415691, 4.070434] 

2D 模型点 
序号 
#17 
#21 
#22 
#26 
#36 
#39 
#42 
#45 
#31 
#35 
#48 
#54 
#57 
#8 

若采用标准 3D 人脸模型中的所有 68 个关键点来估计头部姿态，会大大增

加运算量，从而影响算法效率，因此本文选取其中具有代表性的 14 对特征点作

68 

 
 
 
 
第 4 章  疲劳驾驶检测的实现 

为输入坐标，人脸上的这些点通过连接正好形成三角形，因而使用它们表征头部

姿态时具有稳定性。3D 模型点和 2D 模型点对照如表 4.3 所示。 

用标准 3D 人脸模型匹配检测出的 2D 人脸关键点，求解 3D 点和对应 2D 点

的转换关系，根据旋转矩阵求解欧拉角，实现头部姿态估计。 

模拟驾驶员开车时可能的头部动作，在准确检测出人脸并定位出面部特征点

的前提下，实时输出头部姿态角度，如下图所示： 

图 4.20 头部姿态检测结果 

Figure 4.20 Head posture detection results 

上图中，三维框显示了面部的位姿， ,

x y z 分别代表 pitch, yaw, roll，它们是

,

三个以度为单位的欧拉旋转角度。 

4.3  疲劳驾驶检测的实现 

为了能更为精准地判断驾驶员是否疲劳，使用 4.2.3 节中提取的眼睛、嘴巴

状态与头部姿态的疲劳判断的参数来共同训练支持向量机（SVM）分类器的输入

参数，然后利用训练好的分类器来识别视频中驾驶员的状态。 

目前没有适合上述 SVM 分类器训练用的数据集，所以本文在不同光照环境

下采集了 5 名男性和 5 名女性共 10 个对象模拟驾驶清醒和疲劳状态拍摄的 400

个视频序列来构建正负样本集，其详细信息如表 4.4 所示，设置疲劳状态分类标

签为 1、清醒状态分类标签为 0。 

69 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

根据 4.2.3 的方法对视频的每帧图像计算眼睑闭合度、嘴巴张开度和三个头

部姿态角，每 30 秒统计一次眨眼频率和打哈欠频率，这段时间内 EAR, MAR 和

pitch, yaw, roll 的均值，与 BF, YF 共七种参数构成一个特征向量，然后将每段视

频中所有的特征向量按照串行的方法组合在一起，构成新的特征向量并保存到相

应的文本文件中，由公式(3.46)计算所有样本特征值归一化后的值。 

从采集到的 400 段视频数据集中随机选取 300 段分成 10 份，按照 3.5.2 中步

骤（2）所述进行试验，最终得出最优参数 4.2,

C

=

γ

= 。 
10.0

表 4.4 视频数据集介绍 

Table 4.4 Video data set introduction 

分类  视频数 

内容 

属性 

睁眼、眨眼（包括快速眨眼） 

清醒 

160 

嘴巴闭合、说话（包括大声说话）、 
笑（包括大笑）、惊讶张嘴 

抬头、低头、转头、偏头 

疲劳 

240 

打瞌睡 

眨眼 

打哈欠 

头部后仰、点头、左右倾斜 

640*480 

RGB24 

30 帧/秒 

AVI 格式 

在疲劳驾驶检测的实际应用中，实时性和准确率是两个重要的性能指标，因

此为了验证本文提出的基于多特征融合的疲劳驾驶检测技术的 效果，本文在

Windows  64 位操作系统下，利用 Visual  Studio  2017 结合开源库 OpenCV（所用

版本为 0penCV  4.1.0）和 Dlib（所用版本为 Dlib  19.19）从上述两个方面进行了

实验分析。 

（1）疲劳驾驶检测全过程耗时 

采用分辨率为 640x480 的摄像头实时监控人脸并进行疲劳检测，计算各步骤

的运行时间，进而统计出每一步处理一帧图像的平均耗时，如表 4.5 所示。由下

表可得，本文提出的方法平均用时为 73ms/帧，基本可以满足实时性的要求。 

70 

 
 
 
 
 
 
第 4 章  疲劳驾驶检测的实现 

表 4.5 疲劳检测耗时情况 

Table 4.5 Fatigue testing time-consuming situation 

疲劳检测步骤 

平均运行时间/s 

图像采集及预处理 

人脸检测 

人脸特征点定位 

疲劳状态识别 

0.0159 

0.0061 

0.0438 

0.0072 

（2）疲劳驾驶检测结果对比 

利用数据集中剩余的 100 个视频进行纵向和横向比较，以全面测试本文训练

的 SVM 分类器的准确率。 

1）纵向比较 

在 100 个视频中任意选择 5 个视频，分别基于本文所提取的眼睑闭合度、眨

眼频率、嘴巴张开度、打哈欠频率和头部姿态信息进行疲劳检测，并与融合上述

特征的检测算法相比较，用正确检测疲劳状态的图像帧数与视频总帧数的比值来

衡量算法的准确率，测试结果如表 4.6 所示，最后一列为对应单一特征检测疲劳

的平均准确率，结果表明本文基于多特征融合的疲劳驾驶检测算法正确识别疲劳

状态的能力明显高于传统的基于单疲劳特征的方法。 

表 4.6 不同疲劳特征下检测准确率对比 

Table 4.6 Comparison of detection accuracy under different fatigue characteristics 

        视频编号 

检测准确率 

1 

2 

3 

4 

5 

基于眼睑闭合度 

90.40%  87.70%  83.60%  88.20%  87.10%  87.40% 

基于眨眼频率 

79.30%  80.50%  82.70%  85.90%  84.60%  82.60% 

基于嘴巴张开度 

66.20%  65.80%  64.30%  64.90%  61.90%  64.62% 

基于打哈欠频率 

72.70%  75.20%  74.90%  80.10%  69.50%  74.48% 

基于头部姿态信息  67.90%  73.40%  66.10%  54.80%  60.60%  64.56% 

基于多特征融合 

93.80%  94.50%  96.10%  95.20%  95.70%  95.06% 

71 

 
 
 
 
 
 
基于多特征融合的疲劳驾驶检测技术研究 

2）横向比较 

使用本文提出的基于多特征融合的疲劳驾驶检测方法依次判别 100 个视频

中实验人员的疲劳状态，并与另外两种疲劳驾驶检测方法进行对比，其中基于多

特征加权和的疲劳状态识别方法通过计算特征参数的加权和，根据加权和值进行

疲劳状态判定；融合面部眼嘴状态的疲劳判定方法则选用线性核函数训练 SVM

模型。表 4.7 展示了对比结果，可以看出，相比于其他两种方法，本文方法具有

最高的检测准确率。不过，方法 1 将疲劳状态分为三个等级，而本文只实现了疲

劳状态的二分类；方法 2 对于每帧图像的疲劳检测平均耗时为 64ms，处理速度

快于本文方法。 

表 4.7 不同疲劳驾驶检测方法准确率对比 

Table 4.7 Comparison of the accuracy of different fatigue driving detection methods 

序号 

                                    疲劳状态 
检测准确率 

清醒 

疲劳 

1 

2 

3 

基于多特征加权和的疲劳状态识别 

89.72% 

88.13% 

融合面部眼嘴状态的疲劳判定 

87.46% 

83.58% 

本文算法 

95.67% 

93.84% 

4.4  本章小结 

本章主要对基于多特征融合的疲劳驾驶检测方法进行实验测试和结果分析。

首先利用 3.1 节中所提到的图像预处理算法实现了图像去噪和图像光照均衡，并

对比分析了处理前后的图像效果；然后展示了本文基于 HOG 特征的人脸检测方

法及基于级联的残差回归树的人脸特征点定位方法的结果，经分析，这两种方法

都满足常见疲劳驾驶场景的应用需要；接着分别阐述了本文提取眼部、嘴部和头

部特征的五个疲劳指标的过程，这五个指标分别是：眼睑闭合度、眨眼频率、嘴

巴张开度、打哈欠频率和头部姿态信息；最后利用支持向量机建立基于特征融合

的疲劳检测模型，在制作的驾驶员疲劳检测数据集上进行对比实验，证明了（1）

本文所提出的驾驶员疲劳检测算法运行速度较快，能够满足实时检测的需求；（2）

本文基于多特征融合的疲劳驾驶检测算法正确识别疲劳状态的能力明显高于传

统的基于单疲劳特征的方法，并且与其他现有疲劳驾驶检测方法进行了对比，进

一步验证了所提算法的优越性。

72 

 
第 5 章  总结与展望 

第 5 章  总结与展望 

5.1  总结 

本文提出了一种基于多特征融合的疲劳驾驶检测方法。主要工作总结如下： 

（1） 对视频图像进行预处理。视频图像历经采集、传输、存储，在此过程中其

质量会因受到噪声干扰而降低，而且在行车过程中驾驶员的面部区域会被不

同光线条件所影响，因此本文预先对视频图像进行下述两种处理，保证能够

准确检测人脸：1）基于双邻域中值滤波去除图像噪声；2）结合直方图均衡

化算法和对数变换均匀图像光照。 

（2） 实时人脸检测。综合考虑速度和准确性这两个指标，本文选用 HOG 特征

检测视频图像中的人脸，即在人脸图像上按照不同大小的窗口进行滑动扫描，

同时提取该块的 FHOG 特征，并用 SVM 训练出的人脸分类器判定当前块是

否属于人脸，结束对整幅图像的扫描后，存在同一人脸区域被多次检出的情

况，用非极大值抑制对此现象进行处理，然后得到人脸检测的最终结果。经

实验，该方法对遮挡、人脸变化具有鲁棒性。根据实际应用需要，本文只进

行最大人脸检测。 

（3） 高精度面部特征点定位。在正确检出人脸的基础上，本文基于级联的残差

回归树标注 68 个人脸特征点，这些点的坐标信息将用于计算疲劳特征参数。

实验表明该方法既方便又有高识别率，可以为后续的头部姿态估计提供准确

的人脸特征点坐标值。为了排除其他人脸信息的干扰，本文只对检测出的最

大人脸唯一定位人脸特征点。 

（4） 眼部和嘴部疲劳检测。基于 PERCLOS 准则由人眼的 12 个特征点计算眼

睛纵横比 EAR，根据 EAR 阈值来识别眼部睁闭状态，进而实现眨眼检测，

然后统计在单位时间内发生眨眼的次数，从而求出眨眼频率；对于嘴部疲劳

状态的识别，首先根据嘴巴的 10 个特征点计算嘴部高宽比 MAR，找寻合理

的 MAR 阈值进行哈欠初判，再结合嘴巴张开持续时间来二次验证是否打哈

欠，同样地，对单位时间内的打哈欠次数进行统计，求出打哈欠频率。 

（5） 头部姿态角计算。头部姿态估计是从二维视频图像映射到三维空间的过程，

本文从定位出的 68 个 2D 人脸关键点中选择了 14 个具有代表性的点，通过

73 

 
基于多特征融合的疲劳驾驶检测技术研究 

用这些点去匹配 3D 标准人脸模型，求解出 3D 模型点和对应 2D 图像点之间

存在的转换关系，则头部姿态角可由旋转矩阵求得，从而实现头部姿态估计。 

（6） 多特征融合进行疲劳状态判断。提取出眼睑开合度、眨眼频率、嘴巴张开

度、打哈欠频率和头部姿态角五种疲劳特征，得到七个特征参数，选定了采

用 RBF 核函数的支持向量机将上述特征融合起来建立疲劳检测模型，然后

在自制的疲劳驾驶检测视频数据集上开展对比实验，一方面证明本文所提出

的方法具有较快的运行速度，可以用于进行实时检测；另一方面实验结果表

明本文基于多特征融合的疲劳驾驶检测算法正确识别疲劳状态的能力明显

高于传统的基于单疲劳特征的方法，并且同另外两种现有方法的疲劳驾驶检

测准确率进行比较，进一步体现出了所提方法的优良性能。 

5.2  展望 

本文在模拟驾驶员驾驶状态的条件下对基于多特征融合的疲劳驾驶检测技

术进行了初步的研究，虽然在算法实时性和准确率方面取得了不错的效果，但是

由于作者时间和实验条件的限制，论文中仍存在一些需要完善的地方。后续的改

进工作可以从以下几个方面展开： 

（1） 本文仅仅对驾驶时的疲劳状态进行了最简单的二分类，即清醒和疲劳，然

而疲劳是一个由浅到深缓慢变化的过程，为了更精准地评估疲劳状态并做

出相应的预警，可以考虑对疲劳程度进行进一步划分，比如分为清醒、轻

度疲劳和重度疲劳。 

（2） 本文基于单核（RBF 核）支持向量机训练驾驶员疲劳检测模型，为了提高

SVM 的分类效果，应当考虑通过为不同的疲劳特征训练不同的核函数，

然后将多个核函数进行线性加权的方法来得到具有处理多源信息能力的

组合核。 

（3） 本文的相关实验是在实验室环境下对驾驶情形进行模拟开展的，这造成以

下两方面的影响：一方面模拟真实疲劳状态下人眼部、嘴部和头部的疲劳

动作不可避免地会引入主观因素的影响，从而降低所提取特征的真实性；

另一方面采集到的视频数据集不仅数量十分有限，其内容也欠缺丰富性和

准确性。针对上述两点，将来如有可能应当考虑和车企合作，在实车中搭

74 

 
第 5 章  总结与展望 

建数据采集平台，从而获取大量的实际驾驶数据以支撑驾驶疲劳检测方法

的研究。 

75 

 
基于多特征融合的疲劳驾驶检测技术研究 

76 

 
参考文献 

参考文献 

[1]  朱剑怀. 基于视觉特征融合的驾驶员疲劳检测技术研究[D]. 武汉理工大学. 

[2]  陈三林, 胡剑东. 道路交通事故致因分析与安全预防对策研究[J]. 法制与社会, 2020, (27). 

[3]  杨星. 一种支持向量机的图像多特征疲劳驾驶检测方法研究[D]. 西安理工大学. 

[4]  牛晶. 车辆疲劳驾驶研究方法综述[J]. 汽车实用技术, 2018, 044(007):192-196. 

[5]  范薇. 基于人脸识别的疲劳驾驶检测系统的设计与实现[D]. 电子科技大学, 2014. 

[6]  陈龙, 李冰, 郑雪峰, et al. 一种基于正则极限学习机的非接触式疲劳驾驶检测方法. 2020. 

[7]  郑拓. 基于面部视觉特征的疲劳检测方法研究[D]. 齐鲁工业大学. 

[8]  陈哲. 基于多信息融合的疲劳驾驶检测研究综述[J]. 农业装备与车辆工程, 2019, (9). 

[9]  邹昕彤. 基于表情与头部状态识别的疲劳驾驶检测算法的研究[D]. 吉林大学. 

[10] 陈银星. 多图像去噪方法及应用[D]. 五邑大学, 2019. 

[11] GU  S,  TIMOFTE  R.  A  Brief  Review  of  Image  Denoising  Algorithms  and  Beyond[M]. 

Inpainting and Denoising Challenges, 2019. 

[12] FAN  L,  ZHANG  F,  FAN  H,  et  al.  Brief  review  of  image  denoising  techniques[J].  Visual 

Computing for Industry Biomedicine Art, 2019, 2(1). 

[13] DIWAKAR M, KUMAR M. A review on CT image noise and its denoising[J]. Biomedical 

Signal Processing Control, 2018, 42(APR.):73-88. 

[14] X., Y., GAO, et al. A multi-frame image super-resolution method[J]. SIGNAL PROCESSING 

-AMSTERDAM, 2010. 

[15] LEI  Z,  BAO  P,  WU  X.  Multiscale  LMMSE-based  image  denoising  with  optimal  wavelet 

selection. IEEE Trans Circuits Syst Video Technol[J]. IEEE Transactions on Circuits 

Systems for Video Technology, 2005, 15(4):469-481. 

[16] D  ABOV  K,  FOI  A,  KATKOVNIK  V,  et  al.  Image  Denoising  by  Sparse  3-D  Transform-

Domain Collaborative Filtering[J]. IEEE Transactions on Image Processing, 2007, 16(8):2080-

2095. 

[17] 林天圆. 基于视频的人脸检测和性别识别[D]. 济南大学. 

[18] 康志亮. 基于小波的红外图像增强算法研究[D]. 电子科技大学. 

[19] 黄华, 蒋永馨, 王孝通, et al. 一种基于 Ardely 分割算法的夜间图像增强方法[C]. 第十四届

全国图象图形学学术会议, 2008. 

[20] VOICU L I, MYLER H R, WEEKS A R. Practical considerations on color image enhancement 

using homomorphic filtering[J]. Journal of Electronic Imaging, 1997, 6(1):108-113. 

[21] FATTAL R. Gradient domain high dynamic range compression[J]. Proc. 29th Annual Conf. 

Computer Graphics Interactive Techniques, 2002. 

[22] 黄华, 王孝通. 基于 Retinex 理论的图像增强算法[J]. 兵器装备工程学报, 2009, (1). 

77 

 
基于多特征融合的疲劳驾驶检测技术研究 

[23] 陈超. 改进单尺度 Retinex 算法在图像增强中的应用[J]. 计算机应用与软件, 2013, (04):61-

63+80. 

[24] HUANG  L,  ZHAO  W,  ABIDI  B,  et  al.  A  Constrained  Optimization  Approach  for  Image 

Gradient Enhancement[J]. IEEE Transactions on Circuits 

Systems for Video Technology, 2017:1-1. 

[25] 于典. 基于梯度域的静脉图像增强算法研究[D]. 天津理工大学, 2016. 

[26] 叶亮. 一种基于变形模板匹配的人脸检测方法[J]. 计算机工程, 2004, 30(011):115-117. 

[27] 人脸检测方法综述 [J]. 计算机应用研究, 2004, 21(9):1-4. 

[28] 张捷. 基于核心灰度分布人脸自动检测方法研究[D]. 解放军信息工程大学. 

[29] 刘佰强. 基于人脸视频智能分析的日间驾驶员不安全行为检测分类与预警系统[D]. 西安

理工大学. 

[30] 肖阳. 人脸检测算法综述[J]. 电子技术与软件工程, 2014, 000(004):113-116. 

[31] YANG  G,  HUANG  T  S.  Human  face  detection  in  a  complex  background[J].  Pattern 

Recognition, 1994, 27(1):53-63. 

[32] 董 立 新.  基 于 先 验 知 识 的 人 脸 检 测 算 法 研 究 与 应 用[J].  数 字 技 术 与 应 用,  2010, 

000(001):73-74. 

[33] 徐婷婷. 基于卷积神经网络的人脸检测算法研究[J]. 

[34] LIANG L H, AI H Z, XIAO X P, et al. Face detection based on template matching and support 

vector machines[J]. Chinese Journal of Computers, 2002. 

[35] YUILLE A L, HALLINAN P W, COHEN D S. Feature extraction from faces using deformable 

templates[J]. International Journal of Computer Vision, 1992, 8(2):99-111. 

[36] Deformation  Modeling  for  Robust  3D  Face  Matching  [J].  IEEE  Transactions  on  Pattern 

Analysis and Machine Intelligence, 2008, 30(8):1346-1357. 

[37] 梁路宏, 艾海舟. 基于多模板匹配的单人脸检测[J]. 中国图象图形学报:A 辑, 1999. 

[38] GOVINDARAJU V, SRIHARI S N, SHER D B. A computational model for face location[C]. 

Third International Conference on Computer Vision, ICCV 1990. Osaka, Japan, 4-7 December, 

1990, Proceedings, 1990. 

[39] 苏晨. 非约束场景下的人脸关键点检测算法研究[D]. 华中科技大学. 

[40] TIMOTHY  F.  Active  Shape  Models-Their  Training  and  Application[J].  Computer  Vision 

Understanding, 1995, 61. 

[41] TIRKAZ  C,  ALBAYRAK  S.  Face  Recognition  Using  Active  Appearance  Models[C]. 

European Conference on Computer Vision, 1998. 

[42] Feature Detection and Tracking with Constrained Local Models [J]. Procedings of the British 

Machine Vision Conference 2006, 2006:95.1-95.10. 

[43] 张明丽. 人脸关键点检测算法研究[D]. 北方工业大学, 2018. 

[44] DOLLáR P, WELINDER P, PERONA P. Cascaded pose regression[J]. IEEE Transactions on 

Image Processing, 2010. 

78 

 
参考文献 

[45] 邓健康. 基于级联回归模型的人脸配准研究[D]. 南京信息工程大学, 2015. 

[46] 崔馨方. 关于人脸关键点检测的若干问题研究[D]. 东南大学. 

[47] YI  S,  WANG  X,  TANG  X.  Deep  Convolutional  Network  Cascade  for  Facial  Point 

Detection[C]. Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on, 

2013. 

[48] ZHANG  Z,  PING  L,  CHEN  C  L,  et  al.  Facial  Landmark  Detection  by  Deep  Multi-task 

Learning[C]. European Conference on Computer Vision, 2014. 

[49] ZHANG  K,  ZHANG  Z,  LI  Z,  et  al.  Joint  Face  Detection  and  Alignment  Using  Multitask 

Cascaded  Convolutional  Networks[J].  IEEE  Signal  Processing  Letters,  2016,  23(10):1499-

1503. 

[50] 苑玮琦,  袁英.  基于 PERCLOS 的眼睛张开程度检测算法研究[J].  微计算机信息,  2010, 

26(25):46-48. 

[51] 吕俊杰. 基于仿射对应关系的单目视觉头部姿态估计[D]. 中南大学, 2013. 

[52] 郑德伟. 基于机器学习的人脸面部疲劳表情识别[D]. 北京邮电大学, 2019. 

[53] 薛原.  基于 HOG 特征和多分类器集成学习方法对行人检测的研究[D].  大连理工大学, 

2019. 

[54] 李耀华. 基于眼部特征分析的驾驶员疲劳驾驶实时检算法研究[D]. 华南理工大学. 

[55] 李延枫. 基于眼部识别的疲劳驾驶检测系统设计[D]. 成都理工大学. 

[56] 马召宾. 融合眼部特征及头部姿态的实时疲劳驾驶检测技术研究[D]. 山东大学, 2016. 

[57] 刘委坤. 基于机器视觉的拖拉机驾驶员疲劳检测方法研究[D]. 吉林农业大学. 

[58] 苑玮琦, 滕红艳. 眼睛疲劳程度判定方法研究[J]. 计算机工程与应用, 2013, 49(17):199-203. 

[59] 基于脑电波与眨眼的驾驶员疲劳模拟实验研究[D]. 同济大学, 2011. 

[60] 王豪荣,  胡婷,  葛丽娟.  驾驶员疲劳检测中的嘴部状态研究[J].  电子设计工程,  2015, 

000(002):191-193. 

[61] 李敏. 基于眼部和嘴部特征融合的驾驶员疲劳检测方法研究[D]. 浙江师范大学, 2011. 

[62] 陈云华. 基于可拓学与面部视觉特征的精神疲劳识别研究[D]. 广东工业大学. 

[63] 刘敏. 基于头部特征和姿态估计的疲劳驾驶检测技术的研究[J]. 东华大学, 2019. 

79 

 
 
基于多特征融合的疲劳驾驶检测技术研究 

80 

 
致  谢 

致  谢 

三年时光如白驹过隙，俯仰之间我的硕士研究生生涯已经进入倒计时，行文

至此，似乎也在无声而强有力地宣告我的学生时代的结束。回望来时路，感受了

不一样的风景、遇见了形形色色的人事，它们使我由只知“仰望星空”变得懂得

“脚踏实地”。毕业是终点，更是新的起点，感恩这三年期间帮助、陪伴我的每

一个人，谨以此文向你们表达最真挚的谢意！ 

首先，由衷地感谢我的导师周祚峰研究员，周老师学识渊博、为人正直、勤

勤恳恳、平易近人，与他交往如沐春风。在学习上，周老师为我创造了良好的科

研条件，他诲人不倦，耐心引导我开展课题研究，及时关注、把控我的工作动向

与进展；在生活中，周老师想学生之所想，急学生之所急，给予我极大的关怀、

理解和支持。得师如此，三生有幸。在此，再次向周老师表达我衷心的感谢和崇

高的敬意。 

感谢吴清泉师兄。师兄心思细腻、明察秋毫，无论是学术上还是处世上，师

兄始终在帮助我发现更好的自己，犹记得师兄对我的多次谆谆教诲，语重心长。

师兄成熟稳重、高度自律、热爱工作，同时简单纯粹、宽容豁达、与人为善，他

的作风和品格深深地感染和激励着我。 

感谢课题组的成员们。感谢胡国良师兄和黄会敏师姐，他们幽默、达观，与

他们推心置腹的交谈令我受益匪浅；感谢我的同门许明明同学，无论在国科大还

是回所后，他一直对我照顾有加，在学习和生活上都提供了很多帮助；感谢刘才

钰师弟，虽共事不过寥寥数日，却给课题组带来很多欢乐，并且在论文撰写过程

中经常给我关心、帮助和鼓励。 

感谢因西安光机所结缘的小伙伴们。感谢李瑞眉同学，三年时间常伴我左右，

温柔安静、慢条斯理，对我有求必应；感谢王欢婷同学，和我在雁栖湖朝夕相处，

许多事都能一拍即合；感谢焦茵同学，从不吝啬对我的肯定与欣赏，我们惺惺相

惜；感谢田钰圆同学，从她身上我看到了不一样的世界，收获颇多；感谢董晶同

学，在宿舍生活中与我互相包容，和谐共处；感谢朋友王佳敏和刘应龙，认真协

助我完成论文中的实验测试，另外尤其感谢佳敏妹妹在广州对我的督促、理解和

陪伴。 

81 

 
基于多特征融合的疲劳驾驶检测技术研究 

感谢实验室的曹剑中老师对我科研工作的支持；感谢研究生部赵萍老师、张

雯老师、朱家芹老师在学习和生活中对我的诸多关照。 

感谢徐康顺同学时不时的鼓励以及对我论文的指导；感谢高兴奇同学特殊的

陪伴，让我对每日平淡的生活多了一份期待。 

感谢我的好友段朔。我们于大学相识、相知，硕士阶段各自求学，但彼此同

频，并肩前行，她给我的生活增添了很多色彩，也为我求学、求职提供了行动上

的有力支持。 

最后，特别感谢我的爸爸妈妈和姐姐。他们一直以来为我无私付出，保护我

免受家中琐事的叨扰；他们尊重我的个性发展，支持我的每个选择，始终是我最

坚强的后盾。 

一路走来，要感谢的人太多太多，而文字有限，我将怀揣感恩之心昂首向前。 

82 

 
