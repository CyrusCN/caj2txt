  电 子 测 量 技 术ELECTRONICMEASUREMENTTECHNOLOGY第46卷第20期2023年10月 DOI:10.19651/j.cnki.emt.2312585多特征融合的驾驶员疲劳程度量化方法研究*任建新 许 锋(中国刑事警察学院公安信息技术与情报学院 沈阳 110854)摘 要:针对疲劳驾驶检测系统鲁棒性差和疲劳程度划分过于简单的问题,利用MediaPipe人脸关键点检测技术和模糊推理系统,融合多种面部疲劳特征,研究视频序列中驾驶员疲劳程度量化评估方法,实现对驾驶员疲劳程度的实时评分和疲劳预警。首先利用MediaPipe人脸检测模型定位面部关键点;之后使用检测到的关键点从视频帧中实现对面部疲劳动态特征进行提取,得到单位时间内眨眼次数(PERCLOS)、打哈欠时长、有无瞌睡、人脸摆动近似熵四个评估指标,最后设计模糊推理系统对疲劳程度进行量化,实现对驾驶员疲劳程度的实时评估。研究表明,所提出的方法科学有效的实现了对驾驶员疲劳程度的量化评估,进一步提升了基于面部特征的疲劳驾驶检测的鲁棒性和可靠性。关键词:疲劳驾驶;模糊推理系统;人脸检测;事故预防中图分类号: TP391.4  文献标识码:A  国家标准学科分类代码:510.4050Research on the quantification method of driver fatigue level by fusing multiple featuresRen Jianxin Xu Feng(School of Public Security Information Technology and Intelligence,Criminal Investigation Police University of China, Shenyang 110854, China)Abstract:Aiming at the problems of poor robustness of fatigue driving detection system and too simple classification of fatigue degree, use MediaPipe face key point detection technology and a fuzzy inference system to fuse a variety of facial fatigue features to study the quantitative assessment method of driver fatigue degree in video sequences and realize real-time scoring of driver fatigue degree and fatigue warning. In this paper, firstly, the MediaPipe face detection model is used to locate the facial key points; secondly, the detected key points are used to extract the dynamic features of facial fatigue from the video frames, and four evaluation indexes are obtained: PERCLOS, yawn length, whether or not to nod off, and the approximate entropy of face oscillation; finally, the fuzzy inference system is designed to quantify the fatigue degree and realize the real-time evaluation of driver fatigue. The proposed method shows that the proposed method is scientifically sound. The study shows that the proposed method scientifically and effectively achieves the quantitative assessment of driver fatigue degree and further improves the robustness and reliability of fatigue driving detection based on facial features.Keywords:fatigue driving;fuzzy inference system;face detection;accident prevention 收稿日期:2023-01-08*基金项目:“十三五”国家重点研发技术项目(2017YFC0821004)、2022辽宁省教育厅基本科研重大攻关项目(LJKZZ20220007)、中央高校基本科研业务重大培育项目(3242022004)资助0 引  言  随着社会快速发展,汽车保有量的急剧增加直接导致交通事故频发,造成大量人员伤亡和经济损失,成为全国乃至世界范围内的严重问题。研究表明,驾驶员因素是导致交通事故的主要原因之一,其中疲劳驾驶引发的事故占所有交通事故的35%~45%[1]。通过对驾驶员疲劳程度进行检测与量化有助于在事故发生前检测到驾驶疲劳先兆,并及时预防,能够有效避免疲劳驾驶事故的发生,故进一步开展驾驶员疲劳程度检测与量化的研究十分必要。目前,驾驶员疲劳检测方法主要有基于车辆信息、生理信息、行为特征[2]的方法。基于车辆信息的方法是收集车辆速度、加速度、转向角等信息并分析异常数据来识别疲劳[3-4],这类方法易受驾驶员习惯影响,准确性较低。基于·61· 任建新 等:多特征融合的驾驶员疲劳程度量化方法研究第20期生理信息的方法是对驾驶员的脑电图[5]、心电图、肌电图[6]等生理指标的规律性变化进行检测,能够更直接、准确地检测出疲劳状态,但大都需要佩戴复杂设备,成本高且易影响驾驶[7]。基于行为特征的方法是检测驾驶员面部或头部的行为特征变化检测疲劳状态,近年来,利用图像识别技术提取面部特征并根据疲劳特征进行疲劳检测得到了广泛研究,如检测眨眼状态[8]、嘴巴状态[9]、头部姿势等方法,已经被证明是一种行之有效的方法[10-11]。然而,现有方法大都侧重于面部疲劳特征的检测,而对疲劳程度的评价方法研究不足。首先是评价指标过于依赖某单个特征[12],受环境和个体差异等影响,使用单个疲劳特征判断疲劳可靠性较低[13]。其次是评价方式过于简单,往往简单的判断驾驶员疲劳与否或是按照疲劳等级进行划分,忽略了疲劳程度的渐变性、疲劳特征的持续性,且疲劳程度作为一个模糊概念,无法根据某一指标简单地判断疲劳与否。为弥补以往疲劳驾驶检测系统鲁棒性差和疲劳程度评价过于简单的不足,本文建立一种多特征融合驾驶员疲劳程度实时监测和量化方法。本文的主要贡献有以下几点:1)采用一种面部关键点和图像处理相结合的方法来实现更精确的面部疲劳特征提取。2)提出基于时间累积效应的面部疲劳特征指标,从而更好地反映真实的疲劳状态。3)融合多种疲劳特征,并采用模糊推理系统实现对驾驶员疲劳程度实时量化评估,模型检测更加鲁棒,对驾驶员的疲劳预警更加可靠。1 人脸关键点定位  MediaPipe框架是一个通过构建机器学习方法处理视频、音频等时间序列数据的框架[14]。近年来,得益于占用资源少和性能高效的特点被广泛应用于桌面、服务器和嵌入式设备。MediaPipe Solutions是构建在MediaPipe框架上的,基于特定预训练TensorFlow或TFLite模型的开源预构建解决方案。目前,它提供了16个方案,MediaPipe Face Mesh是其中一种。其仅需一个摄像头,便能够在视频或图像中实时检测和跟踪人脸,并生成三维面部网格模型,进行面部分析。图1 人脸关键点检测模型框架MediaPipe模型框架如图1所示,图像首先输入到Face Detector模块进行人脸检测,检测出的人脸区域进行矫正和归一化处理;处理后的图像输入到3D Mesh Network三维关键点检测网络,得到三维面部模型。如果输入是连续帧,3D Mesh Network会将检测结果输入到下一阶段的网络,使网络综合多阶段的检测结果对人脸进行实时定位追踪。本文使用MediaPipe Face Mesh对驾驶员面部关键点检测,实时估计468个人脸三维关键点。2 面部特征及提取方法2.1 眼部特征  本文使用单位时间内眨眼次数(percentage of eyeiid ciosure,PERCLOS)[15]作为眼部特征,其定义为单位时间内眼睛闭合一定比例所占的时间。PERCLOS已经被证明在量化疲劳方面是有效的,当驾驶员处于警觉状态时,PERCLOS的测量值明显低于驾驶员疲劳时。其判断眨眼有P80、P70、EM三种标准,如EM度量被确定为一定时间内眼睛至少闭合50%的时间比例。使用眼睛纵横比(eye aspect radio,EAR)即眼睛长宽比,衡量眼睛睁开与闭合状态,眼睛睁开时EAR较大,反之EAR趋近于0。首先利用MediaPipe框架对眼部关键点进行定位,选取6个关键点如图2(a)所示。利用眼部关键点的横、纵以及深度坐标计算各点欧氏距离,计算EAR:EAR=‖p1-p5‖+‖p2-p4‖2‖p0-p3‖(1)经验证,EAR值设置为0.15时检测精度较高,故设定EAR小于0.15时,判定眼睛闭合。得到眼睛闭合帧数和总帧数后,进一步计算PERCLOS:PERCLOS=眼睛闭合总帧数检测时间段总帧数×100%(2)2.2 嘴部特征  本文使用单次打哈欠时长作为嘴部特征,使用嘴巴纵横比(mouth aspect ratio,MAR)即嘴巴长宽比,衡量嘴巴张合状态,检测驾驶员是否存在打哈欠行为。首先利用MediaPipe框架对嘴部关键点进行定位,选取八个关键点如图2(b)所示。利用嘴部关键点的横、纵以及深度坐标计算各点欧氏距离,计算MAR:MAR=‖p1-p7‖+‖p2-p6‖+‖p3-p5‖3‖p0-p4‖(3)经验证MAR阈值设为1.7时检测精度较高。故设定MER大于1.7时认为打哈欠,并开始计算打哈欠时长,进一步评估疲劳程度。2.3 头部运动特征  本文使用瞌睡行为和人脸摆动近似熵来作为头部运动特征。1)瞌睡行为计算驾驶过程中人脸欧拉角变化[16],以检测点头或歪头行为,判断驾驶员有无瞌睡行为。首先利用MediaPipe模型获得人脸关键点,输出人脸468个关键点的x、y、z三·71· 第46卷电 子 测 量 技 术维坐标,其中x是图像横坐标,y是图像纵坐标,z是一个表示各关键点距离镜头的远近相对值;选取脸部4个关键点坐标计算3个欧拉角(pitch,yaw,roll),如图3所示。pitch为俯仰角,即绕x轴旋转角度;yaw为偏航角,即物体绕y轴旋转角度;roll为翻滚角,即绕z轴旋转角度。图2 面部关键点图3 头部欧拉角俯仰角(pitch)或翻滚角(roll)瞬间变化过大时,认为存在点头或歪头行为,这在驾驶过程中是不正常的现象。根据图2(c)中特征点的三维坐标,俯仰角、翻滚角定义为:Pitch=arctan|P9z-P18z||P9y-P18y|(4)Yaw=arctan|P446z-P226z||P446x-P226x|(5)2)人脸摆动近似熵基于已得的人脸欧拉角,计算人脸摆动的方向,使用欧拉角中的偏航角(Roll)表示人脸摆动的变化。Roll=arctan|P9y-P18y||P9x-P18x|(6)使用近似熵衡量人脸摆动变化的混乱程度,提取面部疲劳特征。近似熵是一种用于量化时间序列波动规律性和不可预测性的非线性动力学参数,表示一个时间序列的复杂性,越复杂的时间序列对应近似熵越大。计算过程如下:设采集到的原始数据为{u(i),i=0,1,2,…,N},预先给定模式维数m和相似容限r;将序列{u(i)}按顺序组成m维矢量{X(i)},即:X(i)=[u(i),u(i+1),…,u(i+m-1)](7)其中,计算每一个矢量与其余矢量之间的距离:d[X(i),X(j)]=max0~m-1|u(i+k)-u(j+k)|(8)按照给定的阈值r(r>0),对每一个i值统计d[x(i),X(j)]<r的数目及此数目与中的矢量个数N-m+1的比值,记作:Cmi(r)=(number of X(j)) such that d[X(i),X(j)]≤r)/(N-m+1)(9)再求C的对数平均值,得到ϕm(r)。即:Φm(r)=(N-m+1)-1∑N-m+1i=1log(Cmi(r))(10)因此,序列的近似熵可以被定义为:ApEn=Φm(r)-Φm+1(r)(11)3 面部疲劳特征检测算法设计及实现3.1 疲劳检测算法整体流程  模型实现流程如图4所示。实现对一段时间内的视频帧进行评估,实时输出疲劳程度的量化结果。模型输入为视频流,直接输入Mediapipe模型,生成468个人脸关键点;利用关键点数据计算EAR、MAR和欧拉角方向,在连续帧中计算PERCLOS值、打哈欠时长、是否瞌睡和人脸摆动近似熵,并进行数据归一化后,送入模糊推理评分模型,实现疲劳程度量化。图4 算法整体流程经过特征检测部分得到的4个特征值包括:眼睛状态、嘴巴状态,瞌睡状态以及人脸摆动近似熵:1)眼睛状态检测驾驶员在疲劳状态下PERCLOS值增大,可以通过计算PERCLOS判断驾驶员疲劳程度,PERCLOS值大于设定阈值时存在疲劳,持续增大时驾驶员疲劳程度加重。2)嘴巴状态检测打哈欠是人在疲劳状态下一种本能的行为,可以通过嘴巴状态检测驾驶员有无打哈欠行为进而判断驾驶员疲劳程度。MAR大于设定阈值时开始计算嘴巴张开时长,时长超过设定阈值时认为存在打哈欠行为,时长持续增大时驾驶员疲劳程度加重。3)瞌睡检测在疲劳驾驶过程中,由于驾驶员生理状态的变化,往往会不自觉地点头或歪头。故本文模型中,当检测到驾驶员发生点头或歪头时,认为存在瞌睡行为,判定驾驶员疲劳程度加重。4)人脸摆动近似熵计算正常驾驶状态下,驾驶员会主动观察行驶环境和变化·81· 任建新 等:多特征融合的驾驶员疲劳程度量化方法研究第20期的道路条件,使人脸摆动方向有一个持续且无规律的变化,人脸摆动近似熵较大;而在疲劳驾驶情况下,驾驶员人脸摆动比较稳定,变化速度慢,人脸摆动近似熵较小。故本文模型中,检测到驾驶员人脸摆动近似熵较小时,认为驾驶员状态不活跃;反之,认为驾驶员状态活跃。3.2 模糊推理评分模型  为实现对疲劳程度的量化,本文构建了基于模糊推理评分模型。模糊推理系统是一种利用模糊逻辑、通过模糊推理过程将一组输入映射到一组输出的函数的自动控制系统,实现对难以建立数学模型的对象的有效决策。本文模糊推理系统的模糊控制器采用四输入单输出结构,4个输入分别为眼睛状态、嘴巴状态、瞌睡情况和人脸摆动近似熵,输出为疲劳程度。输入一为眼睛状态,对应的模糊语言变量为blink_state,取值为{Low frequency,High frequency,Closed},论域定义在闭区间[0,1],隶属度函数采用高斯隶属函数与S型函数。如图5(a)所示。模糊子集High frequency代表PERCLOS较高,反映存在可能或轻度的疲劳。模糊子集Closed代表PERCLOS高、闭眼甚至瞌睡,反映存在严重疲劳。图5 系统隶属度函数  输入二为嘴巴状态,对应的模糊语言变量为mouth_state,取值为{Closed,Short Yawn,Long Yawn},论域定义在闭区间[0,1],隶属度函数采用高斯隶属函数与S型函数。如图5(b)所示。模糊子集Closed代表嘴巴闭合,反映正常驾驶状态。模糊子集Short Yawn表示较短时间的哈欠,反映可能或轻度的疲劳。模糊子集Long Yawn表示较长时间的哈欠,反映较为严重疲劳状态。输入三为瞌睡情况,对应的模糊语言变量为Nod_state,取值为{Normal,Nod},论域定义在闭区间[0,1],隶属度函数采用S型隶属函数。如图5(c)所示。模糊子集Normal代表没有检测到点头或瞌睡,反映正常驾驶。模糊子集Nod代表检测到点头或瞌睡,反映严重疲劳。输入四为人脸摆动近似熵,对应的模糊语言变量为entropy_state,取值为{Active,Inactive},论域在闭区间[0,1],隶属度函数采用S型隶属函数。如图5(d)所示。模糊子集Active代表人脸摆动近似熵较大、驾驶员比较活跃时,反映正常驾驶状态。模糊子集Inactive代表人脸摆动近似熵较小、驾驶员不活跃,反映可能存在的疲劳状态。输出变量疲劳程度对应的模糊语言变量为Degree of fatigue,取值为{Lower, Low, General, High, Higher},代表疲劳程度由低较高的变化。论域定义在闭区间[0,1]。隶属度函数采用高斯隶属函数。如图5(e)所示。据此,根据实际经验和广泛调研的结果,本文设计出模糊控制器的模糊逻辑规则,如表1所示。表1中一个序号即代表一个模糊逻辑规则。模糊控制器输入模糊变量,应用模糊控制规则创造新的模糊数,经过去模糊化的过程得到最终的实际产出。故选择合适的去模糊化方法十分重要,本文采用面积中心法。3.3 数据归一化处理  在数据输入模糊推理评分模型前,通过面部特征检测系统得到了4个指标:PERCLOS、打哈欠时长、是否瞌睡、人脸运动近似熵。为了方便对指标的观测,设定指标论域均为[0,1],因此首先要对4个指标做归一化操作。对于PERCLOS值,由于PERCLOS的论域本身就为[0,1],无·91· 第46卷电 子 测 量 技 术  表1 模型模糊逻辑规则序号规则1If blink_state=Closed then Degree of fatigue=Higher2If Nod_state=Nod and entropy_state=Inactive then Degree of fatigue=Higher3If blink_state=High frequency and mouth_state=Long Yawn then Degree of fatigue=Higher4If mouth_state=Long Yawn  then Degree of fatigue=High5If blink_state=High frequency and mouth_state=Short Yawn and Nod_state=Normal and entropy_state=Inactive then Degree of fatigue=High6If blink_state=Low frequency and mouth_state=Short Yawn and Nod_state=Normal and entropy_state=Inactive then Degree of fatigue=General7If blink_state=High frequency and mouth_state=Short Yawn and entropy_state=Active then Degree of fatigue=General8If blink_state=Low frequency and mouth_state=Closed and Nod_state=Normal and entropy_state=Inactive then Degree of fatigue=Low9If blink_state=High frequency and mouth_state=Closed and entropy_state=Active then Degree of fatigue=Low10If blink_state=Low frequency and mouth_state=Short Yawn and entropy_state=Active  then Degree of fatigue=Low11If blink_state=Low frequency and mouth_state=Closed and entropy_state=Active then Degree of fatigue=Lower需归一化。对于打哈欠时长,人类打哈欠的平均时长为6.5 s[17],因此将打哈欠时长均除以6.5。对于是否点头,定义检测到点头计为1,否则计为0。对于人脸摆动近似熵,实验中检测0°~180°的人脸摆动角度,首先将角度进行归一化,控制在[0,1]范围,而后计算人脸摆动近似熵,计算值稳定在[0,0.2]附近,故赋予其权重a=5,最终计算值大于1的记为1,控制最终计算值在[0,1]范围。3.4 眼睛面积计算的补偿  由于不同人的眼睛大小存在差异,简单计算眼睛纵横比来判断是否处于闭眼状态误差较大,故对眼睛纵横比的计算加入一定补偿,使模型能够适应不同人眼大小。在我国,睑裂平均宽度为27.88mm,平均高度为7.54mm,眼睛平均纵横比约为0.27。本文中,在最初视频帧中得到睁眼时眼睛高度和宽度,利用平均眼睛纵横比按比例计算应有宽度,应有宽度与测量宽度之比作为之后检测过程中眼睛宽度的权重。4 实验结果与分析 4.1 数据集  实验数据采用了自建数据集和YawDD数据集[18]。在自建数据集中采集了5位志愿者分别在上午、凌晨两个时间段模拟驾驶汽车的情况,数据集中共有视频十段,分有疲劳驾驶和正常驾驶两类。YawDD数据集由车载摄像头记录的视频数据集,PERCLOS已经被证明在量化疲劳方面是有效的,打哈欠行为同样能有效反映驾驶员的疲劳变化[19],故视频中志愿者在不同环境中的实际汽车中模拟说话、保持沉默、快速眨眼、闭眼和打哈欠等各种面部动作,以此模仿疲劳驾驶状态,分有男性和女性、戴和不戴眼镜。其主要用于开发和测试疲劳检测的算法和模型,也可用于面部和嘴巴的识别和跟踪。4.2 实验平台  实验环境配置如表2所示。表2  实验环境配置实验配置型号或版本操作系统Windows10 x64位处理器Intel Core i7-8750H CPU@2.20 GHzGPUNVIDIA GeForce GTX 1060 with Max-Q Design深度学习开发环境JetBrains PyCharm Community Edition 2021.3.2 x64;MATLAB R2020b;Python 3.9;CUDA 11.3;cuDNN 8.4.1;pytorch 1.11.04.3 主要结果分析  1)人脸运动近似熵为比较正常和疲劳驾驶状态下人脸朝向摆动混乱程度的差异,本文统计了部分连续帧下人脸朝向变化并计算其近似熵。图6展示了连续序列中疲劳状态和活跃状态下的人脸朝向方向集合,以实线线条、短划线线条分别代表疲劳状态和活跃状态的人脸摆动情况。可知与疲劳驾驶状态相比,正常驾驶状态下的人脸摆动方向更加分散和混乱。实验统计了5位志愿者分别在模拟正常驾驶与疲劳驾驶时人脸朝向近似熵的值,如表3所示。表中可知,疲劳驾驶时人脸摆动的近似熵明显低于正常值。因此,利用·02· 任建新 等:多特征融合的驾驶员疲劳程度量化方法研究第20期  图6 5组人脸摆动情况表3 近似熵对比12345疲劳0.082 660.071 730.068 710.158 540.094 13活跃0.150 520.167 640.196 710.250 350.199 94人脸摆动近似熵的值在一定程度上能够反映驾驶员的疲劳程度,较高的近似熵表明驾驶员此时比较活跃,较低的近似熵表明驾驶员可能存在疲劳,这也与生活经验相符。2)模糊推理系统通过MATLAB软件构建模糊推理系统,实验界面如图7所示,图中展示了输入组合为[0.5,0.5,0,0.5]时的模型效果。为进一步展示量化效果,列出部分系统输出随输入的变化情况,如表4所示。图7 模糊推理系统测试界面表4中第1~4行可知随输入1增大,即PERCLOS上升,输出增大,隶属度趋近于1。第1、5~7行可知随输入2增大,即哈欠时长增加,输出增大,隶属度趋近于1。第1、第8行可知,其他输入不变时,输入4减小,人脸运动近似熵减小、人脸运动不活跃,输出随之增大,但增大幅度有  表4 模糊推理系统效果展示输入1输入2输入3输入4输出10.10.100.90.19620.20.100.90.24830.50.100.90.55540.80.100.90.92650.10.200.90.34960.10.500.90.56170.10.800.90.79180.10.100.10.25190.10.110.10.939100.10.110.90.196限,符合小权重的预设。第1、8~10行可知其他输入不变时,输入3由0~1,且输入4较小时,输出发生突变,表明在不活跃时发生点头现象,疲劳程度严重,而输入4较大时输出不发生突变,表明点头现象或因活跃导致,不认为是疲劳。实验证明,本文所设计的模糊推理系统符合人们日常经验,融合四种评价指标对驾驶员疲劳程度实现量化,取得了较好的效果。实验证明,所设计的模糊推理系统融合四种评价指标科学有效的实现了驾驶员疲劳程度的量化评估,符合人们日常经验,取得较好的效果。3)模型性能基于MediePipe人脸检测框架在YawDD数据集上进行测试,选取数据集全部的47组男性和43组女性模拟驾驶视频,依照上文方法,计算EAR与MAR,检测驾驶员眨眼与打哈欠行为,结果如表5所示。如表5所示在模型精度方面,驾驶员处于正脸且没有佩戴眼镜时精度较高,侧脸精度较低,主要是因MediePipe对关键点定位存在一定误差,特别是在打哈欠面部发生较大变形时;当驾驶员佩戴眼镜时,精度有所下降,主要是因·12· 第46卷电 子 测 量 技 术  表5 模型检测性能眨眼次数检测次数实际次数精度打哈欠次数检测次数实际次数精度每秒检测数量正脸636498.43191910055~65 FPS侧脸767996.20171989.4755~65 FPS正脸眼镜515592.72202290.9050~60 FPS侧脸眼镜546188.52181994.7440~55 FPS正脸弱光161888.89121210040~50 FPS眼镜镜片反光和镜框干扰;光线较弱时,模型对关键点定位误差加大,精度下降明显。检测速度方面,在本文机器中每秒检测图像数量均达到40 fps以上,多数场景中稳定在50 fps以上,具有较好的实时性。在YawDD数据集上对模型评分系统进行测试,对每一段视频的疲劳程度进行量化,结果如表6所示。表6 模糊推理系统评估结果疲劳程度数量Lower(隶属度:0~0.2)4Low(隶属度:0.2~0.4)25General(隶属度:0.4~0.6)43High(隶属度:0.6~0.8)12Higher(隶属度:0.8~1)6共计90  实验表明,本文模型实现了对YawDD数据集中驾驶视频的精细化评估,能够较好地量化驾驶员的疲劳程度,在该数据集中的90段视频中均不同程度的检测出了面部疲劳现象。但表中也可以看出,多数视频中驾驶员被评估为轻度或中度疲劳,主要是因YawDD数据集中的视频数据是模拟打哈欠的疲劳驾驶视频,其面部行为特征与真实的疲劳特征存在较大差距。5 结  论  本文利用MediaPipe人脸关键点检测技术和模糊推理系统,融合多种面部疲劳特征,对视频序列中驾驶员疲劳程度量化评估方法展开研究,实现对驾驶员疲劳程度的实时检测和预警。首先设计了一种面部关键点和图像处理相结合方法,利用MediaPipe人脸检测模型定位面部关键点,实现更精确的面部疲劳特征提取;其次,利用检测到关键点,从视频帧中实现对面部疲劳动态特征的提取,得到了PERCLOS、打哈欠时长、是否点头瞌睡、人脸摆动近似熵四个面部疲劳特征评估指标,更好地反映真实的疲劳状态。最后融合多种疲劳特征,设计模糊推理系统,实现对驾驶员疲劳程度实时量化评估,使检测模型更加鲁棒,对驾驶员的疲劳预警更加可靠。研究表明,本文方法科学有效实现了对驾驶员疲劳程度的量化评估,进一步提升了基于面部特征的疲劳驾驶检测技术的鲁棒性和可靠性,具有较强的实用价值。参考文献[1] SAHAYADHAS A, SUNDARAJ K, MURUGAPPAN M. Detecting driver drowsiness based on sensors: a review[J]. Sensors, 2012, 12(12): 16937-16953.[2] 张瑞,朱天军,邹志亮,等.驾驶员疲劳驾驶检测方法研究综述[J].计算机工程与应用,2022,58(21):53-66.[3] 蔡素贤,杜超坎,周思毅,等.基于车辆运行数据的疲劳驾驶状态检测[J].交通运输系统工程与信息,2020,20(4):77-82.[4] RIERA L, OZCAN K, MERICKEL J, et al. Detecting and tracking unsafe lane departure events for predicting driver safety in challenging naturalistic driving data[C]. 2020 IEEE Intelligent Vehicles Symposium(IV), IEEE, 2020: 238-245.[5] WANG H, ZHANG C, SHI T, et al. Real-time EEG-based detection of fatigue driving danger for accident prediction[J]. International Journal of Neural Systems, 2015, 25(2): 1550002.[6] ZOU S, QIU T, HUANG P, et al. Constructing multi-scale entropy based on the empirical mode decomposition(EMD) and its application in recognizing driving fatigue[J]. Journal of Neuroscience Methods, 2020, 341: 108691.[7] SUN W, ZHANG X, PEETA S, et al. A self-adaptive dynamic recognition model for fatigue driving based on multi-source information and two levels of fusion[J]. Sensors, 2015, 15(9): 24191-24213.[8] CHANDIWALA J, AGARWAL S. Driver’s real-time drowsiness detection using adaptable eye aspect ratio and smart alarm system[C]. 2021 7th International Conference on Advanced Computing and Communication Systems(ICACCS), IEEE, 2021, 1: 1350-1355.[9] ABTAHI S, HARIRI B, SHIRMOHAMMADI S. Driver drowsiness monitoring based on yawning detection[C]. 2011 IEEE International Instrumentation and Measurement Technology Conference, IEEE, 2011: ·22· 任建新 等:多特征融合的驾驶员疲劳程度量化方法研究第20期1-4.[10] 郭永彩,苏渝维,高潮.基于FPGA的红外图像实时采集系统设计与实现[J].仪器仪表学报,2011,32(3):514-519.[11] DONG L, CAI J. An overview of machine learning methods used in fatigue driving detection[C]. 2022 7th International Conference on Intelligent Information Technology, 2022: 65-69.[12] 吴士力,唐振民,刘永.多特征融合的随机森林疲劳驾驶识别算法[J].计算机工程与应用,2020,56(20):212-219.[13] CHEN L, XIN G, LIU Y, et al. Driver fatigue detection based on facial key points and LSTM[J]. Security and Communication Networks, 2021, 2021: 1-9.[14] LUGARESI C, TANG J, NASH H, et al.Mediapipe: A framework for building perception pipelines[J].ArXiv Preprint,2019, ArXiv:1906.08172.[15] DINGES D F, GRACE R. PERCLOS: A valid psychophysiological measure of alertness as assessed by psychomotor vigilance[J]. US Department of Transportation, Federal Highway Administration, Publication Number,1998,DOI: https://doi.org/10.21949/1502740.[16] CAO Z, CHU Z, LIU D, et al. A vector-based representation to enhance head pose estimation[C]. Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2021: 1188-1197.[17] MASSEN J J M, HARTLIEB M, MARTIN J S, et al. Brain size and neuron numbers drive differences in yawn duration across mammals and birds[J]. Communications Biology, 2021, 4(1): 1-10.[18] ABTAHI S, OMIDYEGANEH M, SHIRMOHAMMADI S, et al. YawDD: A yawning detection dataset[C]. Proceedings of the 5th ACM Multimedia Systems Conference, 2014: 24-28.[19] GALLUP A C, ELDAKAR O T. The thermoregulatory theory of yawning: what we know from over 5 years of research[J]. Frontiers in Neuroscience, 2013, 6: 188.作者简介任建新,硕士研究生,主要研究方向为安全防范、目标检测、图像处理与识别等。许锋,博士, 教授,主要研究方向为声像资料检验、虚拟现场重建、视频现场勘察等方面。E-mail: 1310823520@qq.com·32·