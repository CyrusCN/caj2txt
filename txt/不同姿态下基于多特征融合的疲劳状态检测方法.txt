第38卷第6期Vol.38No.6重庆工商大学学报(自然科学版)JChongqingTechnol＆BusinessUniv(NatSciEd)2021年12月Dec.2021doi:10.16055/j.issn.1672－058X.2021.0006.004不同姿态下基于多特征融合的疲劳状态检测方法*王政，汪军＊＊(安徽工程大学计算机与信息学院，安徽芜湖241000)收稿日期:2020－10－28;修回日期:2021－03－12．*基金项目:安徽省高校协同创新项目(GXXT－2019－020);安徽省重点研究与开发计划项目(1604d0802002)．作者简介:王政(1994—)，男，安徽桐城人，硕士研究生，从事机器智能和模式识别研究．＊＊通讯作者:汪军(1975—)，男，安徽桐城人，教授，硕士，从事图像处理与模式识别研究．Email:wangjun@ahpu．edu．cn．摘要:针对传统的基于单一特征的疲劳检测方法误检率高、可靠性不强、无法适应复杂多变的行车环境等问题，提出了一种将驾驶员的眼睛、嘴巴等多种面部特征进行融合的疲劳驾驶检测方法。与现有的人脸检测模型相比，这里提出的基于梯度提高的学习框架对于侧脸的检测效果更佳，并且能够更好地满足检测时间上的要求;同时通过改进的LeNet－5神经网络模型对视频中的笑容进行分类，排除了表情变化对疲劳驾驶检测的干扰;最后为了降低头部姿态的偏转对疲劳特征提取的影响，引入了基于欧拉角的特征校正算法;对YawDD疲劳驾驶数据集的检测结果表明:不同姿态下基于多特征融合的疲劳驾驶检测不仅能够有效降低头部偏转对疲劳驾驶检测的影响，而且比传统的疲劳检测方法具备更高的鲁棒性。关键词:疲劳驾驶;人脸对齐;PEＲCLOS;笑容检测;特征融合中图分类号:TP391．4文献标志码:A文章编号:1672－058X(2021)06－0026－080引言在全世界交通死亡事件中，疲劳驾驶作为主要诱因的事件占据的比例较高［1］，目前很多严重的交通事故都是由疲劳驾驶引起的，所以对疲劳驾驶的预防具有极大的现实意义。世界上最早关于疲劳检测的研究是借助精密的医学仪器开展的，主要通过分析人体的脑电［2－3］、心电［4－5］等生理信号的变化来辨别是否处于疲劳状态。近现代以来，为了消除仪器带来的侵入式影响，大量的创新成果被提了出来，尤其是随着图像处理技术的不断发展，国内外对疲劳驾驶的研究有了新的突破口，基于机器视觉的疲劳驾驶检测方法应运而生。邹昕彤［6］等通过改进传统的Adaboost(AdaptiveBoosting)算法提高了人脸检测的精度，并依据眼睛和嘴巴的状态对疲劳程度作出了较为清晰的判断。这种方法检测速度快，即使在复杂的光照环境下也有较高的鲁棒性，但是其中涉及的特征信息非常单一，容易造成疲劳误判。针对MTCNN［7］(Multi－taskConvolutionalNeuralNetwork)算法在人脸局部图像上识别效果的不足，沈英超［8］提出了一种基于多任务约束学习的眼睛定位模型，并通过检测眼睛闭合状态来判断疲劳。这种方法很好地解决了遮挡情况下面部检测准确率不高的问题，但是步骤繁多，且计算量大，因此难以满足疲劳检测的实时性要求。为了提高人脸特征点定位的精度，王迪［9］搭建并训练SSD(SingleShotMultiboxDetector)网络模型［10］对人脸图像进行疲劳分类，并表现出较高的可靠性。该方法不依赖于人脸检测的结果，但是容易产生漏检的情况。Li［11］等通过改进YOLO3神经网络搭建了微型人第6期王政，等:不同姿态下基于多特征融合的疲劳状态检测方法脸检测模型，消除了人工在面部特征提取过程中的不确定性影响，并结合眨眼频率和哈欠特征设计了眼口SVM(SupportVectorMachines)分类器，实现了驾驶员的疲劳分类。综合以上因素，本文在人脸检测阶段并未使用传统的Adaboost算法，而是采用基于梯度提高的学习框架，这样不仅能够提高人脸检测的速度和准确率，而且能够对眼部和嘴部进行识别与标定，同时考虑到传统的单一特征的疲劳检测方法存在误检率高、可靠性差、无法适应复杂的行车环境等问题，提出了一种将驾驶员的眼睛、嘴巴等多种面部特征进行融合的疲劳驾驶检测方法，通过引入新的笑脸检测分类模型，排除了笑容对疲劳检测的干扰，进一步提高了疲劳驾驶检测算法的鲁棒性。1疲劳检测流程疲劳是人在生理及心理产生的一个主观感受，处于疲劳状态下的人动作失调、注意力难以集中，尤其会在面部产生更为直观的变化，如眨眼频率增大、打哈欠次数变多等，因此可以根据面部信息对驾驶员的疲劳状态进行检测。具体的检测流程见图1。图1人脸疲劳检测流程Fig.1Theflowchartofhumanfacefatiguedetection1.1人脸检测在进行驾驶员疲劳检测时，如果以获取的整张图像输入会造成大量信息冗余，不仅会增加模型训练的难度和复杂度，延长检测的时间，降低算法的实时性，而且还可能会影响人脸检测的准确率，因此准确获取驾驶员面部有效区域显得尤为重要。驾驶员面部有效区域的获取需要先确定驾驶员面部关键点的位置，然后标记出有效区域，并最终裁剪出用于分析的有效图像。考虑图像的梯度信息能很好地突出目标的边缘，使得图像形状和目标轮廓的特征化过程变得更容易，因此本文基于图像的Hog特征［12］对输入的原始图像进行人脸的检测与识别，其中在YawDD数据集［13］上的实时检测效果如图2所示，2(a)与2(b)分别表示驾驶员头部静止和晃动状态下的人脸区域检测效果。(a)正脸(b)侧脸图2基于Hog特征的人脸检测Fig.2FacedetectionbasedonHogfeature1.2人眼定位在基于面部信息的疲劳驾驶检测方法中，眼睛的状态是一个至关重要的判断依据，而人眼定位作为眼睛区域截取的第一步也显得同样重要，只有精确定位到人眼位置，才能对眼睛的状态进行判别，从而判断驾驶员是否疲劳。EＲT(EnsembleofＲegressionTree)是一种具有开创性的人脸对齐方法，该方法通过使用级联的回归因子来建立一个梯度提升的决策树，最终使图像中人脸的形状逐步回归到真实的位置［14］。EＲT算法的核心思想如下:S=(xT1，xT2，…，xTp∈Ｒ2p)S(t+1)=S(t)+ri(I，S(t))xi∈Ｒ2ΔS(t+1)i=Sπi－S(t+1)(1)式(1)中，I表示输入的人脸图像，xiT为I中第i个特征点的横纵坐标，p为特征点总数，S是I中人脸的真实形状，S(t)为第t次的人脸估计，S(t+1)为第t+1次的人脸估计，rt为回归器，rt(I，S(t))为待学习的残差回归量，ΔSi(t+1)为待更新的增量。本文主要结合Dlib机器学习方法库对众多需72重庆工商大学学报(自然科学版)第38卷要标定的人脸图像进行训练得到EＲT模型，在此基础上，使用该模型对裁剪后的人脸区域进行人脸对齐操作，从而准确获取人眼的位置坐标。具体的实现效果如图3所示，其中为了验证特征点定位的可靠性与实时性，实验采用了与图2来源一致的数据集，经实验验证，驾驶员无论处于平视图3(a)还是侧视图3(b)状态下，EＲT模型均取得了很好的测试结果。(a)平视(b)侧视图3特征点定位效果图Fig.3Theresultsoffeaturepointpositioning1.3笑容检测由于人在微笑过程中会导致眼睛眯起，更容易使模型作出此时驾驶员处于疲劳状态的判断。但是根据人体生理常识，当人的面部存在明显的表情变化时(如开心等)，人的精神高度集中，此时是无法产生睡意的，因此排除驾驶员在行车过程中的笑容对提高疲劳检测的准确率有着极为重要的作用。考虑卷积神经网络比传统的机器学习方法更能高效地提取和识别图像特征，降低工作难度，因此通过训练改进的LeNet－5神经网络来更好地检测驾驶员在行车过程中表情的变化。与识别手写数字的过程类似，本文采用同样的卷积神经网络架构，即交替的Conv2D和MaxPooling2D层，同时考虑到该模型需要处理更大的图像和更复杂的问题，在原有的LeNet－5模型中增加了两个卷积层和两个池化层，这样既可以扩大神经网络的容量，又可以进一步减小最终生成的特征图大小，实现了网络泛化能力的提高。图4所示为本文构造的神经网络模型架构，输入图像的大小为150×150，设置的卷积核和池化核的大小分别为3×3和2×2，由图4可以看出，输入图像连续经过4个卷积层和池化层后得到的特征图的大小为7×7，极大减小了特征图的大小。图4神经网络模型架构Fig.4Thearchitectureofneuralnetworkmodel由于用于训练的genki4k笑脸数据集中包含的可供学习的样本太少，因此为了避免产生过拟合现象，首先采用数据增强［15］的方法从现有的样本中通过一系列随机变换产生更多的训练数据，然后在已设计好的卷积神经网络模型的基础上设置一个Dropout［16］层，进一步降低过拟合的可能性。卷积神经网络模型的准确率和损失函数分别如图中5(a)和5(b)所示。(a)准确率(b)损失函数图5模型训练结果Fig.5Theresultsofmodeltraining1.4参数计算1.4.1不同姿态下的EAＲSoukupova等［17］提出了一个眼睛纵横比(EyeAspectＲatio，EAＲ)的概念，文献［18］表明EAＲ值的大小能够直观地反映人眼的开合程度，可以作为判断眨眼动作的有力依据。在人的脸部信息里，EAＲ值主要由眼睛睁开时的长度与宽度的比值决定，而头部姿态的变化会在一定程度上影响两者的比值。当驾驶员摇头时，偏航角发生变化，人眼的长度减小，EAＲ值随之减小;当驾驶员点头时，俯仰角发生了变化，人眼的宽度减小，EAＲ值随之增大;而当驾驶员前倾或后倾时对EAＲ值影响不大。因此为了降低头部偏转对EAＲ值造成的影响，在头部姿态估计的基础上，针对俯仰和偏航两个方面对EAＲ进行特征提取和校正。以点头为例，若将照相的过程看成一次在空间上的投影，则此时发生变化的是俯仰角。假设平视82第6期王政，等:不同姿态下基于多特征融合的疲劳状态检测方法状态下的俯仰角为β0，投影到二维图像上时的眼睛宽度为h0，点头或抬头时的俯仰角为β1，投影到二维图像上时的宽度为h1，由于现实中点头或抬头时眼睛的宽度不会发生变化，因此，有h0cosβ0=h1cosβ1(2)变换可得:h1=h0cosβ1cosβ0(3)同理，摇头时眼睛长度与偏航角的关系为w1=w0cosα1cosα0(4)其中，α0与α1分别表示平视与摇头时驾驶员头部的偏航角，w0与w1分别表示平视与摇头时投影到二维图像上的眼睛长度。于是，当头部姿态发生变化时，眼睛纵横比的值ＲEAＲ1可表示为ＲEAＲ1=w1w0=w0h0×cosα1cosβ0cosα0cosβ1(5)由此可知，当头部姿态发生变化时，眼睛纵横比ＲEAＲ1与平视状态的眼睛纵横比ＲEAＲ0之间的关系为ＲEAＲ1=ＲEAＲ0×cosα1cosβ0cosα0cosβ1(6)因此，只要识别出平视及偏转时头部姿态，就可以对EAＲ值进行修正，从而进一步判断眼睛状态。图6为人眼的特征点坐标示意图，其中序号36—41，42—47分别代表左眼和右眼的特征点位置。图6人眼特征点坐标Fig．6Thecoordinatesofeyefeaturepoints为了更方便地得到EAＲ的值，令p1—p6分别对应于图6中单个人眼的6个特征点36—39或42—47，因此可以通过人眼纵横比的定义将单个人眼的EAＲ值表示为ＲEAＲ=p2－p6+p3－p52p1－p4(7)图7清晰地展示了特征校正前后眼睛纵横比EAＲ值的变化，其中横坐标表示视频当前帧数，纵坐标为其对应的眼睛纵横比EAＲ的值，实线表示未经校正的EAＲ曲线，虚线表示校正后的EAＲ曲线。图7EAＲ绘图Fig．7TheEAＲdrawing由图2可以看出，人在闭眼过程中EAＲ值波动较为明显，因此只需要确定一个合适的阈值就可以对眼睛的开合状态进行准确的判断。大量研究已经表明，当眼睛闭合程度超过80%时，普遍认为是闭眼状态，因此闭眼阈值ＲEAＲthreshold可由式(8)计算得到:ＲEAＲthreshold=ＲEAＲmin+q×(ＲEAＲmax－ＲEAＲmin)(8)式中:ＲEAＲmax与ＲEAＲmin分别为单位时间内眼睛纵横比的最大值与最小值，比例参数q取0．2。双眼睁闭的状态由左、右眼纵横比值的EAＲ均值进行判断，如图7所示，直线所代表的是YawDD数据集中某一个实验参与者的闭眼阈值，当EAＲ值低于直线时，认为该参与者的眼睛处于闭合状态，否则就认为该参与者处于睁开状态。1.4.2PEＲCLOS最早开始研究眼睛开合状态与疲劳之间相关性的人是WaltWirewille［19］，他采用模拟对比实验的方式探究眼部感受光和疲劳状态之间的关系，得出了眼睛闭合时间与疲劳程度呈正相关的结论。在此之后，PEＲCLOS作为疲劳程度的衡量参数被CarnegieMellon研究所提出，其定义为一段时间内眼睛闭合超过一定程度所占的时间比例［20］。其中P70，P80及EM是PEＲCLOS最常使用的3个标准，它们代表了眼睛闭合状态的3种判断依据，即瞳孔被眼睑遮挡面积超过70%，80%以及50%［21］。相关研究发现，P80指标在模拟驾驶环境中与疲劳状态的相关性最高，因此通过对P80指标的实92重庆工商大学学报(自然科学版)第38卷时监测，能够更为清晰地了解驾驶员的疲劳程度。此外，WalterWierwille在文献［19］中还指出区分人体是否疲劳的PEＲCLOS阈值为0.15，所以本文也将PEＲCLOS的阈值设置为0.15，当PEＲCLOS值小于0.15时，再结合笑脸检测来判断疲劳状态。1.5多特征融合传统的检测方法只使用一种特征作为疲劳检测的判断依据，但是由于每个个体的表现不同，有时就算检测到某一特征，也可能出现误检，因此根据单一特征的疲劳驾驶判定方法的可靠性不高［22］。通过观察发现，人只有在正常状态下才会出现微笑、愤怒、悲伤等表情，同样，频繁眨眼、打哈欠、点头等动作也只会出现在疲劳状态时。因此在得到相应的疲劳参数之后，并未对驾驶员的疲劳状态进行直接衡量，而是将眼睛开合程度与笑容两种特征进行融合计算，排除笑容对疲劳检测的干扰，降低了检测的误检率，进一步提升了方法的准确度与可靠性。图8多特征融合流程图Fig.8Theflowchartofmulti－featurefusion2疲劳测试2.1实验数据集本文采用YawDD［13］数据集作为疲劳检测的标准数据集。YawDD数据集中的视频来源包括从汽车后视镜及仪表盘两个拍摄角度拍摄的驾驶视频，所有视频都拍摄于真实的车辆空间及不均衡的光照环境下，其中参与人员中男女比例均衡，来自不同种族，同时肤色也存在差异，拍摄时对于眼镜等遮挡物的佩戴也有一定的要求。该数据集包括正常驾驶、驾驶时说话或唱歌、驾驶时打哈欠3种不同情况下的视频数据。由于判断视频中驾驶员的精神状态具有主观意愿，同时考虑YawDD数据集主要以驾驶员打哈欠的动作作为检测疲劳的特征，因此将打哈欠的程度作为验证驾驶员是否疲劳的主要依据。为了获取普遍性的实验结果，使其更具说服力，随机抽取男女各5名在不同光照强度和真实的行车环境下拍摄的视频进行测试，考虑视频的帧率为30帧/s，首先对视频每一帧的图像进行预处理，利用高斯滤波去除图像中的噪声，并采用直方图均衡化方法增强人脸图像的对比度，然后基于EＲT模型从前100帧图像中计算出EAＲ的自适应阈值，剔除笑脸后每3s计算一次PEＲCLOS值，最终与设置的PEＲCLOS阈值进行比较，得出驾驶员是否疲劳的结论。同时为了更好地疲劳驾驶检测模型进行说明，对随机抽取的10段视频采用不同的疲劳驾驶检测方法进行检测。2.2实验结果及分析2.2.1与基于眼部特征的检测方法的对比基于眼部特征的疲劳驾驶检测方法是利用驾驶员眼睛的疲劳特征(如EAＲ值、眨眼次数、PEＲCLOS值等)来实现疲劳状态的分类，而本文提出的疲劳驾驶检测方法在提取眼部特征的基础上融合了嘴部的笑容特征，并根据个体的差异性计算出自适应的眼睛开合阈值，实现了驾驶员疲劳状态的检测，其中表1是以上两种检测方法在随机抽取的10段视频数据中的检测结果。由表1可以看出:基于眼部特征的疲劳驾驶检测方法得到的眨眼次数均多于本文方法的检测值，且个体眼睛的开合阈值与基于本文方法得到的结果也存在明显差异，同时发现在第5，10号实验中，由于驾驶员产生了表情变化，导致眼部疲劳特征的提取过程受到干扰，因此基于眼部特征的检测方法难以准确识别疲劳，产生了疲劳误判。2.2.2与传统的多特征融合检测方法的对比由于疲劳状态下驾驶员在面部会呈现更为直观的变化，因此现有的基于多特征融合的疲劳检测方03第6期王政，等:不同姿态下基于多特征融合的疲劳状态检测方法法主要是通过融合驾驶员的眼睛和嘴巴的疲劳因子对驾驶员的疲劳状态进行识别。表2反映了这类方法与本文提出的疲劳检测方法的对比结果。表2表明:融合了眼睛和嘴巴疲劳特征的疲劳驾驶检测算法能够更有效降低疲劳误判产生的可能性，比基于单一特征的检测方法具备更高的可靠性。同时在第2，3，10组实验中发现，当头部偏转速度或角度较大时，传统的基于多特征融合的疲劳驾驶检测方法的准确率未明显提高，而不同姿态下基于多特征融合的疲劳驾驶检测方法的准确率却提高显著，说明降低头部姿态的偏转对提高疲劳检测的准确率有着较为突出的作用。表1与基于眼部特征的疲劳驾驶检测方法的对比Table1Comparisonoffatiguedrivingdetectionmethodsbasedoneyefeatures序号基于眼部特征的疲劳驾驶检测方法本文提出的疲劳驾驶检测方法EAＲ阈值眨眼次数PEＲCLOS值状态判定EAＲ阈值眨眼次数PEＲCLOS值状态判定10.193110.045正常0.19070.043正常20.17650.026正常0.14620.013正常30.191270.183疲劳0.188260.235疲劳40.214260.057正常0.206180.055正常50.235330.195疲劳0.23180.057正常60.248450.317疲劳0.255420.430疲劳70.183340.100正常0.174160.081正常80.211320.149正常0.204190.103正常90.172510.352疲劳0.173250.196疲劳100.168220.152疲劳0.159150.133正常表2与传统的基于多特征融合的疲劳驾驶检测方法的对比Table2Comparedwiththetraditionalfatiguedrivingdetectionmethodbasedonmulti－featurefusion序号传统的基于多特征融合的疲劳驾驶检测方法本文提出的疲劳驾驶检测方法眨眼次数状态判定准确率(%)眨眼次数状态判定准确率(%)111正常90.007正常90.0023正常84.622正常92.86327疲劳76.9226疲劳84.62424正常97.1418正常97.1459正常95.838正常100.00645疲劳83.3342疲劳88.89726正常86.3616正常90.91827正常80.0019正常90.00932疲劳89.4725疲劳94.741020正常87.5015正常93.753结束语与传统的基于Adaboost的人脸检测模型和SSD模型相比，本文提出的人脸检测模型避免了头部姿态的变化对特征提取过程的干扰，能够更有效地提取人脸的形状和局部轮廓特征，实现对人脸实时准确的检测。同时为了研究表情的变化对人脸疲劳检测的影响，改进了原有的手写数字识别神经网络，在LeNet－5模型的基础上增加了两个卷积层和池化层，提高了笑脸检测模型的泛化能力。此外，由于本文所使用的特征来源较为单一，对于光照不均衡等13重庆工商大学学报(自然科学版)第38卷复杂场景的适应能力较弱，因此采用多信息源的疲劳特征进行融合可以进一步提高疲劳驾驶检测的鲁棒性。参考文献(Ｒeferences):［1］FOＲSMANPM，VILABJ，SHOＲTＲA，etal．EfficientDriverDrowsinessDetectionatModerateLevelsofDrowsiness［J］．AccidentAnalysisandPrevention，2012，50(1):341—350［2］HOTTAY，ITOK．EMG－basedDetectionofMuscleFatigueduringLow－levelIsometricContraction:EffectsofElectrodeConfigurationandBloodFlowＲestriction［C］//ConferenceProceedings:AnnualInternationalConferenceoftheIEEEEngineeringinMedicineandBiologySociety．IEEEEngineeringinMedicineandBiologySociety，2011［3］ZHANGYQ，ZHENGWL，LUBL．TransferComponentsbetweenSubjectsforEEG－basedDrivingFatigueDetection［C］//InternationalConferenceonNeuralInformationProcessing．SpringerInternationalPublishing，2015［4］LIMA，ZHANGC，YANGJF．AnEEG－basedMethodforDetectingDrowsyDrivingState［C］//5thInternationalConferenceonBioMedicalEngineeringandInformatics．IEEE，2012［5］周展鹏，孔万增，王奕直，等．基于心电和脑电的驾驶疲劳检测研究［J］．杭州电子科技大学学报(自然科学版)，2014，34(3):25—28ZHOUZP，KONGWZ，WANGYZ，etal．ＲesearchonDrivingFatigueDetectionBasedonECGandEEG［J］．JournalofHangzhouDianziUniversity(NaturalScienceEdition)，2014，34(3):25—28(inChinese)［6］邹昕彤，王世刚，赵文婷，等．基于眼睛与嘴部状态识别的疲劳驾驶检测［J］．吉林大学学报(信息科学版)，2017，35(2):204—211ZOUXT，WANGSG，ZHAOWT，etal．FatigueDrivingDetectionBasedonStateＲecognitionofEyesandMouth［J］．JournalofJilinUniversity(InformationScienceEdition)，2017，35(2):204—211(inChinese)［7］ZHANGK，ZHANGZ，LIZ，etal．JointFaceDetectionandAlignmentUsingMultitaskCascadedConvolutionalNetworks［J］．IEEESignalProcessingLetters，2016，23(10):1499—1503［8］沈英超．基于眼部特征的疲劳驾驶检测系统的研究与实现［D］．桂林:桂林电子科技大学，2019SHENYC．ＲesearchandImplementationofFatigueDrivingDetectionSystemBasedonEyeFeatures［D］．Guilin:GuilinUniversityofElectronicTechnology，2019(inChinese)［9］王迪．基于人眼状态的疲劳检测算法研究与应用［D］．成都:电子科技大学，2020WANGD．ＲesearchandApplicationofFatigueDetectionAlgorithmBasedonHumanEyeState［D］．Chengdu:UniversityofElectronicScienceandTechnologyofChina，2020(inChinese)［10］WEIL，DＲAGOMIＲA，DUMITＲUE，etal．SSD:SingleShotMulti－boxDetector［C］//EuropeanConferenceonComputerVision．IEEE，2016［11］LIK，GONGY，ＲENZ．AFatigueDrivingDetectionAlgorithmBasedonFacialMulti－featureFusion［J］．IEEEAccess，2020，8(10):101244—101259［12］DALALN，TＲIGGSB．HistogramsofOrientedGradientsforHumanDetection［C］//IEEEComputerSocietyConferenceonComputerVision＆PatternＲecognition．IEEE，2005［13］ABTAHIM，OMIDYEGANEHM，SHIＲMOHAMMADS，etal．YawDD:AYawningDetectionDataset［C］//ProcACMMultimediaSystems．Singapore，2014［14］王娟．基于形变模型的人脸三维重构与表情传递的研究［D］．哈尔滨:哈尔滨工业大学，2018WANGJ．Ｒesearchon3dＲeconstructionofHumanFaceandExpressionTransferBasedonDeformableModel［D］．Harbin:HarbinInstituteofTechnology，2018(inChinese)［15］IBＲAHIMH，KONGNSP．BrightnessPreservingDynamicHistogramEqualizationforImageContrastEnhancement［J］．IEEETransactionsonConsumerElectronics，2007，53(4):1752—1758［16］HINTONGE，SＲIVASTAVAN，KＲIZHEVSKYA，etal．ImprovingNeuralNetworksbyPreventingCo－adaptationofFeatureDetectors［J］．ComputerScience，2012，3(4):212—223［17］SOUKUPOVAT，CECHJ．EyeBlinkDetectionUsingFacialLandmarks［C］//21stComputerVisionWinterWorkshop．ＲimskeToplice，Slovenia，2016［18］KIMT，LEEEC．ExperimentalVerificationofObjectiveVisualFatigueMeasurementBasedonAccuratePupilDetectionofInfraredEyeImageandMulti－feature23第6期王政，等:不同姿态下基于多特征融合的疲劳状态检测方法Analysis［J］．Sensors，2020，20(17):4814—4818［19］KNIPLINGＲＲ，WIEＲWILLEWW．Vehicle－basedDrowsyDriverDetection:CurrentStatusandFutureProspects［C］//ProceedingsoftheIVHSAMEＲICAConference．MovingTowardDeployment，1994［20］马召宾．融合眼部特征及头部姿态的实时疲劳驾驶检测技术研究［D］．济南:山东大学，2016MAZB．ＲesearchonＲeal－timeFatigueDrivingDetectionTechnologyIntegratingEyeFeaturesandHeadPosture［D］．Ji’nan:ShandongUniversity，2016(inChinese)［21］潘志庚，刘荣飞，张明敏．基于模糊综合评价的疲劳驾驶检测算法研究［J］．软件学报，2019，30(10):2954—2963PANZG，LIUＲF，ZHANGMM．ＲesearchOnFatigueDrivingDetectionAlgorithmBasedonFuzzyComprehensiveEvaluation［J］．JournalofSoftware，2019，30(10):2954—2963(inChinese)［22］季映羽．基于面部特征分析与多指标融合的疲劳状态检测算法研究［D］．长春:吉林大学，2019JIYY．ＲesearchonFatigueStateDetectionAlgorithmBasedonFacialFeatureAnalysisandMulti－indexFusion［D］．Changchum:JilinUniversity，2019(inChinese)FatigueStateDetectionMethodBasedonMulti－featureFusionunderDifferentPosturesWANGZheng，WANGJun(SchoolofComputerandInformation，AnhuiPolytechnicUniversity，AnhuiWuhu241000，China)Abstract:Aimingatsolvingtheproblemsofhighfalsedetectionrateandlowreliabilityoftraditionalsinglefeature－basedfatiguedetectionmethods，whichcannotadapttothecomplexandchangingdrivingenvironment，afatiguedrivingdetectionmethodthatfusesdriversmultiplefacialfeaturessuchasdriver＇seyesandmouthisproposed．Comparedwiththeexistingfacedetectionmodels，thegradient－basedlearningframeworkproposedhereismoreeffectiveforsidefacedetectionandcanbettermeetthedetectiontimerequirements．Meanwhile，theimprovedLeNet－5neuralnetworkmodelisusedtoclassifythesmilesinvideos，whichexcludestheinterferenceofexpressionchangesonfatiguedrivingdetection．Finally，inordertoreducetheinfluenceofheadposturedeflectiononfatiguefeatureextraction，theEulerangle－basedfeaturecorrectionalgorithmwasintroduced．ThedetectionresultsoftheYawDDfatiguedrivingdatasetshowthatthefatiguedrivingdetectionbasedonmulti－featurefusionindifferentposturescannotonlyeffectivelyreducetheinfluenceofheaddeflectiononfatiguedrivingdetection，butalsohashigherrobustnessthanthetraditionalfatiguedetectionmethods．Keywords:fatiguedriving;facejustification;PEＲCLOS;smiledetection;featurefusion责任编辑:李翠薇引用本文/Citethispaper:王政，汪军．不同姿态下基于多特征融合的疲劳状态检测方法［J］．重庆工商大学学报(自然科学版)，2021，38(6):26—33WANGZ，WANGJ．FatigueStateDetectionMethodBasedonMulti－featureFusionunderDifferentPostures［J］．JournalofChongqingTechnologyandBusinessUniversity(NaturalScienceEdition)，2021，38(6):26—3333