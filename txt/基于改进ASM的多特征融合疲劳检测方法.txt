２０１９年１１月第４０卷　第１１期计算机工程与设计ＣＯＭＰＵＴＥＲ　ＥＮＧＩＮＥＥＲＩＮＧ　ＡＮＤ　ＤＥＳＩＧＮＮｏｖ．２０１９Ｖｏｌ．４０　Ｎｏ．１１基于改进ＡＳＭ的多特征融合疲劳检测方法陈　鑫，李为相＋，李　为，张文卿，朱　元（南京工业大学电气工程与控制科学学院，江苏南京２１１８１６）摘　要：为解决驾驶员在行驶过程中头部发生多角度变化导致难以定位面部特征的问题，应用改进的ＡＳＭ算法精确定位眼睛和嘴部区域，计算眼睛的长宽比值、嘴部高度值和嘴部附近的黑白像素比值，得出眨眼频率和嘴巴张开程度，将眼部状态和嘴巴的张开程度作为模糊推理机的输入，得出三类疲劳水平，准确量化疲劳程度。实验结果表明，该非入侵式疲劳驾驶检测方法将经典ＡＳＭ算法分类能力的结构误差降到了最小，该模糊推理系统对检测驾驶员疲劳程度和提高行车安全性方面是有效的。关键词：疲劳检测；主动形状模型；眨眼检测；打哈欠检测；模糊推理系统中图法分类号：ＴＰ３９１．４１　文献标识号：Ａ　文章编号：１０００－７０２４（２０１９）１１－３２６９－０７ｄｏｉ：１０．１６２０８／ｊ．ｉｓｓｎ１０００－７０２４．２０１９．１１．０３５收稿日期：２０１８－１０－０８；修订日期：２０１８－１１－１６基金项目：江苏省“六大人才高峰”基金项目（ＸＸＲ－０１２）作者简介：陈鑫（１９９４－），男，江苏南通人，硕士研究生，研究方向为图像处理、模式识别；＋通讯作者：李为相（１９７３－），男，河南信阳人，博士，副教授，研究方向为智能决策理论与应用、社交网络、图像处理；李为（１９９４－），男，湖北武汉人，硕士研究生，研究方向为图像处理、模式识别；张文卿（１９９５－），女，江苏南京人，硕士研究生，研究方向为图像处理、模式识别；朱元（１９９４－），女，江苏扬州人，硕士研究生，研究方向为图像处理、模式识别。Ｅ－ｍａｉｌ：ｌｗｘｌｆ＠ｎｊｔｅｃｈｅｄｕ．ｃｎＤｒｉｖｅｒ’ｓ　ｆａｔｉｇｕｅ　ｄｅｔｅｃｔｉｏｎ　ｂａｓｅｄ　ｏｎ　ｉｍｐｒｏｖｅｄ　ａｃｔｉｖｅｓｈａｐｅ　ｍｏｄｅｌ　ａｎｄ　ｆｕｓｉｏｎ　ｏｆ　ｍｕｌｔｉ－ｃｌｕｅｓＣＨＥＮ　Ｘｉｎ，ＬＩ　Ｗｅｉ－ｘｉａｎｇ＋，ＬＩ　Ｗｅｉ，ＺＨＡＮＧ　Ｗｅｎ－ｑｉｎｇ，ＺＨＵ　Ｙｕａｎ（Ｃｏｌｌｅｇｅ　ｏｆ　Ｅｌｅｃｔｒｉｃａｌ　Ｅｎｇｉｎｅｅｒｉｎｇ　ａｎｄ　Ｃｏｎｔｒｏｌ　Ｓｃｉｅｎｃｅ，Ｎａｎｊｉｎｇ　Ｔｅｃｈ　Ｕｎｉｖｅｒｓｉｔｙ，Ｎａｎｊｉｎｇ　２１１８１６，Ｃｈｉｎａ）Ａｂｓｔｒａｃｔ：Ｔｏ　ａｄｄｒｅｓｓ　ｔｈｅ　ｐｒｏｂｌｅｍ　ｔｈａｔ　ｉｔ　ｉｓ　ｄｉｆｆｉｃｕｌｔ　ｔｏ　ｌｏｃａｔｅ　ｔｈｅ　ｆａｃｉａｌ　ｆｅａｔｕｒｅｓ　ｗｈｅｎ　ｔｈｅ　ｄｒｉｖｅｒ’ｓ　ｈｅａｄ　ｃｈａｎｇｅｓ　ｄｕｒｉｎｇ　ｔｈｅ　ｄｒｉｖｉｎｇｐｒｏｃｅｓｓ，ｔｈｅ　ｉｍｐｒｏｖｅｄ　ＡＳＭ　ａｌｇｏｒｉｔｈｍ　ｗａｓ　ｐｒｏｐｏｓｅｄ　ｔｏ　ａｃｃｕｒａｔｅｌｙ　ｌｏｃａｔｅ　ｔｈｅ　ｅｙｅ　ａｎｄ　ｍｏｕｔｈ　ａｒｅａ，ａｎｄ　ｔｈｅ　ａｓｐｅｃｔ　ｒａｔｉｏ　ｏｆ　ｔｈｅ　ｅｙｅ，ｔｈｅ　ｍｏｕｔｈ　ｈｅｉｇｈｔ，ａｎｄ　ｔｈｅ　ｂｌａｃｋ－ａｎｄ－ｗｈｉｔｅ　ｐｉｘｅｌ　ｒａｔｉｏ　ｎｅａｒ　ｔｈｅ　ｍｏｕｔｈ　ｗｅｒｅ　ｃａｌｃｕｌａｔｅｄ　ｔｏ　ｏｂｔａｉｎ　ｔｈｅ　ｂｌｉｎｋ　ｆｒｅｑｕｅｎｃｙ　ａｎｄ　ｔｈｅ　ｄｅｇｒｅｅｏｆ　ｍｏｕｔｈ　ｏｐｅｎｉｎｇ．Ｔｈｅ　ｓｔａｔｅ　ｏｆ　ｔｈｅ　ｅｙｅ　ａｎｄ　ｔｈｅ　ｄｅｇｒｅｅ　ｏｆ　ｍｏｕｔｈ　ｏｐｅｎｉｎｇ　ｗｅｒｅ　ｕｓｅｄ　ａｓ　ｔｈｅ　ｉｎｐｕｔｓ　ｏｆ　ｔｈｅ　ＦＩＳ　ｔｏ　ｏｂｔａｉｎ　ｔｈｅ　ｔｈｒｅｅｔｙｐｅｓ　ｏｆ　ｆａｔｉｇｕｅ　ｌｅｖｅｌｓ，ｓｏ　ａｓ　ｔｏ　ａｃｃｕｒａｔｅｌｙ　ｑｕａｎｔｉｆｙ　ｔｈｅ　ｄｅｇｒｅｅ　ｏｆ　ｆａｔｉｇｕｅ．Ｅｘｐｅｒｉｍｅｎｔａｌ　ｒｅｓｕｌｔｓ　ｓｈｏｗ　ｔｈａｔ　ｔｈｅ　ｎｏｎ－ｉｎｖａｓｉｖｅ　ｆａｔｉｇｕｅｄｅｔｅｃｔｉｏｎ　ｍｅｔｈｏｄ　ｒｅｄｕｃｅｓ　ｔｈｅ　ｓｔｒｕｃｔｕｒａｌ　ｅｒｒｏｒ　ｏｆ　ｔｈｅ　ｃｌａｓｓｉｃａｌ　ＡＳＭ　ａｌｇｏｒｉｔｈｍ　ｃｌａｓｓｉｆｉｃａｔｉｏｎ　ａｂｉｌｉｔｙ　ｔｏ　ｔｈｅ　ｍｉｎｉｍｕｍ．Ｔｈｅ　ｆｕｚｚｙ　ｉｎ－ｆｅｒｅｎｃｅ　ｓｙｓｔｅｍ　ｉｓ　ｅｆｆｅｃｔｉｖｅ　ｆｏｒ　ｄｅｔｅｃｔｉｎｇ　ｄｒｉｖｅｒ　ｆａｔｉｇｕｅ　ａｎｄ　ｉｍｐｒｏｖｉｎｇ　ｔｈｅ　ｓａｆｅｔｙ　ｏｆ　ｄｒｉｖｉｎｇ．Ｋｅｙ　ｗｏｒｄｓ：ｆａｔｉｇｕｅ　ｄｅｔｅｃｔｉｏｎ；ＡＳＭ；ｂｌｉｎｋｉｎｇ　ｄｅｔｅｃｔｉｏｎ；ｙａｗｎｉｎｇ　ｄｅｔｅｃｔｉｏｎ；ＦＩＳ０　引　言通常情况下直接度量驾驶员的疲劳程度比较困难，但是通过视觉技术和非视觉技术间接度量疲劳特征如闭眼程度、眨眼频率等，或通过仪器测量驾驶员的心率、脑电波等生理变化已成为目前主要的研究热点。文献［１－３］是基于包括心电图（ＥＣＧ）、肌电图（ＥＭＧ）、脑电图（ＥＥＧ）和眼电图（ＥＯＧ）等人体生理信号的检测方法，虽然这些方法检测结果较为精确，但是传感器和医疗设备穿戴不便，会影响驾驶员的正常驾驶，故存在局限性。文献［４］通过采集方向盘转向角、车辆横摆角和车辆位置等参数来判断驾驶员的疲劳状态。虽然该方法不具备入侵性，但是受车型、路况以及不同驾驶员操作习惯的影响，不能够作为疲劳水平的准确判断标准。文献［５］是基于机器视觉的方法，通过内置摄像头监控驾驶员的行为，如打哈欠、闭眼、眨眼和头部偏移等动作。Ｇａｏ等［６］将Ａｄａｂｏｏｓｔ和主动形状模型（ＡＳＭ）方法结合，根据Ｐ８０标准计算眨眼参数并建立疲劳检测模型的支持向量机，　计算机工程与设计２０１９年但ＰＥＲＣＬＯＳ方法存在一定程度的时滞，难以满足实时监测的要求。Ｎａｗａｌ等［７］提出了一种基于圆形霍夫变换（ＣＨＴ）的眼睛和嘴巴状态分析方法，通过识别虹膜来检测疲劳程度，但当驾驶员注意力不集中或者头部发生偏移时其检测效果不好。本文对经典ＡＳＭ算法进行改进，以快速准确获取面部特征点，并在此基础上提取眼睛和嘴部区域，得出眼睛的长宽比ＥＡＲ值和嘴部高度值ｈ及嘴部附近的黑白像素比值；然后通过连续监测驾驶员的面部状态来判断疲劳程度，建立模糊推理系统实现两种特征的融合，最终将眼睛和嘴巴的状态值作为观测输入，经过模糊规则推理得出疲劳状态，达到一种实时准确和高鲁棒性的疲劳检测效果。１　人脸定位１．１　经典的ＡＳＭ算法ＡＳＭ是目前主流的人脸特征点提取方法。ＡＳＭ训练通常分为建立形状模型和ＡＳＭ搜索两个部分。首先收集ｎ个训练样本，以人脸检测为例，训练的每一个样本中都需要含有人脸区域，然后在人脸上标定ｎ个关键点｛（ｘｉ，ｙｉ）｝，｛（ｘｉ，ｙｉ）｝形成一个形状向量Ｘ＝（ｘ１，ｙ１，…，ｘｎ，ｙｎ），其中（ｘｉ，ｙｉ）表示训练样本上第ｉ个特征点的坐标。定义训练集Ｓ＝｛Ｘｉ｝，运用普氏分析法（ＧＰＳ）［８］对训练集Ｓ的形状进行对齐。具体步骤如下：（１）将训练集Ｓ中的所有形状向量对齐到第１个形状向量；（２）计算平均形状向量珚ｇ＝（∑ｎｉ＝１ｇｉ）／ｎ；（３）将所有形状向量对齐到平均形状向量珚ｇ；（４）重复步骤（２）、（３）直到收敛。根据步骤（２）求出珚ｇ，将对齐后的形状向量运用主成份分析法（ＰＣＡ）［９］处理以减少数据维数，即计算所有向量的协方差矩阵Ｓ，如式（１）所示，计算矩阵Ｓ的特征值并选取前ｔ个特征值构成特征向量矩阵Ｐ＝（Ｐ１，Ｐ２，…，Ｐｔ），并且相应的特征值需满足式（２）Ｓ＝（∑ｎｉ＝１（ｇｉ－ｇ）Ｔ（ｇｉ－珚ｇ））／ｎ（１）（∑ｔｉ＝１λｌ）／（∑ｑｉ＝１λｓ）＞ｆｖＶＴ（２）式（２）中ｆｖ是特征向量个数确定的比例系数，取９７．５％，ＶＴ是ｔ个特征值之和。然后，通过确定灰度值在特征点周围建立灰度统计模型，并建立表示训练形状变化的子空间。一维轮廓由固定长度直线上的灰度级构成，且这些直线与特征点处的形状的边缘正交。将灰度样本存储为向量形式，再通过用灰度级的强度（该点和前一点的灰度级差）替换向量中的每个元素，并除以平均向量来标准化。最后为金字塔模型的每个点和３个级别生成平均形状向量和协方差矩阵（金字塔中的每个图像是之前图像尺寸的一半）。同理，训练数据集也可以通过灰度图像的推导在特征点处计算二维轮廓。将目标矩阵转换成向量之后，通过Ｓｉｇｍｏｉｄ变换对形状向量ｇ′ｉ的每个特定元素进行归一化，如式（３）所示，其中ｑ为常量ｇ′ｉ＝ｇｉ／（｜ｇｉ｜＋ｑ）（３）在某些情况下，使用一维轮廓来寻找特征点准确率不高，如图１说明了目标位置为Ｐ１的情况。然而，一维轮廓会搜索到点Ｐ２而不是Ｐ１，因此需要用二维轮廓来解决。通过二维轮廓可以精确的搜寻到点Ｐ１，并且可以有效减少错位误差。图１　局部特征说明在训练阶段，通过该方法为每个层级的图像构建典型的多级模型。首先从金字塔的底层（第２层）开始采样直到最高层（第０层）结束，到达第０层的时候特征点的错位误差会比第２层低很多，通过建立特征点与相邻的候选点间的向量关系来搜索新的特征点的最佳位置，通常会选择具有一般特征点绝大部分特征的候选点作为新特征点的位置。先验信息认为特征点主要是图像的强边缘点，并且图像灰度的梯度服从高斯分布，只要找到模型特征点附近梯度最大的值，即认为是特征点所在的位置，如图２所示。图２　ＡＳＭ模型在图像中的匹配而ＡＳＭ方法中用于确定特征点的加权函数为形状向量ｇ和平均形状向量ｇ－算得的最小马氏距离，如式（４）所示ｆ１（ｘ）＝（ｇ－ｇ－）ＴＳ－１ｇ（ｇ－ｇ－）（４）并且该方法会在多级模型的所有层级上通过在特征点周围对像素为１５×１５的二维向量进行搜索。当所有的特征点位移到最佳位置时，所有特征点组成·０７２３·第４０卷　第１１期　　陈鑫，李为相，李为，等：基于改进ＡＳＭ的多特征融合疲劳检测方法　的新的形状（Ｘｉ）通过式（５）转换成一个代表脸部轮廓的形状ｘＬ＝ｘ－＋Ｐｂ（５）其中，ｘＬ为最接近的形状向量（Ｘｉ），ｘ－为平均形状向量，Ｐ为特征向量矩阵，ｂ为预测产生面部形状的向量参数。通过循环计算参数ｂ使得式（６）的距离最小ｄｉｓｔ（ｘＩ，Ｔ（ｘ－＋Ｐｂ））（６）其中，Ｔ是一个使ｘＩ和（ｘ－＋Ｐｂ）之间距离最小化的变换［１０］。定义向量ｂ的第ｉ个子向量是ｂｉ，取值范围为（－ａλ槡ｉ，＋ａλ槡ｉ），其中ａ取３，λｉ为第ｉ个特征值。通过对ｂ的约束使生成的形状与原始训练集中模型形状相似。在多级模型的每个层级上都要进行上述的循环，直到变换参数Ｔ和ｂ变化不是很大或者迭代次数达到规定次数为止（即两个连续循环中的特征点的位置没有发生明显的变化）。当参数在低层级收敛时，通过尺度变换改变模型形状并作为下一层级的初始模型，直到到达金字塔最高层级停止搜索。１．２　改进的ＡＳＭ算法为了均衡图像中的亮度以及区分图像中高低频率的变化，本文结合了直方图均衡化和Ｓｏｂｌｅ滤波函数来确定每个点的二维轮廓。步骤如下：（１）使用直方图均衡化算法来标准化图像的亮度；（２）在ｘ和ｙ两个方向上使用Ｓｏｂｌｅ滤波函数，用矩阵中的每一个元素构造纹理矩阵，矩阵中每个元素ｆ的值如式（７）所示ｆ（ｘ′，ｙ′）＝（ｘ′）２＋（ｙ′）槡２（７）（３）用式（７）将矩阵归一化为向量ｇ′ｉ＝ｇｉ／∑ｇｉ（８）为了提高经典ＡＳＭ算法难以找到形状边界上特征点的能力，本算法增加了加权函数ｆ２（ｇ），如式（８）所示ｆ２（ｇ）＝（ｃ－Ｉ）（ｇ－ｇ－）ＴＳ－１ｇ（ｇ－ｇ－）（９）其中，Ｉ是候选点处的灰度值，对于非边界上的点Ｉ取值为０，对于边界上的点Ｉ取值为１。ｃ为常数，本文取值为２［１１］。又因为经典ＡＳＭ算法中ＰＣＡ降维不会考虑正负样本的区别，导致搜索特征点的过程存在局部极值情况，所以本文使用线性支持向量机［１２］的方法来区分正负样本。对于每个特征点，通过支持向量机的方法来确定二维轮廓。从焦点出发开始搜索正样本（特征点），而负样本（该点不是特征点）随机选择与正样本具有相同大小和不同焦点的窗口。算法搜索当前特征点周围的候选点来确定新的特征点，最终选择使函数ｆ２（ｇ）最小的（ｘ′，ｙ′）作为新的特征点。在经典的ＡＳＭ算法中，轮廓窗口的长度在多层模型的每一个层级上都是相同的，然而通过实验发现在高层级上特征点的位移较小，并且当候选点接近特征点时位移更小。因此，本文根据不同的水平调整轮廓窗口的长度，不仅节省了计算量，也提高了搜索特征点的精度。２　基于改进ＡＳＭ算法的人脸疲劳检测２．１　人脸检测本文仿真环境为Ｐｙｔｈｏｎ３．２，基于ＯｐｅｎＣＶ开源库完成人脸疲劳检测。对于人脸检测，对齐阶段的第一步是先检测图像中的人脸区域，本文使用ＯｐｅｎＣＶ库中的Ｖｉｏｌａ－Ｊｏｎｅｓ算法来检测人脸。检测到人脸后，对面部形状模型进行旋转、缩放、平移等变换使得模型能适应检测到的人脸。将搜索到的形状向量作为初始形状，在此基础上循环搜索特征点，最终这些特征点将形成一个接近面部特征的形状。本实验中设定第一层级的窗口长度为Ｌ，第二层级的长度为Ｌ／２，第三层级的长度为Ｌ／４。本文使用的第一层的长度为１５像素。实验结果如图３所示，图（ａ）是平视时的人脸检测结果，图（ｂ）是当头部发生偏移时的检测结果，相对经典的ＡＳＭ算法，每个特征点新位置的定位精度得到了优化。图３　人脸检测结果２．２　眨眼检测２．２．１　眨眼检测原理正常情况下人的眨眼持续时间约１００ｍｓ－４００ｍｓ，但现有的ＰＥＲＣＬＯＳ算法［１３］以及文献［１４］的二值图像分割算法存在一定程度时滞，难以满足实时检测的要求。因此本文在改进ＡＳＭ方法的基础上，对眼部特征点之间的距离构造函数求出ＥＡＲ值，如式（１０）所示，用作眼睛状态的判断依据。但由于每帧图像的ＥＡＲ值不能完全准确识别眨眼，因此本文将时间窗口较大的帧作为样本进行训练ＥＡＲ＝（ｐ２－ｐ６＋ｐ３－ｐ５）／２　ｐ１－ｐ４（１０）其中，ｐ１，…，ｐ６是平面上的特征点，如图４所示。该等式的分子计算眼睛垂直特征点之间的距离，分母计算眼睛水平特征点之间的距离，因为水平方向特征点只有一组而垂直方向特征点有两组，所以对分母进行适当加权。当眼睛睁开时，ＥＡＲ值是一个近似恒定的值，但是当眼睛闭合时，ＥＡＲ值会降为零。虽然每个人的ＥＡＲ值会有一些很小的差异，但是通过图像的均匀缩放和旋转不会·１７２３·　计算机工程与设计２０１９年影响该比值。考虑到人眨眼时是两眼同时进行的，因此本文求得两眼ＥＡＲ值的平均值作为评判值。２．２．２　眨眼检测结果正如图４所示，左边是一个完全睁开时的眼睛，ＥＡＲ值会很大，随着时间的推移其值会趋于恒定。当人一旦有眨眼动作（图４（ｂ）），ＥＡＲ值急剧下降约等于零。图４　眼部特征点说明当检测系统确定视频段中发生眨眼时，开始计算ＥＡＲ值。如果ＥＡＲ值从低于阈值的地方超过阈值，再低于阈值，则记为一次有效的眨眼，本文定义阈值名为ＥＹＥ＿ＡＲ＿ＴＨＲＥＳＨ，默认它的值为０．２。图５为基于ＡＳＭ方法的眼部区域获取结果，图６为ＥＡＲ阈值设定为０．２时的眨眼检测结果。最后定义一个常量ＥＹＥ＿ＡＲ＿ＣＯＮＳＥＣ＿ＦＲＡＭＥ来对帧进行计数，取值为３，表明ＥＡＲ值在３个帧内必须都小于设定的阈值，从而计算眨眼次数。图５　基于ＡＳＭ方法的眼部区域获取结果图６　ＥＡＲ阈值设定为０．２时的眨眼检测结果２．２．３　眨眼分类器的训练通常情况下ＥＡＲ值较低并不意味着一个人在眨眼，当发生非有效眨眼时ＥＡＲ值也变低，其鲁棒性不高。本文通过ＳＶＭ分类器对每一帧的开眼程度进行分类训练，训练出眨眼与非眨眼模式，并将时间窗口较大的帧作为分类器的输入，通过实验发现对于３０　ｆｐｓ的视频，±６帧内的眨眼检测效果最好。所以对于每个视频帧，将其±６帧的平均ＥＡＲ值作为评判眨眼的一个特征。２．２．４　ＡＳＭ算法与本文算法比较传统的ＡＳＭ方法只能用于检测人脸和眼睛区域，本文算法在此基础上还可以完成眨眼检测和疲劳识别等功能。本文选取５个视频段进行测试，实验结果见表１，表２。表１为本文算法的眨眼识别结果，可以看出本文眨眼检测的平均成功率为９５．７％，疲劳检测成功率为１００％。表２给出了ＡＳＭ算法和本文算法之间的功能性比较。表１　使用本文算法的眨眼识别结果测试号视频时长检测数量误检测量成功率／％１　６０ｓ１１３　６　９４．６２　６０ｓ１２８　５　９６．１３　６０ｓ１０６　７　９３．４４　６０ｓ１１４　２　９８．２５　６０ｓ１０９　４　９６．３平均值６０ｓ１１４　４．８　９５．７表２　ＡＳＭ算法与本文算法的人眼检测结果比较功能ＡＳＭ本文算法人脸检测是是眼部追踪是是眨眼检测否是疲劳识别否是２．３　打哈欠检测２．３．１　打哈欠检测原理目前国内外检测嘴巴区域算法的缺陷包括：检测到的嘴巴边缘无法收敛于兴趣区域边缘；检测对于彩色图像可以运行，对于某些特殊图像无法进行检测；检测所需的时间较长，不能快速检测嘴巴。本文首先通过ＡＳＭ方法确定嘴部区域的位置，将嘴部特征点内的区域作为输入图像，并将输入的ＲＧＢ图像转换为灰度图像，从而减少图像的处理时间［１５］，转换公式如式（１１）所示Ｇｒａｙ＝０．２９９Ｒ＋０．５８７Ｇ＋０．１１４Ｂ（１１）第二步进行图像增强处理，调节其灰度值直到嘴部区域与背景之间的灰度值强度超过设定阈值。图像增强会影响嘴部状态的分类结果，以及对打哈欠行为的判断。第三步对嘴部区域的图像进行二值化，通过形态学重建去除噪声并填充嘴部空白区域。最后提取嘴部区域的高度值和嘴部附近的黑白像素比值，对开口程度进行评估。嘴部区域的高度值和嘴部附近的黑白像素比值必须满·２７２３·第４０卷　第１１期　　陈鑫，李为相，李为，等：基于改进ＡＳＭ的多特征融合疲劳检测方法　足３个基本条件ＮＢＣ／ＮＢＳ＞Ｔｈ１（１２）ＮＢＣ／ＮＷＣ＞Ｔｈ２（１３）ｈ＞Ｔｈ３（１４）其中式（１２）表示当前帧与参考帧中的黑色像素数之比必须大于阈值Ｔｈ１，式（１３）表示当前帧嘴部区域的黑色像素数量与嘴部周围区域中的白色像素数量之比必须大于阈值Ｔｈ２。式（１４）中的ｈ表示嘴部区域的高度，高度必须大于阈值Ｔｈ３。只有当３个条件同时满足，系统才判定检测到的特定帧为打哈欠，并且对视频的后续帧重复该过程。２．３．２　打哈欠检测结果图像预处理如图７所示，打哈欠检测结果如图８所示。如图７（ｂ）所示，当嘴张开的时候，图像的黑色像素值会骤增，并且会超过本文设定的阈值，计算得出嘴部张开与闭合时的黑色像素数量，并对嘴部张开程度和视频帧数建立坐标系，如果嘴巴处的黑色像素值在连续帧内都都超过阈值，则判定驾驶员处于打哈欠状态。图７　正常照明条件下的图像预处理步骤由图８可知，正常光照条件下，当嘴巴高度为０时代表嘴巴处于关闭状态，当发生打哈欠时，嘴巴高度会迅速增长到３５，打哈欠结束时其值最终又回到０。通过对每个视频帧中打哈欠时嘴巴的初始高度进行多次对比分析，本文选取高度２５作为打哈欠的零界点，即任何低于２５的值都表示为非打哈欠状态，任何不低于２５的值都表示为打哈欠状态。图８　基于嘴巴高度与视频帧数的打哈欠检测结果３　基于模糊推理系统的疲劳判定３．１　模糊推理系统组成因为驾驶员的疲劳程度是一个很模糊的概念，所以只能通过一些量化的信息来间接判断，比如眨眼频率、打哈欠、闭眼时间等。如何提取这些疲劳症状并将它们融合成为一个整体并进行疲劳检测是一个难点，本文人脸疲劳检测流程如图９所示。本文的疲劳检测系统使用逻辑ＡＮＤ作为模糊逻辑运算符和５个ｉｆ－ｔｈｅｎ规则的Ｍａｍｄａｎｉ型模糊推理系统［１６］，系统由两个输入和一个输出组成。摄像头采集到的眼部和嘴部的数据作为模糊推理系统（ＦＩＳ）的观测输入，包括眼部区域的ＥＡＲ值、嘴部区域的黑白像素比值。眼睛部分的跟踪输出由３部分组成，其隶属度函数的语言变量的取值为｛眨眼，困倦，闭眼｝，论域区间为［０，１］。嘴部的跟踪输出由两部分组成，其隶属度函数的语言变量的取值为｛正常，打哈欠｝，论域区间为［０，１］。图９　人脸疲劳检测流程用以提示驾驶员的模糊推理系统的输出由３部分组成，其隶属度函数的语言变量的取值为｛正常，疲劳，危险｝，论域区间为［０，１］。最终，通过规则将模糊推理系统的输入和输出联系起来，本文采用的去模糊化方法为ｃｅｎｔｒｏｉｄ。模糊推理系统的规则如下所示。·３７２３·　计算机工程与设计２０１９年（１）Ｉｆ（ｅｙｅ＿ｓｔａｔｅ　ｉｓ眨眼）ａｎｄ（ｍｏｕｓｅ＿ｓｔａｔｅ　ｉｓ正常）ｔｈｅｎ（ｏｕｔｐｕｔ１ｉｓ正常）；（２）Ｉｆ（ｅｙｅ＿ｓｔａｔｅ　ｉｓ困倦）ｔｈｅｎ（ｏｕｔｐｕｔ１ｉｓ疲劳）；（３）Ｉｆ（ｅｙｅ＿ｓｔａｔｅ　ｉｓ困倦）ａｎｄ（ｍｏｕｓｅ＿ｓｔａｔｅ　ｉｓ打哈欠）ｔｈｅｎ（ｏｕｔｐｕｔ１ｉｓ疲劳）；（４）Ｉｆ（ｅｙｅ＿ｓｔａｔｅ　ｉｓ闭眼）ａｎｄ（ｍｏｕｓｅ＿ｓｔａｔｅ　ｉｓ正常）ｔｈｅｎ（ｏｕｔｐｕｔ１ｉｓ危险）；（５）Ｉｆ（ｍｏｕｓｅ＿ｓｔａｔｅ　ｉｓ打哈欠）ｔｈｅｎ（ｏｕｔｐｕｔ１ｉｓ疲劳）。３．２　疲劳程度推理结果图１０和图１１为模糊推理系统的两个输入的隶属度函数，图１２为模糊推理系统输出的隶属度函数。图１３为系统输出的疲劳检测结果，其中图（ａ）为驾驶员清醒时疲劳检测系统的输出结果，图（ｂ）为系统检测到驾驶员在连续帧内闭眼并且嘴巴在连续帧内（３ｓ－４ｓ）持续张开的输出结果。图１０　模糊系统的输入（眼部状态）图１１　模糊系统的输入（嘴部状态）目前疲劳检测的实验数据库相对较少，因此本实验征集了５名不同肤色、不同性别的志愿者，记录他们在清醒、疲劳和严重疲劳状态下模拟驾驶的视频段作为模糊推理系统的验证数据。视频共计２０组，每组视频由２０个１分钟的视频段组成，共计３００个视频段。模糊推理机验证结果见表３，疲劳程度判断平均准确率达９５．１％，其中不存在清醒状态判断为严重疲劳的情况，满足疲劳检测系统的性图１２　模糊系统的输出（疲劳状态）图１３　疲劳检测结果能要求。表４显示了本文算法与文献［６］和文献［７］的算法对比结果，可以看出在正常和疲劳两种情况下，本文的准确率均优于这两种算法。表３　验证结果实际状态实验结果正常困倦危险准确率／％正常４８　３　１　９５困倦４　４７　１　９４．６危险０　４　４８　９５．７表４　算法对比结果文献对比参数正常准确率／％疲劳准确率／％文献［６］９２　９１．３文献［７］９０　９４本文算法９５　９５．７４　结束语本文将改进的ＡＳＭ算法与模糊推理机相结合，提出了一种非入侵式疲劳程度检测系统。首先在ＡＳＭ算法中加入直方图均衡化和Ｓｏｂｅｌ滤波函数，并结合支持向量机提高了搜索特征点的速度及精度；然后构造函数计算眼部和嘴部·４７２３·第４０卷　第１１期　　陈鑫，李为相，李为，等：基于改进ＡＳＭ的多特征融合疲劳检测方法　状态值，得出眨眼频率和嘴巴张开程度；最后利用模糊推理系统综合眼部状态和嘴部状态实现两种特征的融合，准确率达９５％。实验结果表明本文方法对疲劳驾驶检测是可行的，但如何解决有遮挡物时驾驶员的疲劳状态检测以及夜间环境的疲劳驾驶检测问题都是值得开展的研究方向。参考文献：［１］Ｆｕ　Ｒ，Ｗａｎｇ　Ｈ．Ｄｅｔｅｃｔｉｏｎ　ｏｆ　ｄｒｉｖｉｎｇ　ｆａｔｉｇｕｅ　ｂｙ　ｕｓｉｎｇ　ｎｏｎｃｏｎ－ｔａｃｔ　ＥＭＧ　ａｎｄ　ＥＣＧ　ｓｉｇｎａｌｓ　ｍｅａｓｕｒｅｍｅｎｔ　ｓｙｓｔｅｍ［Ｊ］．Ｉｎｔｅｒｎａ－ｔｉｏｎａｌ　Ｊｏｕｒｎａｌ　ｏｆ　Ｎｅｕｒａｌ　Ｓｙｓｔｅｍｓ，２０１４，２４（３）：１４５０００６．［２］Ａｂａｓ　Ａ，Ｍｅｌｌｏｒ　Ｊ，Ｃｈｅｎ　Ｘ．Ｎｏｎ－ｉｎｔｒｕｓｉｖｅ　ｄｒｏｗｓｉｎｅｓｓ　ｄｅｔｅｃ－ｔｉｏｎ　ｂｙ　ｅｍｐｌｏｙｉｎｇ　ｓｕｐｐｏｒｔ　ｖｅｃｔｏｒ　ｍａｃｈｉｎｅ［Ｃ］／／ＩｎｔｅｒｎａｔｉｏｎａｌＣｏｎｆｅｒｅｎｃｅ　ｏｎ　Ａｕｔｏｍａｔｉｏｎ　ａｎｄ　Ｃｏｍｐｕｔｉｎｇ．ＩＥＥＥ，２０１４：１８８－１９３．［３］Ｂｅｌａｋｈｄａｒ　Ｉ，Ｋａａｎｉｃｈｅ　Ｗ，Ｄｊｍｅｌ　Ｒ，ｅｔ　ａｌ．Ａ　ｃｏｍｐａｒｉｓｏｎ　ｂｅ－ｔｗｅｅｎ　ＡＮＮ　ａｎｄ　ＳＶＭ　ｃｌａｓｓｉｆｉｅｒ　ｆｏｒ　ｄｒｏｗｓｉｎｅｓｓ　ｄｅｔｅｃｔｉｏｎ　ｂａｓｅｄｏｎ　ｓｉｎｇｌｅ　ＥＥＧ　ｃｈａｎｎｅｌ［Ｃ］／／Ｉｎｔｅｒｎａｔｉｏｎａｌ　Ｃｏｎｆｅｒｅｎｃｅ　ｏｎ　Ａｄ－ｖａｎｃｅｄ　Ｔｅｃｈｎｏｌｏｇｉｅｓ　ｆｏｒ　Ｓｉｇｎａｌ　ａｎｄ　Ｉｍａｇｅ　Ｐｒｏｃｅｓｓｉｎｇ．ＩＥＥＥ，２０１６：４４３－４４６．［４］ＨＵＡＮＧ　Ｈａｏ．Ｆａｔｉｇｕｅ　ｄｒｉｖｉｎｇ　ｄｅｔｅｃｔｉｏｎ　ｂａｓｅｄ　ｏｎ　ｄｒｉｖｅｒ　ｂｅｈａ－ｖｉｏｒ　ａｎｄ　ｖｅｈｉｃｌｅ　ｓｔａｔｅ［Ｄ］．Ｎａｎｊｉｎｇ：Ｓｏｕｔｈｅａｓｔ　Ｕｎｉｖｅｒｓｉｔｙ，２０１６（ｉｎ　Ｃｈｉｎｅｓｅ）．［黄皓．基于驾驶操作及车辆状态的疲劳驾驶行为检测研究［Ｄ］．南京：东南大学，２０１６．］［５］ＨＵ　Ｊｉｅ．Ｒｅｓｅａｒｃｈ　ｏｎ　ｄｒｉｖｅｒ　ｆａｔｉｇｕｅ　ｄｅｔｅｃｔｉｏｎ　ｓｙｓｔｅｍ　ｏｎ　ｔｈｅ　ｅｍ－ｂｅｄｄｅｄ　ｓｙｓｔｅｍ［Ｄ］．Ｘｉ’ａｎ：Ｃｈａｎｇ’ａｎ　Ｕｎｉｖｅｒｓｉｔｙ，２０１４（ｉｎＣｈｉｎｅｓｅ）．［胡捷．嵌入式驾驶员疲劳检测系统的研究［Ｄ］．西安：长安大学，２０１４．］［６］Ｇａｏ　Ｙ，Ｗａｎｇ　Ｃ．Ｆａｔｉｇｕｅ　ｓｔａｔｅ　ｄｅｔｅｃｔｉｏｎ　ｆｒｏｍ　ｍｕｌｔｉ－ｆｅａｔｕｒｅ　ｏｆｅｙｅｓ［Ｃ］／／Ｉｎｔｅｒｎａｔｉｏｎａｌ　Ｃｏｎｆｅｒｅｎｃｅ　ｏｎ　Ｓｙｓｔｅｍｓ　ａｎｄ　Ｉｎｆｏｒｍａ－ｔｉｃｓ．Ｈａｎｇｚｈｏｕ：ＩＥＥＥ，２０１８：１７７－１８１．［７］Ａｂｄｕｌｌａｈ　Ｍ　Ｈ，Ｒａｍａｎ　Ｋ　Ｊ，Ａｚｍａｎ　Ａ，ｅｔ　ａｌ．Ｄｒｉｖｅｒ　ｆａｔｉｇｕｅｄｅｔｅｃｔｉｏｎ［Ｍ］／／Ｉｎｆｏｒｍａｔｉｏｎ　Ｓｃｉｅｎｃｅ　ａｎｄ　Ａｐｐｌｉｃａｔｉｏｎｓ．ＳｐｒｉｎｇｅｒＳｉｎｇａｐｏｒｅ，２０１６．［８］ＸＩＯＮＧ　Ｙｕｘｕｅ，ＹＡＮＧ　Ｈｕｉｆａｎｇ，ＺＨＡＯ　Ｙｉｊｉａｏ，ｅｔ　ａｌ．Ｃｏｍ－ｐａｒｉｓｏｎ　ｏｆ　ｔｗｏ　ｋｉｎｄｓ　ｏｆ　ｍｅｔｈｏｄｓ　ｅｖａｌｕａｔｉｎｇ　ｔｈｅ　ｄｅｇｒｅｅ　ｏｆ　ｆａｃｉａｌａｓｙｍｍｅｔｒｙ　ｂｙ　ｔｈｒｅｅ－ｄｉｍｅｎｓｉｏｎａｌ　ｄａｔａ［Ｊ］．Ｊｏｕｒｎａｌ　ｏｆ　ＰｅｋｉｎｇＵｎｉｖｅｒｓｉｔｙ（Ｈｅａｌｔｈ　Ｓｃｉｅｎｃｅｓ），２０１５，４７（２）：３４０－３４３（ｉｎＣｈｉｎｅｓｅ）．［熊玉雪，杨慧芳，赵一姣，等．两种评价面部三维表面数据不对称度方法的比较［Ｊ］．北京大学学报：医学版，２０１５，４７（２）：３４０－３４３．］［９］ＺＨＡＮＧ　Ｒｉｄｏｎｇ，ＪＩＡ　Ｋｅｂｉｎ．Ｌｏｃａｌ　ｔｗｏ－ｄｉｍｅｎｓｉｏｎａｌ　ｐｒｉｎｃｉｐａｌｃｏｍｐｏｎｅｎｔ　ａｎａｌｙｓｉｓ　ａｌｇｏｒｉｔｈｍ　ｆｏｒ　ｆａｃｉａｌ　ｅｘｐｒｅｓｓｉｏｎ　ｒｅｃｏｇｎｉｔｉｏｎ［Ｊ］．Ｃｏｍｐｕｔｅｒ　Ａｐｐｌｉｃａｔｉｏｎｓ　ａｎｄ　Ｓｏｆｔｗａｒｅ，２０１８，３５（２）：１７２－１７７（ｉｎ　Ｃｈｉｎｅｓｅ）．［张日东，贾克斌．一种用于表情识别的局部二维主成分分析算法［Ｊ］．计算机应用与软件，２０１８，３５（２）：１７２－１７７．］［１０］Ｃｏｏｔｅｓ　Ｔ　Ｆ，Ｒｏｂｅｒｔｓ　Ｍ　Ｇ，Ｂａｂａｌｏｌａ　Ｋ　Ｏ，ｅｔ　ａｌ．Ａｃｔｉｖｅｓｈａｐｅ　ａｎｄ　ａｐｐｅａｒａｎｃｅ　ｍｏｄｅｌｓ［Ｍ］／／Ｈａｎｄｂｏｏｋ　ｏｆ　ＢｉｏｍｅｄｉｃａｌＩｍａｇｉｎｇ．Ｓｐｒｉｎｇｅｒ　ＵＳ，２０１５：１０５－１２２．［１１］Ｓｉｋａｒｗａｒ　Ｒ，Ｙａｄａｖ　Ｐ．Ａｎ　ａｐｐｒｏａｃｈ　ｔｏ　ｆａｃｅ　ｄｅｔｅｃｔｉｏｎ　ａｎｄ　ｆｅａ－ｔｕｒｅ　ｅｘｔｒａｃｔｉｏｎ　ｕｓｉｎｇ　ｃａｎｎｙ　ｍｅｔｈｏｄ［Ｊ］．Ｉｎｔｅｒｎａｔｉｏｎａｌ　Ｊｏｕｒｎａｌｏｆ　Ｃｏｍｐｕｔｅｒ　Ａｐｐｌｉｃａｔｉｏｎｓ，２０１７，１６３（４）：１－５．［１２］Ｘｉｅ　Ｙ，Ｂｉａｎ　Ｃ，Ｍｕｒｐｈｅｙ　Ｙ　Ｌ，ｅｔ　ａｌ．Ａｎ　ＳＶＭ　ｐａｒａｍｅｔｅｒｌｅａｒｎｉｎｇ　ａｌｇｏｒｉｔｈｍ　ｓｃａｌａｂｌｅ　ｏｎ　ｌａｒｇｅ　ｄａｔａ　ｓｉｚｅ　ｆｏｒ　ｄｒｉｖｅｒ　ｆａｔｉｇｕｅｄｅｔｅｃｔｉｏｎ［Ｃ］／／ＩＥＥＥ　Ｓｙｍｐｏｓｉｕｍ　Ｓｅｒｉｅｓ　ｏｎ　ＣｏｍｐｕｔａｔｉｏｎａｌＩｎｔｅｌｌｉｇｅｎｃｅ．Ｈｏｎｏｌｕｌｕ：ＩＥＥＥ，２０１７：１－８．［１３］Ｚｈａｎｇ　Ｆ，Ｓｕ　Ｊ，Ｇｅｎｇ　Ｌ，ｅｔ　ａｌ．Ｄｒｉｖｅｒ　ｆａｔｉｇｕｅ　ｄｅｔｅｃｔｉｏｎ　ｂａｓｅｄｏｎ　ｅｙｅ　ｓｔａｔｅ　ｒｅｃｏｇｎｉｔｉｏｎ［Ｃ］／／Ｉｎｔｅｒｎａｔｉｏｎａｌ　Ｃｏｎｆｅｒｅｎｃｅ　ｏｎＭａｃｈｉｎｅ　Ｖｉｓｉｏｎ　ａｎｄ　Ｉｎｆｏｒｍａｔｉｏｎ　Ｔｅｃｈｎｏｌｏｇｙ．Ｓｉｎｇａｐｏｒｅ：ＩＥＥＥ，２０１７：１０５－１１０．［１４］ＭＡＯ　Ｘｕｗｅｉ，ＪＩＮＧ　Ｗｅｎｂｏ，ＷＡＮＧ　Ｘｉａｏｍａｎ，ｅｔ　ａｌ．Ａ　ｆａ－ｔｉｇｕｅ　ｄｒｉｖｉｎｇ　ｄｅｔｅｃｔｉｏｎ　ｍｅｔｈｏｄ　ｂａｓｅｄ　ｏｎ　ｅｙｅ　ｓｔａｔｅ［Ｊ］．Ｊｏｕｒｎａｌｏｆ　Ｃｈａｎｇｃｈｕｎ　Ｕｎｉｖｅｒｓｉｔｙ　ｏｆ　Ｓｃｉｅｎｃｅ　ａｎｄ　Ｔｅｃｈｎｏｌｏｇｙ（ＮａｔｕｒａｌＳｃｉｅｎｃｅ　Ｅｄｉｔｉｏｎ），２０１６，３９（２）：１２５－１３０（ｉｎ　Ｃｈｉｎｅｓｅ）．［毛须伟，景文博，王晓曼，等．一种基于眼部状态的疲劳驾驶检测方法［Ｊ］．长春理工大学学报（自然科学版），２０１６，３９（２）：１２５－１３０．］［１５］Ｊａｓｔｒｚｂｓｋｉ　Ｄ，Ｋｏｐｙｔ　Ａ，Ｇｏｌｏｎ　Ｋ，ｅｔ　ａｌ．Ｆｕｚｚｙ　ｌｏｇｉｃ　ａｓ　ａｍｏｄｅｌ　ｏｆ　ａｎ　ａｃｔｏｒ－ｄｒｉｖｅｒ　ｉｎ　ｓｉｍｕｌａｔｏｒ　ｓｃｅｎａｒｉｏｓ［Ｃ］／／Ｐｒｏｃｅｅ－ｄｉｎｇ　ｏｆ　ｔｈｅ　Ｉｎｔｅｒｎａｔｉｏｎａｌ　ＩＲＣＯＢＩ　Ｃｏｎｆｅｒｅｎｃｅ　ｏｎ　ｔｈｅ　Ｂｉｏ－ｍｅｃｈａｎｉｃｓ　ｏｆ　Ｉｎｊｕｒｙ，２０１７：５９５－５９６．［１６］Ｐｏｕｒｊａｖａｄ　Ｅ，Ｓｈａｈｉｎ　Ａ．Ｔｈｅ　ａｐｐｌｉｃａｔｉｏｎ　ｏｆ　ｍａｍｄａｎｉ　ｆｕｚｚｙ　ｉｎ－ｆｅｒｅｎｃｅ　ｓｙｓｔｅｍ　ｉｎ　ｅｖａｌｕａｔｉｎｇ　ｇｒｅｅｎ　ｓｕｐｐｌｙ　ｃｈａｉｎ　ｍａｎａｇｅｍｅｎｔｐｅｒｆｏｒｍａｎｃｅ［Ｊ］．Ｉｎｔｅｒｎａｔｉｏｎａｌ　Ｊｏｕｒｎａｌ　ｏｆ　Ｆｕｚｚｙ　Ｓｙｓｔｅｍｓ，２０１７，２０（１８）：１－１２．·５７２３·