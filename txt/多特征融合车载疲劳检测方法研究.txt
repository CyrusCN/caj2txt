中图分类号：TP391.41论文编号：学科分类号：520.6040密级：公开专业学位硕士学位论文（全日制）多特征融合车载疲劳检测方法研究作者姓名：叶华洲专业名称：计算机技术研究方向：图像处理导师姓名：王军号高级实验师导师单位：安徽理工大学答辩委员会主席：朱家兵论文答辩日期：2022年12月04日安徽理工大学研究生院2022年12月10日ADissertationincomputertechnologyResearchonmulti-featurefusionvehiclefatiguedetectionmethodCandidate:YeHuazhouSupervisor:WangJunhaoComputerScienceandEngineeringSchoolAnhuiUniversityofScienceandTechnologyNo.168,TaifengStreet,Huainan,232001,Anhui,P.R.China摘要-I-摘要随着经济的发展，私家车的数量不断上升，我国每年的交通事故数量也随之攀升。相关报道显示，以疲劳驾驶为主要原因的交通事故数量占总体事故数量的20%左右。若可以在驾驶途中及时对驾驶员进行疲劳警示，就能降低由疲劳驾驶造成的交通事故数量。在目前的疲劳检测算法中，基于驾驶员生理信号特征的疲劳检测方法会干扰驾驶员，使其本身成为危害驾驶安全的因素。基于车辆行为特征的疲劳检测受路况、天气影响，且不同车辆的参数不同，其鲁棒性较低。基于驾驶员行为特征的疲劳检测，结合一定的图像处理技术，可以在不干扰驾驶员的前提下进行疲劳检测，且不受环境、车辆参数的影响，具有高精度、高鲁棒性的优点。本文研究了一种分析驾驶员面部行为特征判断驾驶员疲劳状态的方法，研究内容主要有以下几方面：1.疲劳特征区域定位。优化了多特征提取流程，提出了多任务卷积网络从图像中检测人脸区域并获得头部姿态，使用ERT算法获得人脸特征点定位眼部区域与嘴部区域。多任务卷积神经网络将人脸分类、边界框回归与头部姿态估计任务融合到级联网络中，人脸分类任务准确率达到99.2%，边界框回归任务在WIDERFACE官方评价中取得0.665的分数，头部姿态估计任务平均绝对误差为8.021。相较于使用MTCNN+FAS-Net的方式，每秒检测帧数由12FPS提升至25FPS。2.疲劳参数提取。获取特征区域后，在眼部区域使用眼部纵横比获取眨眼信息，使用PERCLOS均值与眨眼次数衡量眼部疲劳状态。在嘴部区域使用嘴部纵横比获取哈欠信息，使用哈欠次数衡量嘴部疲劳状态。在头部使用头部姿态（俯仰角、偏航角和滚转角）判断点头与歪头动作，使用点头次数与异常姿态时长衡量头部疲劳状态。3.多特征融合疲劳检测。因为单种疲劳指标存在准确率低，容易误判的问题，本文采取多特征融合的方法进行疲劳状态判断。使用以CART树为基决策树的随机森林作为多特征融合方法，将5种疲劳参数作为特征。对UTA数据集进行处理，以30s的短视频为样本，选取其中部分作为训练集与测试集。实验结果表明，本文采取的疲劳检测方法可以达到96.2%的准确率，对于疲劳驾驶检测具备较好的可行性。图36表13参70关键词：疲劳驾驶检测；CART树；特征融合；PERCLOS；ERT分类号：TP39；摘要-II-AbstractWiththedevelopmentofeconomy,thenumberofprivatecarsisrising,andthenumberoftrafficaccidentsperyearinChinaisalsorising.Relevantreportsshowthatthenumberoftrafficaccidentswithfatiguedrivingasthemainreasonaccountsforabout20%ofthetotalnumberofaccidents.Ifthedrivercanbealertedtofatigueintimewhiledriving,thenumberoftrafficaccidentscausedbyfatigueddrivingcanbereduced.Inthecurrentfatiguedetectionalgorithm,thefatiguedetectionmethodbasedonthecharacteristicsofthedriver'sphysiologicalsignalwillinterferewiththedriver,makingitafactorendangeringdrivingsafety.Fatiguedetectionbasedonvehiclebehaviorcharacteristicsisaffectedbyroadconditionsandweather,andtheparametersofdifferentvehiclesaredifferent,soitsrobustnessislow.Fatiguedetectionbasedondriverbehaviorcharacteristics,combinedwithcertainimageprocessingtechnology,canperformfatiguedetectionwithoutdisturbingthedriver,andisnotaffectedbytheenvironmentandvehicleparameters,soithastheadvantagesofhighprecisionandhighrobustness.Thispaperstudiesamethodtoanalyzethedriver'sfacialbehaviorcharacteristicstojudgethedriver'sfatiguestate.Theresearchcontentmainlyincludesthefollowingaspects:1.Fatiguefeaturearealocalization.Optimizedmulti-featureextractionprocess,proposedmulti-taskconvolutionalnetworktodetectfaceregionsfromimagesandobtainheadpose,usetheERTalgorithmtoobtainthefacefeaturepointstolocatetheeyeareaandthemoutharea.Themulti-taskconvolutionalneuralnetworkintegratesfaceclassification,boundingboxregressionandheadposeestimationtasks.Themulti-taskconvolutionalneuralnetworkhasanaccuracyrateof99.2%forfacetasks,theboundingboxregressiontaskachievesascoreof0.665intheofficialWIDERFACEevaluation,andtheaverageabsoluteerroroftheheadposeestimationtaskis8.021.ComparedwithusingMTCNN+FAS-Net,theframesperseconddetectionisincreasedfrom12FPSto25FPS.2.Fatigueparameterextraction.Afterobtainingthefeaturearea,usetheeyeaspectratiotoobtaintheblinkinformationintheeyearea,andusethePERCLOSmeanandthenumberofblinkstomeasuretheeyefatiguestate.Usethemouthaspectratiotoobtainyawninformationinthemoutharea,andusethenumberofyawnstomeasure摘要-III-mouthfatiguestatus.Theheadposture(pitchangle,yawangle,androllangle)wasusedtojudgethenoddingandtiltingofthehead,andthenumberofnodsandthedurationofabnormalpostureswereusedtomeasurethefatiguestateofthehead.3.Multi-featurefusionfatiguedetection.Becauseasinglefatigueindexhastheproblemoflowaccuracyandeasymisjudgment,thispaperadoptsthemethodofmulti-featurefusiontojudgethefatiguestate.RandomforestbasedonCARTtreeisusedasamulti-featurefusionmethod,and5kindsoffatigueparametersareusedasfeatures.ProcesstheUTAdataset,take30sshortvideosassamples,andselectsomeofthemastrainingsetsandtestsets.Theexperimentalresultsshowthatthefatiguedetectionmethodadoptedinthispapercanachieveanaccuracyof96.2%,whichhasgoodfeasibilityforfatiguedrivingdetection.Figure36Table13Reference70KeyWords：fatiguedrivingdetection;CARTtree;featurefusion;PERCLOS;ERTChineseBooksCatalog:TP39目  录 1 绪论 ......................................................................................................... 1 1.1 课题研究背景与意义 ....................................................................... 1 1.2 国内外研究现状 ............................................................................... 2 1.2.1 基于驾驶员生理信号特征的疲劳检测 .................................... 4 1.2.2 基于车辆行为特征的疲劳检测 ................................................. 5 1.2.3 基于驾驶员行为特征的疲劳检测 ............................................. 5 1.3 本文研究内容 ................................................................................... 6 1.4 论文的组织结构 ............................................................................... 7 2 相关理论与技术分析 ............................................................................ 8 2.1 图像增强 ........................................................................................... 8 2.2 卷积神经网络在人脸检测中的应用 .............................................. 9 2.3 人脸特征点检测算法 ..................................................................... 10 2.4 本章小结 ......................................................................................... 11 3 疲劳特征区域定位 .............................................................................. 12 3.1 疲劳特征区域定位流程优化 ........................................................ 12 3.2 图像预处理 ..................................................................................... 14 3.2.1 图像去噪 ................................................................................... 14 3.2.2 暗光图像处理 ........................................................................... 16 3.3 多任务卷积神经网络 ..................................................................... 17 3.3.1 网络任务与检测流程 ............................................................... 17 3.3.2 网络结构 ................................................................................... 18 3.3.3 损失函数 ................................................................................... 23 3.3.4 网络训练 ................................................................................... 25 3.3.5 训练结果与网络性能分析 ....................................................... 30 3.4 人脸特征点检测 ............................................................................. 32 3.4.1 建立模型 ................................................................................... 32 3.4.2 模型训练 ................................................................................... 34 3.5 本章小结 ......................................................................................... 35 4 疲劳参数提取 ...................................................................................... 37 4.1 眼部疲劳参数 ................................................................................. 37 4.1.1 眨眼判断 ................................................................................... 37 4.1.2 PERCLOS 参数获取 ................................................................ 39 4.1.3 眨眼次数获取 ........................................................................... 40 4.2 嘴部疲劳参数 ................................................................................. 41 4.3 头部姿态疲劳参数 ......................................................................... 43 4.3.1 点头次数获取 ........................................................................... 43 4.3.2 头部异常姿态时长获取 ........................................................... 44 4.4 本章小结 ......................................................................................... 45 5 多特征融合疲劳检测 .......................................................................... 46 5.1 疲劳状态评价 ................................................................................. 46 5.2 多特征融合疲劳检测算法 ............................................................ 47 5.1.1 CART树 .................................................................................... 47 5.1.2 随机森林 ................................................................................... 49 5.3 实验结果与分析 ............................................................................. 50 6 总结与展望........................................................................................... 53 6.1 总结 ................................................................................................. 53 6.2 展望 ................................................................................................. 54 参考文献 ................................................................................................... 55 1绪论-1-1绪论1.1课题研究背景与意义随着我国经济发展水平的提高，人民越来越富裕，对生活的品质愈加关注。私家车作为一种可以随时出行、体验舒适的交通工具成为每个家庭的必备品。国家统计局数据显示，2020年我国每百户保有家用汽车37.1辆[1]。从2014到2020年我国民用汽车和机动车驾驶员数量稳步增长，详细情况如表1所示。表12014-2020年全国车辆和驾驶员数量统计表Table1ThenumberofvehiclesanddriversinChinafrom2014to2020年份民用汽车拥有量/万辆机动车驾驶员/万人201414598.1129892.32201516284.4532853.05201618574.5435876.98201720906.6736016.94201823231.2341030.16201925376.3843636.74202027340.9245702.49汽车数量以及机动车驾驶员数量不断增加，在如此庞大基数的情况下，道路交通事故的数量也不断增加。2020年共发生244671起交通事故，其中机动车事故211074起，造成55950人死亡[1]。复杂交通环境与极端天气是引发交通事故的客观因素，驾驶员的危险驾驶行为是引发交通事故的主观因素，疲劳驾驶就属于危险驾驶行为的一种。Gander[2]和Forsman[3]等人研究发现，疲劳驾驶是诱发交通事故的重要因素，相比于正常驾驶状态，疲劳状态下发生交通事故的几率高出4到6倍。每年以疲劳驾驶为主要原因的交通事故数量占全部交通事故数量的10%~20%，占特大交通事故数量的40%以上[4]。驾驶员在驾驶中长期保持固定姿势会引起血液循环不畅，进而引起肢体疲劳，长时间观察路况，精神缺少放松时间进而引起注意力涣散。生理与心理状态的恶化导致驾驶员在遭遇紧急情况时反应能力下降，极大增加了交通事故发生的概率。迫于生计或存有侥幸心理，部分驾驶员在行驶过程中即使意识到自己已经陷入疲劳状态，对车辆的操控能力下降，仍会强忍疲劳继续行驶。更多的驾驶员则是在车辆行驶过程中，没有意识到自己正在疲劳驾驶，甚至已经进入深度疲劳状态仍1绪论-2-不自知，在无意识情况下操纵车辆，引发单方事故的风险急剧升高，也更容易引发重大交通事故。当驾驶员处于疲劳时，会进入以下危险状态：1.打哈欠，表情僵硬；2.视线模糊，漏看交通指示灯、指示牌等信息；3.感觉眼睛难以睁开，睁眼时眼睛睁开程度变小；4.眼睛发红、发干，频繁揉眼；5.感觉头部沉重，无法保持头部水平，甚至频繁点头；6.注意力难以集中，接受信息并判断的速度下降；7.对肢体的操控能力下降，无法保持方向盘稳定，车辆频繁发生小幅转向；8.方向感与距离感下降，对车身转向幅度、车间距的把控能力降低；9.对车辆速度感知能力下降，无意识的加速或减速，速度不稳定。状态1、4与状态5使司机在短时间内失去车辆前方视野，在回复视野的窗口期遭遇突发状况时司机无法及时反应，从而酿成大祸；司机处于状态2下可能进行违规变道、闯红灯等极易引发交通事故的行为；状态7、8与状态9令司机的驾驶轨迹飘忽不定，对其他驾驶者造成严重威胁。疲劳状态会降低司机对车辆的操作能力，大大提高交通事故的发生率。大型交通与铁路机构会制定科学的排班制度并对司机定期培训与警示，这些受雇的司机知悉疲劳驾驶的危害，受制于严厉的惩罚机制，依赖科学严谨的排版与作息，能够尽量避免在行驶过程中进入疲劳状态。但是更多的私家车驾驶员、个人经营的货车驾驶员不够重视自己的驾驶状态，往往也不能发现自己已经疲惫不堪，因此开发一种可靠的、实时的车载疲劳驾驶检测系统是必要的。该系统能够准确及时的对驾驶员的疲劳程度进行判定并提醒驾驶员，从而减少因疲劳驾驶发生的交通事故，既能保障驾驶员自身安全，也提高了交通安全系数。1.2国内外研究现状针对疲劳状态的检测，尤其是针对驾驶员的疲劳检测一直是研究的重点。疲劳驾驶检测涉及到生理学、心理学、图像处理、运动跟踪、模式识别等多个领域，是一个复杂而又同时兼具理论与现实价值的研究课题[5]。在长时间驾驶中，驾驶员的疲劳随驾驶时间逐渐加深，若能实时检测驾驶员疲劳状态并采取警示、降速和人工智能接管等操作，可以大大减低交通事故发生率。疲劳检测根据检测方式可以分为俩类：主观评测法和客观评测法。1绪论-3-1.主观评测法主观评测法指通过他人问询、观测或被测人自述的感受、填写的问卷等方式获得的主观评价来判断被测人疲劳状态的方法。主观测评法的具体操作方式主要有以下三种：1）主观问卷方式：精心设计好调查问卷与相应的评估方法，由被测人填写调查问卷并通过评估方法得出结论。主观问卷方式也被用于精神状态评估、世界观评估等领域。2）自我评价方式：通过被测人叙述自身的感受评估被测人疲劳状态。自我评价方式由受测人凭感官口述，受测人主观意愿会极大影响评价结果。3）反馈应答方式：通过对被测人进行人工问询，观察其反应与回答判断被测人是否处于疲劳状态。主观评测法简单易用，但其准确性不高，不同个体的差异很大，每个人对疲劳的认识不同，且存在受测人主观谎报的情况。主观测评法一般用于事后分析，在事故发生后划分事故责任。2.客观评测法客观评测法指通过传感器、图像采集处理设备等器械获取受测人的生理信息或行为特征推断受测人疲劳程度的方法。在针对驾驶员的疲劳检测方法中，还可以通过车辆信息推断驾驶员疲劳状态。针对驾驶员的疲劳检测难题，国内外研究人员提出了四种基于不同技术的解决方案：1）基于驾驶员生理信号特征的疲劳检测。医学上研究人体生理信号如肌电信号（EMG）、脑电信号（EEG）和心电信号（ECG）等发现，人体生理信号在清醒状态与疲劳状态之间有较明显区别，在此基础上通过研究疲劳时生理信号的特征来判断受测人的疲劳状态；2）基于车辆行为特征的疲劳检测。驾驶员的疲劳会反映在其对车辆的操控上，通过检测诸如方向盘偏转幅度、车辆加速度、车身与车道的夹角等参数来判断驾驶员的疲劳状态；3）基于驾驶员行为特征的疲劳检测。当驾驶员生理发生变化时，其行为往往也会发生变化，表现出一些明显的特征，如打哈欠、揉眼睛、点头等。可以通过计算机视觉的方法提取出这些行为特征用来判断受测人的疲劳状态。4）多源信息融合的疲劳检测。单一的检测指标准确率不高，且有可能出现指标中断导致检测失败的情况。为提高疲劳检测的准确度与鲁棒性，常常运用多种1绪论-4-检测方式进行检测，运用多种指标综合判断驾驶员的疲劳状态。以下小节将介绍前三种客观评测法的研究现状。1.2.1基于驾驶员生理信号特征的疲劳检测基于驾驶员生理信号的疲劳检测中使用的生理信号包含脑电波信号（EEG）、心电波信号（ECG）、眼电图（EOG）、肌电波信号（EMG）、脉搏和血氧饱和度（SpO2）等。南姣芬[6]分别使用了S变换、希尔伯特-黄变换以及高阶谱分析方法提取驾驶疲劳时的脑电特征，判断驾驶员的疲劳程度。实验表明当驾驶员连续驾驶超过40分钟后，驾驶员的精神活动开始减少，驾驶40-60分钟时间段内驾驶员视觉疲劳先于精神疲劳出现。王海玉[7]研究多熵值特征下的EEG疲劳检测模型，通过对疲劳检测过程中的去噪、特征提取和分类等三个主要步骤进行分析研究，建立起三个准确率较高、特征稳定的疲劳检测分析模型。采用ICA对不同的主体进行处理，然后对样本熵、信息熵、模糊熵和AR系数进行特征提取，最终使用AdaBoost将最小二乘矢量积集成到基于三种内核分类器的强分类器中进行疲劳判断。王斐[8]提出了基于电极-频率分布图和迁移学习策略的疲劳状态检测模型，相较于传统的方法，具有识别率高，特征提取快速的优点。EEG信号检测的可靠性和灵敏度很好，其抗干扰性也很强，但是其检测成本高、装置结构复杂、可扩展性较差[9]。郭玮珍[10]从心电信号中提取心率（HR）和心率变异性（HRV），并对其5项时频域指标进行分析。实验结果发现采用5项心电图时频域指标，可以对疲劳程度进行定量化的反映和评价。郝贺[11]提出一种QRS波群检测算法处理心电信号。QRS波检测是心电信号检测的基础，通过检测也电信号中的QRS综合波和R峰值,可以得到有关心率、传导速度、心脏内各种组织状态和各种不正常状况的信息，对于心电信号的分析具有十分重要的意义。眼电图是通过在眼睛上下方放置的电极，获得EOG（electrooculogram）在垂直方向上的变化。OhsugaM[12]通过研究眨眼过程的EOG变化情况得出，在闭眼时EOG达到峰尖幅值，EOG上升时间长度与睁眼持久度相关，EOG下降时间长度与闭眼持久度相关。在此基础上，OhsugaM通过对EOG波形中峰尖时间，上升时间与下降时间进行聚类，得到不同精神状态下的EOG波形图，以此来判断受测人疲劳状态。1绪论-5-1.2.2基于车辆行为特征的疲劳检测基于车辆行为特征的疲劳检测属于间接疲劳检测方法。基于车辆行为特征的疲劳检测方法通过采集车辆信息，使用统计学分析与机器学习的方法推测驾驶员的疲劳状态。间接疲劳检测的精准度不高，但不需要对车辆进行大幅度改造，不会提高车辆制造成本，且该方法对驾驶员透明，不会对驾驶员造成任何影响，因此各大汽车生产商纷纷投入研发，并已产品化。梅赛德斯-奔驰公司开发了一套名为AttentionAssist的车载疲劳检测系统。该系统基于车辆状态参数来推断驾驶员驾驶行为与状态，例如车速、发动机转速、横摆角速度等及各信号的后处理参数，综合考虑以上因素进行分析计算得到驾驶员状态监测结果[13]。大众则通过转向角传感器和电子助力转向系统收集驾驶员转向动作信息来确定其是否处于疲劳状态。在行驶过程中驾驶员疲劳探测系统会不断更新参数，计算出疲劳指数。日产公司利用电动助力转向（ElectricPowerSteering，EPS）系统的转向盘转角与角速度、转向盘力矩信号，结合车辆状态信号和车内环境信息判断驾驶员是否疲劳。澳大利亚国际大学开发的DAS（driverassistancesystems）[14]系统，可以检测车辆盲点、检测车辆间的距离辅助会车、检测驾驶员对车道保持的状态以及方向盘握力来判断疲劳。PiluttiT[15]等人在使用道路偏离警告和干预系统的背景下进行驾驶员状态评估，采用车辆侧边与道路边沿的距离作为评估算法的输入，方向盘方向作为输出。在行驶中算法不断在线更新参数，模拟驾驶的结果表明使用车辆侧边与道路边沿的距离作为评价指标是有效的。BertozziM[16]等人开发了一种基于立体视觉的硬件和软件系统，可以检测障碍物和道路航线来判断车辆是否偏航，以此判断驾驶员状态。MaoM[17]等人通过收集车辆驾驶时的车速、方向盘角度、状态加速器以及转向灯的状态，使用离散小波变换处理数据，得出疲劳驾驶状态与正常驾驶状态的参数区别，借此判断驾驶员状态。1.2.3基于驾驶员行为特征的疲劳检测基于驾驶员行为特征的疲劳检测方法通过检测驾驶员疲劳时的外在行为表现来判断其疲劳程度。早期的基于驾驶员行为特征的疲劳检测系统需要对车辆进行较大改装。ASCI（AdvancedSafetyConceptsInc.）[18]研制了一种定位驾驶员头部的装置，该装置安置在座椅正上方，通过电容传感器阵列定位驾驶员头部，并通过头部位置变化1绪论-6-信息，即点头摇头等动作判断其是否处于疲劳状态。该系统需提前在驾驶员头部贴上标志才可使仪器定位头部，影响驾驶员状态，且在座椅上方安装定位装置也需要对车辆进行大幅改造。基于计算机视觉的疲劳检测方法随着深度学习的兴起得以盛行，只需在车内安装摄像头便可获得驾驶员的多种行为特征。邹昕彤[19]通过Adaboost算法在视频中检测出人脸区域，之后使用灰度直方图统计特征值的方法判断眼部状态，使用似圆度判断嘴部打哈欠情况，通过眼部与嘴部疲劳状态综合判断受测人疲劳状态。刘忠旭[20]使用MTCNN网络获得人脸区域，之后通过Shi-Tomasi算法进行眼睛角点定位。在获得人脸区域与眼睛角点后，截取并校正眼部与嘴部图像并将其分别输入眼部状态识别模型与嘴部状态识别模型。获得眼部与嘴部状态后，融合打哈欠参数、PERCLOS值与闭眼时长三个参数判断驾驶员疲劳状态。邬敏杰[21]通过harr特征得到面部区域，使用人眼模板匹配眼睛位置，得到人眼位置后，通过俗称“三庭五眼”人脸的几何特征对嘴部区域进行搜寻。获得人眼PERCLOS值与嘴部动作频率后，使用加权平均法求得最终状态参数判断疲劳状态。1.3本文研究内容结合国内外研究现状，在三种检测方法中，基于驾驶员生理信号的疲劳检测方法需要驾驶员穿戴检测设备，接触式的生理信号获得方式会干扰驾驶员正常驾驶；基于车辆行为特征的疲劳检测受到道路状况的干扰，且不同车辆正常驾驶时参数范围不同，泛用性差；基于驾驶员行为特征的疲劳检测方式与计算机视觉结合后，使用摄像头这种非接触式设备获得驾驶员状态信息，不受路况限制，不同车辆进行简单改造即可使用，泛用性强。本文研究内容主要有以下几个方面：1.优化疲劳检测流程，采取合并任务的方式缩短疲劳特征区域定位流程。2.研究一种可以同时检测出人脸区域和头部偏转角的多任务卷积神经网络。使用一种人脸特征点定位算法定位人眼区域与嘴部区域。3.研究如何通过人脸特征点获得眼部与嘴部状态，通过头部偏转角获得头部状态。研究如何获得合适的前述状态的参数化表示用于疲劳检测。4.研究一种多特征融合的疲劳检测方法。使用以CART决策树为基决策器的随机森林综合单位时间内PERCLOS均值、眨眼次数、哈欠次数、点头次数和头部异常姿态时长来判断驾驶员疲劳程度。1绪论-7-1.4论文的组织结构本文共分六个章节，章节内容如下：第1章绪论，介绍论文的研究背景及意义。阐述当前疲劳检测技术的分类，分析基于驾驶员生理信号的疲劳检测、基于机动车行为特征的疲劳检测和基于驾驶员行为特征的疲劳检测的研究现状。明确研究内容，结合论文完成的任务确定论文主要的工作。第2章相关理论和技术分析，介绍常见的图像增强算法及其原理；介绍卷积神经网络在人脸检测任务中的应用；介绍人脸特征点检测的几种方式。第3章疲劳特征区域定位，介绍优化后的疲劳检测流程，疲劳特征区域定位方法；介绍适用于本文的图像增强算法；介绍多任务卷积神经网络的构成，网络训练结果及其在数据集上的表现；介绍人脸特征点检测方法。第4章疲劳参数提取，介绍在第三章获取疲劳特征区域的基础上，从图像中提取疲劳参数并进行合适的数值化表示。第5章多特征融合疲劳检测，介绍使用以CART决策树为基决策器的随机森林综合单位时间内PERCLOS均值、眨眼次数、哈欠次数、点头次数和头部异常姿态时长来判断驾驶员疲劳程度。第6章总结与展望，对本课题中所完成的工作进行总结，并对下一步的研究工作做出展望。2相关理论与技术分析-8-2相关理论与技术分析2.1图像增强图像增强伴随数字图像的诞生而出现，用于提高成像不清晰的图像质量或突出图像的某些特征，使得图像更易被人眼或是检测算法识别，提高可读性。图像增强算法在软件方向可以分为两大类：空域增强处理法(Spatial-basedDomainEnhancement)和频域增强处理法(Frequency-basedDomainEnhancement)。多数空域增强算法的原理是对图像本身进行处理，包括直方图变换、灰度变换、滤波器处理、模糊逻辑增强、基于遗传算法优化等。基于频域的图像增强处理方法先使用某种变换将图像转换成其他形式，再对变换后的形式进行某种处理，最后进行反变换将处理后的变换形式转换成图像来达到去除图像噪声的目的[22]。常见的频域增强处理方法有傅里叶变换、小波变换、余弦变换等。图像在生成过程中由于光线问题致使图像特征不明显，通常采用空域增强处理法来突显图像特征。灰度变换是空域增强处理法中最基本的方法，直接对单个像素点进行操作。常用的灰度变换有：图像反转、Gamma矫正（矫正图像数据来减轻显示器失真）、对比度拉伸（将灰度密集区域变换到较大范围）、灰度级分层（增强需要层级的灰度区域）等。直方图变换方法基于图像的灰度直方图对像素进行操作。直方图变换方法统计图像中每一级灰度出现的次数，也可以标准化为概率显示，在此基础上通过不同策略对像素进行操作获得不同的变换效果。直方图拉伸指对灰度集中的图像，将其灰度的分布区间由[1,255]的子集拉伸至[1,255]，从而加强图像对比度，提高可读性。直方图均衡化指将原始图像灰度直方图从某一比较集中的区间转化为在全区间上的均匀分布，相较与直方图拉伸，直方图均衡化不仅扩大了灰度范围，也对每一灰度上的像素点数量做出了限制。图像在生成、传输和记录的过程中，由于电磁波的干扰、传感器自身的局限、通信系统的故障等因素，产生冗余和不必要的干扰信息，这就是图像噪声。图像噪声严重影响图像的视觉效果，干扰图像信息的提取，因此在进行边缘检测、图像分割、特征提取和模式识别等工作之前，采用适当的方法减少噪声是一项非常重要的图像预处理步骤[23]。噪声根据其性质可以分为高斯噪声（白噪声）与脉冲噪声（椒盐噪声），高斯噪声的概率密度函数符合正态分布，脉冲噪声是离散型噪声的统称。2相关理论与技术分析-9-滤波器变换将图像看作一个二维信号，将像素值的灰度看作信号的强弱，使用信号增强的方式处理图像。常见的滤波器分为俩类：线性滤波器与非线性滤波器。线性滤波器对邻域中的像素的计算为线性运算，如利用窗口函数进行平滑加权求和的运算，或者某种卷积运算，都可以称为线性滤波，其代表有均值滤波、高斯滤波等。非线性滤波器产生的新图像与原图像具有某种逻辑关系。均值滤波去噪将数字图像中某一像素点的值用该点的一个邻域中各像素点的均值替换，在实践中可以很好的去除高斯噪声，对脉冲噪声效果不佳，同时会模糊图像的边缘信息，丢失图像细节；中值滤波去噪将数字图像中某一像素点的值用该点的一个邻域中各点像素点的中值替换，可以有效的消除脉冲噪声，但随着脉冲噪声密度的增大，中值滤波去噪也会丢失图像细节[24]。2.2卷积神经网络在人脸检测中的应用人脸检测是计算机视觉领域的一个重要分支，大量任务都有涉及人脸检测或需要人脸检测作为前置条件。身份认证任务需要首先获得人脸区域才能进行人脸特征匹配，人机交互任务需要获得人脸区域以识别人脸动作、表情作为交互的信息，头部姿态识别、人脸特征点检测等任务也都基于人脸检测的基础上。随着人脸检测的广泛应用，产品对人脸检测算法的性能要求也越来越高，实际使用场景中难以实现将人脸约束在某一姿势下，故无约束条件下人脸检测任务的准确率与检测速度受到科研人员的重视并作为独立课题进行研究。基于卷积神经网络的人脸检测方法最早可以追溯到1994年[25]，随着训练数据的大量增加，卷积神经网络在人脸检测任务上的表现愈发优秀。在卷积神经网络的基础上，不断有新的网络被发表。级联神经网络（CascadedNeuralNetwork）[26]使用多级网络模型以期将多种网络的优点结合起来，采取多种不同的特征提取策略避免对特征学习的遗漏。在人脸检测任务中级联神经网络通过前几级网络筛选大量非人脸区域，极大的提高人脸识别速度。多任务卷积神经网络（multi-taskconvolutionalneuralnetworks）[27]将人脸检测任务与人脸对齐任务同时进行，实验结果表明多任务同时进行相比单任务提高了准确率，说明同时进行有关联的任务时可以获得比单任务更好的效果。除了对网络本身的改进，UnitBox[28]使用IOU（重叠度）损失替代l2损失函数来进行网络训练，将表示人脸位置的四个点作为一个整体，使训练结果更加准确。由于IOU表示预测区域与准确区域的重叠度，其值介于[0,1]，这天然的归一化属性使其在多尺度任务上有更强的处理能力。GridLoss[29]针对人脸遮挡问题，提出将整个人脸部分划分为多个子区域，分别为这些2相关理论与技术分析-10-子区域训练独立的检测器。当人脸的某一部分被遮挡时，网络仍可以通过对未遮挡区域的检测定位到人脸区域。人脸检测任务是单目标检测任务，因此有些更具普适性的目标检测算法也可以被用于人脸检测。区域卷积神经网络(Region-CNN）[30]是第一个成功在目标检测任务上应用深度学习的算法。R-CNN在图片上选出所有目标可能出现的区域框，对每个框提取特征、图像分类、非极大值抑制进行目标检测。由于候选区域过多，R-CNN的识别速度极慢，为克服这一缺点，出现了很多基于R-CNN的改良网络：SPP-Net[31]、FastR-CNN[32]、FasterR-CNN[33]、YOLO[34]等，这些网络均可以用于人脸检测。部分人脸检测算法在FDDB数据集上的表现如表2所示。表2部分人脸检测算法在FDDB数据集上的检测表现Table2DetectionperformanceofsomefacedetectionalgorithmsonFDDB算法TruepositiverateFalsepositiveCascadeCNN[26]0.85672000JointCascade[35]0.86672000HeadHunter[36]0.88082000GridLoss-big[29]0.89401000Faceness[37]0.90982000UnitBox[28]0.9442500MTCNN[27]0.950420002.3人脸特征点检测算法人脸特征点检测任务可以看作在给定人脸图像得前提下，从人脸图像上定位一系列事先定义的人脸特征点。这些特征点通常用来描述人眼、鼻子、嘴唇和面部的轮廓。通过这些特征点可以对人脸属性进行分析，在性别识别、表情识别、年龄识别、面部动作捕捉等方面有广泛的应用。人脸特征点检测算法根据其使用的模型种类可以被分为两大类：基于参数模型的方法和基于非参数模型的方法。基于参数模型的方法假定人脸特征点的位置符合某种概率分布，如混合高斯分布、多元高斯分布等，事先人为设定参数数量。基于非参数模型的方法无须假定一个概率分布，这种方法并非没有参数，而是在训练过程中，参数量随着训练数据量的增加而增加[38]。2相关理论与技术分析-11-主动形状模型（ActiveShapeModel）是经典的基于参数模型的人脸特征点检测算法，通常用于预测人脸68个特征点。Coote等人[39]使用每个特征点的x，y坐标构成一个136维的向量来描述人脸形状，在假定人脸形状满足各向同性高斯分布的前提下使用主成分分析（principalcomponentanalysis，PCA）对形状向量进行降维，在训练中不断使用新的人脸形状来更新形状向量。由于ASM迭代时仅考虑图像的局部信息，Coote随后又提出主动外观模型（activeappearancemodel,AAM）[40]，使用图像金字塔从训练集中获得不同分辨率下的平均模型。AAM不仅包括形状轮廓模型，还包括纹理轮廓模型，使其在图像分割方向取得较ASM更好的效果。随着卷积神经网络被用于人脸检测并取得较好的效果，在人脸特征点检测领域也不断有基于卷积神经网络的方法被提出。YiSun等[41]首次将级联卷积神经网络用于人脸特征点定位，并在当年取得state-of-art的结果，这种级联的多层卷积神经网络又被称为DCNN（DynamicConvolutionNeuralNetwork）。DCNN的具体结构如图1所示。图1DCNN结构图Fig1ArchitecturesofDCNNDCNN共使用三个等级的网络完成不同的任务，最后输出精确的人脸关键点。人脸检测器得到人脸位置输入Level1网络，Level1网络得到包含特征点的最小图像区域输入Level2网络。在Level2网络中，特征点被粗略的定位，通过这些被粗略定位的特征点裁剪出包含单个特征点的小区域图像，将这些小区域图像送至Level3网络中得到最终的特征点位置。2.4本章小结本章包含三部分内容，一是图像增强的常用方法，介绍了图像增强的分类。二是卷积神经网络在人脸检测中的应用，介绍了卷积神经网络的发展与历代网络创新之处。三是人脸特征点检测算法，介绍了人脸特征点检测算法的发展与分类。3疲劳特征区域定位-12-3疲劳特征区域定位3.1疲劳特征区域定位流程优化本文所需检测的疲劳特征包括眼部疲劳特征、嘴部疲劳特征与头部姿态疲劳特征，即需要定位驾驶员眼部区域图像，嘴部区域图像与头部图像并分析。在传统的疲劳检测流程中，都是在获得人脸区域的基础上，使用不同的方法定位眼部与嘴部区域并获得头部姿态，之后由这些原始图像信息获得各部分疲劳状态并进行综合判断。传统的疲劳检测流程如图2所示。图2传统的疲劳检测流程图Fig2Traditionalfatiguetestingflowchart图2中有蓝色方框包围的流程即为疲劳区域定位流程。文献[42]使用Haar-like特征与Adaboost分类器进行人脸检测，使用标准人脸模板粗定位人眼位置。在对粗定位的图像进行处理后，使用边缘提取的方式获得眼睛部位的精确像素图，最后使用模糊综合评价判断眼睛睁闭情况。文献[43]获得眼部区域精确像素图后，判断其最大外接矩形的大小来判断眼睛睁闭情况，监测人脸区域中心坐标判断驾驶员是否点头。文献[44]使用分段高斯模型在YCbCr空间下进行肤色分割，通过唇色样本统计和聚类分析得到唇色的三重闭值，在可能的肤色区域中搜索嘴唇区域。文献[45]使用PFLD算法同时检出人脸特征点与头部姿态，通过人脸特征点定位眼部与嘴部区域。为了缩短疲劳检测流程，受MTCNN网络的构建思想启发，本文将人脸检测任务与头部姿态检测任务统一，使用级联的多任务卷积神经网络同时获得人脸区域与头部姿态。使用ERT人脸特征点检测方法获得68人脸特征点并以此定位眼部区域与嘴部区域。优化后的疲劳检测流程如图3所示。改进后，检测流程中的人脸检测与头部姿态检测合并为一个任务，人眼区域检测与嘴唇区域检测合并为3疲劳特征区域定位-13-一个任务，总任务由4个变为2个，简化了检测流程，提高了检测效率。图3本文的疲劳检测流程图Fig3Myfatiguetestingflowchart优化后的疲劳区域定位流程如图4所示。图4优化后的疲劳区域定位流程Fig4Optimizedfatigueareapositioningprocess3疲劳特征区域定位-14-3.2图像预处理3.2.1图像去噪小波变换（wavelettransform）作为一种变换域信号处理方法，在信号分析、图像处理、地震勘探和非线性科学等诸多领域得到了广泛应用[46]。小波变换在图像处理领域具有低熵性、多尺度特性、去相关性与选基灵活性等优点[47]。小波变换去噪的基本依据是信号点的频率与噪声点的频率不同，一般而言信号点的频率较低而噪声点的频率较高，图像的高频信号几乎由噪声组成，将源信号进行小波变换后，信号点的小波系数幅值较大，噪声点的小波系数幅值较小，此时将幅值小的小波系数置0即可去除噪声点。基于此原理，小波变换去噪的步骤如下：1.二维信号的小波分解。对含噪信号S进行小波变换，得到一组小波分解系数wjk；2.设定一个阈值，使用阈值函数对小波分解后的系数进行处理，得到处理后的系数w jk；3.二维信号的小波重构。利用处理后的系数w jk计算二维信号的小波重构。小波变换去噪的常用阈值函数可以分为硬阈值函数、软阈值函数和半软阈值函数。硬阈值函数 =>0≤(3−1)软阈值函数 =(−)>0≤(3−2)式中：λ表示小波系数的阈值，sign()表示符号函数，表示处理前的小波分解系数， 表示处理后的小波分解系数。半软阈值函数 =>12(−2)1−22≤≤10<2(3−3)式中：1表示小波系数的阈值，2表示小波系数的阈值，sign()表示符号函数，3疲劳特征区域定位-15-表示处理前的小波分解系数， 表示处理后的小波分解系数。使用硬阈值函数可以较好的保留图像边缘等局部特征，但是会产生震铃，伪Gibbs效应等视觉失真，且小波系数在±λ附近不连续。使用软阈值函数处理结果相对平滑，但由于改变了对应图像信号的小波系数，在重构后会丢失图像局部细节，造成图像边缘模糊。半软阈值函数在选择合适的阈值的前提下，可以在硬阈值函数与软阈值函数之间很好的折中。Donoho[48]和Johnstone[49]提出了全局阈值选取模型，其计算公式为：=2(3−4)式中：T表示最终阈值，σ表示噪声图像的标准方差，N表示图像的长度。在正态高斯模型下，对于多维独立正态变量联合分布，当维数趋于无穷时，大于该阈值的系数含有噪声信号的概率趋近于0。本文使用半软阈值函数作为小波去噪的阈值函数，并令λ1=2T,λ2=T。作为对比的硬阈值函数与软阈值函数也使用T作为阈值。对原图像加入均值为0，方差为25的高斯噪声，原图、噪声图及使用三种阈值函数去噪后的结果如图5所示。图5三种去噪方式效果对比图Fig5Comparisonofthreedenoisingmethods主观上很难判断使用哪一种阈值函数的去噪效果更好，为了更好的衡量图像去噪的效果，使用PSNR（PeakSignaltoNoiseRatio）判断去噪效果的好坏。PSNR意为峰值信噪比，单位为dB，越大代表去噪效果越好,其计算公式如下所示：=10×102(3−5)3疲劳特征区域定位-16-式中：MAXI表示图像颜色的最大数值，在灰度图像中为255。MSE表示噪声图像与原图像之间的均方误差。MSE的计算公式如下所示：=1=0−1=0−1,−,2  (3−6)式中：m表示图像的长度,n表示图像的宽度，I表示噪声图像，K表示原图像。噪声图像与去噪后的图像相对于原图的PSNR如表3所示。表3不同去噪方式的PSNR值Table3PSNRvaluesofdifferentdenoisingmethods图像噪声图像软阈值函数去噪硬阈值函数去噪半软阈值函数去噪PSNR20.288621.112220.291020.4125由表3可知，半软阈值函数去噪效果处于软阈值函数与硬阈值函数之间，得到了与理论相符的折中效果。3.2.2暗光图像处理驾驶员在夜间行驶更易陷入疲劳，然而夜间光线不足，通过摄像头得到的画面存在轮廓不明显，人脸特征难以识别的问题。使用一种快速有效增强暗光条件下人脸对比度的方法：直方图均衡化（HistogramEqualization）。灰度直方图（histogram）是灰度级分布的函数，它表示图像中具有每种灰度级的像素的个数，反映图像中每种灰度出现的频率。直方图均衡化通过图像直方图均衡的操作将原图像密集的灰度映射到更大的灰度范围，均匀化各灰度范围的像素量，以此达到增强对比度的效果。如图6所示，蓝色部分为原始灰度图的直方图，橙色部分为算法增强后得到的均衡图像的直方图。图6均衡化前后图像直方图对比Fig6Comparisonofimagehistogrambeforeandafterequalization3疲劳特征区域定位-17-直方图均衡化的原理是：使用累计分布函数对原图像的像素进行线性映射，映射后的像素保持原有的像素值大小顺序。映射公式如下所示：==0 ,=0,1,2,...,−1(3−7)式中：N表示图像中像素的总数，L表示图像的灰度级数，nk表示第k级灰度在图像内的像素点个数，Sk表示第k级像素映射后的像素值。由于待处理图像是彩色图像，所以分别在原图的RGB三色通道上进行直方图均衡化，再填充各像素点新的灰度值，最后联结这三个数组形成三维矩阵，恢复直方图处理后的图像。处理结果如图7所示，可以看到人脸的轮廓特征被加强，画面也更加明亮。图7均衡化前后对比图Fig7Comparisonbeforeandafterequalization3.3多任务卷积神经网络3.3.1网络任务与检测流程本文所述的多任务卷积网络，借鉴MTCNN的多任务思想，同时完成人脸区域定位任务与头部姿态估计任务以缩短检测流程。MTCNN网络使用了多任务级联的网络架构，在完成面部检测功能的同时加入了同样是回归任务的人脸关键点检测，在同一网络完成了人脸定位与人脸五个关键点的输出，实验结果表明该举措同时提高了俩个任务的准确率。考虑到当人脸偏转幅度过大导致脸部被遮挡时，人脸关键点必然产生缺失，而人脸检测与头部姿态估计对头部偏转的鲁棒性更好，因此将这俩个任务同时进行。此外，首先进行头部姿态估计，可以在头部偏转角过大时，不再进行人脸关键点检测，避免3疲劳特征区域定位-18-因遮挡或大姿态下人脸关键点算法所得关键点位置偏移过大造成疲劳检测失误。多任务卷积神经网络运行流程如图8所示，通过三个层级的网络不断提升检测精度，最终由O-Net网络输出人脸位置与头部偏转角。图8网络检测流程图Fig8Networkdetectionflowchart3.3.2网络结构针对待解决的任务，选择合适的网络模型，并在此基础上加以改进及优化是深度学习研究的重要方法。多任务卷积网络就是在借鉴MTCNN的网络结构基础上，针对实际问题进行的改进与优化。1.建议网络（ProposalNetwork，P-Net）P-Net是三层网络中的第一个网络，网络结构是FCN类型的全连接网络，其作用是对输入的图片进行简单预测，去除大量不是人脸的区域，输出认为有可能是人脸的区域坐标。原始图像进行不同尺度变换生成图像金字塔后输入P-Net完成人脸区域建议，同时输出各区域的人脸概率，最终将不同大小图片的检测结果映射回原图。如图9所示，P-Net网络的输入是尺寸为12×12的三通道RGB图3疲劳特征区域定位-19-像。第1个卷积层使用10个3×3的卷积核，并进行尺寸为2×2的最大池化，生成了10个5×5的特征图；第2个卷积层使用16个3×3的卷积核，生成了16个3×3的特征图；第3层采用32个大小为3×3的卷积核，生成了32个1×1的特征图；最后一层使用卷积核为1×1的卷积操作代替全连接，获得1×1×2的人脸置信度，1×1×4的人脸边框和1×1×3的头部姿态。图9P-Net网络结构图Fig9ThearchitecturesofP-Net2.提纯网络（RefineNetwork，R-Net）第二层R-Net对P-Net输出的人脸候选区域的进一步筛选，相对于P-Net拥有更复杂的网络结构。R-Net的输入是P-Net的输出，即可能是人脸区域的原图切片，R-Net将对这些切片进行进一步检测，删除置信度低的区域并对边界框进行调整，从而达到大量过滤低质量预测和人脸区域优化的效果。如图10所示，R-Net的输入图像是一个24×24的三通道的RGB图像，该图像由P-Net生成的候选区域缩放得来。第一个卷积层使用28个3×3的卷积核，并进行尺寸为3×3的最大池化，生成了28个11×11的特征图；第二个卷积层使用48个4×4的卷积核，并进行尺寸为3×3的最大池化，生成了48个4×4的特征图；第三个卷积层使用64个2×2大小的卷积核，生成了64个3×3的特征图。将这64个特征图压缩至1×576后，使用全连接操作得到一个128维向量，从该向量中获得三个任务的输出。由此完成人脸分类、人脸候选框回归以及头部姿态估计这三大任务。图10R-Net网络结构图Fig10ThearchitecturesofR-Net3疲劳特征区域定位-20-3.输出网络（OutNetwork，O-Net）第三层网络O-Net输出输出人脸置信度、对人脸候选框筛选后人脸的最终回归边界框、三个头部偏转角。如图11所示，O-Net的输入图像尺寸更大，为48×48的三通道RGB图像，能够包含更多图像细节。第一个卷积层使用32个3×3的卷积核，并进行尺寸为3×3的最大池化，生成了32个23×23的特征图；第二个卷积层使用64个3×3的卷积核，并进行尺寸为3×3的最大池化，生成了64个10×10的特征图；在此之后，使用CBAM（ConvolutionalBlockAttentionModule）[50]对得到的特征图施加通道注意力与空间注意力，使得网络能够抑制无相关噪声信息；第三个卷积层同样使用64个3×3的卷积核，并进行尺寸为2×2的最大池化，生成了64个4×4的特征图；第四个卷积层仅使用128个2×2的卷积核，生成了128个3×3的特征图；将这128个特征图压缩为1×1152并使用得到一个256维向量，并由此向量获得最终输出的人脸框与对应的头部偏转角。图11O-Net网络结构图Fig11ThearchitecturesofO-Net卷积神经网络注意力模块（CBAM）由通道注意力机制模块与空间注意力机制模块串联而成，其对输入特征层的处理过程即主要结构如图12所示。图12CBAM主要结构示意图Fig12MainstructurediagramofCBAMCBAM的前半部分为通道注意力机制，该部分首先对输入特征分别进行一次全局平均池化和全局最大池化得到俩个Channel×1×1的结果，对池化后的结果使用共享的全连接层进行缩小后再放大，将得到的俩个结果相加并使用sigmoid函数将参数映射到0~1之间，就得到了每一个通道的权重。其计算如公式（3-8）所示，ChannelAttention系数计算流程如图13所示。3疲劳特征区域定位-21-=×=(+(3−8)图13通道注意力系数计算流程图Fig13FlowchartofchannelattentioncoefficientcalculationCBAM的后半部分为空间注意力机制，特征层经过空间注意力机制计算过后，对每个通道施加空间注意力机制。首先对特征层的每一个通道分别取最大值与平均值得到俩个Weight×Height的矩阵，将这俩个矩阵堆叠，使用1×1的卷积核进行卷积，对卷积得到的结果使用sigmoid函数映射到0~1之间，得到特征层每一个点的权重。SpatialAttention系数计算流程如图14所示。图14空间注意力系数计算流程图Fig14Flowchartofspatialattentioncoefficientcalculation4.激活函数在回归任务中，为了提高网络在零值附近的拟合能力，采用P-ReLU激活函数替换常用的ReLU激活函数。P-ReLU激活函数在ReLU激活函数的基础上，在负值方向增加了梯度，避免了使用ReLU激活函数在正向传播时，若x<0会导致神经元未被激活的问题。P-ReLU激活函数的解析式为：P−ReLU=max(xα,x)，其中α为初始随机的超参数，可以在反向传播中被学习，从而在当前神经元获得最好的负值梯度。P-ReLU函数的图像如图15所示。3疲劳特征区域定位-22-图15P-ReLU函数示意图Fig15SchematicdiagramofP-ReLUfunction在分类任务，即分辨当前区域是否为人脸时，使用Tanh激活函数替代sigmoid激活函数。Tanh激活函数由sigmoid激活函数变体而来，解决了sigmoid函数输出不以零为中心的问题，二者的关系为：Tanh(x)=2sigmoid(2x)−1。Tanh激活函数的解析式为：Tanh(x)=ex−e−xex+e−x(3−9)Tanh激活函数的图像如图16所示。图16Tanh函数示意图Fig16SchematicdiagramofTanhfunction3疲劳特征区域定位-23-3.3.3损失函数多任务卷积神经网络共有三个任务：人脸与非人脸的二分类任务、人脸边界框的回归任务和头部姿态估计的回归任务。因此本网络需要对这三个任务与总任务分别设计损失函数，接下来分别介绍这些损失函数。1.人脸分类任务的损失函数人脸分类任务是一个二分类任务，人脸分类器输出的是输入图片包含人脸的概率，损失函数越小则代表模型越稳定、抗干扰能力越强。对于每一个训练样本x，定义其交叉熵损失函数为：=−((1−)(1−log())+log())(3−10)式中：pi表示网络输出的样本x中包含人脸的概率，yidet∈{0,1}表示由标签提供的样本x中包含人脸的真实概率，Lidet表示分类的损失函数。2.边界框（boundingbox）回归任务的损失函数人脸候选框的坐标位置被表示为区域左上角点的横纵坐标及区域的长宽。该任务的学习目标是一个回归问题，输出为连续量，对于每一个预测的候选边界框，计算它与最近的真实人脸区域的偏移量，使用均方误差损失函数来度量其误差，其公式如下：=|| −||22 ,∈4(3−11)式中：Libox表示边界框回归的损失函数，y ibox,yibox为四元组，包含区域左上角点的横坐标、纵坐标、区域右下角点的横坐标、纵坐标，y ibox表示包含人脸区域的真实坐标，yibox表示网络预测的人脸区域坐标。3.头部姿态估计任务的损失函数人头部的旋转可以由三个欧拉角(EulerAngle)来表示：pitch(围绕X轴旋转)，yaw(围绕Y轴旋转)和roll(围绕Z轴旋转)，学名为俯仰角、偏航角和滚转角。其图像表示如图17所示。头部姿态检测器的输出为三个连续的角度数值，因此该任务为回归任务。若同边界框回归任务一样，使用均方误差损失函数来度量其误差，在网络训练中发现头部姿态估计任务的损失难以减小，致使在收敛时整体任务的损失过大，严重影响训练效果。使用文献[51]中所提出的多重损失函数作为头部姿态检测任务损失函数。该损失函数预先将人脸偏转角[-90°,90°]以间隔3°分为60个类别，对网络得到的偏转角，既计算其与真实值的误差，也计算其所在类别与真实值所在类3疲劳特征区域定位-24-别的分类误差。头部姿态估计的损失函数公式（3-11）所示，计算其交叉熵损失函数与均方差损失函数的加权和。=, +∙|| −||22 ,∈3(3−12)式中：Liangle表示边界框回归的损失函数，Hy,y 表示输出偏转角所在类别与真实偏转角所在类别的多分类损失函数，y iangle,yiangle为三元组，包含俯仰角、偏航角和滚转角，y ibox表示头部的真实旋转度数，yibox表示网络预测的头部偏转度数。本文中加权系数α取1。图17头部姿态示意图Fig17Schematicdiagramofheadposture4.多任务训练损失函数每一层网络的训练任务不同：P-Net侧重于人脸识别，旨在找出包含人脸的区域；R-Net侧重于精确的人脸识别与粗略的边界框回归；因为R-Net在人脸识别任务上已经足够精确，O-Net对边界框回归与头部姿态估计更加关注。在每个CNN中，训练时都有不同类型的训练图像来满足不同的训练任务，因此并不是每个样本都需要用到上述三个损失函数。为了表示某个样本需要用到怎样的损失函数，使用一个指示值来建立所有网络整体的目标函数即多任务损失函数，其公式如下所示：==1∈{,,}  (3−13)式中：N表示训练的样本总数，αj表示当前网络训练时三种损失函数的权重，βij表示当前样本的类型，Lij表示上述三种类型的损失函数。对于P-Net与R-Net，αj被赋值为αdet=1、αbox=0.5、αengle=0.5，在O-Net中，αj被赋值为αdet=0.5、αbox=1、αengle=1。3疲劳特征区域定位-25-3.3.4网络训练1.数据集本章所提出的多任务卷积神经网络训练需要俩个以不同任务为目标的数据集共同训练：对于人脸分类与边界框回归任务，采取WIDERFACE[52]数据集进行训练；对于头部姿态估计任务，采取BiwiKinectHeadPoseDatabase（BIWI）[53]数据集进行训练。WIDERFACE是一个人脸检测的benchmark数据集，其中的图像都是从公开的数据集中获取。WIDERFACE共包含32203图像，这些图像中共有393703张在比例、姿势和遮挡方面具有高度变化范围的人脸。其部分样本如图18所示。BIWI包含20个人（14位男性与6位女性）的超过15000张含标注的人脸姿态图像，头部姿态范围包括大约±75度的偏航角、±60度的俯仰角和±50度的滚转角。其部分样本如图19所示。图18WIDERFACE部分样本Fig18PartialsamplesofWIDERFACE图19BIWI部分样本Fig19PartialsamplesofBIWI3疲劳特征区域定位-26-2.训练数据集生成模型训练时需要生成不同类型的训练数据，为了更好的对训练数据做出分类，引入IntersectionoverUnion（IOU，交并比）作为数据分类的依据。假设区域A左上角坐标为（1,1)，右下角坐标为(2,2)，区域B左上角坐标为（1,1)，右下角坐标为(2,2)。区域A与区域B按图20所示重合。图20IOU计算示意图Fig20SchematicdiagramofIOUcalculation区域A与区域B的相交区域面积为：∩=|1−2|×|1−2|(3−14)区域A与区域B并集的面积表示为：∪=|1−2|×|1−2|+|1−2|×|1−2|−∩(3−15)区域A与区域B的交并比表示为：=∩∪(3−16)级联网络的每一级网络（P-Net、R-Net和O-Net）都需要通过上述俩个数据集生成训练集，每一个网络的训练集各不相同但都包含四类训练数据：1）positive训练集：训练图片中包含的人脸部分与完整人脸的IOU大于0.65，有人脸坐标标注。2）part训练集：训练图片中包含的人脸部分与完整人脸的IOU介于0.4到0.65之间，有人脸坐标标注。3）negative训练集：训练图片中包含的人脸部分与完整人脸的IOU低于0.4或图片中不含人脸，没有人脸坐标标注。4）pose训练集：训练图片中包含完整人脸并有头部姿态标注。3疲劳特征区域定位-27-生成训练集数据时这四类数据的比例为3：1：1：2。对于三个级联网络，后一个网络的训练集生成需要依赖前一个网络的输出，即R-Net的训练集需要在P-Net训练完成后生成，O-Net的训练集需要R-Net训练完成后生成。第一个网络P-Net的训练集需要用到图像金字塔算法，通过对一张原始图像的缩放来检测不同大小的人脸。图像金字塔算法如下所示：算法3.1图像金字塔输入：原始图片source输出：图片集合results过程：1）确定图片缩放系数resize_factor。确定图片缩放的最小尺寸minsize。2）result=source×resize_factor3）results.append(result)4）while(result.size<minisize):result=result×resize_factorresults.append(result)resize_factor系数其大小一般在0.7与0.8之间，设定较大缩放生成的图片较多，使检测时间延长，系数设定较小则会导致漏检中小型人脸。结合检测疲劳驾驶的具体要求，摄像头获得的图像中司机人脸区域偏大，因此设定resize_factor=0.708。minsize即网络所需识别的最小区域的大小，其作用为过滤人脸得分过低的识别框，在本文所述网络中minsize=40。对WIDERFACE数据集中的图片，生成其图像金字塔，随机从中截取一些12×12大小的图像，将不包含人脸的图像标记为negative数据。在人脸坐标周围随机截取12×12大小的图像，将与完整人脸的IOU小于0.3的作为negative数据，介于0.4到0.65之间的作为part数据，高于0.65的作为positive数据。对BIWI数据集中的图片，截取其中的人脸并缩放至12×12作为pose数据。以上数据按照3：1：1：2的比例构成P-Net的训练集。在P-Net训练完成后，使用P-Net对WIDERFACE数据集中的图片进行人脸识别，对识别结果使用非极大值抑制（Non-maximumsuppression，NMS）算法去除重复度高的区域。NMS算法如下所示：3疲劳特征区域定位-28-算法3.2非极大值抑制输入：面部候选区域集合R=r1,r2,...,rn与对应的分数集合S=s1,s2,...,sn输出：筛选后的候选区域集合D=d1,d2,...,dk与对应的分数集合Sk=s1,s2,...,sk过程：1）whileR≠∅do:2）rmax=findmaxS(R)3）将rmax及其分数加入D与Sk，从R与S中去除rmax及其分数4）forriinRdo:5）ifIOU(rmax,ri)>0.5:6）将ri及其分数从R与S中去除对P-Net的预测结果进行NMS后将人脸框缩放至24×24，并将其按照与完整人脸的IOU分类为positive、part与negative数据。对BIWI数据集中的图片，截取其中的人脸并缩放至24×24作为pose数据。以上数据按照3：1：1：2的比例构成R-Net的训练集。当R-Net训练完成后，使用P-Net，R-Net对WIDERFACE数据集中的图片进行级联预测并输出人脸位置，使用NMS算法精简后，将预测的人脸位置缩放至48×48，并将其按照与完整人脸的IOU分类为positive、part与negative数据。对BIWI数据集中的图片，截取其中的人脸并缩放至48×48作为pose数据。以上数据按照3：1：1：2的比例构成O-Net的训练集。3.模型训练结果图21所示为第一级P-Net网络训练准确率曲线（a）与loss曲线（b）。图21P-Net网络训练准确率与loss曲线Fig21P-Nettrainingaccuracyandlosscurve3疲劳特征区域定位-29-图22所示为第二级R-Net网络训练准确率曲线（a）与loss曲线（b）。图22R-Net网络训练准确率与loss曲线Fig22R-Nettrainingaccuracyandlosscurve图23所示为第三级O-Net网络训练准确率曲线（a）与loss曲线（b）。图23O-Net网络训练准确率与loss曲线Fig23O-Nettrainingaccuracyandlosscurve图24所示为去除CBAM模块后第三级网络O-Net网络训练准确率曲线（a）与loss曲线（b）。图24去除CBAM模块O-Net网络训练准确率与loss曲线Fig24O-NettrainingaccuracyandlosscurvewithoutCBAM3疲劳特征区域定位-30-3.3.5训练结果与网络性能分析1.CBAM模块的效果由图23、24可知，O-Net在加入CBAM模块后多任务损失降低。O-Net的多任务损失函数中各任务损失函数占比为0.5：1：1，需要网络更多的关注边界框回归任务与头部姿态回归任务。CBAM模块使得网络能从人脸区域中自适应的寻找关键特征，在参数量不变的前提下提升网络性能。2.人脸分类任务由图21、22与23可知，随着网络级数的增加，人脸分类任务的准确率由P-Net的95%左右增加到R-Net的98%附近，在O-Net上准确率增加至99.2%左右。三个网络中O-Net收敛最快，R-Net的训练数据最多。3.边界框回归任务使用WIDERFACE数据集提供的模型性能评估方法对多任务卷积神经网络（MyNet）的性能进行评估。对比网络的算法数据由WIDERFACE官网得到，对比结果如图25所示。图25WIDERFACE官网对比结果Fig25ComparisonresultsofWIDERFACEofficialwebsite由在WIDERFACE上算法测评的结果来看，本章提出的多任务卷积神经网络模型在边界框回归任务上优于部分人脸检测算法，同时与一些优秀的人脸检测算法如PyraminBox[54]、FaceR-CNN[55]等仍然存在较大差距，略弱与参考模型MTCNN。这是由于本章所提出的为轻量化网络模型，相较于深度网络精度存在3疲劳特征区域定位-31-劣势，头部姿态估计任务与边界框回归任务的关联度没有人脸关键点检测任务与边界框回归任务的关联度高，因此在最终性能提升上相比MTCNN较少。该模型的主要任务是给出可用的人脸区域供人脸特征点检测算法使用并给出较精确的头部姿态估计，对检测出的人脸区域要求并不严苛。4.头部姿态估计任务头部姿态估计任务性能的评估使用AFLW2000数据集进行，使用平均绝对误差（MeanAbsoluteError，MAE）来评估网络在头部姿态估计任务上的性能，其公式如下：=1=1− (3−17)面部姿态估计性能测试中，选择俩个人脸关键点检测算法FAN[56]和ERT[57]，俩个头部姿态估计算法Multi-LossResNet50[51]和3DDFA[58]作为对比。对比结果如表4所示。表4头部姿态估计任务MAE评估结果Table4MAEevaluationresultsofheadposeestimationtask方法名称YawPitchRollMAEMulti-LossResNet50(α=2)6.4706.5595.4366.1553DDFA5.4008.5308.2507.393MyNet6.7688.6538.6428.021FAN(12points)6.35812.2778.7149.119Dlib(68points)23.15313.63310.54515.777从表4可知，本文所述模型在头部姿态估计任务上优于使用人脸特征点对头部姿态进行估计，劣于深度网络在头部姿态估计任务上的性能。同时模型在Pitch角和Roll角的检测上表现较好，接近3DDFA的性能，在Yaw角检测上表现较差，略逊于Multi-LossResNet50。5.网络运行效率本文所述多任务卷积神经网络同时完成了人脸区域定位与头部姿态估计任务，相较于先使用MTCNN进行人脸区域定位任务再使用FAS-Net进行头部姿态估计任务的方法降低了检测时间，每秒检测帧数从12FPS提升至25FPS。相较于先进行人脸区域定位任务再使用ERT算法进行人脸特征点检测任务，之后使用人脸特征点估计头部姿态的方法，平均绝对误差从15.777降低至8.021。3疲劳特征区域定位-32-3.4人脸特征点检测在3.3节定位人脸区域的基础上，需要定位驾驶员眼部区域与嘴部区域来获得眼部与嘴部状态。本节基于级联回归树（EnsembleofRefressionTrees,ERT）算法建立人脸特征点检测模型，进而对眼部与嘴部区域进行定位并获得状态信息。ERT[57]是一种基于回归树的人脸对齐算法，算法通过建立的一个级联残差回归树（GBDT）来预测当前输入图像中人脸特征点的位置。GBDT由很多棵树构成，这些树的每一个叶子结点上都存储着一个残差回归量，输入的图片经过树的分叉最终会落到一个叶子结点上，将该叶子结点存储的残差加到输入上，使输入向真实值回归，当所有树遍历完时，所有残差叠加在一起就获得了最终的人脸特征点输出。该算法的核心是俩层级联回归树建立的模型，主要包括建立训练模型与模型拟合俩个部分。ERT算法在保证高准确率的前提下，能够快速获得68个人脸特征点，包含人眼、嘴唇、鼻子和脸部轮廓信息。3.4.1建立模型在建立ERT模型之前，先要确定人脸关键点的模型。设Xi∈R2表示输入图像I的第i个特征点坐标，人脸形状向量S被表述为=1,2,...,，其中n表示人脸特征点的数量。在本文所述ERT算法中，检测的人脸特征点数量为68个。标准人脸68个特征点标注如图26所示。图26标准人脸68个特征点标注Fig26Standard68featurepointannotations1.回归模型的建立ERT算法采用级联回归的方式建立多个级联的回归器。3疲劳特征区域定位-33-记训练数据集为1,1,2,2,...,,，其中,表示第n张训练图及其人脸形状。初始迭代公式为： +1= +, (3−18)式中： 表示当前对人脸形状S的估计，由人脸特征点的坐标组成；γt表示回归器，其输入为当前人脸图片I与当前估计的形状 ，输出为当前人脸形状的更新。每经过一个迭代器，人脸形状估计就会被更新，使之与真实人脸形状愈发接近。为了使迭代能顺利进行，首先要得到每张训练图像的初始人脸形状。记人脸图像三元数组为, (0),∆(0)，依次代表人脸图像，初始人脸形状和目标更新步长。每张训练图像三元数组的计算如下：∈1,2,..., (0)∈1,2,...,\∆(0)=− (0)(3−19)获得三元数组后，对于每一个训练图像，使用其人脸图像三元数组迭代训练回归器γ0,γ1,...,γk−1，其中k为设置的回归器数量。回归器的最终迭代训练公式为： (+1)= ()+, ()∆(+1)=− (+1)(3−20)当t=0时，使用初始人脸图像三元组进行训练，之后在训练过程中不断动态调整人脸图像三元组中的人脸形状与目标更新步长。不断重复上述迭代公式，经过k次迭代可得到k个回归器。2.回归器的训练ERT算法使用基于平方误差总和的梯度提升树（gradienttreeboosting）来训练回归器γt。其训练算法如下：算法3.3回归器训练算法输入：数据集, (),∆()=1输出：回归函数γtI,S (t)1）设置学习速率0<v<12）回归器的初始化：3疲劳特征区域定位-34-0(, ())=∈2=1∆()− 3）对于=1,2,...,;=1,2,...,，每次迭代更新γik的值，更新公式如下：=∆()−−1, 4）更新(, ):(, ())=−1(, ())+(, ())其中(, ())是由γik得到的弱回归方程。5）不断重复步骤3）、4），最终达到迭代次数或迭代收敛，收敛条件为：γtI,S (t)=fKI,S (t)，最终得到回归函数γtI,S (t)。ERT算法采用的损失函数为平方误差：=12−2(3−21)在每一步迭代中，使用平方误差的导数作为拟合对象构建模型。每次迭代时，随机选取检测到的人脸形状中的500对点对进行实验，以最大化降低方差。将选取的点对的像素差值表征为图像的人脸特征点，选取差值可以有效降低光照不均对特征点检测的影响。使用这些像素差值特征构成回归树，其中非叶子节点保存分类阈值，叶子节点保存特征点的残差。3.模型拟合在获得回归模型后，本段介绍得到最优模型后的搜索拟合过程，过程如下：1）初始化人脸形状。从输入图像中检测出人脸特征点，并得到初始人脸形状向量。2）基于人脸检测的结果，计算人脸特征点对的像素差值，使用像素差值进行树的分裂。3）使用所有的决策树求残差。将像素差值与非叶子节点中保存的阈值进行比较，计算出差值，得到的残差保存在叶子节点上。将所有的残差求和得到全局残差。4）将本次迭代获得的全局残差与上一次迭代的结果求和。重复2）、3）、4）的操作直至达到迭代次数。3.4.2模型训练人脸特征点是很多其他任务的前置任务，因此有大量公开的人脸特征点数据3疲劳特征区域定位-35-集供算法训练使用。本文选用300-W数据集训练ERT算法，300-W数据集包含afw（337）、helen（train2000+test330）、ibug（135）和lfpw（train811+test224），共计3148张训练图片与689张测试图片。该数据集中包含的图像可能不止一个人脸但是只有一个人脸会被标注，标注方式为标准68个人脸特征点。模型训练采用第三方库Dlib提供的训练方法，训练参数如表5所示。ERT算法在不同级联级数下的效果如图27所示。其中，（f）为真实人脸坐标标注，T代表级联级数，当级联数为0时，人脸关键点向量是初始值，通过不断地级联回归，可以看出随着T的增大，人脸关键点的坐标位置与实际位置越来越接近，当级联级数为T为10时，基本接近真实坐标。表5ERT模型训练参数Table5ParameterofERTtraining参数名设置级联级数10每层级联树的数量500树的深度5正则项0.1特征池的大小400回归树节点分裂个数20样本扩大倍数20图27ERT算法流程图Fig27FlowchartofERT3.5本章小结本章介绍了获取包含疲劳特征的头部姿态及面部区域（眼部区域与嘴部区域）的方法：多任务卷积神经网络和基于计算回归树的人脸特征点检测。本章详细介绍了多任务卷积神经网络的网络构成、训练策略以及性能评估，多任务卷积神经网络在人脸分类任务上取得了98%的准确率，在边界框回归任务上性能优于部分3疲劳特征区域定位-36-网络，在头部姿态估计任务上优于使用人脸特征点计算头部姿态的方法。多任务卷积神经网络为ERT的使用奠定了基础，为第四章疲劳参数的提取建立了前提与保障。4疲劳参数提取-37-4疲劳参数提取4.1眼部疲劳参数4.1.1眨眼判断疲劳状态下，驾驶员会感到眼睛酸涩、眼皮沉重，眨眼频率与眨眼动作特征都与清醒状态下不同。眨眼频率使用单位时长的眨眼次数来统计，单次眨眼动作疲劳判断使用PERCLOS准则。眼部疲劳特征的提取基于对眨眼动作的正确判断。当前图像驾驶员是否闭眼可以使用EAR（EyeAspectRation，眼睛纵横比）的大小来判断。EAR的计算公式如下：=ℎℎ(4−1)EAR能够直观的反应人眼的睁闭状态，值越大表明眼睛睁开幅度越大。使用比例而非眼睛睁开的宽度可以避免人眼大小对判断结果的影响，结合人脸特征点，可以快速、精准的反应人眼状态。ERT算法在人眼处的标注如图28所示，结合后的EAR算法如下：=44−48+45−47243−46(4−2)=38−42+39−41237−40(4−3)=+2(4−4)图28ERT算法在人眼处的标注Fig28AnnotationofERTalgorithmathumaneyes选取一名测试人员记录其眨眼过程的EAR值，其变化如图29所示。4疲劳参数提取-38-图29眨眼时EAR值的变化曲线Fig29CurveofEARvalueduringblinking由图29可知：在非眨眼的情况下，EAR值基本维持在一个范围内，当眨眼行为发生时EAR值急速减少之后快速恢复。为了准确判断眨眼动作的发生，本文使用UTA-RLDD[59]（UTAReal-LifeDrowsinessDataset）中的数据进行EAR阈值测定实验。UTA-RLDD共包含11名受测人员拍摄的包含正脸的视频，选取每名受测人员各一段视频，总计270s，眨眼63次。为更好的描述检测效果，引入精确率(precision)、召回率（recall）和1来对检测结果进行评估，其计算公式如下。=+(4−5)=+(4−6)1=2+(4−7)式中：P表示精确率，R表示召回率，1是对精确率和召回率的加权平均，能更好的反应整体效果，1越高，说明整体效果越好。TP表示眨眼行为被检测为眨眼的次数；FP表示非眨眼行为被检测为眨眼的次数，即误检次数；FN表示眨眼行为被检测为非眨眼行为的次数，即漏检次数。实验结果如表6所示。由表6可知，取EAR阈值为0.205的眨眼检测效果较好。4疲劳参数提取-39-表6眨眼判断EAR阈值实验Table6EARthresholdexperimentofblinkjudgmentEAR阈值设定实际眨眼次数TPFPFNPR10.25635812050.3260.9210.49720.2363569470.3730.8890.52550.21635322100.7070.8410.76820.205635211110.8250.8250.82500.2063458180.8490.7140.77570.1963346290.8500.5400.66044.1.2PERCLOS参数获取当驾驶员处于疲劳状态时，单次眨眼动作时间延长，眨眼动作各部分所占比重也不同。卡内基梅隆研究所经过大量实验论证，提出PERCLOS（percentageofeyelidclosureoverthepupilovertime）准则用于判断驾驶员疲劳程度。PERCLOS指在单位时间内眼睛闭合时间占总时间的比值，是在疲劳检测中被广泛使用的判断指标。该准则通常有70，80和三种测量方式：70：眼皮盖过眼球的面积超过70%所占的时间比例。80：眼皮盖过眼球的面积超过80%所占的时间比例。：眼皮盖过眼球的面积超过50%所占的时间比例。1999年美国联邦高速公路管理局召集专家学者，研究讨论九种不同疲劳指标的有效性。通过对实验数据的对比，证明了PERCLOS相对于驾驶员其他特征，更能直接反映驾驶员的疲劳程度，其中使用80测量方式判断结果最佳[60]。在80测量方式下，眨眼过程可以被划分为图30所示。其中1为开始时刻，2时眼睛睁度下降至20%，即眼皮盖过眼球80%，3时眼睛睁度上升至20%，4为结束时刻。在如图30所示标注下PERCLOS的计算公式为：=3−24−1(4−8)4疲劳参数提取-40-图30眨眼过程划分Fig30Divisionofblinkprocess为了计算PERCLOS值，需要得到眼球被覆盖80%时EAR的值。由于眨眼时眼睛的宽不变，因此眼球覆盖80%时即EAR值域的前20%处，由此可得：=−×0.2+(4−9)由4.1.1节可知，=0.205，对多个闭眼对象计算其EAR值，可以得到=0.15，可计算=0.161。将PERCLOS准则与EAR值结合，PERCLOS计算公式变形为：=(4−10)式中：表示一次眨眼动作的总帧数，表示一次眨眼动作中EAR值低于的总帧数。由国内外实验人员的分析可知，当PERCLOS值小于0.1时，推断驾驶员处于清醒状态；当PERCLOS值处于0.1到0.3时，推断驾驶员处于轻度疲劳状态；当PERCLOS值处于0.3到0.5时，推断驾驶员处于中度疲劳状态；当PERCLOS值大于0.5时，推断驾驶员处于重度疲劳状态[61]。4.1.3眨眼次数获取当驾驶员疲劳时，还有几种特征可能表现在眼部：长时间睁眼、长时间闭眼和频繁眨眼。一般情况下，一分钟时间内眨眼次数约为15~20次，大约每隔3~6秒眨一次眼睛，每次眨眼时间约为0.2~0.4秒[62]。处于疲劳状态时，驾驶员会不自觉进入走神状态，此时驾驶员目光呆滞，眼睛长时间睁开，眨眼频率下降；驾驶员也可能感到眼睛酸涩，频繁眨眼，眨眼频率上升。当处于重度疲劳时，驾驶4疲劳参数提取-41-员可能发生长时间闭眼的情况，此时PERCLOS准则失效，极易发生交通事故。为了判断出上述三种情况下驾驶员的疲劳状态，使用眨眼频率作为疲劳特征之一。当驾驶员的眨眼频率超出或低于正常范围时，推断其处于疲劳状态。一次眨眼动作指眼睛从开始闭合到完全睁开，在本文中指EAR值从降低到阈值以下到上升至阈值。如图31所示，通过监测EAR值与阈值的关系即可判断眨眼次数。图31共检测到2次眨眼动作。图31眨眼次数统计方法示意图Fig31SchematicDiagramofBlinkingTimesStatistics4.2嘴部疲劳参数除眼部疲劳特征外，嘴部在疲劳时也会表现出明显特征：打哈欠。当人处于疲劳、困倦状态时，呼吸节奏放缓，血液中二氧化碳含量增加，氧气含量变少。此时大脑呼吸中枢感知到血液变化，令人不受控制的进行深呼吸动作吸入氧气，同时令面部肌肉紧张，加速头部血液流通，其外在表现便是打哈欠。由此可以知道哈欠动作是很好的疲劳表现，单位时间内哈欠的次数与疲劳程度密切相关。仿照眨眼判断的思想，通过对嘴部纵横比的检测来判断嘴张开的大小，即使用MAR（MouthAspectRation，嘴部纵横比）检测哈欠行为。在ERT算法中，嘴部的标注如图32所示：4疲劳参数提取-42-图32ERT算法在嘴唇处的标注Fig32AnnotationofERTalgorithmathumanmouth通过人脸特征点检测算法得到嘴部外侧的8个二维坐标位置，在ERT中被标记为49、51、52、53、55、57、58、59，由此可得到MAR的计算公式：=59−51+58−52+57−53355−49(4−11)选取嘴部外侧的特征点可以避免当张嘴时内部特征点标注受牙齿、舌头的影响出现偏移，而外部特征点的干扰较少。邀请一名测试人员录制一段视频，测试人员进行说话、唱歌和打哈欠行为，其MAR变化如图33所示。由图33可知，当测试人员说话或唱歌时MAR快速上下波动，打哈欠时MAR峰值明显高于前两者，且会维持一段时间。图33MAR值变化曲线Fig33MARvaluechangecurve哈欠行为的MAR均值与说话、唱歌行为的MAR均值区别较大，可以确定一个阈值来区分哈欠行为与其他行为。此外，哈欠行为通常持续2～3s，因此低于4疲劳参数提取-43-1s的高MAR值区间应被视为检测失误或说话、唱歌行为的特异点。本文使用YawDD[63]来测定哈欠行为的MAR阈值，YawDD包含不同性别、不同人种以及佩戴眼镜的驾驶员在不同光照下模拟驾驶的视频。选取其中8段视频，共计哈欠26次。实验结果如表7所示。表7哈欠判断MAR阈值实验Table7MARthresholdexperimentofyawnjudgmentMAR阈值实际哈欠次数TPFNFPPR10.95261214010.46150.63150.926188010.69230.81820.852626880.69230.69230.69230.82618460.78570.84610.81480.752626220.92310.92310.92310.72626050.838710.9123实验数据分析：阈值设定过高会导致部分哈欠无法被检测到，使得漏检次数过多；设置在0.8左右会在一次哈欠行为进行中出现MAR低于阈值的情况，从而导致系统将一次哈欠判定为俩次，误检次数明显上升；设置在0.7会将非哈欠行为判断为哈欠行为，致使误检次数上升；设置在0.75可以获得较高的1值，即获得较好的效果。4.3头部姿态疲劳参数驾驶员陷入疲劳时，很难维持正常的头部姿态，出现不断点头、歪头乃至长时间低头不动的情况，所以驾驶员头部姿态可以有效反应驾驶员疲劳状态。在第三章获得头部姿态的前提下，使用欧拉角描述驾驶员头部姿态，使用单位时间内点头次数和单位时间内头部异常姿态时长来描述疲劳特征。4.3.1点头次数获取驾驶员在疲劳时，会陷入短暂失神导致无力控制头部肌肉，点头后惊醒并快速调整头部姿态，如此反复。摄像机设定在驾驶员前方方向盘处，在描述头部姿态的欧拉角中，俯仰角pitch与点头行为的关系最为密切，当驾驶员点头时，pitch值上下波动。点头前后的pitch值变化如图34所示。4疲劳参数提取-44-图34点头时pitch值的变化Fig34Changeofpitchvaluewhennodding从图34中可以看出，在点头动作发生时pitch值有了大幅度的下降，而在非点头时pitch值也是不断波动的，这是由于驾驶员不可能保持头部静止不动，而且车辆在行驶过程中难免有震动。考虑到不同驾驶员的身高与开车习惯的不同，点头动作的检测不使用pitch阈值比较的方式进行判断，算法检测连续10帧的pitch值，若10帧内pitch值减少25°，认为进行了点头动作。4.3.2头部异常姿态时长获取当驾驶员由于疲劳进入失神状态时，对头部的控制力减弱，致使头部姿态与清醒状态下不同，出现歪头、偏头与低头的姿态。由于pitch角已经被用于描述点头次数，本小节使用yaw角与roll角描述头部异常姿态。yaw角与roll角的理论范围为-90°至90°，然而由于人的生理限制，成年人的头部姿态角事实范围无法达到理论值，其中yaw角范围为-40.9°至36.3°，roll角范围为-79.8°至75.37°[64]。仿照80原则，以0°为中心，将偏离中心超过值域20%的头部姿态角定义为异常姿态，偏离中心20%以内的头部姿态角定义为正常姿态，即当yaw角小于-8.18°或大于7.26°，roll角小于-15.96°或大于15.07°时，认为驾驶员处于头部异常姿态下。头部异常姿态时长的获取公式如下：=(4−12)式中：time为头部异常姿态时长，F为头部异常姿态帧数，FR为视频帧率。4疲劳参数提取-45-4.4本章小结本章介绍了如何在第3章获取疲劳特征区域与头部姿态角的基础上提取疲劳参数。在眼部区域，可以提取单位时间内PERCLOS均值与单位时间内眨眼次数作为疲劳判断依据；在嘴部区域，可以提取哈欠次数作为疲劳判断依据；通过头部姿态角，可以提取单位时间内点头次数与单位时间内头部异常姿态时长作为疲劳判断依据。5多特征融合疲劳检测-46-5多特征融合疲劳检测5.1疲劳状态评价目前疲劳判断没有统一的标准，本文采用GhoddoosianR[59]在文献中提出的疲劳等级判断方法，并使用其发布的开源数据集UTAReal-LifeDrowsinessDataset(UTA-RLDD)。UTA-RLDD对疲劳等级的定义如表8所示。表8疲劳状态定义Table8Definitionoffatiguestate疲劳分类疲劳等级警惕（Alert）1.极度警觉2.非常警觉3.警觉警惕性低（LowVigilant）4.相当警觉5.既不警觉也不困倦6.有一些困倦的迹象昏昏欲睡（Drowsy）7.困倦，但容易保持清醒8.困倦，努力保持清醒9.极度困倦，竭力抵抗入睡GhoddoosianR将1到3级疲劳定义为Alert，即受试者能保持警惕，处于清醒状态，可以轻松长时间驾驶；4到6级被定义为LowVigilant，即受试者出现困倦的迹象或是不需要警惕的细微状况，此时受试者可能可以驾驶但不鼓励这么做；7到9级被定义为Drowsy，即受试者需要努力抵抗睡眠，此时不可进行驾驶。UTA-RLDD数据集由60位志愿者拍摄的视频组成。志愿者被要求在三种状态下，使用任意摄像设备拍摄自己当前状态，每段视频时长10分钟。所有视频都是以双目可见的角度拍摄，并且要求相机放置在距离拍摄对象一臂的距离内，志愿者还被要求进行阅读、观看视频和发呆动作，这些操作可以模拟在汽车中获取的视频的状态，例如将摄像头设置在仪表盘上拍摄，驾驶员专注路况或是候车等情况。数据集中部分帧图像如图35所示。5多特征融合疲劳检测-47-图35UTA-RLDD图例Fig35SampleofUTA-RLDD5.2多特征融合疲劳检测算法5.1.1CART树CART（ClassificationAndRegressionTrees）意为决策与回归树，即该算法既可以用来进行分类任务，也可以进行回归任务。与传统的IDE3算法相比，CART算法可以同时处理离散型特征与连续型特征，适用于本文所获得的疲劳特征；与C4.5算法相比，CART算法生成的决策树为二叉树，不易产生数据碎片，精度往往比多叉树更高[65]。故本文选用CART算法作为基分类器构造多特征融合疲劳检测方法。1.特征选择决策树每一次对数据集的划分都依赖于特征选择，而找到最优特征的前提是找到最优切分点。CART算法使用基尼指数（Giniindex）来衡量每一个可能的切分点划分后数据集的纯度，其公式如下所示:5多特征融合疲劳检测-48-==1≠  =1−=12 (5−1)式中：表示数据集D中的样本总类别数，表示第k类样本所占的比例，数值越小，数据集D的纯度越高。反映了从数据集D中随机抽取俩个样本，其类别不一致的概率。在属性a上划分后，得到的1与2俩个子集的基尼指数计算公式如下：|=11+22(5−2)算法选择划分后基尼指数最小的划分点作为最优划分进行树的分支。针对不同的特征类型，算法采用不同的划分方法。1.连续型特征划分方法假设1,2,...,为数据集D中某个连续型特征A的取值并按升序排列。取这些连续值相邻俩个值的均值作为划分点，共得到m-1种划分方式，计算这m-1种划分方式对数据集D进行划分后得到的子集的基尼指数，取使基尼指数最小值的划分点作为该特征A上的最佳划分。2.离散型特征划分方法假设1,2,...,为数据集D中某个离散型特征B的取值。对于任意离散值，将数据集D划分为包含特征值与不包含特征值的俩部分，共得到n种划分方式，计算这n种划分方式对数据集D进行划分后得到的子集的基尼指数，取使基尼指数最小值的划分点作为该特征B上的最佳划分。在得到全部特征上的最佳划分后，比较其基尼指数大小，取基尼指数最小的特征与其最佳划分点进行数据集划分，即CART树的分叉。2.树的生成树的生成算法如下所示：算法5.1CART树的生成输入：数据集D，停止计算的条件输出：二叉决策树1.判断当前数据集是否满足停止条件，若满足则算法结束，不满足则以当前数据集为根结点。2.遍历当前数据集上的特征，判断其性质（离散型或连续型），使用对应方法5多特征融合疲劳检测-49-找到其最佳划分。比较每个特征上最佳划分后的基尼指数，选择基尼指数最小的特征为最优特征。3.将当前数据集以最优特征进行最佳划分得到俩个子集1,2，建立当前结点的子结点，左结点为1，右结点为2。将此最优特征的最佳划分点去除。4.对1,2重复进行操作1~4。算法的停止条件有多种：1）当前数据集基尼指数小于某一指定阈值，即认为当前数据集不需要再划分；2）当前数据集每个特征上仅有一个值，无法划分；3）当前数据集样本数小于某一指定阈值，即认为当前数据集没有划分意义；4）当前CART树深度达到预设值，停止分裂预防过拟合。5.1.2随机森林过拟合是决策树学习算法面对的重要问题，在决策树划分过过程中，有时会出现分支过多，过度的学习训练集，将一些训练集自身的特点或偏好作为普适的特征学习，造成决策树过拟合，泛化性能下降。为了解决过拟合问题，国内外学者提出了诸多办法：预剪枝、后剪枝和分类器组合等办法。随机森林是分类器组合方法中的一种，其理论来自于统计学习。随机森林利用bootstrap方法从原始样本中进行随机放回抽样，最终得到k个与原始样本相同大小的数据集，使用这些数据集得到k个决策树。在面对新的输入时，使用k个决策树对输入进行预测，使用给定的结合策略对k个决策树的结果进行结合，输出最终结果。在树的生成过程中，对决策树的每一个结点，首先从该结点的属性集合中随机抽取包含m个属性的子集，然后从属性子集中选取最优划分进行树的分裂，在一般情况下，推荐=2[66]。随机森林生成算法如下所示：算法5.2随机森林的生成输入：训练集={{1,1},{2,2},...,{,}}；生成决策树数量k；输出：k个CART决策树过程：1.随机放回抽样生成k个大小为n的数据集，记为={1,2,...,}2.forin:3.计算每次分裂时属性数量d，随机选择2个属性进行分裂5多特征融合疲劳检测-50-5.3实验结果与分析第4章所提取的疲劳参数大多为过程量，需要一定检测时间才可得出，同时为了获得更多样例，将RLDD数据集中的视频裁切为30s时长的短视频，共计获得633个样本，三类样本各211个。选取其中501个样本进行训练，132个样本进行测试。测试数据集中五个疲劳参数的取值方法如下：1.PERCLOS值疲劳参数取30s内的PERCLOS平均值；2.眨眼次数疲劳参数取30s内眨眼次数；3.哈欠次数疲劳参数取30s内哈欠次数；4.点头次数疲劳参数由30s内点头次数；5.头部异常姿态时长疲劳参数取30s内头部异常姿态时间。部分样本的五个疲劳参数如下所示：表9部分样本数据Table9Partialsampledata疲劳类型PERCLOS均值眨眼次数哈欠次数点头次数头部异常姿态时长Alert0.0723006.367Alert0.0367004.333LowVigilant0.14370317.833LowVigilant0.19480216.2Drowsy0.89632419.833Drowsy0.452120225.433使用训练集训练一颗CART树，训练结果如图36所示。图36单棵CART决策树Fig36SingleCARTdecisiontree5多特征融合疲劳检测-51-在训练集中，决策树的分类结果如表10所示。表10单棵决策树在训练集上的分类结果Table10Classificationresultofsingledecisiontreeontrainingset样本类别样本个数正确识别样本数错误识别样本数准确率Alert167162597.0%LowVigilant1671561193.4%Drowsy1671670100%由表10可以发现，单棵CART树对Alert与LowVigilant的分类失误较多。这是由于这俩类数据特征相近，单棵CART树无法很好的区分这俩者，在叶结点出现样本数量低于停止条件但是当前集合仍不纯净的情况。随机森林可以很好的解决单棵树分类能力不足的缺点，本文所提随机森林采用投票法得出结果，共由50棵CART决策树构成。在训练集中，随机森林的分类结果如表11所示。表11随机森林在训练集上的分类结果Table11Classificationresultsofrandomforestsontrainingsets样本类别样本个数正确识别样本数错误识别样本数准确率Alert167164398.2%LowVigilant167161696.4%Drowsy1671670100%由表11可以看出，随机森林在训练集上的分类能力相较单棵CART树更强。使用单特征perclos值与点头次数分别在训练集上建立CART决策树，四种决策树在测试集上的表现如表12所示。表12不同决策树在测试集上的分类结果TableClassificationresultsofdifferentdecisiontreesontestsets决策树类别样本个数正确识别样本数错误识别样本数准确率基于perclos的决策树132706253.0%基于点头次数的决策树132864665.2%单棵多特征决策树1321042878.8%随机森林132127596.2%由表12可以得出，多特征决策树性能优于单特征决策树，单特征决策树无法将样本正确分类。随机森林性能优于单棵决策树，对特征相近的样本分类能力更强。5多特征融合疲劳检测-52-本文对不同文献的疲劳检测方法进行对比，实验结果如表13所示。表13不同疲劳检测方法对比Table13Comparisonofdifferentfatiguetestingmethods文献疲劳检测方法准确率文献[67]无监督学习+面部特征提取+K均值聚类87.5%文献[68]PERCLOS+哈欠次数+车辆运行参数90%文献[69]DINN+LBF+MSPM+ASPM+PERCLOS90.15%文献[70]EnlightenGAN+MTCNN+ESC-Net93.79%文献[42]人眼状态+SSD96%本文多特征随机森林96.2%文献[67]使用无监督学习的方法直接从面部提取特征，对得到的特征使用Softmax预测的类别概率来改进K均值聚类算法中的均值向量初始化方法，进行驾驶员疲劳状态类别划分。使用混淆矩阵进行检测结果的评价，其中疲劳状态的检测正确率达到87.5%。文献[68]使用HOG与SVM结合完成人脸检测，使用级联回归树得到人脸特征点定位眼部区域与嘴部区域。结合PERCLOS、哈欠次数与车辆运行时长综合判断驾驶员疲劳状态，其检测准确率达到90%。文献[69]使用深度混合神经网络（DINN）识别驾驶员眼睛开闭状态，提出了基于时空局部二值模式（时空LBF）和Gabor融合特征的驾驶员动态疲劳表情识别模型。使用9个特征建立特征空间，将通用疲劳特征空间和自适应疲劳特征空间结合构建一种驾驶员自适应疲劳判别模型，检测驾驶员疲劳状态，其准确率达到90.15%。文献[70]针对低光条件下识别率地下的问题，采用EnlightenGAN对夜间图像进行增强，使用MTCNN定位眼部区域并判断眼睛睁闭，采取ESC-Net进行疲劳分类，最终检测准确率达到93.19%文献[42]采用深度卷积神经网络（SSD）进行目标检测，直接得出人脸状态，精确率达99.7%。使用模糊评价思想与单指标批判方法进行疲劳程度判定，在测试集上的总体准确率为96%。6总结与展望-53-6总结与展望6.1总结随着经济水平的快速发展，私家车的数量不断增多。大量新增驾驶员缺乏驾驶经验，对驾驶技能不够重视，同时工作时间的普遍延长致使人们经常无法获得足够的休息，这些因素导致疲劳驾驶风险的升高，进而引发交通事故。在前人工作的基础下，本文提出了一种多特征融合车载疲劳检测的方法，旨在当驾驶员陷入疲劳状态时及时提醒驾驶员，避免因此引发的交通事故。本文的研究内容包括以下几点：1.介绍了本文的研究背景。总结了以往的疲劳检测方法，包括主观疲劳检测法与客观疲劳检测法，客观检测法包含以下几类：基于驾驶员生理信号特征的疲劳检测方法；基于车辆行为特征的疲劳检测方法；基于驾驶员行为特征的疲劳检测方法。2.介绍了本文所使用的相关理论与技术。图像增强算法历史悠久，是大部分图像处理工作的前置工序；卷积神经网络在人脸识别领域有大量应用，是很好的人脸定位工具；人脸特征点检测算法形式多样，主动形状模型与神经网络都可以很好的完成人脸特征点检测。3.优化了特征区域的获取方法。本文优化了特征区域获取流程，提出了多任务卷积神经网络获取人脸区域与头部姿态信息，使用ERT人脸特征点检测算法获取眼部区域与嘴部区域。4.提出了从特征区域提取疲劳参数的方法。使用EAR参数从眼部区域提取PERCLOS值与单位时间内眨眼次数；使用MAR参数从嘴部区域提取哈欠次数；使用pitch角、roll角与yaw角从头部姿态信息中提取单位时间内点头次数与头部异常姿态持续时间。5.提出了多特征融合疲劳检测方法。使用UTA-RLDD定义的疲劳状态等级与数据，使用以CART树为基的随机森林作为多特征特征融合疲劳检测方法。在自制测试集上取得了96.2%的准确率。6总结与展望-54-6.2展望本文研究了基于驾驶员行为特征的疲劳检测方法，综合了单位时间内眨眼次数、哈欠次数、点头次数、PERCLOS均值与头部异常姿态持续时间五个疲劳参数判断驾驶员疲劳状态。回顾实验进行中遇到的问题，发现仍有如下几点缺点与改进方法：1.疲劳数据集中的视频帧率均为30FPS。在进行PERCLOS值计算时，由于视频帧率的限制，包含眨眼动作的图像中存在闭眼图片缺失的情况，由此计算的部分PERCLOS值偏小。可以在录制数据集时提高视频帧率来避免这种现象。2.本文的EAR阈值测定仅采用了疲劳数据集中的11名受测人员的视频测定，样本数据量少，在实际场景中使用预计效果不佳。解决方法有俩种：扩大样本量确保EAR阈值具有普适性；提出一种自适应EAR阈值方法，在车辆启动后对当前驾驶员进行采样并确定其个人的EAR阈值。3.本文提出的疲劳检测算法仅融合了驾驶员行为特征的疲劳参数，在实践中可以针对不同车型在模型中加入车辆运行时的参数提高疲劳检测算法的检测能力。4.本文所采取的特征区域定位方法为多任务卷积神经网络+ERT人脸特征点检测算法，检测流程虽有优化，但仍旧相对复杂缓慢，在未来的研究中可以将一次性检出特征区域作为研究方向。参考文献-55-参考文献[1]中华人民共和国国家统计局.中国统计年鉴[J].北京:中国统计出版社,2021.[2]GanderPH,MarshallNS,JamesI,etal.Investigatingdriverfatigueintruckcrashes:Trialofasystematicmethodology[J].TransportationResearchPartF:TrafficPsychologyandBehaviour,2006,9(1):65-76.[3]ForsmanPM,VilaBJ,ShortRA,etal.Efficientdriverdrowsinessdetectionatmoderatelevelsofdrowsiness[J].AccidentAnalysis&Prevention,2013,50:341-350.[4]牛清宁,周志强,于鹏程,王秋鸿.国内外货运车辆驾驶人疲劳驾驶管理政策研究[J].交通工程,2017,17(06):45-48.DOI:10.13986/j.cnki.jote.2017.06.009.[5]薛雷.考虑驾驶员生物电信号的疲劳驾驶检测方法研究[D].吉林大学,2015.[6]南姣芬.基于脑电信号的驾驶疲劳检测方法研究[D].陕西师范大学,2011.[7]王海玉.基于脑电信号多熵特征的驾驶疲劳检测模型研究[D].江西农业大学,2019.DOI:10.27177/d.cnki.gjxnu.2019.000242.[8]王斐,吴仕超,刘少林,张亚徽,魏颖.基于脑电信号深度迁移学习的驾驶疲劳检测[J].电子与信息学报,2019,41(09):2264-2272.[9]吴雅萱,李文书,施国生,周涛.疲劳驾驶检测技术研究综述[J].工业控制计算机,2011,24(08):44-46+49.[10]郭玮珍,郭兴明,万小萍.以心率和心率变异性为指标的疲劳分析系统[J].医疗卫生装备,2005(08):1-2.[11]郝贺.基于心率变异性的人体精神疲劳检测系统研究[D].东北大学,2014.[12]OhsugaM,KamakuraY,InoueY,etal.ClassificationofBlinkWaveformsTowardtheAssessmentofDriver'sArousalLevels-AnEOGApproachandtheCorrelationwithPhysiologicalMeasures.2007.[13]于立娇,吴振昕,王文彬,高洪伟.驾驶员疲劳状态监测系统综述[J].汽车文摘,2019(03):24-30.[14]Fletcher,L,Apostoloff,etal.Visioninandoutofvehicles[J].IntelligentSystems,IEEE,2003.[15]PiluttiT,UlsoyG.On-lineidentificationofdriverstateforlane-keepingtasks[C]//Proceedingsof1995AmericanControlConference-ACC'95.IEEE,1995.[16]BertozziM,BroggiA.Real-TimeLaneandObstacleDetectionontheGOLDSystem[C]//IntelligentVehiclesSymposium,1996.Proceedingsofthe1996IEEE.参考文献-56-IEEE,1996.[17]MaoM,DuL.Researchondrivefatiguedetectionusingwavelettransform[C]//IEEEInternationalConferenceonVehicularElectronics&Safety.IEEE,2008.[18]KithilPW.Driveralertnessdetectionresearchusingcapacitivesensorarray[C]//DrivingAssesmentConference.UniversityofIowa,2001,1(2001).[19]邹昕彤,王世刚,赵文婷,赵晓琳,李天舒.基于眼睛与嘴部状态识别的疲劳驾驶检测[J].吉林大学学报(信息科学版),2017,35(02):204-211.DOI:10.19292/j.cnki.jdxxp.2017.02.015.[20]刘忠旭.基于面部特征的驾驶员疲劳状态检测[D].长春工业大学,2022.DOI:10.27805/d.cnki.gccgy.2022.000640.[21]邬敏杰,穆平安,张彩艳.基于眼睛和嘴巴状态的驾驶员疲劳检测算法[J].计算机应用与软件,2013,30(03):25-27+54.[22]刘祝华.图像去噪方法的研究[D].江西师范大学,2005.[23]关新平,赵立兴,唐英干.图像去噪混合滤波方法[J].中国图象图形学报,2005(03):332-337.[24]赵高长,张磊,武风波.改进的中值滤波算法在图像去噪中的应用[J].应用光学,2011,32(04):678-682.[25]VaillantR,MonrocqC,LeCunY.Originalapproachforthelocalisationofobjectsinimages[J].IEEProceedings-Vision,ImageandSignalProcessing,1994,141(4):245-250.[26]LiH,LinZ,ShenX,etal.Aconvolutionalneuralnetworkcascadeforfacedetection[C]//ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2015:5325-5334.[27]ZhangK,ZhangZ,LiZ,etal.Jointfacedetectionandalignmentusingmultitaskcascadedconvolutionalnetworks[J].IEEEsignalprocessingletters,2016,23(10):1499-1503.[28]YuJ,JiangY,WangZ,etal.Unitbox:Anadvancedobjectdetectionnetwork[C]//Proceedingsofthe24thACMinternationalconferenceonMultimedia.2016:516-520.[29]OpitzM,WaltnerG,PoierG,etal.Gridloss:Detectingoccludedfaces[C]//Europeanconferenceoncomputervision.Springer,Cham,2016:386-402.参考文献-57-[30]GirshickR,DonahueJ,DarrellT,etal.Richfeaturehierarchiesforaccurateobjectdetectionandsemanticsegmentation[C]//ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2014:580-587.[31]HeK,ZhangX,RenS,etal.Spatialpyramidpoolingindeepconvolutionalnetworksforvisualrecognition[J].IEEEtransactionsonpatternanalysisandmachineintelligence,2015,37(9):1904-1916.[32]GirshickR.Fastr-cnn[C]//ProceedingsoftheIEEEinternationalconferenceoncomputervision.2015:1440-1448.[33]RenS,HeK,GirshickR,etal.Fasterr-cnn:Towardsreal-timeobjectdetectionwithregionproposalnetworks[J].Advancesinneuralinformationprocessingsystems,2015,28.[34]RedmonJ,DivvalaS,GirshickR,etal.Youonlylookonce:Unified,real-timeobjectdetection[C]//ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2016:779-788.[35]ChenD,RenS,WeiY,etal.Jointcascadefacedetectionandalignment[C]//Europeanconferenceoncomputervision.Springer,Cham,2014:109-122.[36]MathiasM,BenensonR,PedersoliM,etal.Facedetectionwithoutbellsandwhistles[C]//Europeanconferenceoncomputervision.Springer,Cham,2014:720-735.[37]YangS,LuoP,LoyCC,etal.Fromfacialpartsresponsestofacedetection:Adeeplearningapproach[C]//ProceedingsoftheIEEEinternationalconferenceoncomputervision.2015:3676-3684.[38]JinX,TanX.Facealignmentin-the-wild:Asurvey[J].ComputerVisionandImageUnderstanding,2017,162:1-22.[39]CootesTF,TaylorCJ.Activeshapemodels—‘smartsnakes’[M]//BMVC92.Springer,London,1992:266-275.[40]CootesTF,EdwardsGJ,TaylorCJ.Activeappearancemodels[J].IEEETransactionsonpatternanalysisandmachineintelligence,2001,23(6):681-685.[41]SunY,WangX,TangX.Deepconvolutionalnetworkcascadeforfacialpointdetection[C]//ProceedingsoftheIEEEconferenceoncomputervisionandpattern参考文献-58-recognition.2013:3476-3483.[42]王迪.基于人眼状态的疲劳检测算法研究与应用[D].电子科技大学,2020.DOI:10.27005/d.cnki.gdzku.2020.001881.[43]牛正存.驾驶员疲劳特征提取方法的研究及检测系统的设计[D].电子科技大学,2017.[44]马艳.基于颜色与模板匹配的人脸检测方法[D].大连理工大学,2006.[45]郑伟成,李学伟,刘宏哲,代松银.基于深度学习的疲劳驾驶检测算法[J].计算机工程,2020,46(07):21-29.DOI:10.19678/j.issn.1000-3428.0055912.[46]王剑平,张捷.小波变换在数字图像处理中的应用[J].现代电子技术,2011,34(01):91-94.DOI:10.16652/j.issn.1004-373x.2011.01.049.[47]B.VidakovicandC.B.Lozoya,"Ontime-dependentwaveletdenoising,"inIEEETransactionsonSignalProcessing,vol.46,no.9,pp.2549-2554,Sept.1998,doi:10.1109/78.709544.[48]Donoho,D.L.De-noisingbysoft-thresholding[J].IEEETransactionsonInformationTheory,2002,41(3):613-627.[49]DonohoDL,JohnstoneIM.AdaptingtoUnknownSmoothnessviaWaveletShrinkage[J].[50]WooS,ParkJ,LeeJY,etal.Cbam:Convolutionalblockattentionmodule[C]//ProceedingsoftheEuropeanconferenceoncomputervision(ECCV).2018:3-19.[51]RuizN,ChongE,RehgJM.Fine-GrainedHeadPoseEstimationWithoutKeypoints[C]//2018IEEE/CVFConferenceonComputerVisionandPatternRecognitionWorkshops(CVPRW).IEEE,2018.[52]YangS,LuoP,LoyCC,etal.Widerface:Afacedetectionbenchmark[C]//ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2016:5525-5533.[53]FanelliG,DantoneM,GallJ,etal.Randomforestsforrealtime3dfaceanalysis[J].Internationaljournalofcomputervision,2013,101(3):437-458.[54]TangX,DuDK,HeZ,etal.Pyramidbox:Acontext-assistedsingleshotfacedetector[C]//ProceedingsoftheEuropeanconferenceoncomputervision(ECCV).2018:797-813.参考文献-59-[55]WangH,LiZ,JiX,etal.Facer-cnn[J].arXivpreprintarXiv:1706.01061,2017.[56]BulatA,TzimiropoulosG.Howfararewefromsolvingthe2d&3dfacealignmentproblem?(andadatasetof230,0003dfaciallandmarks)[C]//ProceedingsoftheIEEEInternationalConferenceonComputerVision.2017:1021-1030.[57]KazemiV,SullivanJ.Onemillisecondfacealignmentwithanensembleofregressiontrees[C]//ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2014:1867-1874.[58]ZhuX,ZhenL,LiuX,etal.FaceAlignmentAcrossLargePoses:A3DSolution[C]//2016IEEEConferenceonComputerVisionandPatternRecognition(CVPR).IEEE,2016.[59]GhoddoosianR,GalibM,AthitsosV.Arealisticdatasetandbaselinetemporalmodelforearlydrowsinessdetection[C]//ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognitionWorkshops.2019:0-0.[60]薛丽.基于改进MTCNN网络的多特征疲劳驾驶检测研究[D].长安大学,2021.DOI:10.26976/d.cnki.gchau.2021.001197.[61]朱名流,李顶根.基于人脸特征点的疲劳检测方法研究[J].计算机应用研究,2020,37(S2):305-307.[62]徐忠帅.基于面部特征的驾驶员疲劳检测研究[D].辽宁工业大学,2019.[63]AbtahiS,OmidyeganehM,ShirmohammadiS,etal.YawDD:Ayawningdetectiondataset[C]//ACMMultimediaSystems(MMSys).ACM,2014.[64]陈书明,陈美玲.头部姿态估计技术研究综述[J].泉州师范学院学报,2015,33(06):78-85.DOI:10.16125/j.cnki.1009-8224.2015.06.015.[65]栾丽华,吉根林.决策树分类技术研究[J].计算机工程,2004(09):94-96+105.[66]Breiman,L.RandomForests.MachineLearning45,5–32(2001).[67]王静静.基于深度学习的驾驶员疲劳检测[D].合肥工业大学,2020.DOI:10.27101/d.cnki.ghfgu.2020.000088.[68]王仕卿.货运车辆疲劳驾驶检测方法研究[D].吉林大学,2021.DOI:10.27162/d.cnki.gjlin.2021.006918.[69]赵磊.基于深度学习和面部多源动态行为融合的驾驶员疲劳检测方法研究[D].山东大学,2018.[70]李晓星.基于深度学习的疲劳驾驶检测方法研究[D].中国科学技术大参考文献-60-学,2020.DOI:10.27517/d.cnki.gzkju.2020.000652.