基于多尺度特征融合的疲劳驾驶 检测方法研究      重庆大学硕士学位论文 （专业学位）   学生姓名：李依玲 指导教师：曾孝平 教授 专业学位类别：工程（电子与通信工程） 研究方向：智能信息处理 答辩委员会主席：谢显中 教授 授位时间：2022年6月   Research of Fatigue Driving Detection Method Based on Multi-Scale Feature Fusion     A Thesis Submitted to Chongqing University in Partial Fulfillment of the Requirement for the  Master of Engineering   By   Yiling Li Supervised by Prof.Xiaoping Zeng    June , 2022 中文摘要 I  摘    要 疲劳驾驶作为诱发交通事故的主要因素之一，其造成的交通事故占总交通事故的20%左右，占特大交通事故的40%以上，危害性极大。基于面部特征的疲劳检测方法无需与驾驶员进行接触，具有成本低、受限小且精度高等优点。如何通过面部特征快速、准确地检测驾驶员的疲劳状态具有重要的研究意义和应用价值。 目前，基于面部特征的疲劳检测方法未能融合图像的多尺度特征及多层次信息，在复杂多变的驾驶环境下难以满足实时性和准确性两方面要求。因此本文立足于实际应用场景，以提高疲劳检测方法的准确率、鲁棒性及泛化能力为目标，从疲劳特征选取、面部特征提取以及疲劳判定等多角度进行深入的研究，提出了一种多尺度特征融合的疲劳检测方法，结合智能数字座舱项目需求设计并实现了基于面部特征的疲劳驾驶检测系统，本文主要研究内容及成果如下： ① 针对现有方法不能充分利用图像的多尺度特征及多层次信息的问题，本文提出了一种基于多尺度特征融合的疲劳检测方法。该方法使用多尺度特征层的融合策略和轻量、高效的门控模块，结合具有较强语义的深层特征与细节丰富的浅层特征，充分挖掘图像中的有效特征信息，抑制无效信息，从而更好地检测面部的疲劳特征状态。结合多特征综合的疲劳评定方式，所提的疲劳检测方法在视频数据集上检测的平均准确率能达到96%，表明了该方法能够准确地检测出驾驶员的疲劳状态。 ② 针对疲劳检测系统进行了需求分析，首先基于多尺度特征融合方法设计了一种疲劳检测方案。其次采用Pytorch框架、PyQt5以及辅助硬件设备实现了基于面部特征的疲劳驾驶检测系统。该系统可通过摄像头实时采集视频或拉取资源库中视频的方式检测驾驶员的疲劳状态，可以利用脱岗检测模块来监测驾驶过程中是否存在脱岗现象，并设计了相应的警告功能进行提示。最后对系统进行了相关测试，测试结果证实了该系统能够满足实时性、可用性以及易用性要求，能判断驾驶员疲劳状态并给予相应反馈，其整体性能较好，具有一定的使用价值。  关键词：疲劳检测；图像信息；特征提取；多尺度特征融合      英文摘要 III  Abstract As one of the main factors inducing traffic accidents, fatigue driving causes about 20% of the total traffic accidents and more than 40% of the mega traffic accidents, which is extremely harmful. The fatigue detection method based on facial features does not require any contact with the driver, and has the advantages of low cost, small limitation and high accuracy. How to detect driver fatigue quickly and accurately by facial features has important research significance and application value. At present, the fatigue detection method based on facial features fails to fuse the multi-scale features and multi-level information of images, and it is difficult to meet the requirements of both real-time and accuracy in the complex and changing driving environment. Therefore, based on practical application scenarios, this thesis aims to improve the accuracy, robustness and generalization ability of fatigue detection methods, and conducts in-depth research from multiple perspectives such as fatigue feature selection, facial feature extraction, and fatigue judgment, and proposes a method. The fatigue detection method of multi-scale feature fusion, combined with the requirements of the intelligent digital cockpit project, designed and implemented a fatigue driving detection system based on facial features. The main research contents and achievements of this thesis are as follows: Aiming at the problem that existing methods cannot fully utilize the multi-scale features and multi-layer information of images, this thesis proposes a fatigue detection method based on multi-scale feature fusion. The method uses a fusion strategy of multi-scale feature layers and a lightweight and efficient gating module to combine deep features with strong semantics and detail-rich shallow features to fully exploit the effective feature information in the image and suppress the invalid information, so as to better detect the fatigue feature state of the face. Combined with the multi-feature integrated fatigue assessment approach, the proposed fatigue detection method can reach an average accuracy of 96% on the video dataset, demonstrating that the method can accurately detect the fatigue state of the driver. A requirement analysis was conducted for the fatigue detection system, and firstly a fatigue detection scheme was designed based on a multi-scale feature fusion method. Secondly, a fatigue driving detection system based on facial features is implemented using the Pytorch framework, PyQt5 and auxiliary hardware devices. The system can 重庆大学硕士学位论文 IV  detect the driver's fatigue status by means of real-time video capture by camera or pulling videos from the resource library. The off-duty detection module can be used to monitor whether there is off-duty phenomenon during driving and the corresponding warning function is designed for prompting. The final test results confirm that the system can meet the requirements of real-time, usability and ease of use, and can judge the driver's fatigue state and give corresponding feedback. Its overall performance is good and has certain practical value.  Keywords: Fatigue Detection; Image Information; Feature Extraction; Multi-Scale Feature Fusion 目  录 1 绪论 ......................................................................................................... 1 1.1 研究背景及意义 ............................................................................... 1 1.2 国内外研究现状 ............................................................................... 2 1.2.1 主观检测法 ................................................................................. 4 1.2.2 客观检测法 ................................................................................. 4 1.3 主要研究内容 ................................................................................... 7 1.4 论文章节安排 ................................................................................... 7 2 疲劳检测相关技术基础 ........................................................................ 9 2.1 疲劳特征选取及判别标准 .............................................................. 9 2.1.1 眼部特征选取及判别标准 ......................................................... 9 2.1.2 嘴部特征选取及判别标准 ....................................................... 10 2.2 疲劳检测方法理论基础................................................................. 11 2.2.1 卷积神经网络 ........................................................................... 12 2.2.2 VGG网络模型 .......................................................................... 15 2.2.3 目标检测技术 ........................................................................... 16 2.3 本章小结 ......................................................................................... 17 3 基于面部特征的疲劳检测方法设计与性能评估 .............................. 19 3.1 基于面部特征的疲劳检测方法整体架构 .................................... 19 3.2 数据集的采集与构建 ..................................................................... 20 3.3 基于改进SSD的面部特征提取网络 ........................................... 23 3.3.1 传统SSD网络架构及基本原理 ............................................. 23 3.3.2 多尺度特征融合网络架构 ....................................................... 26 3.3.3 多尺度特征融合网络的训练方法 ........................................... 29 3.3.4 实验与结果分析 ....................................................................... 32 3.4 基于面部多特征的疲劳检测方法 ................................................ 39 3.4.1 多特征综合的疲劳评定方式 ................................................... 39 3.4.2 基于多尺度特征融合的疲劳检测方法 .................................. 41 3.4.3 实验与结果分析 ....................................................................... 42 3.5 本章小结 ......................................................................................... 45 4 疲劳驾驶检测系统设计与实现 .......................................................... 47 4.1 系统需求分析 ................................................................................. 47 4.1.1 功能性需求 ............................................................................... 47 4.1.2 非功能性需求 ........................................................................... 48 4.1.3 硬件设备及开发环境 ............................................................... 48 4.2 系统总体设计 ................................................................................. 49 4.2.1 系统总流程设计 ....................................................................... 50 4.2.2 系统主体功能设计 ................................................................... 52 4.3 系统实现及测试 ............................................................................. 53 4.4 本章小结 ......................................................................................... 57 5 总结与展望........................................................................................... 59 5.1 论文工作总结 ................................................................................. 59 5.2 未来工作展望 ................................................................................. 60 参考文献 ................................................................................................... 61 1  绪    论 1  1  绪    论 1.1 研究背景及意义 在经济全球化和科技进步不断加快的背景下，汽车行业发展迅猛，驾驶员数量逐年增加，机动车已成为人们日常生活中不可或缺的交通工具。截至2021年底，公安部统计报告[1]中显示全国机动车保有量达3.95亿辆，汽车数量已超过3亿辆；机动车驾驶员达4.81亿人，其中汽车驾驶员数量占驾驶人总数的92.24%，已经达到4.44亿人。 随着机动车保有量的逐年上升，城市道路交通安全问题日益凸显，交通安全形势愈发严峻。世界卫生组织（World Health Organization，WHO）在2011-2020年道路安全十年情况的报告[2]中指出：每年，全世界都约有135万人因交通意外丧生，另外还约有5千万人在事故中受到了不同程度的伤害。近年来，社会对于酒后驾驶的关注度越来越高，但忽视了疲劳驾驶也是道路交通的主要“安全杀手”，其造成的巨大社会经济损失已不容忽视。据报道，疲劳驾驶所引发的交通事故在所有交通事故中的占比逐年增长，根据文献[3]的调研显示由疲劳驾驶造成的交通事故约占20%，在特大交通事故中的占比更高，约为40%。我国机动车保有量和驾驶人总量均居世界第一，如何从根源上避免交通事故的产生、减少因交通事故给社会带来的损失、提高汽车的智能化和安全性，是国内社会稳定与国民经济发展亟待解决的重要问题。 引发疲劳驾驶的因素是多方面的，其中驾驶员睡眠不足和长时间、高强度行车是导致疲劳驾驶的主要原因。当驾驶员处于疲劳状态时会呈现身心疲惫状态，从而导致生理及心理机能减退、反应灵敏度和开车技能显著降低。如今，中国公路建设快速发展，公路网规模持续扩大，公路里程数逐年增加，由长时间驾驶引发的感知延迟及决策偏差等驾驶疲劳问题不甚枚举。目前，中国主要以驾驶员的连续驾驶时间作为判定驾驶员是否疲劳驾驶的主要依据，根据《中华人民共和国道路交通安全法》规定[4]，若驾驶员连续驾驶4小时，必须停车休息至少20分钟，否则将被判为违法行为。但是，疲劳驾驶具有隐蔽性，且它是一个渐进、累积的过程，法律法规并不能积极有效地减少和消除驾驶员的疲劳驾驶现象。由于疲劳驾驶的危害性大，对驾驶员进行状态监测是一项具有重要意义的应用，对此人们迫切的需要一种能够准确检测机动车司机驾驶状态的方法。 在过去的疲劳检测研究中，该领域亦取得了丰硕的成果，经相关人员研究发现：疲劳现象发生时，会伴随着打哈欠[5]、眨眼频率降低、闭眼时间变长[6]、心率及脉搏变化等许多疲劳特征的出现。目前，国内外学者针对疲劳驾驶问题提出了重庆大学硕士学位论文 2  以下三种解决方案[7-9]：基于驾驶员生理特征、基于车辆运动特征和基于驾驶员面部特征的检测方法。通过采集生理信号对疲劳状态进行检测是最客观准确的方式，能够很好地反映驾驶员的疲倦程度，但在实际应用中，其设备昂贵复杂且都为接触性设备，对驾驶员的操作带来了极大的干扰，因此削弱了发展空间；车辆运动特征检测是通过检测车辆行为的一系列参数来判断驾驶员是否处于疲劳状态的方式，但车辆行为易受驾驶员个人习惯及地形环境等不可控因素的影响，“正常”与“非正常”状态难以区分，因此最终的检测结果可能与实际驾驶员状态存在较大的误差；而面部特征眼睛和嘴部状态是判断疲劳驾驶最重要的载体，人眼特征和嘴部特征在众多疲劳识别参数中占有重要地位，该方法在保证精确度的同时具备成本低，设备简单，无接触性等优点。基于对现有方法的研究，将上述三种主要检测方式总结于表1.1中。  表1.1 疲劳检测方法评价 Table 1.1 Evaluation of fatigue detection methods 方法类别 方法描述 准确性 实用性 普及性 生理特征检测 脑电、心电、眼电、脉搏等 好 一般 差 车辆行为特征检测 车辆外部行驶状态等 差 好 一般 面部特征检测 眼部、嘴部状态等 好 好 好  近年来，深度学习和计算机视觉在各个领域取得了巨大的成就，并依据上述研究背景分析，基于深度学习的驾驶员面部特征检测方法已成为疲劳驾驶研究领域的主流方法，为减少因疲劳而造成的社会损失，跟随技术发展的热潮，结合人机交互的思想理念，通过面部图像特征实现对人体疲劳状态的监控具有十分重要的意义。因此本文选用面部特征进行疲劳检测方法研究，该方法可普适于民，从长远角度来看更具有社会意义。  1.2 国内外研究现状 国外对疲劳检测的研究起步较早，早期主要通过医学角度进行研究，根据人体的生理指标检测疲劳状态。美国洲际商业协会于1935年发布的《城市内机动车驾驶服务时间管理条例》初步形成了对驾驶安全的法制性重视[10]，到20世纪80年代，美国允许交通部研究商业机动车的驾驶和交通安全情况，关于疲劳检测的研究才开始进入到实质性阶段。反观国内，疲劳检测的相关研究开始稍晚，于20世纪60年代开始对疲劳驾驶进行基础性研究。多年来，在国家相关部门的重视和1  绪    论 3  支持下，取得了一些成绩。20世纪90年代，疲劳驾驶检测的评判标准与理论逐渐成熟，国内外的研究也进入了非常活跃的阶段。进入21世纪，随着社会的进步与科技的不断发展，计算机视觉、大数据分析及人工智能等前沿技术为疲劳检测领域提供了强有力的支撑，促进了该方向的发展。 近年来，国内外对疲劳状态产生的原因、规律及预防手段做了多方面的理论与实验研究。国际上普遍认为，疲劳状态是人的精神与身体同时作用的结果，其产生过程十分复杂。在真实的驾驶环境中，驾驶员需要使用脑力思考驾驶行为，并通过信息传递给运动器官去执行相应的动作，因此脑力和体力负荷会在驾驶时同时产生并贯穿于整个驾驶过程中，最终导致驾驶员身心疲劳，如图1.1所示。  身体状况、心理情绪睡眠质量、道路环境…大脑及中枢神经系统运动执行器官脑力疲劳脑力疲劳车辆控制灵敏度降低脑力疲劳体力疲劳信息传递 图1.1 人车系统疲劳示意图 Fig. 1.1 Fatigue diagram of the human-vehicle system  基于上述的研究工作不仅可以让科研人员更全面地把握疲劳状态的产生原因和过程，也可以为如何有效地检测疲劳状态提供可靠的理论支撑与设计思路。文献调研发现，疲劳状态的检测方法可分为两大类：主观和客观检测法，如图1.2所示。本文重点研究基于面部特征状态的疲劳检测方法。  疲劳驾驶检测客观检测法主观检测法自评他评生理状态行车数据面部状态 图1.2 疲劳检测方法分类 Fig. 1.2 Classification of fatigue detection methods 重庆大学硕士学位论文 4  1.2.1 主观检测法 主观检测法是根据被测人意识所提供的生理、心理状态指标等进行主观评价的方式，分为自评和他评两种。自评是通过自我评价的方式对自身的疲劳状态进行评定；他评是首先通过录制等形式记录被测者的驾驶行为，然后由专家评判小组进行疲劳状态评价的方式。主观检测法可以通过睡眠质量调查表、驾驶行为记录表以及评价表等对疲劳状态进行评定，常用的主观检测疲劳量表有皮尔逊疲劳量表，斯坦福嗜睡量表等。 主观检测法具有实施简单、成本低廉、普及性高等优势，通常用于在事后分析驾驶员状态或疲劳产生的因素，具有一定的参考价值，但其不具备时效性，很难反应被测者实时的情况，并且由被测者自身或他人主观衡量是否疲劳存在较大的个体差异，易受被测者驾龄以及个体思维等影响。因此，其存在不规范、对评价人员专业度要求高、时效性差、准确度难以保证等缺陷。 1.2.2 客观检测法 客观检测法是不因个人的主观意愿、个体差异而改变的检测方法，它需要使用到信号测量仪、图像采集器等辅助硬件设备来采集被测者的面部状态、生理指标等身体直接信息以及车辆的形式轨迹、道路状况等间接信息，从而快速掌握驾驶员的疲劳状态。其所使用到的特征信息及评判标准都是客观的，并且可以做到实时采集，实时监测，可以快速进行疲劳检测，因此其有较好的准确性、实时性及可靠性。根据不同的角度，客观检测法可划分为基于驾驶员生理特征、基于车辆运动特征和基于驾驶员面部特征三种不同类别的研究方法。 ① 基于驾驶员生理特征检测方法 驾驶员在处于疲劳状态时，心电波（Electrocardiogram，ECG）、脑电波（Electroencephalogram，EEG）、肌电波（Electromyogram，EMG）及眼电波（Electrooculogram，EOG）等生理参数会发生显著变化，能直观地反应出驾驶员的疲劳状态，具有很好的准确性。 国外较早开始研究生理特征值与疲劳状态的相关关系，并证实了疲劳状态与各项生理指标有密切联系。1993年Kecklund等人[11]研究发现，疲劳状态下脑电图θ波会明显增加，依据θ波形的变化轨迹曲线能够有效地检测出被测者的疲劳状态。Lal等人[12]在2002年研究得出驾驶员在处于疲劳驾驶时ECG信号明显呈节律性下降趋势。2007年Mieko等人[13]通过观察眼电图参数的变化，对其峰尖幅值、上升时长和下降时长进行了详细的分析，证实了眼电图与疲劳状态之间存在相关性，可以通过不同状态下的眼电图判断人的精神状态。 随后，国内外大批学者针对生理信号变化对疲劳状态进行了更加深入的研究1  绪    论 5  [14-18]，浙江大学的吴群[19]对心电图的R波频段进行采样，利用R频段的极值非线性特性可以模拟出驾驶员在驾驶过程中从清醒到疲劳状态的心电信号，依据疲劳程度与驾驶员心电图参数的直接相关关系可以判定其疲劳状态。Budi等人[20]通过评估四个脑电信号的活动得出慢波及快波与驾驶员疲劳状态存在联系，从而确定了疲劳状态的检测指标。在近期的研究中，陈朝阳等人[21]通过绘制脑电波图分析出β波在驾驶员疲倦时其相对功率谱会增加，得出β波能很好地反应驾驶员的疲劳状态。王琳等人[22]通过腰部肌电图和脑电图的信号变化来监测驾驶疲劳状态。Jing等人[23]在高原环境下对驾驶员的脑电信号进行了监测，通过检测结果得到了低氧环境下θ、α和β波的功率谱密度图，最终将()αθβ+和()αβθ+作为评估低压低氧环境下的疲劳特性指标。 ② 基于车辆运动特征检测方法 由于驾驶员在驾驶过程中产生疲劳可能会导致车辆的运行状态发生变化，可通过驾驶员手握方向盘的压力、车辆运行轨迹以及车身偏离程度等因素间接反应驾驶员的疲劳状态。美国Electronic Safety Products公司发现司机在疲劳时其车辆的方向盘会处于停顿状态，从而推出了方向盘监视系统[24]（Steering Attention Monitor，SAM），当驾驶员连续4s内未对方向盘做出任何操作，SAM系统就会自动发出警告进行提示。上海交通大学石坚等人[25]在车辆内部安装传感器等设备，通过该装置来测量车辆方向盘转动角等参数，若测量到的参数在一段时间内保持一个固定值就可以判定驾驶员处于疲劳状态。Sandberg和Wahde等人[26]采集了方向盘角度、车辆速度等指标信息，并将这些信息的时间序列作为人工神经网络的输入，最终输出驾驶员的疲劳状态分类结果，结果显示能准确地检测出驾驶员的疲劳状态。Mcdonald等人[27]将车辆速度和加速度、方向盘转向角度以及脚踏板压力等信息送入到动态贝叶斯网络中进行疲劳状态的检测。 ③ 基于驾驶员面部特征检测方法 在日常生活中，通过面部特征判断疲劳状态是最直接有效的方式，随着计算机视觉技术与机器学习领域的不断进步，基于面部的疲劳检测方式成为了疲劳检测领域研究的重点。 早期卡内基梅隆大学的Grace等人[28]发现人类的视网膜在不同波长红外线下有着不同的反射系数，根据这个特点他们通过两幅图像的差分提取出了瞳孔的位置和大小，从而提出了度量疲劳的物理量PERCLOS值。随后，美国交通安全管理局等机构也证实了PERCLOS指标与疲劳状态存在很强的相关性，这个消息的公布使得PERCLOS值被公认为最有效的疲劳判定标准。因此，基于面部特征的疲劳检测方法广泛采用PERCLOS物理量作为疲劳状态的评判标准[29-31]。 重庆大学硕士学位论文 6  随着深度学习技术的飞速普及，借助深度神经网络强大的非线性模拟能力，在分类任务上的优越表现可见一斑，使得疲劳检测领域快速涌现了大批卓越的算法思路。例如：吉林大学的童兵亮[32]采集被测者嘴部状态的时间序列，利用嘴部图像训练出人工神经网络模型，采用嘴部开合比来描述嘴巴的张开程度，通过设定开合比阈值来判断驾驶员是否疲劳。中南大学的李衡峰等人[33]研制出以纹理特征和神经网络为原理的疲劳驾驶测评系统，该系统使用自适应提升（Adaptive Boosting，Adaboost）算法和粒子滤波方法分别获取人脸位置和人眼位置，运用纹理提取和径向基函数（Radial Basis Function，RBF）神经网络方法对人眼状态进行检测。Zhang等人[34]在级联卷积神经模型的基础上提出了多任务卷积神经网络（Multi-task Convolutional Neural Network，MTCNN）模型，该模型同时实现了人脸检测和关键点检测两个任务，在高精确度的基础上保证了检测的速度。Du等人[35]综合心率、睁眼程度和张嘴程度等多因素提出了一种多模式融合递归的神经网络，该网络有效提高了疲劳驾驶检测的精度。Ngxande等人[36]采用生成对抗网络（Generative Adversarial Networks，GAN）对图像进行数据增强来解决数据集不足的问题，从而能有效增强卷积神经网络的表达能力。还有部分文献[37-41]使用神经网络提取特征对疲劳检测算法进行研究，能够达到较好的实时性及较高的准确率。 综上所述，现有的疲劳检测方法主要通过检测驾驶员生理特征、车辆运动特征和驾驶员面部特征来实现。基于生理信息的疲劳检测虽然有较高的准确性，但该方法需要用到专业的仪器设备，成本昂贵，并且会对驾驶员的操作造成不便。基于车辆运动特征的非接触性检测方法易受到驾驶员个人差异以及道路情况等方面的影响，准确率较低，因此上述两种疲劳检测方式均存在一定的局限性。基于面部特征进行疲劳检测的方法无需与驾驶员进行接触，具有成本低、受限小、精度高等优点，因此成为了当前疲劳驾驶研究领域的主流方式。但现有基于面部特征的疲劳检测方法在复杂多变的实际驾驶环境中仍面临姿态多变、光照不均等挑战，使得此类方法对图像的细节处理能力不佳，检测精度较低，且实时性不高，难以投入到实际应用中。因此，在复杂背景环境下提升目标的检测准确率是亟待解决的关键问题。 目前疲劳检测技术的研究理论日渐完善，基于认知科学对疲劳检测进行研究，需要设计的检测算法需要对疲劳状态进行更为准确的量化与分析，本文依托一体化智能数字座舱技术研发项目，对基于面部特征的疲劳检测技术开展相关研究，旨在充分挖掘多层次特征间的关联性及互补性，进而获取具有细节丰富和强语义的特征信息，在保证检测实时性的同时进一步提升对疲劳状态的检测效果。  1  绪    论 7  1.3 主要研究内容 目前基于面部特征的疲劳检测方法在复杂多变的驾驶环境下难以满足实时性和准确率两方面要求。因此本文立足于实际应用场景，结合疲劳检测和深度学习相关理论技术，提出了一种多尺度特征融合的疲劳检测方法来解决实时性不高且检测精度较低的问题，根据一体化智能数字座舱技术研发项目需求设计并实现了一种疲劳驾驶检测系统。主要研究内容如下： ① 基于面部特征的疲劳检测方法研究。疲劳状态表现为面部特征的变化，现有方法多通过提取显著的疲劳特征来实现，忽略了图像的多尺度特征及多层级信息。针对此问题，本文提出了一种基于多尺度特征融合的疲劳检测方法以增强特征的多层次表现能力。该方法通过多尺度特征融合策略将具有较强语义的深层特征与细节丰富的浅层特征相结合，并采用轻量、高效的门控融合模块将多尺度卷积层间的有效特征信息进行融合，充分挖掘图像中有效的特征信息，抑制无效信息，从而达到准确检测疲劳特征状态的目的。最后将多个特征指标融合形成更具鲁棒性的多特征综合的疲劳评定方式来缓解单一特征判别易出现的误判问题，能够更准确地实现驾驶员的疲劳检测。 ② 基于多尺度特征融合的疲劳检测系统设计及实现。本文基于所提出的多尺度特征融合的疲劳检测方法设计并实现了一种疲劳驾驶检测系统。该系统依赖PyQt5、Pytorch等开发环境及辅助硬件设备对各功能模块进行了实现，通过摄像头或拉取资源库中视频的方式检测驾驶员的疲劳状态，并利用脱岗检测模块来监测驾驶过程中是否存在脱岗行为。最后经测试证实了该系统能满足实时性、可用性及易用性要求，能很好地判断驾驶员状态并给予相应反馈，整体性能较好，具有一定的使用价值。  1.4 论文章节安排 本文共包括五个章节，具体的结构安排如下： 第1章：绪论。本章节首先对疲劳状态的产生原因及定义进行了介绍，并对疲劳检测的研究背景和意义进行了探讨，分析了各类检测方法的优缺点，之后阐述了疲劳检测技术的发展现状以及亟待解决的问题，最后罗列出了本文的主要研究内容以及各章节的具体工作安排。 第2章：疲劳检测相关技术基础。该章节是本文开展的前提条件，首先阐述了基于面部特征的疲劳检测方法所使用到的特征信息及其评判标准，为后续疲劳状态的判定奠定了重要基础。然后本章从卷积神经网络的基础理论入手，介绍了经典的VGG图像分类网络模型，并针对目标检测领域进行了理论分析，为后续研重庆大学硕士学位论文 8  究提供理论基础。 第3章：基于面部特征的疲劳检测方法设计与性能评估。本章首先介绍了基于面部特征的疲劳检测方法的整体架构和设计思路，随后按照整体框架逐一介绍了该方法的疲劳特征提取及检测模块。本章基于实际驾驶应用场景提出了一种多尺度特征融合网络来提取面部状态特征，之后通过将多个特征指标融合形成更具鲁棒性的多特征综合的疲劳评定方式来实现驾驶员的疲劳检测。通过在疲劳图像数据集以及视频数据集上进行了实验分析，验证了该方法的实时性、有效性和可行性。 第4章：疲劳驾驶检测系统设计与实现。本章节对疲劳驾驶检测系统进行了需求分析，并针对系统的开发环境、整体功能模块以及系统的总体流程设计进行了详细的讲述。之后采用PyQt5工具包对系统进行了GUI界面设计，通过人机交互界面展示了系统各功能模块的测试结果，针对测试结果进行了多方面的分析，验证了基于面部特征的疲劳检测方法的可行性和有效性以及本系统的可用性、实时性及易用性。 第5章：总结与展望。本章围绕本文的研究主体内容和相关实验结果总结了本文提出的基于面部特征的疲劳驾驶检测方法和系统存在的缺陷以及不足，最后对疲劳检测领域未来的研究方向和发展进行了展望。 2  疲劳检测相关技术基础 9  2  疲劳检测相关技术基础 人体疲劳是一个复杂的生理过程，人的面部特征状态会随着身体的疲劳出现显著的变化，因此需要通过选择较好的面部疲劳特征目标和判别标准来进行疲劳状态的判定，下面首先对疲劳特征的选取和判定依据进行了详细地阐述，之后本章从卷积神经网络的基础理论入手，介绍了深度学习的疲劳检测方法所使用到的经典网络模型，并对目标检测领域的基础理论进行了论述分析。  2.1 疲劳特征选取及判别标准 实验研究得出眼睛的开合程度、眨眼频率、嘴巴打哈欠动作及次数等特征与驾驶员疲劳状态有很强的相关性。因此，本文将眼部及嘴部状态作为检测的特征目标进行分析，选取了驾驶员的疲劳特征及判别标准。 2.1.1 眼部特征选取及判别标准 随着驾驶员从清醒转为疲劳状态，其眼睛的闭眼时长占比会增加，眨眼频率会出现明显的降低。因此本文采用PERCLOS和眨眼频率进行眼部特征状态判别，下面将针对这两种判别标准进行介绍。 ① PERCLOS准则 1994年4月美国公路管理局公布了PERCLOS准则是最合适的疲劳驾驶评判标准，并通过大量实验证实了PERCLOS值的有效性。PERCLOS物理量代表单位时间内眼睛闭合超过某阈值所占的时间百分比，其常用的标准有EM、P70和P80，分别代表眼睑遮挡瞳孔面积超过50%、70%以及80%的时间长度占总时长的比例。  0t2t3t420406080100t1时间(s)眼睛张开程度(%) 图2.1 PERCLOS P80原理图 Fig. 2.1 Schematic diagram of PERCLOS P80 重庆大学硕士学位论文 10  国内外学者对三种常用的PERCLOS判定标准进行了相关实验，研究得出PERCLOS中P80与疲劳状态的相关性最佳，因此，本文将P80标准作为评价驾驶员是否疲劳的基本准则，其原理图如2.1所示。图中将眼睛初始位置设定为最大瞳孔状态，其张开程度为100%，1tt=时眼睛处于80%瞳孔状态位置，2t和3t时间点代表眼睑遮挡瞳孔的面积为80%的状态，4t是又返回到眼睛闭合程度为20%状态的时间点，因此图中的14~tt是完成一次眨眼过程所需要花费的时间段，将23~tt时间段内的眼部状态标记为闭眼状态，p表示PERCLOS值，其计算方式如下式：  3241100%ttptt−=×− (2.1) ② 眨眼频率 眨眼是指眼睛从睁开到闭合再睁开的生理动作，眨眼频率通过一段时间内眨眼次数除以这段时间的时长得到。根据医学统计学研究，人在正常情况下一分钟眨眼次数为10到15次，每次眨眼之间间隔3到5秒，持续时间约为0.3秒。若眨眼频率过低，则驾驶员可能处于走神、发呆或者疲劳状态。本文通过眨眼频率来判定驾驶员的疲劳状态，首先设定好清醒状态下的眨眼频率阈值，其次将检测出的眨眼频率结果与设定好的阈值进行比较，若检测结果小于阈值则认为驾驶员处于疲劳状态，计算该时段内的平均眨眼频率如下式，其中bf为眨眼频率，bn为眨眼次数，bT为记录眨眼次数的时间长度。  bbbnfT= (2.2) 2.1.2 嘴部特征选取及判别标准 除眼部特征可以判断疲劳状态以外，嘴部特征也是判定驾驶员疲劳状态的重要特征之一，但疲劳时不一定都会出现打哈欠的动作，因此本文将嘴部的疲劳特征作为判别疲劳的辅助指标，配合眼部状态进行检测。 嘴部状态有紧闭、微张和打哈欠三种情况。通常情况下，嘴部一般会处于闭合状态或者因为聊天等动作产生小幅度的开合，当人体进入疲劳状态时，往往会不自主得发生打哈欠的行为，嘴部张开程度明显大于正常开合程度，并且持续时间较长。据统计，一次打哈欠的时间约为4秒，因此，可以依据嘴部张合程度的变化检测出打哈欠的动作，从而通过打哈欠的行为判断人体是否进入疲劳状态。 打哈欠是指嘴巴从闭合到张开再到闭合的生理动作，打哈欠频率是通过一段时间内打哈欠次数除以这段时间的时长得到。本文通过设置嘴部变化通用模板对嘴部特征状态进行评定，使用特征检测网络检测嘴部状态，并设定打哈欠频率阈值来判别驾驶员的疲劳状态，具体公式如下，其中yf为打哈欠频率，ym为打哈欠次数，yT为记录打哈欠次数的时间长度。 2  疲劳检测相关技术基础 11   yyymfT= (2.3)  2.2 疲劳检测方法理论基础 近年来，深度学习在图像识别领域掀起了一股热潮，并且凭借其强大的特征表述能力以及对非线性数据的高效拟合能力，在特征提取和分类任务中受到广泛关注。2006年，Hinton等人提出了深度学习的概念，它有两个重要特点：其一是自动提取特征，它可以避免传统方法提取特征的繁琐步骤；其二是逐层抽象，其过程是通过深度网络结构来发现数据的分布特征，通过学习得到更多、更抽象的高层特征信息。 多层感知机（Multilayer Perception，MLP）是深度学习中常见的一种结构。它以单层神经网络为基础，在输入层和输出层之间引入了一到多个隐藏层，隐藏层中的神经元与输入层和输出层中各个神经元呈全连接状态。含有一个隐藏层的多层感知模型如图2.2所示。  x2x1x3x4h1h2h3h4h5o2o1o3隐藏层输出层输出层 图2.2 多层感知机模型图 Fig. 2.2 Model diagram of a multilayer perceptron  图中各神经元连接情况如有向箭头所示，每条连接线都包括权值和偏差参数。输入层不涉及计算，它只接收需要训练的样本，之后通过隐藏层变换后进行输出，输出层神经元个数为分类任务数，计算输出方式如下式：  ()hhφ=+HXWb (2.4)  oo=+OHWb (2.5) 重庆大学硕士学位论文 12  式中X为输入样本，H为隐藏层输出，O为输出层输出，hW和hb为隐藏层权重参数和偏差参数，φ表示激活函数，oW和ob为输出层权重参数和偏差参数。 在深度学习中，以多层感知机为基础构造了很多经典的网络模型，其中包括深度神经网络（Deep Neural Network，DNN）、卷积神经网络（Convolutional Neural Networks，CNN）和循环神经网络（Recurrent Neural Network，RNN）等。由于神经网络算法相较于传统算法具有更好的自主学习能力和非线性映射能力，此外它也具有很强的适应性、实时处理能力和强容错能力，因此研究人员逐渐将各种神经网络引入到疲劳驾驶领域来检测被测者的疲劳状态，以下基于本文的研究内容介绍卷积神经网络相关理论基础。 2.2.1 卷积神经网络 卷积神经网络作为深度学习的经典算法，适用于计算机视觉领域。它是受视觉认知机制启发而来的一种前馈神经网络，CNN网络使用卷积层和池化层来替换隐藏层，相对于传统人工神经网络结构更加复杂，层数更多，具有更强大的图像表征能力，在图像分类和检测领域应用广泛，本文的工作就体现了卷积神经网络在疲劳检测方面的应用。 CNN模型图反映了特征输入到输出整个过程的变换，它能通过卷积操作自动提取输入信息中的高级特征，之后再通过反向传播算法进行参数的训练和学习。卷积神经网络主要由特征提取和分类识别两个模块构成，其中卷积、激活函数和池化操作三个部分用于提取特征，全连接层的作用在于对目标进行分类输出，其一般结构如图2.3所示。  RGB三通道图像原始图像卷积层池化层卷积层池化层全连接层Output输出... 图2.3 卷积神经网络结构图 Fig. 2.3 Structure diagram of convolutional neural network  ① 卷积层 卷积层具有多个卷积核，是提取特征的关键，它以原始数据或上一层特征图作为输入，采用不同的卷积核和滑动窗口的方式对输入样本完成卷积操作，得到卷积后的特征图。卷积层采用积分变换的数学方法对输入进行卷积运算，()yt为x、h的卷积，其公式如(2.6)所示。 2  疲劳检测相关技术基础 13   ()()()()()ytxphtpdpxtht∞−∞=−=∗∫ (2.6) 图片的卷积运算本质是将卷积核与局部感受野的值进行加权求和，实现一种特殊的模糊，若某个图像与该卷积核的卷积值较大，则认为该卷积可以很好的模拟该部分图像的特征。卷积核通常为较小尺寸的矩阵，比如11×、33×、55×等奇数，其值在初始化时被随机设置为不同的值，并在随后的网络训练过程中不断更新迭代。 卷积基本计算过程如图2.4所示，其中卷积核尺寸为33×，滑动步长为1单位，原图上的33×区域与卷积核的对应位置进行相乘并将这九个数进行线性相加就能得出该区域的特征值，之后通过窗口滑动策略计算不同位置的卷积核特征值，综合得到最后的结果。   图2.4 卷积计算过程示意图 Fig. 2.4 Schematic diagram of the convolution calculation process  ② 激活函数 在实际应用场景中，数据只有在最简单的二分类情况下才会呈现线性可分的状态，复杂场景下的数据表现为线性不可分。由于全连接层只对数据做仿射变换，线性模型的表达力不够，因此需要引入非线性变换，再输入到全连接层中，可以增强神经网络的学习和表达能力，让其能更好的解决实际问题，需要加入的非线性函数称为激活函数。常用的激活函数包括以下几种： Sigmoid函数是一种呈S型曲线的函数，可以将元素的值变换到0和1之间，其公式见(2.7)，其函数曲线如图2.5(a)所示。 重庆大学硕士学位论文 14   ()11xfxe−=+ (2.7) Tanh函数是sigmiod函数的改进，可以将元素的值变换到-1和1之间，形状与sigmoid类似并且关于原点对称，其公式见(2.8)，其函数曲线如图2.5(b)所示。  ()2211xxefxe−−−=+ (2.8) Relu函数是在2012年提出的一种新的激活函数，它提供了一个简单的非线性变换方式，公式如(2.9)所示，其函数曲线如图2.5(c)所示。  ()()max0,fxx= (2.9)   (a) sigmoid函数  (b) tanh函数  (c) relu函数 图2.5 不同激活函数示意图 Fig. 2.5 Schematic diagram of different activation functions  由图2.5(a)可以看出，sigmoid函数曲线的特点在于连续、单调和平滑，输出范围在0到1之间，它可以作为很好的阈值函数，并且其导数形式简单，计算相对容易，曾被广泛使用，但它饱和时梯度值很小，因此其缺点在于网络的权值不能得到有效的更新。同理，图2.5(b)中的tanh函数仍然存在梯度消失问题。relu函数则可以很好地解决反向传播算法在优化深层神经网络时的梯度耗散问题，并且其收敛快，成为了最常用的激活函数，如图2.5(c)所示。 ③ 池化层 由于卷积层处理后会提取出大量特征，特征过多计算量过大，网络复杂度过高则容易造成过拟合的问题，因此池化层的作用之一在于压缩特征图的大小，简化网络的计算复杂度，其二是进行特征压缩，提取出主要的特征。平均池化和最大池化操作是使用最广泛的两种方式。 平均池化操作是将输入图像中各区域的像素平均值作为该区域的平均池化后的输出值，如图2.6左箭头所指向的位置所示，其作用是使得滑动窗口中比较突出或细微的特征信息变得均匀。图2.6的右图是通过最大池化操作得到，最大池化则是取滑动窗口中该区域的最大值，它只关注该区域的最显著特征信息，其余特征2  疲劳检测相关技术基础 15  当做冗余信息丢弃，虽然该方法在一定程度上达到了增强整体特征信息的鲁棒性，但也会使泛化能力减弱，可能会产生过拟合现象。  212333167823421023523684平均池化最大池化 图2.6 池化操作示意图 Fig. 2.6 Schematic diagram of pooling operation  ④ 全连接层 全连接层通常位于卷积神经网络尾部，主要用于对上一层提取出来的局部特征做加权求和，进行特征融合，融合后的输出为一维特征向量，最后将输出的数据转化为对应的类别概率，扮演一个分类器的角色。 2.2.2 VGG网络模型 2014年，VGG网络图像分类模型被牛津大学的Karen Simonyan等人[42]提出，它针对AlexNet网络架构不规范问题提出通过重复使用简单的基础块来构建深度网络模型的思想，基于VGG块来搭建模型。2014年在ImageNet数据集上获得了75.2%的top-1准确率和92.5%的top-5准确率。 VGG网络的特点在于通过加深网络结构来提升网络的性能，它由五个VGG基础块、三个全连接层模块以及softmax输出层构成，每层之间均添加了最大池化层，激活函数是ReLU函数。其采用了比AlexNet中更小的33×卷积核和更深层次的网络，其中VGG基础块由多个填充为1、大小为33×的卷积核加上一个步幅为2、大小为22×的最大池化层构成，该网络的优势在于拓展性很强，迁移到其他图片数据上的泛化性很强，并且其网络结构非常简洁。现阶段，由于VGG网络易迁移到其他图像识别任务上，因此仍被广泛应用来提取图像特征，其中最常用的是VGG16网络模型。 由于VGG16网络模型既能保证有效的识别效果，又能兼顾计算量和速度两方面要求，并且使用该网络模型时可以加载已在多个大型数据集上训练好的网络权重参数进行初始化，使得训练收敛速度更快。由于疲劳驾驶领域的检测任务在准确率和实时性方面要求较高，基于上述分析VGG16网络能很好地满足本文多方面重庆大学硕士学位论文 16  需求，因此将其模型应用于本文的方法中，其网络模型架构如图2.7所示。  Convolution+ReLUsoftmaxFully connected+ReLUmax pooling224×224×64224×224×3112×112×12828×28×51214×14×51256×56×2567×7×5121×1×40961×1×1000 图2.7 VGG16网络架构图 Fig. 2.7 Architecture diagram of VGG16 network  2.2.3 目标检测技术 目标检测技术作为计算机视觉领域的重要基本任务，其作用在于通过算法精确定位图片的目标位置并识别出定位框的物体类别。该技术可以实时感知周围的环境，分析应用场景并快速做出相应的判断，并且可以根据具体的应用场景调整模型以适应不同的识别目标。因此，目标检测技术被广泛应用于自动驾驶感知和人脸识别领域中，以下将对传统的目标检测算法以及基于深度学习的目标检测算法进行介绍。 传统的目标检测算法普遍采用基于滑动窗口的检测策略，具有代表性的算法有VJ[43]（Viola-Jones）算法、方向梯度直方图算法（Histogram of Oriented Gradient，HOG）、DPM[44]（Deformable Part Model）算法等，其基本流程如图2.8所示。  输入候选框特征提取分类器判定目标或背景NMS输出 图2.8 传统目标检测算法流程 Fig. 2.8 Process of traditional target detection algorithm  近年来，深度学习技术推动了目标检测领域的快速发展，使得目标检测领域2  疲劳检测相关技术基础 17  取得了更大的突破。依据算法流程的阶段性而言，可以将基于深度学习的目标检测算法划分为两阶段和单阶段模型[45]。两阶段方法需要首先生成候选框再进行分类定位回归，流程图见2.9所示，其经典的主流算法有R-CNN、Fast R-CNN、Faster R-CNN等。  输入生成候选区域分类回归CNN提取特征 图2.9 两阶段目标检测算法流程 Fig. 2.9 Process of two-stage target detection algorithm  单阶段方法在两阶段方法的基础上减少了生成候选框的步骤，只需要使用卷积神经网络对特征进行提取、分类和定位回归即可，相比于两阶段方法检测速度更快，更适合在移动平台上进行部署，单阶段目标检测网络基本流程如图2.10所示。基于深度学习技术的单阶段目标检测主流算法主要包括Redmon等人[46]提出的YOLO算法及其系列和Liu等人[47]提出的SSD算法及其系列。由于疲劳检测领域需要兼顾准确率及实时性多方面要求，因此本文将单阶段目标检测网络作为疲劳特征检测部分的关键网络。  输入CNN提取特征分类回归 图2.10 单阶段目标检测算法流程 Fig. 2.10 Process of single-stage target detection algorithm  2.3 本章小结 本章针对疲劳检测所使用到的相关技术进行了详细的阐述，首先介绍了基于面部特征的疲劳检测方法所使用到的特征信息，针对眼部和嘴部区域选取了多样化的疲劳判别方式，并且详细的阐述了判定疲劳状态的标准。之后围绕基于深度学习的疲劳检测方法使用到的卷积神经网络进行了理论基础介绍，重点分析了网络中的卷积层、池化层和全连接层，并针对目标检测领域的算法进行了分析，通过对比多种目标检测网络的算法流程，结合本文的应用场景选取最适合的方法，为后续使用的目标检测网络做铺垫。    重庆大学硕士学位论文 18   3  基于面部特征的疲劳检测方法设计与性能评估 19  3  基于面部特征的疲劳检测方法设计与性能评估 通过对驾驶员进行疲劳检测来降低交通事故的发生率、提高驾驶途中的安全性是一项具有重要意义的应用。现有针对面部特征的疲劳检测方法存在诸多问题，例如实际驾驶环境存在姿态多变和光照不均等复杂场景，而疲劳特征目标在图像中占比较小，包含特征信息较少，难以消除复杂背景的干扰，从而影响检测的准确性。鉴于单阶段目标检测网络具有实时性、稳定性以及准确性较好的优势，本章基于SSD目标检测网络进行疲劳特征状态识别，针对传统SSD网络存在的缺陷提出多尺度特征融合的网络架构，通过结合多层次特征映射的互补优势来达到丰富特征细节和语义信息的目的，提高检测的准确率。最后通过将多个特征指标融合形成更具鲁棒性的多特征综合的疲劳评定方式来实现驾驶员的疲劳检测。  3.1 基于面部特征的疲劳检测方法整体架构 本文研究基于面部特征的驾驶员疲劳检测方法，其首要任务是通过摄像机录制脸部图像，获取面部特征信息，其关键和基础在于如何从图像中准确获取与疲劳相关的特征目标，并通过网络进行目标定位与状态分类，最终提取出面部特征状态进行疲劳判定。本研究提出了一种基于驾驶员面部特征的疲劳检测方法，该方法主要由三大模块组成，分别为疲劳特征选取与判定模块、面部特征提取模块以及疲劳检测模块。疲劳检测方法的整体框架设计如图3.1所示。  特征提取网络疲劳检测数据集状态队列信息疲劳判定方式（面部特征选取）眼部特征选取嘴部特征选取特征判定准则特征选取及判定模块面部特征提取模块获取的特征状态疲劳检测模块疲劳/清醒 图3.1 疲劳检测方法整体框图 Fig. 3.1 Overall block diagram of fatigue detection  图中特征选取及判定模块包括选取特征及判定指标，该部分已在第二章节中进行了详细的介绍，针对疲劳的表现形式选取了强相关的特征目标并对特征目标重庆大学硕士学位论文 20  确定状态判别标准。选取到的特征信息包括眼部和嘴部区域的疲劳特征，其判别标准包括PERCLOS、眨眼频率和哈欠频率。 面部特征提取模块是首先根据方法需要采集疲劳状态数据集，将构建好的数据集输入到面部特征提取网络中进行特征定位及状态分类，最后提取出需要用到的眼部和嘴部疲劳状态信息。 疲劳检测模块是首先设定相关疲劳参数阈值，提出综合多特征的评定方式，其次获取特征目标状态的时间队列结合特征判定阈值标准对提取到的面部特征状态进行判定，最后检测出驾驶员的精神状态。该方法能准确高效地检测出驾驶员在行车途中的实时状态，可普适于民，对降低交通事故的发生率、提高驾驶途中的安全性具有重要的意义。  3.2 数据集的采集与构建 由于通过目标检测网络提取面部特征疲劳状态的相关研究还较少，且现存没有完全符合本文疲劳场景的公开标注数据集，因此结合实际检测任务需要自行采集图像并进行图像标注。 为了采集符合本文实验的人脸图像数据集，通过录制真实场景下的视频以及获取网上公开驾驶员疲劳视频的方式进行数据集的构建，其中视频图像按照录制速度转换为每一帧的图像序列，并抽取具有代表性的图片构建所需要的数据集，因此本文构建的数据集能够保证真实性、丰富性、交互性和连续性。   图3.2 部分原始数据集 Fig. 3.2 Part of the original dataset  本文共采集了来自26名不同对象的4117张图片，在完成数据图像采集后按序列顺序对图片进行命名，并将其保存至文件夹中，为之后数据集的标注工作做3  基于面部特征的疲劳检测方法设计与性能评估 21  好前期准备，部分原始数据图像如3.2所示。由于考虑到真实驾驶场景中存在不同头部姿势、不同采集角度、不同拍摄场景、不同光照条件以及佩戴或不佩戴眼镜等因素，因此其中3416张图片是来自真实驾驶场景的图片。 由于本文所使用到的目标检测算法不依赖于人脸仅对面部特征目标进行检测，其主要任务是同时实现眼部、嘴部定位及状态识别，因此需要对上述构建好的数据集进行眼部及嘴部区域的标注。其中眼部特征目标状态有睁眼与闭眼两种，人在眨眼过程中其眼部张开程度有多种，本文采用第二章介绍到的PERCLOS P80准则对眼部的状态进行区分，即当眼睑遮挡瞳孔面积超过80%时记为闭眼状态，否则记为睁眼状态；同样，嘴部特征目标分为张嘴和闭嘴两种，打哈欠及非打哈欠情况下嘴部的张开程度也分为多种情况，打哈欠情况下嘴部张开程度比正常的嘴部状态张开程度高很多，因此基于本文特征目标状态判定的方法，按照以下设定的状态通用模板进行状态划分，如图3.3所示。  闭眼睁眼闭嘴张嘴眼部状态嘴部状态 图3.3 人眼状态与嘴巴状态模板示例 Fig. 3.3 Example of human eye state and mouth state template  原始图像的标注工作十分重要，其作用在于获取原始图像中目标物体的具体位置及状态类别。深度学习领域的数据集标注工具常用的有LabelImg、Vatic、Yolo_mark等，本文则采用LabelImg进行图像目标的标注，LabelImg是一个常用的基于Python和Qt编写的轻量级可视化的图像标注软件，通过矩形框进行标注，并将标注的目标位置信息保存在PASCAL VOC格式的xml文件中。 本文所标注的目标状态分为：睁眼、闭眼、张嘴、闭嘴四种，对应的标签信息为：open_eye、closed_eye、open_mouth和closed_mouth，通过打开已经构建好的数据集文件夹，对每张图片进行眼部及嘴部状态标注，标注时需要注意将目标完全包含在边界框的区域内，矩形框代表人工标定的区域，标定时编写相应的标签信息，每个标定区域对应的标签在标定完成后都会自动显示在右侧的标签区域中，如图3.4所示。  重庆大学硕士学位论文 22   图3.4 LabelImg标注工具示意图 Fig. 3.4 Schematic diagram of LabelImg labeling tool  图片标注完成后都会生成一个xml文件，其文件名与对应标注的图片名一致，它包括图片高宽、状态类别标签以及目标矩形框的位置坐标和状态等信息，目标的详细信息如图3.5所示。   图3.5 xml标注文件内容 Fig. 3.5 Contents of xml annotated files 3  基于面部特征的疲劳检测方法设计与性能评估 23  完成标注工作后按照PASCAL VOC数据集标准将索引文件、原图和生成的标注文件分别存储在相应的目录结构中，其中ImageSets文件夹下的Main文件用于存放训练、验证和测试图片名索引的txt文件，trainval.txt文件为train.txt和val.txt的总和，其中训练集和验证集之比为7:3，test.txt文件是测试集的图片索引，它占总数据集的20%；原始数据集图片存放在JPEGImages文件夹中；LabelImg生成的xml文件保存至Annotationas文件夹下。  3.3 基于改进SSD的面部特征提取网络 SSD网络是Wei Liu等人提出的一种使用单个深层神经网络进行端到端检测图像中目标的方法，它结合了YOLO系列的回归原理以及Faster R-CNN中的锚机制是一种优秀的单阶段目标检测网络。SSD网络采用不同尺度的先验框对多尺度特征图进行回归处理，可以很好地实现速度和检测精度上的平衡，因此本文采用该网络作为研究疲劳检测的基础，通过该网络实现对眼部及嘴部区域的定位及状态分类，为后续能很好地进行疲劳状态判定奠定基础。 3.3.1 传统SSD网络架构及基本原理 SSD网络模型是以VGG16为基础的特征提取网络外加多尺度特征检测的辅助卷积神经网络构成。其主要思想就是使用CNN网络提取不同尺度目标物体的特征，并通过不同尺度和长宽比的先验框均匀地在图片的不同位置进行密集抽样，直接预测物体位置、判定所属类别、计算置信度，最后结合多尺度特征图的特征信息利用非极大值抑制[48]（Non-max Suppression，NMS）算法给出检测的结果，其网络模型架构如图3.6所示。  Conv9_2SSD3003003003输入图像VGG16网络（到Conv5_3）Conv4_3Conv6（FC6）Conv7（FC7）Conv8_2383819191919101051210241024512Conv:3×3×1024Conv:1×1×1024Conv:1×1×256Conv:3×3×512-s2Conv:1×1×128Conv:3×3×256-s255256Conv:3×3×(4×(Classes+4))Conv:3×3×(6×(Classes+4))Conv10_2Conv11_22561133256Conv:1×1×128Conv:3×3×256-s1Conv:1×1×128Conv:3×3×256-s1每个类输出8732个先验框NMS多尺度特征图Conv:3×3×(4×(Classes+4)) 图3.6 SSD300网络架构图 Fig. 3.6 Architecture diagram of SSD300 network  图3.6展示了图片输入大小为300300×的SSD网络模型。由图可见，由于两重庆大学硕士学位论文 24  部分网络需要直接相连进行操作，因此SSD网络在经典的VGG16网络结构上做了如下修改：采用Conv6和Conv7替换VGG16原有的2个全连接层FC6和FC7；为保证输入到Conv6卷积层的特征图大小保持不变调整前一层的最大池化层的池化核大小为33×，步长为1，填充为1；Conv6卷积层采用33×，膨胀率为6的膨胀卷积核来增大感受野；Conv7卷积层采用11×的卷积核不改变空间位置信息，只进行维度信息的融合。SSD网络的核心设计理念可以总结为以下三个方面： ① 输出多尺度特征图用于检测 由于卷积神经网络中特征图的尺寸与卷积层的深度成反比，因此可以根据不同的卷积层位置输出不同的特征图，特征图提取位置见图3.6中网络紫色部分所示，SSD300网络选取了6个不同尺度的特征图用于检测。图3.7可以看出，不同尺度的特征图能有效检测不同尺度的特征目标，小目标物体可以通过大尺寸特征图来检测，而小尺寸特征图更有利于大目标的检测。例如：88×的特征图相较于44×的特征图有更多的单元格，但每个单元的先验框尺度较小。   图3.7 不同尺度特征图视野 Fig. 3.7 Views of feature maps at different scales  ② 全过程采用卷积层输出进行检测 SSD网络未采用全连接层进行输出，而是对多尺度的特征图进行卷积操作输出两个预测值，实现分类预测和位置调整，这样可以减少网络的参数、提高检测的效率。例如：尺寸为mnp××的特征图，通常使用33p××的小卷积核进行卷积操作，并依据回归和置信预测需要使用的通道数进行输出，通过卷积处理后产生类别分数或相对于先验框的坐标偏移量。 ③ 设置不同尺度和长宽比的先验框 使用多尺度特征图进行目标检测的关键在于设置不同尺度和长宽比的先验框，依据上述②可知需要对获取到的每一个有效特征层进行两个不同的操作，分别输出_4numanchors×和__numanchorsnumclasses×的预测值，_numanchors指的是特征图中每个像素点所对应的先验框数，_numclasses是需要识别的分类数。因此3  基于面部特征的疲劳检测方法设计与性能评估 25  模型中的特征图输出计算公式可以理解为每个像素点的先验框个数与分类类别数和四个位置信息之和的乘积。对于SSD300网络采用4，6，6，6，4，4个先验框对六个特征层分别进行输出，最终获得8732个先验框，具体特征图先验框的详细信息见表3.1所示。  表3.1 特征图的先验框信息 Table 3.1 Prior box information of the feature map 多尺度特征图 先验框（个） 多尺度分支的回归特征图 多尺度分支的分类特征图 Conv4_3(38, 38, 512) 4 (38, 38, 16) (38, 38, 4_numclasses×) Conv7(19, 19, 1024) 6 (19, 19, 24) (19, 19, 6_numclasses×) Conv8_2(10, 10, 512) 6 (10, 10, 24) (10, 10, 6_numclasses×) Conv9_2(5, 5, 256) 6 (5, 5, 24) (5, 5, 6_numclasses×) Conv10_2(3, 3, 256) 4 (3, 3, 16) (3, 3, 4_numclasses×) Conv11_2 (1, 1, 256) 4 (1, 1, 16) (1, 1, 4_numclasses×)  通常情况下每个单元设置的多个先验框都存在一定的差异，如图3.8所示，各个特征图的每个像素点都使用了4种不同尺度scale和长宽比ar的先验框，先验框的尺寸和形状分别由获取到的特征图的大小及不同的横纵比决定，并且先验框的大小随着特征图尺寸的降低而增加。   图3.8 先验框示意图 Fig. 3.8 Schematic diagram of the prior box  生成先验框的尺度由以下公式得到，其中m表示特征图个数，由于Conv4_3特征图单独设置，因此m的值为5；ks表示先验框大小相对于特征图的比例；mins和maxs表示比例的最小值和最大值。   重庆大学硕士学位论文 26   ()maxminmin-1,[1,]1ksssskkmm−=+∈− (3.1) 将先验框的长宽比设置为ra，每个先验框的宽度akw和高度akh可根据以下公式进行计算：  111,2,3,,23ra∈ (3.2)  akkrakkrwsasha== (3.3) 默认情况下，每个特征图都有一个正方形的先验框，其= 1ra且尺度为ks，除此之外，网络还设置了一个尺度为'1kkksss+=且= 1ra的先验框，因此，每个特征图都有两个长宽比为1但尺度不同的正方形先验框，特征图的6个先验框长宽比设置如下：  '111,2,3,,,123ra∈ (3.4) Conv4_3，Conv10_2，Conv11_2层的特征图未使用到长宽比为3和13的先验框，因此只有4个先验框作为输出。每个像素单元格的中心点处于各单元格的中心位置，其中心位置如下式，kf表示第k个特征图的尺寸。  0.50.5,,,[0,)kkkijijfff++∈ (3.5) 综上所述，SSD网络采用不同尺度的多个特征图对特征目标进行预测，该网络可以适配不同大小尺度的目标，并且采用小卷积进行分类回归大大降低了参数，提高了检测速度。 3.3.2 多尺度特征融合网络架构 基于真实环境实现驾驶员疲劳检测存在以下挑战：其一检测的驾驶环境存在多变复杂的情况，增加了精准检测目标的难度，易出现漏检情况；其二基于眼部及嘴部区域的小目标检测任务，目标识别和定位的矛盾会更加突出，导致其检测的精度不高。因此如何增强图像的细节处理能力，在复杂环境中精准地提取目标并准确地判断其状态是本节研究的重点内容。 由图3.6可知，由于传统SSD算法仅在各个不同尺度的特征层上单独进行输出预测，层与层之间没有联系，而浅层特征图有利于目标定位但缺乏足够的语义信息，随着卷积神经网络的加深，特征映射可以表示更多的语义信息，有利于目标识别但不利于目标定位，因此，该网络难以解决目标识别和定位之间的矛盾问题，无法获取图像中有用的多层信息。除此之外，眼部及嘴部属于小目标检测范3  基于面部特征的疲劳检测方法设计与性能评估 27  畴，而其检测任务依赖上下文信息[49]，该网络没有充分地利用局部的细节特征和全局的语义特征[50]。 针对传统SSD网络存在的缺陷，本文对传统SSD网络进行了改进，通过多特征层的融合策略和轻量、高效的特征融合模块将细节特征与全局语义特征相结合，提出一种多尺度特征融合架构的网络模型进行疲劳检测，该模型能很好地缓解传统SSD网络目标探测器存在的目标定位和识别之间的矛盾问题，如图3.9所示。  VGG16Conv4_3Conv7(FC7)Conv9_219×19×1024300×3009×9×256Conv 1×1Conv1×1Bilinear Interp38×38×256GFF38×38×512X3X2GFFGFF38×38×25638×38×2565×5×2563×3×2561×1×25638×38×51210×10×51219×19×512X1XNGateGate...G1GNXLGateGL1-GLLX加法乘法NMSDetections:8732GFF模块示意图特征融合模块图中：N LX2X3X1X3X1X21X2X3X 图3.9 多尺度特征融合的网络架构 Fig. 3.9 Network architecture for multi-scale feature fusion  该架构采用多尺度特征融合的思想加强各个特征层之间的联系，结合卷积神经网络高低层各自的优势，联合高低层特征图的有用特征信息，通过增加浅层特征图的语义信息及深层特征图的定位信息来提高目标的检测精度，减少漏检情况，以达到更好的性能。 本文主要定义了多尺度特征融合网络的体系结构，通过特征融合模块的框架搭建深度卷积神经网络，其保留原始VGG16的基础网络不变，将额外增加的卷积层结构进行修改，并将不同层次、不同尺度的特征投影信息拼接在一起，之后通过下采样子模块将融合的特征图调整为同一尺度，最后通过门控融合模块对同一尺度大小的不同特征图进行多尺度特征融合，再将融合后的特征层作为基础生成新的特征金字塔，并做归一化处理。该网络主要通过多尺度特征层融合策略以及重庆大学硕士学位论文 28  门控融合模块[51]（Gated Fully Fusion，GFF）来实现，具体描述如下： ① 多尺度特征层融合策略 由于金字塔特征层从低到高小目标定位信息逐渐减弱，语义信息逐渐增强，因此需要选择的特征层为小目标定位信息较强的浅层和语义信息较丰富的深层，以及综合上下文信息的一个中间层。根据需要，本文选择VGG16的Conv4_3、Conv7（FC7）和新增卷积层的Conv9_2作为融合的特征层。其中Conv8_2层在传统SSD网络基础上进行修改，将其步长大小调整为1，此时Conv9_2层输出的卷积特征图应为99256××。 将特征层输入到GFF融合模块之前需要将其变换为相同大小的卷积特征图，变换方式如下式：  ()'iiiX=XΓ (3.6) 式中iX表示需要被融合的特征图，包括Conv4_3、Conv7（FC7）、Conv9_2。每个被融合的特征层都需要经过一个变化函数iΓ将其缩放至同一尺度，针对Conv4_3层而言，通过11×卷积核将其通道数调整为256，Conv7（FC7）、Conv9_2两个特征层通过双线性插值将特征图的大小调整到3838×，并通过11×卷积核调整通道数至256，所有的卷积层后面都跟一个BN层和ReLU激活函数。 ② 门控融合模块 若仅通过高层特征和低层特征直接结合的方法进行特征融合会使得大量无用信息掩盖有用信息，通过GFF门控融合模块结合多层次特征映射的互补优势进行多尺度特征图的特征融合，可以在大量无用信息的干扰下聚合各层间的有用信息来达到丰富细节和增强语义的目的。 GFF门控融合模块具有双重选通机制，它使用门控机制去像素级衡量每个特征向量的有用性，不仅可以通过门将有用的信息调整到正确的位置，还可以有效地抑制发送端和接收端的无用信息，避免信息冗余，从而控制信息的融合。该方法可以最小化网络中的冗余信息，使其能够以更有效的方式融合多层次特征图，实现公式如下所示：  {}{}1212,...,...fLLXXXXXX→ (3.7)  ()()1,11LLLLLiiiiLXGXGGX=≠=+×+−××∑ (3.8) 式中{12,...LXXX}是被选定的特征图，{12,...LXXX}是被门控模块处理后的输出特征图。LG是第L层的特征层LX通过门获得的响应图，只有当iG的值很大而LG的值很小的时候()1LG−公式部分才能起作用，将从第1层开始除第L层以外的所有特征层的有用信息被融合到该特征层LX中。例如：1X特征层的有用信息在网络传输到3X层的时候消失了，此时采用门模块可以放大3X层原有的有用信息，并且将3  基于面部特征的疲劳检测方法设计与性能评估 29  1X层的有用信息有效融合到3X层中。 使用GFF门控模块进行特征融合的目的是减少无用的冗余信息，融合更多的全局有用信息，在这种融合模块的作用下可以有效缓解目标的定位和语义特征存在矛盾的问题，能结合多层次特征映射的互补优势提高目标的检测精度，最后将通过GFF门控模块处理后的多特征层使用连接的方式进行结合，并生成新的特征金字塔，特征金字塔获取的多尺度特征图的大小及使用的各个像素的特征框个数与传统的SSD网络一致，将它们用于目标位置和分类检测。 3.3.3 多尺度特征融合网络的训练方法 在多尺度特征融合网络的训练中，首先需要对每一个图像样本进行预处理使其能很好地适配该网络，并通过数据变换增强的方式来提高模型的鲁棒性。之后经过网络处理输出不同尺度的特征图，通过卷积层获取各个特征图中的像素先验框合集。最后将获取到的所有先验框与该图像的目标真实框匹配，匹配成功则作为正样本参加分类和回归训练，生成分类置信度和正确的定位框，若匹配不成功则视为负样本只进行分类训练。因此，该网络的训练过程主要由图像预处理、先验框匹配策略、损失函数以及难例挖掘4个部分组成。 ① 图像预处理 通过对训练的图片进行数据增强处理来提高模型的泛化能力和实际应用下的算法稳定性，并且能让模型对多种不定情况下的目标有更好的鲁棒性。其使用了包括光学变换与几何变换在内的多种图像处理方法，其整体流程如图3.10所示。  输入对比度随机调整饱和度随机调整色调随机调整亮度随机调整通道随机变换随机扩张随机裁剪随机镜像变换缩放到固定比例去均值光学变换几何变换 图3.10数据增强流程图 Fig. 3.10 Flow chart of data enhancement  其中光学变换主要采用的技术有亮度，对比度，色相与饱和度的随机调整、随机调换颜色通道，几何变换操作主要有随机扩展、随机裁剪、水平翻转等操作，经数据增强处理后的图片见3.11所示。由于大部分操作为随机过程，因此能够保证图像的丰富性，提升模型的泛化能力。 重庆大学硕士学位论文 30  原图几何变换镜像翻转随机扩充随机裁剪尺寸调整：300×300光学变换对比度调整饱和度调整色调调整亮度调整颜色通道调整 图3.11数据增强处理 Fig. 3.11 Enhanced processing of data  ② 先验框匹配策略 网络训练阶段会将先验框与目标真实框相匹配，若先验框匹配成功则用于预测该样本，该算法中采用交并比（Intersection over Union，IoU）最大匹配原则，即通过计算真实框与先验框的交并比找出与每个真实框交并比最大的先验框匹配，其中计算IoU的公式如下：  (),ABABJABABABAB∩∩==∪+−∩ (3.9) 通过上述IoU的计算方式可以确保每个真实框都能与一个先验框匹配，若其余先验框中存在与真实框IoU值大于0.5的情况，也将它与对应的真实框匹配，因此，一个真实框至少能与一个先验框匹配，但一个先验框仅能与其IoU值最大的真实框匹配，匹配成功的先验框视为正样本，其余则为负样本。 ③ 损失函数 该算法的损失函数定义为位置损失(),,locLxlg和置信度损失函数(),confLxc的加权和：  ()()()()1,,,,,,conflocLxclgLxcLxlgNα=+ (3.10) 式中l表示预测框的参数，g表示真实框的参数，c是类别信息置信度的预测值，α系数因子用于平衡两类误差占比，默认情况下为1，N是匹配到真实框的正样本先验框数量，若0N=则(),,,0Lxclg=。 位置损失函数(),,locLxlg采用SmoothL1 loss[52]函数进行计算，可以很好地避免训练初期预测值与真实值差异过大导致训练不稳定，以及训练后期预测值与真3  基于面部特征的疲劳检测方法设计与性能评估 31  实值差异过小难以收敛到更高精度的情况，其计算如下所示：  ()(){}1,,,ˆ,,NpmmlocijLijiPosmcxcywhLxlgxsmoothlg∈∈=−∑∑ (3.11)  ˆcxcxjicxjwigdgd−= (3.12)  ˆcycyjicyjhigdgd−= (3.13)  ˆlogwjwjwiggd= (3.14)  ˆloghjhjhiggd= (3.15)  ()210.5      if 10.5   otherwiseLxxsmoothxx<=− (3.16) 式中mil代表了第i个正样本的位置偏差量预测值，ˆmjg代表第i个正样本和第j个真实框的位置偏差真实值，(),,,cxcywh表示矩形框位置，(),cxcy为矩形框中心位置，w代表宽度，h代表高度。0pijx=作为一个指示参数，当该值为1时表示第i个先验框与第j个真实框匹配成功，并且真实框的类别为p，0pijx=时则表示匹配不成功，因此仅对正样本进行位置误差的计算。 置信度损失函数(),confLxc采用Softmax Loss函数进行计算，其实现如下式：  ()()()0osˆˆ,logNppconfijiiiPiNegLxcxcc∈∈=−−∑∑ (3.17)  ()()expˆexppipipipccc=∑ (3.18) ④ 难例挖掘 通过匹配策略完成先验框与真实框配对后，由于配对的正样本数量仅占所有先验框合集中的一小部分，此时负样本数量远高于正样本数量，为保证正负样本数量均衡则使用困难样本挖掘的方法对负样本进行抽样选择，从而保证模型的训练效果。难例挖掘策略的原则是首先选取所有的正样本数量作为输入pN，之后将所有负样本的置信度损失值进行递减排序取前3pN作为真实训练的负样本，通过该方式来确保正负样本的比例为1:3。难例挖掘策略能加速网络模型的优化，使得训练更加稳定。 如图3.12所示，本文是将眼部和嘴部作为目标检测的区域，可以看出简单正样本与真实框的交集远大于阈值，简单负样本几乎与真实框没有交集，困难负样本和困难正样本与真实框的交集在阈值附近，区分较为困难。简单负样本对损失重庆大学硕士学位论文 32  值的影响小但其数量占比大，不利于网络的训练，困难样本挖掘的作用即消除负样本在损失值中的引导性作用。  简单正样本简单负样本损失值小困难负样本困难正样本损失值大训练重点 图3.12 正负样本示意图 Fig. 3.12 Schematic diagram of positive and negative samples  3.3.4 实验与结果分析 为证实多尺度特征融合架构的有效性，使用构建好的VOC数据集对改进前后的网络进行训练及测试。本文通过对比实验来验证两个模型识别面部特征目标状态的效果。 ① 实验环境配置 本文所采用的实验环境配置如表3.2所示。  表3.2 实验环境配置信息 Table 3.2 Configuration information of the experimental environment 名称 配置条件 操作系统 Ubuntu 16.04 CPU Intel(R) Core(TM) i7-9700K GPU GeForce RTX 2080 Python 3.7.11 Pytorch 1.7.1 CUDA 10.1 cuDNN 7.3.1  本文采用Python开发编程语言编写该网络的疲劳检测算法，基于Pytorch深度学习框架进行网络模型的搭建，其版本为1.7.1，操作系统为Ubuntu64系统，使用的GPU为GeForce RTX 2080，采用10.1的CUDA版本进行加速运算。 ② 实验参数设置及网络训练 3  基于面部特征的疲劳检测方法设计与性能评估 33  本文采用迁移学习[53-55]的思想进行网络的训练，迁移学习指的是将其他数据集上训练好的网络模型用于本文适用环境中的学习任务，即将预训练的权重文件导入需要训练的网络模型中，通过预训练的方式对VGG16基础网络模型参数进行初始化，这样可以提高样本不充足情况下的任务分类识别结果。由于本文加载的预训练模型已在多个大型数据集上进行了数万次的训练，因此该基础模型参数已经得到了一定的优化效果，对于本文识别眼部及嘴部状态的驾驶疲劳特定任务场景而言，仅需要对该场景下的数据集中的目标特征进行针对性的学习即可，使用特定数据集调整后的网络模型可以在一定程度上减少训练的时间。 训练中使用随机梯度下降（Stochastic Gradient Descent，SGD）优化器作为优化算法，其动量因子参数为0.9，学习率为4510−×，学习率衰减率设置为0.1，权重衰减系数设置为4510−×，一个批次的大小为32，迭代次数为100000次，图3.13为网络训练后得到的损失曲线图。   (a) 传统SSD网络损失值曲线  (b) 多尺度特征融合网络损失值曲线 图3.13 网络改进前后训练损失值曲线图 Fig. 3.13 Plot of training loss values before and after network improvement  由损失曲线图可以看出随着迭代次数的增加损失值逐渐下降。在训练开始时，传统SSD网络的损失值为28左右，多尺度特征融合网络的损失值在15附近，迭代了5万次之后两个网络的损失值均趋于稳定，最后损失值都能收敛到1附近。 ③ 模型测试及结果分析 1）实验评估指标 本研究采用目标检测网络进行疲劳状态特征提取，该实验为多标签的图像分类任务，因此不能以单标签的分类标准来评定，需要采用多标签图像分类标准均值平均精度（mean Average Precision，mAP）指标来评判模型的好坏，该指标也是目前主流的目标检测模型的评价指标。 重庆大学硕士学位论文 34  mAP指标是针对整个数据集所有类别而言的，它是通过各类AP取平均值得到，AP是针对数据集中某一个类别而定义的，它的计算需要通过精确率和召回率得到。精确率（Precision）是指模型检测出来的某类别的目标中真实属于该类别的数量占检测出的该类别目标总数的比例；召回率（Recall）是指检测到的某类别目标中真实属于该类别的数量占该类别实际样本集正样本总数的比例。精确率和召回率的具体定义如图3.14所示。  FNTPTNFPPrecision =Recall =正类负类 图3.14 评估指标示意图 Fig. 3.14 Schematic diagram of evaluation indicators  其中TP（True Positives）代表真正例；TN（True Negatives）是真反例；FP（False Positives）是假正例；FN（False Negatives）是假反例。依据3.14示意图，精准率和召回率的计算公式如下所示：  TPPrecisionTPFP=+ (3.19)  TPRecallTPFN=+ (3.20) 将训练好的模型权重文件进行测试可得到该模型的精确率和召回率，根据计算某一类别P-R曲线下的面积来获得该目标类别的平均精确度AP值，在对比实验时AP越高则说明分类效果越好，最后将所有类别的AP值求平均即可得到该模型的mAP值。由于本文需要对多特征进行状态识别分类，属于多标签任务，因此mAP指标越好则说明网络模型越佳。 2）实验对比分析 本文采用mAP指标对训练好的网络模型进行测试，即对测试集图片进行人眼睁闭与嘴部开合状态的检测。表3.3展示了网络改进前后经过不同迭代次数测试得到的mAP值，图3.15展示了网络改进前后总体mAP对比图。  3  基于面部特征的疲劳检测方法设计与性能评估 35  表3.3 改进前后网络的mAP指标 Table 3.3 The mAP metrics of the network before and after the improvement mAP指标 迭代次数（次） 传统SSD网络 多尺度特征融合网络 10000 0.9152 0.9224 20000 0.9246 0.9234 30000 0.9035 0.9441 40000 0.9230 0.9265 50000 0.9049 0.9269 60000 0.9052 0.9268 70000 0.9029 0.9270 80000 0.9055 0.9271 90000 0.9058 0.9271 100000 0.9059 0.9271   图3.15 不同迭代次数的mAP指标对比图 Fig 3.15 Comparison of mAP indicators for different iterations  图3.15中，传统SSD网络在迭代次数达到2万次时为模型的最优状态，其mAP值为0.9246，多尺度特征融合网络在迭代到3万次时表现最佳，其mAP值为0.9441。对比网络改进前后最优状态下的mAP值可知，本文提出的多尺度特征融合架构的网络模型在整体表现出更好的检测性能，能更好的识别特征目标状态，重庆大学硕士学位论文 36  在mAP指标上的提升近2%。因此，该实验验证了多尺度特征融合架构的有效性，它能充分利用各个特征层间的有效信息，通过融合目标定位信息较强的浅层和语义信息较为丰富的深层，结合多层次特征映射的互补优势达到了丰富特征细节和语义的目的。 为更好地掌握模型检测各个类别的情况，选取上述两个网络中最优状态下的各类AP指标进行对比分析，各类别AP值如表3.4所示，通过图3.16可以更加直观的对比各类指标的具体情况。  表3.4 改进前后网络最优状态下的各类AP值 Table 3.4 Various AP values in the optimal state of the network before and after the improvement 网络模型 closed_eye open_eye closed_mouth open_mouth 传统SSD网络 0.9045 0.8905 0.9062 0.9969 多尺度特征融合网络 0.9734 0.9040 0.9075 0.9915   图3.16 改进前后网络最优状态下的各类AP值对比图 Fig. 3.16 Comparison chart of various AP values in the optimal state of  the network before and after the improvement  对比图3.16中各个类别的AP指标可知，通过多尺度特征融合网络能很好地提升眼部状态的检测能力，其中闭眼状态类别的AP值从90.45%提升到了97.34%，该类别的AP值提升了6.9%，睁眼状态下的AP值从89.05%提升到了90.4%，其AP值提升了1.4%，因此实验结果证实了多尺度特征融合架构能更好地检测小目标的特征状态。对于嘴部特征状态而言，多尺度特征融合网络在闭嘴状态的类别中0.99690.90620.89050.90450.99150.90750.9040.97340.800.850.900.951.00open_mouthclosed_mouthopen_eyeclosed_eye多尺度特征融合网络传统SSD网络3  基于面部特征的疲劳检测方法设计与性能评估 37  AP值提升了0.13%，但由于嘴部状态的检测性能在传统的SSD网络中已经达到了较高的水平，其张嘴的AP值已达到99.7%，能很好地分辨出张嘴和闭嘴状态，因此改进前后AP指标相差不大。通过最佳状态的权重文件测试得到的各类AP值中睁眼、闭眼和闭嘴这三个类别状态的AP值均有所提高。  表3.5 改进前后网络的计算成本比较 Table 3.5 Computational cost comparison of network before and after improvement 网络模型 mAP（%） FLOPs（G） Params（M） 传统SSD网络 92.46 30.6 24.1 多尺度特征融合网络 94.41 37.4 32.5  表3.5中研究了本文所提出的多尺度特征融合网络与传统SSD网络的计算开销，其中本文提出的方法相较于基准SSD网络有所增加，但mAP指标提升较为明显，因此，本文提出的多尺度特征融合的网络模型相较于传统SSD网络模型提高了面部特征状态的检测准确率，能更有效地保障行车中的安全。为检验提出的网络模型是否满足实时性要求，将帧率作为实时性的检测指标来测量网络的检测速度，通过总测试图片数除以总测试时间计算得到该网络的帧率能达到39帧/秒（frames per second，fps），因此能很好地满足实时性要求。   (a)  (b)  (c)  (d)  (e)  (f) 图3.17 选取的图片示意图 Fig. 3.17 Schematic diagram of selected pictures 重庆大学硕士学位论文 38  为更直观的展示多尺度特征融合网络的鲁棒性，本文将图片进行测试，通过网络输出检测效果图的方式进行漏检情况和置信度对比。考虑到真实场景中存在不同头部姿势、不同采集角度、不同拍摄场景、不同光照条件以及佩戴或不佩戴眼镜等因素，本文选用多张极具代表性的图片进行了实验对比，选取的图片如图3.17所示。 漏检对比：由图3.18所示，其中a1~a3展示了传统SSD网络的测试效果图，由识别结果可以看出图片在曝光，光线较暗以及侧脸等情况下存在漏检现象，无法完整检测出面部所有的特征区域；b1~b3展示了多尺度特征融合网络的测试效果图，通过实验测试图的对比可以看到多尺度特征融合网络能很好的避免上述漏检情况。   (a1)  (a2)  (a3)  (b1)  (b2)  (b3) 图3.18 改进前后漏检情况对比图 Fig. 3.18 Comparison of missed inspections before and after improvement  置信度对比：网络改进前后的置信度对比图见3.19所示，a1~a3展示了传统SSD网络的测试效果图，b1~b3展示了多尺度特征融合网络测试效果图。图中展示了每张图片的检测置信度详细结果，能清晰地看出多尺度特征融合网络的置信度值比传统SSD网络更优。  左open_eye: 无右open_eye: 0.96closed_mouth: 0.94左open_eye: 0.88右open_eye: 0.72closed_mouth: 无左closed_eye: 0.91右closed_eye: 无closed_mouth: 0.70左open_eye: 0.52右open_eye: 0.91closed_mouth: 0.98左open_eye: 0.80右open_eye: 0.78closed_mouth: 0.99左closed_eye: 0.92右closed_eye: 0.96closed_mouth: 0.733  基于面部特征的疲劳检测方法设计与性能评估 39   (a1)  (a2)  (a3)  (b1)  (b2)  (b3) 图3.19改进前后置信度对比图 Fig. 3.19 Comparison of confidence levels before and after improvement  3.4 基于面部多特征的疲劳检测方法 3.4.1 多特征综合的疲劳评定方式 眼睛的开合程度、眨眼频率以及打哈欠频率都与驾驶员的疲劳程度有直接或间接的关系。每个特征都可以作为疲劳或清醒状态的判定条件，但在某些情况下非疲劳状态也能达到单个特征的疲劳标准导致误判，因此本文提出多特征综合的评定方式对驾驶员的状态进行判定，能够更准确地判断驾驶员的实时状态。 据文献统计，Walt Wierwile[56]研究得出，驾驶员处于清醒状态时PERCLOS值较低，通常处于00.15f<≤范围内，随着疲劳程度的加深，PERCLOS值越来越大，文献[57]采用了该阈值作为疲劳的判定条件；万玉丽等人[58]采用PERCLOS和眼睛持续闭合时长相结合的方式来判定疲劳状态，目前将多因素作为疲劳判定条件的方式广泛应用于疲劳驾驶研究中[59-61]；董迎春等人[62]通过比较不同状态下的PERCLOS和眨眼频率参数值，结合这两个参数来评判疲劳状态，将PERCLOS大于0.2且每秒眨眼频率小于0.2次的状态记为疲劳。为进一步确保PERCLOS值在不同疲劳状态下的变化，本文采集了4种不同疲劳状态下的视频对PERCLOS值的变化进行了测试，视频包括清醒、轻度疲劳、中度疲劳以及重度疲劳状态，150帧图像的测试结果见图3.20所示。 由3.20测试结果图可知，驾驶员在清醒状态时PERCLOS值较低，而疲劳状态下的PERCLOS值均有超过0.4的情况，并且随着疲劳程度的加深超过0.4的比左open_eye: 0.78右open_eye: 0.98closed_mouth: 0.55左open_eye: 0.85右open_eye: 0.93closed_mouth: 0.88左open_eye: 0.98右open_eye: 0.87closed_mouth: 0.99左open_eye: 0.96右open_eye: 1.00closed_mouth: 0.88左open_eye: 0.97右open_eye: 1.00closed_mouth: 0.96左open_eye: 1.00右open_eye: 1.00closed_mouth: 1.00重庆大学硕士学位论文 40  例逐渐增加，因此结合上述阈值选取条件及文献分析，本文使用PERCLOS值和眨眼频率综合判定眼部的疲劳状态，其中将PERCLOS参数的阈值设置为0.4，每秒眨眼频率参数的阈值设置为0.2，并将嘴部状态作为辅助特征与眼部疲劳状态进行综合考量。针对嘴部判定条件而言，本文将张嘴状态持续时间超过2秒作为一次打哈欠动作，在计算打哈欠频率时，将单位时间设定为1分钟，哈欠参数阈值设定为6次，因此哈欠频率的阈值被设定为0.1。多特征参数设定及综合判定方式如图3.21所示。  图3.20 不同状态下PERCLOS值的测试图 Fig. 3.20 Test chart of PERCLOS values in different states  Nperclos > 0.4N0.1yawnfNYYY疲劳状态清醒状态0.2blinkf开始结束 图3.21 多特征综合评定流程图 Fig. 3.21 Flow chart of multi-feature comprehensive assessment 3  基于面部特征的疲劳检测方法设计与性能评估 41  3.4.2 基于多尺度特征融合的疲劳检测方法 本文研究基于驾驶员面部特征的疲劳检测方法，其首要任务是通过摄像机录制脸部图像，获取脸部特征信息完成检测，由于上述章节已经证实了多尺度特征融合网络的优势，因此本节采用多尺度特征融合网络进行特征状态的提取，将输出得到的眼部和嘴部特征状态时间序列用于疲劳检测。 在实际应用中通过摄像头采集驾驶员的视频图像，并将每一帧的图片送入训练好的多尺度特征融合网络模型中提取眼部和嘴部区域的标签信息。依据该标签信息可以确定需要保存的状态，本文将睁眼状态和张嘴状态信息标记为“1”，闭眼状态和闭嘴状态标记为“0”。如表3.6所示。  表3.6 状态标签对照表 Table 3.6 Checklist for status labels 部位 状态标签 标记信息 眼部 open_eye 1 closed_eye 0 嘴部 open_mouth 1 closed_mouth 0  本文通过采集一段时间内的驾驶员眼部和嘴部状态信息来计算疲劳相关参数，因此考虑使用队列的形式保存状态信息，将检测到的结果存入初始化定义好的队列中，如图3.22所示。  711654321101111189101112131415111000 图3.22 状态队列信息 Fig. 3.22 Status queue information  存储到一定时间段内的状态队列信息后需要进一步计算PERCLOS值、眨眼频率以及打哈欠频率值。由于队列中的信息以整数“1”和“0”的形式存在，因此由视频中记录为闭合状态的帧数除以有效总图像帧数来计算PERCLOS值，在计算PERCLOS值时，将队列中的元素值之和作为眼部睁开的帧数量，将队列长度与眼重庆大学硕士学位论文 42  部睁开帧和之差作为眼部闭合状态的帧数量，实现公式如下：  1()qopenqqLSperclosavgSL−==− (3.21) 式中qL是存储的队列的长度，openS是队列中所有元素的和，即眼睛睁开状态所占的帧数量，qS表示队列中所有值的总和，()qavgS是将队列中所有元素相加取平均数。 眨眼频率通过眨眼动作计算得到，考虑到检测的实时性要求，将队列中出现的1-0-1状态记为一次眨眼动作。眨眼频率的计算则通过存储的队列长度和统计时长决定，本系统将单位时间设定为30秒来计算眨眼频率，下式中blinkt为统计时长，blinkn为统计时间内的眨眼次数，blinkf为眨眼频率。  blinkblinkblinknft= (3.22) 哈欠频率的计算与眨眼频率相似，为避免误判，短暂的张嘴状态不能判定为打哈欠，只有当嘴部存在超过2秒的张嘴状态时则可以判断为一次打哈欠动作，即产生“111……10”的队列。本系统将打哈欠的单位时长设定为60秒来计算打哈欠频率，下式中yawnt为统计时间，yawnm为统计时间内的打哈欠次数，yawnf为打哈欠频率。  yawnyawnyawnmft= (3.23) 3.4.3 实验与结果分析 本文通过测试视频的方式对基于多尺度特征融合网络的疲劳检测方法进行了效果测试，采用YAWDD[63]数据集测试驾驶员面部特征状态准确率，并通过构建多样化视频数据集的方式测试检测疲劳状态的准确率。 YAWDD数据集是一组在真实光照条件下由车内摄像头拍摄的视频数据集，它记录了一辆真实汽车上的司机各种面部特征，视频中驾驶员有说话、唱歌、沉默和打哈欠这四种状态。本文选取了具有代表性的12个视频文件作为测试数据集用于测试眨眼和打哈欠的检测效果，其中每段视频时长在40s到100s之间。视频测试集如图3.23所示，包括佩戴眼镜、不佩戴眼镜、不同光照等情况。  3  基于面部特征的疲劳检测方法设计与性能评估 43   图3.23 视频数据集 Fig. 3.23 Dataset of video  YAWDD部分视频数据的测试结果如表3.7所示，可以看出该系统能较好地检测出驾驶员的面部特征状态，即眨眼和打哈欠状态，其中打哈欠的检测次数与实际参数完全一致，无漏检情况；眨眼检测次数在某个别视频中存在极少的漏检情况，所有视频集中的平均漏检率为2.75%，因此，该测试结果证实了基于多尺度特征融合网络的疲劳检测方法具有较好的检测效果和鲁棒性。  表3.7面部疲劳特征检测结果 Table 3.7 Detection results of facial fatigue features 视 频 序 号 实际参数（次） 检测结果（次） 漏检率 眨眼次数 哈欠次数 眨眼次数 哈欠次数 眨眼 打哈欠 1 37 3 35 3 0.05 0.00 2 30 3 30 3 0.00 0.00 3 34 3 33 3 0.03 0.00 4 47 3 46 3 0.02 0.00 5 34 3 34 3 0.00 0.00 6 12 2 12 2 0.00 0.00 7 49 3 46 3 0.02 0.00 8 16 3 15 3 0.06 0.00 9 12 3 12 3 0.00 0.00 10 25 2 24 2 0.04 0.00 11 39 4 37 4 0.05 0.00 12 17 2 16 2 0.06 0.00  采用视频数据集的方式测试系统检测疲劳的效果，为确保视频的丰富性本文采集了38段不同场景下的视频片段，结合已有的12段YAWDD视频数据集，共重庆大学硕士学位论文 44  使用50段视频文件用于实验，每段视频文件时长在5分钟以内，其中有28段视频是在处于不同疲劳状态下录制的，其余的22段是在清醒状态下录制的视频，视频中也包括多种情况，视频片段的测试结果总体情况见表3.8所示。  表3.8疲劳检测的准确率 Table 3.8 Accuracy of fatigue detection 视频分类 测试视频数（个） 正确识别状态视频数（个） 准确率（%） 清醒 22 21 95.5 疲劳 28 27 96.4 所有视频 50 48 96.0  由实际测试结果表明，基于多尺度特征融合的疲劳检测方法在不同的客观条件下都能达到较好的检测效果，其鲁棒性较好，漏检率较低，综合检测驾驶员状态的准确率能达到96%。为验证本文所提方法的先进性，从疲劳状态检测的准确率方面采用自建视频数据集与现有的成果进行比较，如表3.9所示。  表3.9不同疲劳检测算法的性能对比 Table 3.9 Performance comparison of different fatigue detection algorithms 编号 疲劳检测方法 准确率（%） 1 Adaboost算法+PERCLOS 90.2 2 基于模糊综合评价的疲劳检测算法 93.8 3 MTCNN关键点检测+CNN网络 94.5 4 基于人脸特征点定位的疲劳检测算法 94.6 5 本文所提的疲劳检测方法 96.0  上述表格中方法1是通过Adaboost分类算法进行人脸、人眼及嘴部定位，其次通过PERCLOS标准对驾驶人的疲劳程度进行判断；方法2首先分割人眼区域，其次利用积分投影和Sobel算子精准提取人眼位置，最后采用模糊综合评价法对人眼睁闭状态进行判定；方法3则是通过MTCNN网络提取人脸关键点，其次采用“三庭五眼”分割出眼部及嘴部区域传入CNN网络，最后通过PERCLOS的判断标准反馈疲劳结果；方法4是通过dlib算法得到68个人脸特征点，根据特征点的变化特征提取疲劳状态信息，从而实现疲劳状态的检测。 3  基于面部特征的疲劳检测方法设计与性能评估 45  在本文的具体应用中基于多尺度特征融合的疲劳检测方法不依赖其他图像处理技术，能够同时进行人眼及嘴部的定位和状态识别，由上述对比可知，基于多尺度特征融合的疲劳检测方法在准确率上达到最好的效果。因此，本文提出的基于多尺度特征融合网络的疲劳检测方法及多特征综合的判定方式能很好地适用于实际应用中，在复杂场景下能够准确地检测出驾驶员眼部、嘴部的特征状态和驾驶员的疲劳状态。  3.5 本章小结 本章首先对传统SSD网络在实际复杂环境中存在检测精度不高的情况进行分析，得出传统SSD网络无法获取有效的多尺度特征信息，存在目标识别和定位之间的矛盾问题。针对该问题提出基于多尺度特征融合的面部特征提取网络，该网络通过多尺度特征层融合策略和轻量、高效的特征融合模块将细节特征与全局语义特征相结合来达到丰富特征细节和语义的目的，能更好地检测驾驶员面部特征状态，通过实验结果表明多尺度特征融合网络整体性能更优，能很好地减少漏检情况。之后针对单一疲劳特征存在误判的问题提出多特征综合的评定方式，对疲劳参数进行了阈值的选取，将多个指标融合形成更具鲁棒性的疲劳判定条件进行疲劳检测，实验结果表明，本文提出的疲劳检测方法能够达到96%的平均准确率，因此证实了该方法的有效性，能很好地适用于实际应用中。                 重庆大学硕士学位论文 46   4  疲劳驾驶检测系统设计与实现 47  4  疲劳驾驶检测系统设计与实现 疲劳驾驶已成为道路交通的主要“安全杀手”，其造成的巨大社会经济损失不容忽视，因此对驾驶员进行状态监测具有重要的社会意义。本章结合项目需求基于前文提出的疲劳检测方法实现疲劳驾驶检测系统，首先针对该系统进行了需求分析，其次针对该系统的总体流程进行了设计，之后采用PyQt5、Pytorch等开发环境对系统各功能模块进行实现，最后展示了该系统主体功能的可视化界面，并对基于GUI界面的系统检测疲劳的效果进行了分析。  4.1 系统需求分析 由于本文所设计的疲劳检测系统是针对面部状态进行实时监测的，所以需要通过摄像头等辅助硬件来实现，该系统需要满足疲劳检测必要的功能性需求以及驾驶途中所必需的非功能性需求。 4.1.1 功能性需求 功能性需求是疲劳检测系统必备的功能清单，其主要包括疲劳检测功能、可视化显示功能、以及脱岗监测功能等，其中将疲劳检测的功能设定为在线和离线两种，在线检测即通过摄像头接入的方式对驾驶员进行实时监测，而离线的检测方式则是通过拉取视频库中已保存的历史视频文件数据进行驾驶员疲劳分析，因此基于功能性需求总结出GUI可视化界面的功能清单，如图4.1所示。  关闭相机打开相机测试摄像头接入功能读取文件文件路径选择视频文件选择功能眼部状态显示嘴部状态显示当前状态显示PERCLOS值显示眨眼频率显示哈欠频率显示指标显示功能保存记录开始运行退出程序脱岗监测其他必要功能菜单测试视频功能性需求 图4.1 系统功能性需求 Fig. 4.1 Functional requirements of the system 重庆大学硕士学位论文 48  ① 测试摄像头接入功能：该系统需要通过摄像头检测驾驶员行车途中的精神状态，因此需要提供测试摄像头接入功能来确保摄像头与电脑正常的连接。 ② 视频文件选择功能：除摄像头监测功能以外，本系统还通过文件路径选择功能提供了一个视频输入端接口，该功能可以从本地资源库中抽取需要测试的视频文件进行导入以提供多种方式的接入。 ③ 指标显示功能：在对驾驶员进行监测时，使用者也希望能通过视频以及检测结果实时了解驾驶员的状态。基于面部的疲劳状态主要表现在眼睛和嘴巴区域，因此需要设计相应的图形用户界面（Graphic User Interface，GUI）实现多融合监测，在检测过程中显示眨眼频率、哈欠频率和PERCLOS值以及当前状态。 ④ 其他必要功能菜单：开始运行是自动调用摄像头对驾驶员进行监测的功能；测试视频功能是调取资源库中的视频进行检测的功能；保存记录功能是保存某个特定时间点的GUI界面显示图；脱岗检测功能是在驾驶过程中若驾驶员脸部未正常处于录制视频范围内，即认定驾驶员未处于驾驶状态，则对系统而言被认为处于危险状态，因此设置脱岗功能检测；退出程序则实行退出界面的功能。 4.1.2 非功能性需求 非功能性需求是该系统在满足功能性需求的基础上，依据系统使用时需要而必须具有的特性，具体内容如下： ① 实时性：实际驾驶场景中，若该系统能够及时对驾驶员的疲劳状态进行精准判断并及时提示，则可以降低事故发生的几率并有效避免车祸的发生，因此系统的实时性是非常重要的一个要素。该系统需要实时监测驾驶员的状态，若驾驶员处于疲劳状态应立即通过报警方式提醒驾驶员。帧率是反应实时性的重要指标，为满足实时性要求，其主体功能的帧率应达到15fps以上。 ② 可用性：本文设计出的疲劳检测系统需要满足实际应用场景中所必须的基本功能，该系统需要具有较强的容错性和稳定性，确保它在驾驶过程中的可无故障地持续运行。 ③ 易用性：疲劳检测系统的GUI可视化界面需要以用户需求和体验为目标进行设计，即简洁明了、清晰易懂、系统信息显示完整，保证使用者的操作便捷并且可以灵活使用，对于不规范操作进行相应的提示。 4.1.3 硬件设备及开发环境 该系统需要对驾驶员进行视频图像采集，为更好的监测驾驶员的状态采用罗技C270i IPTV高清摄像头获取驾驶员的实时图像信息，并且使用惠普显示屏显示GUI系统实现的界面，硬件设备展示图如4.2所示。  4  疲劳驾驶检测系统设计与实现 49   (a) 视频图像输入设备  (b) 系统显示设备 图4.2 硬件设备展示图 Fig. 4.2 Display diagram of hardware equipment  表4.1 系统环境配置信息 Table 4.1 Configuration information of the system environment 名称 配置条件 操作系统 Ubuntu 16.04 CPU Intel(R) Core(TM) i7-9700K GPU GeForce RTX 2080 CUDA 10.1 cuDNN 7.3 Python 3.7 Pytorch 1.4 PyQt5 5.15 相关依赖库 Numpy 1.21；Opencv 4.5；Matplotlib 3.5等  本文设计的系统中方法部分是通过Python语言和PyTorch框架实现，GUI交互界面是通过PyQt5工具包实现，其版本为5.15。Python是一个高层次的结合了解释性、编译性、互动性和面向对象的脚本语言，它的语法简单易上手，并自带标准库及很多高质量的库，能使人快速实现程序功能，因此能够很好地满足效率要求。PyTorch框架是由Facebook开源的神经网络框架，相比于TensorFlow框架而言速度上有所提升，并且具备自动反向求导技术，也提升了代码的简洁度，目前常用于数字图像处理等领域。交互部分使用到的PyQt5工具包是基于图形程序框架Qt5的Python接口，它是一个跨平台的工具包，可以运行在多操作系统上。  4.2 系统总体设计 本节主要讲述了疲劳检测系统的总体流程设计，该系统由多个功能模块组成，重庆大学硕士学位论文 50  能通过获取面部状态信息检测驾驶员的疲劳状态，当驾驶员处于疲劳状态时及时进行报警提示。该系统的架构主要包括开发环境层、基础资源层、数据处理层、业务逻辑层以及表示层这五层，每一层通过功能模块进行连接，低层为高层服务，高层展示最后的GUI交互界面结果图，让观测者能够及时观测到驾驶员的精神状态，并通过警示音的形式对驾驶员不规范的行为进行提示，系统架构的详细内容见图4.3所示。  开发环境平台基础资源层数据处理层业务逻辑层表示层PyQt5工具包OpenCV视觉库资源库已有的测试视频摄像头实时采集视频视频文件加载改进的多尺度融合网络模型加载眼部检测嘴部检测疲劳判定GUI交互界面PyTorch框架Python语言Ubuntu系统……警告提示功能性需求非功能性需求硬件支持 图4.3 疲劳检测系统架构 Fig. 4.3 System architecture for fatigue detection  4.2.1 系统总流程设计 本文设计的系统整体流程如图4.4所示，其首先通过摄像头采集视频图像，将视频图像帧送入人脸检测网络中进行人脸区域及关键点监测判断驾驶员是否脱岗，之后通过多尺度特征融合网络对驾驶员人眼目标和嘴部目标实现定位，并将定位到的目标区域进行状态分类，最后使用提取出的特征状态序列计算PERCLOS、眨眼频率和打哈欠频率来判定疲劳状态，若检测出驾驶员正处于疲劳状态则通过警告音进行提示。该流程图中的有向箭头表示流程指向，其中Y表示“是”，N表示“否”。  4  疲劳驾驶检测系统设计与实现 51  开始摄像头实时采集视频已采集的测试视频YN人脸检测及关键点定位眼部区域检测嘴部区域检测YN脱岗警告视频图像帧序列是否脱岗疲劳检测参数计算Nperclos > 0.4N0.1yawnfNYYY疲劳状态疲劳警告清醒状态是否继续检测YN结束0.2blinkf 图4.4 疲劳检测系统流程图 Fig. 4.4 Flow chart of fatigue detection system 重庆大学硕士学位论文 52  4.2.2 系统主体功能设计 综合疲劳检测系统的需求分析和系统架构可以设计出完整的疲劳驾驶检测原型系统。本系统采用PyQt5框架进行设计，通过QtCore、QtGui和QtWidgets模块构成整个交互界面，本节将需要用到的主体功能模块及其设计进行阐述。 ① 脱岗监测功能设计：系统实现脱岗监测功能之前需要在车辆内部安装摄像头读取视频数据，通过调用OpenCV库函数打开摄像头进行人脸及关键点的检测。脱岗监测功能是通过MTCNN[64,65]算法的人脸检测模块实现，MTCNN是一种基于深度学习的人脸检测及人脸对齐方法，可同时完成两个任务，相比于传统的算法性能更好。基于MTCNN级联网络的人脸检测主要包括四个操作，首先需要对图片构造图像金字塔，将原始图像缩放到不同比例，之后将不同尺度的图像金字塔送入P、R和O三层网络中训练，实现多尺度目标检测。P网络用于判断是否存在人脸区域；R网络用于输出人脸框的精确位置；O网络输出人脸的5个关键点信息。利用该模块可以准确判断出驾驶员的脸部区域和人脸关键点位置。 本系统将训练好的网络模型权重文件pnet.npy、rnet.npy和onet.npy直接加载到网络中进行测试，如图4.5展示了不同头部位置、佩戴眼镜和不佩戴眼镜的人脸检测示意图。     图4.5 MTCNN检测人脸及关键点示意图 Fig. 4.5 Schematic diagram of MTCNN detecting faces and key points  ② 多指标融合的疲劳检测功能设计：该功能基于多尺度特征融合网络的疲劳检测方法实现，本系统通过GUI交互界面显示驾驶员的眨眼频率、哈欠频率、PERCLOS值以及当前状态来实时显示被测者的状态。 ③ 保存记录功能设计：该功能采用Python的PIL库，通过ImageGrab模块实现截屏操作，系统可以保存某个时间段内的GUI界面效果图来记录该时间段内驾驶员的状态。 ④ 提示报警功能设计：首先导入报警音效，其次采用Python的pygame.mixer混音器模块实现报警功能。当系统在视频中未检测到人脸则认为其脱离了驾驶岗4  疲劳驾驶检测系统设计与实现 53  位，此时被判定为危险驾驶，系统会及时通过报警音提示驾驶员此时正处于危险驾驶状态；当系统实时检测到驾驶员处于疲劳时同样会启动报警装置，通过报警提示驾驶员应当自我调节或到服务区休息，避免车祸的发生。  4.3 系统实现及测试 通过系统需求分析和详细功能设计实现疲劳检测系统，以下通过系统测试来验证该系统的实现效果，图4.6展示了设计出的疲劳检测系统初始GUI界面。   图4.6 疲劳检测系统初始界面 Fig. 4.6 Initial interface of fatigue detection system  本系统主要包括测试摄像头接入、视频文件选择、疲劳检测、状态记录以及脱岗监测等功能，以下将展示该系统各个主要功能的GUI界面： ① 测试摄像头接入功能：该功能作用在于查看摄像头是否与输入接口正常连接，能否正常开启摄像头，如图4.7所示，图(a)展示了摄像头未能正常与输入接口连接的示意图，系统会自动跳出“请检测相机与电脑是否连接正确”的警告提示；图(b)是摄像头与输入接口连接正常的示意图，点击“打开相机”按钮可以打开摄像头。  重庆大学硕士学位论文 54   (a) 摄像头未正常连接  (b) 摄像头正常连接 图4.7 测试摄像头接入功能示意图 Fig. 4.7 Schematic diagram of the test camera function  ② 视频文件选择功能：如图4.8所示，通过点击“读取文件”按钮可以调取资源库中相应的测试视频文件进行疲劳检测。   图4.8 视频文件选择功能示意图 Fig. 4.8 Schematic diagram of video file selection function  ③ 脱岗监测功能：该功能是通过人脸及关键点检测的方式查看驾驶员是否在岗，若检测到人脸则在脱岗监测处显示“在岗”；若检测不到人脸则显示“脱岗”，若驾驶员处于脱岗状态则表明该车辆正在违法驾驶，因此采用提示音进行报警提示，如图4.9所示。本文通过记录帧率的方式来验证该功能的实时性，计算得出该功能检测的帧率为50fps。 4  疲劳驾驶检测系统设计与实现 55   (a) 驾驶员在岗  (b) 驾驶员脱岗 图4.9 脱岗监测功能示意图 Fig. 4.9 Schematic diagram of off-duty monitoring function  ④ 疲劳检测功能：可以通过开启摄像头和拉取资源库中的测试视频两种方式进行疲劳检测。该示意图4.10中(a)、(b)展示了摄像头实时录制视频所检测出的清醒、疲劳状态，图(c)、(d)展示了通过资源库中读取测试视频进行疲劳检测的状态。GUI交互界面可以通过眼部状态和嘴部状态内容框显示眨眼和打哈欠字样；通过当前状态的内容框显示疲劳或清醒的字样。本文通过记录帧率的方式来验证该功能的实时性，计算得出该功能检测的帧率为25fps。   (a) 清醒状态  (b) 疲劳状态  (c) 清醒状态  (d) 疲劳状态 图4.10 疲劳检测功能示意图 Fig. 4.10 Schematic diagram of fatigue detection function 重庆大学硕士学位论文 56  ⑤ 保存记录功能：图4.11展示了系统的截屏功能，通过点击“保存记录”按钮可以进行截屏操作，将其保存至设定的默认位置，此时按钮会显示“停止记录”，当点击“停止记录”后，截屏的功能结束，按钮又会回到“保存记录”状态。   图4.11 保存记录功能示意图 Fig. 4.11 Schematic diagram of the function of saving records  ⑥ 退出系统功能：通过点击“退出程序”按钮可以跳出“关闭”的提示按钮，再点击“确定”即可退出程序，如图4.12所示。   图4.12 退出系统功能示意图 Fig. 4.12 Function diagram of exiting the system  放大图4  疲劳驾驶检测系统设计与实现 57  4.4 本章小结 本章主要对前文所述方法进行了系统实现和GUI界面设计，并针对系统进行了需求分析和总体设计。该系统由多个主体模块构成，其主要包括测试摄像头接入、视频文件选择、疲劳检测、状态记录以及脱岗监测等功能，最后对系统的主体功能进行了测试，并通过主体功能的帧率来展示系统的性能，该性能指标能够满足项目的需求。测试结果证实了该系统能很好地满足实时性、可用性及易用性要求，能很好地判断驾驶员状态并给予相应反馈，整体性能较好，具有一定的使用价值。                          重庆大学硕士学位论文 58   5  总结与展望 59  5  总结与展望 5.1 论文工作总结 随着科技的不断发展，汽车保有量逐年增加，道路交通安全问题日益凸显，由疲劳驾驶造成的交通事故已成为引发交通事故的主要原因之一，因此，针对疲劳驾驶的研究是行车安全领域的热点话题。由于疲劳驾驶危害大，通过疲劳检测方法对驾驶员状态进行实时监测具有重要的意义。基于面部特征判断疲劳状态是最直接有效的方式，此类方法无需与驾驶员接触，成本低、受限小且精度高，因此可普适于民，它能够通过面部图像特征快速准确地检测出驾驶员的疲劳状态。 本文立足于实际应用场景，以提高疲劳检测方法的准确率、鲁棒性及泛化能力为目标，从疲劳特征选取、面部疲劳特征提取以及疲劳判定等多角度进行深入的研究，提出了一种多尺度特征融合的疲劳检测方法，该方法在图像和视频数据集上进行了实验分析，在整体表现出更好的检测性能，最后根据一体化智能数字座舱技术研发项目需求设计并实现了一种疲劳驾驶检测系统。本文完成的主要工作如下： ① 由于现存没有完全符合本文疲劳场景的公开标注数据集，因此本文结合实际检测任务需要通过录制真实场景下的视频以及获取网上公开驾驶员疲劳视频的方式自行采集图像并进行图像标注。本文制作了用于疲劳特征状态检测的VOC数据集，该数据集中包括26名对象的4117张图片。 ② 现有的疲劳特征状态检测方法仅提取显著的疲劳特征，忽略了图像的多尺度特征及多层级的信息，检测准确率较低。针对此问题，本文提出了一种基于多尺度特征融合的网络架构，该方法首先通过多尺度特征融合策略将具有强语义的深层特征与细节丰富的浅层特征相结合，其次采用轻量、高效的门控融合模块将多尺度卷积层间的有效特征信息进行关联。之后在数据集上进行了实验结果分析，结果表明多尺度特征融合网络相较于基准网络在整体表现出更好的检测性能，能达到准确检测疲劳特征状态的目的。 ③ 本文首先选取了与驾驶员疲劳状态相关的特征信息及判别方式，之后将多个特征指标融合形成更具鲁棒性的多特征综合的疲劳评定方式来缓解单一特征判别易出现的误判问题。最后在视频数据集上进行了实验结果分析，实验结果表明驾驶员状态的检测的平均准确率能达到96%，证实了基于多尺度特征融合网络的疲劳检测方法能够准确地检测出驾驶员的疲劳状态。 ④ 针对疲劳驾驶检测原型系统进行了需求分析，使用PyQt5工具包设计了疲劳检测以及脱岗监测等功能模块的GUI界面，之后结合项目需求，基于多尺度特重庆大学硕士学位论文 60  征融合网络的疲劳检测方法，采用Pytorch框架以及辅助硬件设备设计并实现了一种疲劳检测系统。该系统可通过摄像头或拉取资源库中视频的方式检测驾驶员的疲劳状态，并利用脱岗检测模块来监测驾驶过程中是否存在危险行为。最后对系统做了相关测试，通过测试实验结果证实了该系统能够满足实时性、可用性及易用性要求，能很好地判断驾驶员状态并给予相应反馈。  5.2 未来工作展望 本文针对疲劳驾驶问题做了深入的研究，设计并实现了一款适用于驾驶舱的疲劳检测系统，在一定程度上能对疲劳驾驶进行有效的检测，并且能够通过报警的方式对处于疲劳状态下的驾驶员进行提示，但本系统仍然存在很多问题与不足，对后续的工作展望主要有以下几点： ① 由于现阶段缺乏疲劳驾驶的公开数据集，因此本文采集了来自26名不同对象的4117张图片用于实验研究，但该数据集样本有限，未来的研究可根据实际应用场景专门建立一个针对疲劳检测的数据集，以进行更加准确的研究。 ② 本文通过多尺度特征融合网络的疲劳检测方法实现对驾驶员状态的检测，该方法可以在一定程度上提升检测精度，减少漏检情况，但在实际夜间驾驶环境下检测的性能会稍有下降，该问题需要在未来的研究中进行解决，是未来研究的重点，同时这也是疲劳检测研究中的重要挑战。 ③ 在日常生活中，除面部特征目标能反应驾驶员疲劳状态外，还可以通过头部转动，语音等多种方式来反应疲劳。因此可以通过头部姿态转动、语音信号数据相结合的方式进行多模态疲劳检测，通过多样化的信息来增强疲劳检测系统的鲁棒性，实现更准确的疲劳检测。 ④ 本文研究的疲劳检测方法虽然能够满足现阶段的实时性要求，但疲劳驾驶检测系统需要移植到嵌入式平台投入商用，需要较好的硬件设备和实时性较高的算法来支撑系统的正常运作，因此如何优化算法的实时性，配备较好的硬件设备并投入商用是该领域的挑战，这将是本系统实现市场化后续所必需研究的工作。  参考文献 61  参 考 文 献 [1] 交通管理局. 2021年全国机动车保有量达3.95亿新能源汽车同比增59.25%[EB/OL]. https://app.mps.gov.cn/gdnps/pc/content.jsp?id=8322369, 2022-01-11. [2] World Health Organization. Third Global Ministerial Conference on Road Safety[EB/OL]. https://www.who.int/news-room/events/detail/2020/02/19/default-calendar/third-global-ministerial-conference-on-road-safety, 2020-2-19. [3] 刘文玲, 钱晓飞, 裴军. 基于关联规则的公交事故受伤情况预测研究[J]. 控制工程, 2016, 23(9): 1448-1453. [4] 李承. 如何预防高速公路上的疲劳驾驶[J]. 道路交通管理, 2009, (8): 58. [5] Kamieńska-Żyła M, Prync-Skotniczny K. Subjective fatigue symptoms among computer systems operators in Poland[J]. Applied Ergonomics, 1996, 27(3): 217-220. [6] Schleicher R, Galley N, Briest S, et al. Blinks and saccades as indicators of fatigue in sleepiness warnings: looking tired?[J]. Ergonomics, 2008, 51(7): 982-1010. [7] Tabrizi P R, Zoroofi R A. Open/closed eye analysis for drowsiness detection[C]. 2008 First Workshops on Image Processing Theory, Tools and Applications (IPTA), Sousse, Tunisia: IEEE, 2008: 179-185. [8] Hu J, Xu L, He X, et al. Abnormal driving detection based on normalized driving behavior[J]. IEEE Transactions on Vehicular Technology, 2017, 66(8): 6645-6652. [9] 李晓星. 基于深度学习的疲劳驾驶检测方法研究[D]. 中国科学技术大学, 2020. [10] Piazzi A, Bianco C G L, Bertozzi M, et al. Quintic G/sup 2/-splines for the iterative steering of vision-based autonomous vehicles[J]. IEEE Transactions on Intelligent Transportation Systems, 2002, 3(1): 27-36. [11] Kecklund G, Åkerstedt T. Sleepiness in long distance truck driving: an ambulatory EEG study of night driving[J]. Ergonomics, 1993, 36(9): 1007-1017. [12] Lal S K L, Craig A. Driver fatigue: electroencephalography and psychological assessment[J]. Psychophysiology, 2002, 39(3): 313-321. [13] Ohsuga M, Kamakura Y, Inoue Y, et al. Classification of blink waveforms toward the assessment of driver’s arousal levels-an EOG approach and the correlation with physiological measures[C]. International Conference on Engineering Psychology and Cognitive Ergonomics (EPCE), Beijing, China: Springer, 2007: 787-795. [14] Wei C S, Wang Y T, Lin C T, et al. Toward drowsiness detection using non-hair-bearing EEG-based brain-computer interfaces[J]. IEEE Transactions on Neural Systems and 重庆大学硕士学位论文 62  Rehabilitation Engineering, 2018, 26(2): 400-406. [15] Zheng W L, Gao K, Li G, et al. Vigilance estimation using a wearable EOG device in real driving environment[J]. IEEE Transactions on Intelligent Transportation Systems, 2019, 21(1): 170-184. [16] Huo X Q, Zheng W L, Lu B L. Driving fatigue detection with fusion of EEG and forehead EOG[C]. 2016 International Joint Conference on Neural Networks (IJCNN), Vancouver, BC, Canada: IEEE, 2016: 897-904. [17] Arunasalam M, Yaakob N, Amir A, et al. Real-Time Drowsiness Detection System for Driver Monitoring[C]. IOP Conference Series: Materials Science and Engineering (MSE), Perlis, Malaysia: IOP Publishing, 2020: 012066. [18] Hwang S, Lee P, Park S, et al. Learning subject-independent representation for eeg-based drowsy driving detection[C]. 2021 9th International Winter Conference on Brain-Computer Interface (BCI), Gangwon, Korea (South): IEEE, 2021: 1-3. [19] 吴群. 基于心电信号的驾驶疲劳检测方法研究[D]. 浙江大学, 2008. [20] Jap B T, Lal S, Fischer P, et al. Using EEG spectral components to assess algorithms for detecting fatigue[J]. Expert Systems with Applications, 2009, 36(2): 2352-2359. [21] 陈朝阳, 王文军, 张超飞, 等. 监测疲劳驾驶时定量脑电图特征量化指标分析[J]. 汽车安全与节能学报, 2016, 7(2): 160-166. [22] 王琳, 化成城, 姜鑫, 等. 基于颈腰部肌电及脑电信号的疲劳驾驶检测[J]. 东北大学学报 (自然科学版), 2018, 39(1): 102-102. [23] Jing D, Liu D, Zhang S, et al. Fatigue driving detection method based on EEG analysis in low-voltage and hypoxia plateau environment[J]. International Journal of Transportation Science and Technology, 2020, 9(4): 366-376. [24] Wu S, Kan M, He Z, et al. Funnel-structured cascade for multi-view face detection with alignment-awareness[J]. Neurocomputing, 2017, 221: 138-145. [25] 石坚, 吴远鹏, 卓斌, 等. 汽车驾驶员主动安全性因素的辨识与分析[J]. 上海交通大学学报, 2000, 34(4): 441-444. [26] Sandberg D, Wahde M. Particle swarm optimization of feedforward neural networks for the detection of drowsy driving[C]. 2008 IEEE International Joint Conference on Neural Networks (IJCNN), Hong Kong, China: IEEE, 2008: 788-793. [27] McDonald A D, Lee J D, Schwarz C, et al. A contextual and temporal algorithm for driver drowsiness detection[J]. Accident Analysis & Prevention, 2018, 113: 25-37. [28] Grace R, Byrne V E, Bierman D M, et al. A drowsy driver detection system for heavy 参考文献 63  vehicles[C]. Digital Avionics Systems Conference (DASC), Bellevue, WA, USA: IEEE, 1998: 1-8. [29] Sommer D, Golz M. Evaluation of PERCLOS based current fatigue monitoring technologies[C]. 2010 Annual International Conference of the IEEE Engineering in Medicine and Biology (EMBC), Buenos Aires, Argentina: IEEE, 2010: 4456-4459. [30] Daza I G, Hernández N, Bergasa L M, et al. Drowsiness monitoring based on driver and driving data fusion[C]. 2011 14th International IEEE Conference on Intelligent Transportation Systems (ITSC), Washington, DC, USA: IEEE, 2011: 1199-1204. [31] 侯科. 基于OpenCV的疲劳驾驶检测系统的设计与实现[D]. 华中科技大学, 2012. [32] 童兵亮. 基于嘴部状态的疲劳驾驶和精神分散状态监测方法研究[D]. 吉林大学, 2004. [33] Sahayadhas A, Sundaraj K, Murugappan M. Drowsiness detection during different times of day using multiple features[J]. Australasian Physical & Engineering Sciences in Medicine, 2013, 36(2): 243-250. [34] Zhang K, Zhang Z, Li Z, et al. Joint face detection and alignment using multitask cascaded convolutional networks[J]. IEEE Signal Processing Letters, 2016, 23(10): 1499-1503. [35] Du G, Li T, Li C, et al. Vision-based fatigue driving recognition method integrating heart rate and facial features[J]. IEEE Transactions on Intelligent Transportation Systems, 2020, 22(5): 3089-3100. [36] Ngxande M, Tapamo J R, Burke M. Bias remediation in driver drowsiness detection systems using generative adversarial networks[J]. IEEE Access, 2020, 8: 55592-55601. [37] Dwivedi K, Biswaranjan K, Sethi A. Drowsy driver detection using representation learning[C]. 2014 IEEE International Advance Computing Conference (IACC), Gurgaon, India: IEEE, 2014: 995-999. [38] Sun W, Zhang X, Wang J, et al. Blink number forecasting based on improved Bayesian fusion algorithm for fatigue driving detection[J]. Mathematical Problems in Engineering, 2015, 2015: 1-13. [39] Jang S W, Ahn B. Implementation of detection system for drowsy driving prevention using image recognition and IoT[J]. Sustainability, 2020, 12(7): 3037-3037. [40] Ed-Doughmi Y, Idrissi N, Hbali Y. Real-time system for driver fatigue detection based on a recurrent neuronal network[J]. Journal of Imaging, 2020, 6(3): 8-8. [41] Yang H, Liu L, Min W, et al. Driver yawning detection based on subtle facial action recognition[J]. IEEE Transactions on Multimedia, 2020, 23: 572-583. [42] Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image 重庆大学硕士学位论文 64  recognition[EB/OL]. https://arxiv.org/abs/1409.1556, 2014-9-4. [43] Viola P, Jones M J. Robust real-time face detection[J]. International Journal of Computer Vision, 2004, 57(2): 137-154. [44] Mordan T, Thome N, Cord M, et al. Deformable part-based fully convolutional network for object detection[EB/OL]. https://arxiv.org/abs/1707.06175, 2017-7-19. [45] 谢娟英, 刘然. 基于深度学习的目标检测算法研究进展[J]. 陕西师范大学学报: 自然科学版, 2019, 47(5): 1-9. [46] Redmon J, Divvala S, Girshick R, et al. You only look once: Unified, real-time object detection[C]. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, USA: IEEE, 2016: 779-788. [47] Liu W, Anguelov D, Erhan D, et al. Ssd: Single shot multibox detector[C]. European Conference on Computer Vision (ECCV), Amsterdam, The Netherlands: Springer, Cham, 2016: 21-37. [48] Neubeck A, Van Gool L. Efficient non-maximum suppression[C]. 18th International Conference on Pattern Recognition (ICPR), Hong Kong, China: IEEE, 2006: 850-855. [49] Chen C, Liu M Y, Tuzel O, et al. R-CNN for small object detection[C]. Asian Conference on Computer Vision (ACCV), Taipei: Springer, Cham, 2016: 214-230. [50] Li Z, Zhou F. FSSD: feature fusion single shot multibox detector[EB/OL]. https://arxiv.org/abs/1712.00960, 2017-12-4. [51] Li X, Zhao H, Han L, et al. Gated fully fusion for semantic segmentation[C]. Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), New York, USA: AAAI Press, 2020: 11418-11425. [52] Girshick R. Fast r-cnn[C]. Proceedings of the IEEE International Conference on Computer Vision (ICCV), Santiago, Chile: IEEE, 2015: 1440-1448. [53] Oquab M, Bottou L, Laptev I, et al. Learning and transferring mid-level image representations using convolutional neural networks[C]. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Columbus, OH, USA: IEEE, 2014: 1717-1724. [54] Gašić M, Mrkšić N, Rojas-Barahona L M, et al. Dialogue manager domain adaptation using gaussian process reinforcement learning[J]. Computer Speech & Language, 2017, 45: 552-569. [55] Tan C, Sun F, Kong T, et al. A survey on deep transfer learning[C]. International Conference on Artificial Neural Networks (ICANN), Rhodes Island, Greece: Springer, Cham, 2018: 270-279. [56] Knipling R R, Wierwille W W. Vehicle-based drowsy driver detection: Current status and future prospects[J]. 1994: 245-256. 参考文献 65  [57] 李洪研, 赵学敏. 基于人眼PERCLOS特征的列车驾驶员疲劳检测系统[J]. 中国铁路, 2011, (12): 32-34. [58] 万玉丽, 谢金法. 一种基于PERCLOS驾驶员疲劳检测方法的实现算法[J]. 农业装备技术, 2009, 35(2): 25-28. [59] Abe T, Nonomura T, Komada Y, et al. Detecting deteriorated vigilance using percentage of eyelid closure time during behavioral maintenance of wakefulness tests[J]. International Journal of Psychophysiology, 2011, 82(3): 269-274. [60] Mandal B, Li L, Wang G S, et al. Towards detection of bus driver fatigue based on robust visual analysis of eye state[J]. IEEE Transactions on Intelligent Transportation Systems, 2016, 18(3): 545-557. [61] Sun W, Zhang X, Peeta S, et al. A real-time fatigue driving recognition method incorporating contextual features and two fusion levels[J]. IEEE transactions on intelligent transportation systems, 2017, 18(12): 3408-3420. [62] 董迎春. 基于FPGA的疲劳检测系统设计与实现[D]. 西华师范大学, 2020. [63] Abtahi S, Omidyeganeh M, Shirmohammadi S, et al. YawDD: A yawning detection dataset[C]. Proceedings of the 5th ACM Multimedia Systems Conference (ACM), Singapore: Association for Computing Machinery, New York, NY, United States, 2014: 24-28. [64] Deng W, Zhan Z, Yu Y, et al. Fatigue Driving Detection Based on Multi Feature Fusion[C]. 2019 IEEE 4th International Conference on Image, Vision and Computing (ICIVC), Xiamen, China: IEEE, 2019: 407-411. [65] Zeng L, Wang Y, Han Q, et al. Driving Fatigue Detection Combining Face Features with Physiological Information[C]. 2021 7th IEEE International Conference on Network Intelligence and Digital Conten (IC-NIDC), Beijing, China: IEEE, 2021: 138-142.           重庆大学硕士学位论文 68  E. 学位论文数据集： 关键词 密级 中图分类号 疲劳检测；图像信息；特征提取；多尺度特征融合 公开 TN 学位授予单位名称 学位授予单位代码 学位类别 学位级别 重庆大学 10611 专业学位 硕士 论文题名 并列题名 论文语种 基于多尺度特征融合的疲劳驾驶检测方法研究 无 中文 作者姓名 李依玲 学号 201912131118 培养单位名称 培养单位代码 重庆大学 10611 学科专业 研究方向 学制 学位授予年 电子与通信工程 智能信息处理 3年 2022年 论文提交日期 2022年6月 论文总页数 80页 导师姓名 曾孝平 职称 教授 答辩委员会主席 谢显中 教授 电子版论文提交格式  文本（√）  图像（） 视频（） 音频（） 多媒体（） 其他（） 