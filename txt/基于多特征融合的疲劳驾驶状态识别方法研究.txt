第

49

卷 第

期

月

4

4

年

2 0 2 2

湖 南 大 学 学 报 （ 自 然 科 学 版 ）

Journal of Hunan University

Natural Sciences

（

）

文章编号：

（

）

1674-2974

2022

04-0100-08

Vol.49

，

No.4

Apr. 2 0 2 2

：

10.16339/j.cnki.hdxbzkb.2022274

DOI

基于多特征融合的疲劳驾驶状态识别方法研究

胡峰松†，程哲坤 ，徐青云 ，彭清舟 ，全夏杰

（湖南大学 信息科学与工程学院，湖南 长沙

）

410082

摘 要：针对交通安全中疲劳驾驶状态识别问题，使用单一的疲劳驾驶特征的方法识别率

较低，本文提出一种基于面部多特征加权和的疲劳识别方法

通过人眼状态检测算法提取眼

部疲劳参数，即持续闭眼时间、闭眼帧数比、眨眼频率，通过打哈欠状态检测得到打哈欠次数

和打哈欠持续时间，通过头部运动状态分析得到点头频率，建立融合以上六个特征的驾驶疲

劳状态检测模型来评估驾驶员的疲劳等级并进行相应的预警

实验测试数据选自

驾驶

员疲劳检测视频数据集的部分数据

经实验调整后，发现该方法的识别准确率较高，识别效

NTHU

.

.

果好

.

.
关键词：驾驶安全；特征点定位；眨眼状态识别；多特征融合；疲劳识别

中图分类号：

N39

文献标志码：
A

Research on Fatigue Driving State Recognition
Method Based on Multi-feature Fusion

†，

，

，

，

HU Fengsong
（
College of Computer Science and Electronic Engineering

CHENG Zhekun

XU Qingyun
，

PENG Qingzhou

，

Hunan University

Changsha 410082

QUAN Xiajie
）
China

，

Abstract：

Aiming at the problem of fatigue driving state recognition in traffic safety, the recognition rate of using

a single fatigue driving feature is low. This paper studies and proposes a fatigue recognition method based on the

weighted sum of facial multi-features. The eye fatigue parameters, such as continuous eye closing time, eye closing

frame ratio and blink frequency, are extracted by human eye state detection algorithm. The number and duration of

yawning are obtained through yawning state detection, the nodding frequency is obtained through head motion state

analysis, and a driving fatigue state detection model integrating the above six characteristics is established to evaluate

the driver

s fatigue level and give the corresponding early warning. The experimental test data are selected from part

’

of the NTHU driver fatigue detection video data set. After experimental adjustment, it is found that this method has

high recognition accuracy and provide a good recognition effect.
；

Key words：

；

driving safety

feature point positioning

blink of an eye state recognition

；

multiple feature fusion

；

fa⁃

tigue recognition

基金项目：赛尔网络下一代互联网技术创新项目（
作者简介：胡峰松（

NGII20161009
—），男，湖南衡阳人，湖南大学信息科学与工程学院副教授，博士

CERNET Innovation Project

），

（

NGII20161009

）

收稿日期：

2021-09-30

∗

通信联系人，

†

E-mail

hfs@hnu.edu.cn

1969
：

第

期

4

胡峰松等：基于多特征融合的疲劳驾驶状态识别方法研究

101

随着汽车数量的迅猛增长，汽车在给人们生活

1.2 基于 SVM 的睁闭眼状态识别

带来快捷与便利的同时，频繁的道路交通事故也带

来了惨重的经济损失，人民的生命安全受到了巨大

］
1
.

研究表明，应用机器学习、模式识

的威胁，疲劳驾驶已成为全球一个严重而亟待解决
的交通安全问题［
别等技术对疲劳驾驶状态检测识别及预警的方法效
］，能有效预防道路交通事故的发生，疲劳
果较好［
驾驶检测技术已逐步从研究领域转移到工业应用领
域并不断发展完善 ［

2-3

4-5

］
.

疲劳驾驶识别研究领域目前还存在很多难点，

在不同的场景下如戴太阳镜、光照明暗等都会影响
识别的准确率［
息、嘴部疲劳信息和头部疲劳信息，识别方法可分为

疲劳驾驶状态信息包括眼部疲劳信

］
4
.

单一特征疲劳信息识别和多特征疲劳信息识别，而单
一特征疲劳信息识别的准确率有待提高［
根据多特征疲劳信息来进行疲劳驾驶状态识别

本文主要

］
6
.

首

先，基于

的睁闭眼状态识别算法判断眼部疲劳状

态，然后通过嘴部高宽比和点头频率判断嘴部和头部

SVM

.

疲劳状态，最后融合多特征进行疲劳驾驶状态识别

.

1 眼部疲劳状态判断

1.1 人眼定位

Kazemi

使用由

和
树的人脸关键点定位算法进行人眼定位［
1
）中人脸特征点模型所示，根据图中关键点序号可
（
a

提出的基于级联回归

Sullivan

如图

］
7
.

以知道每个特征点的位置，如左眼的序号为

，

36~41

.
W

右眼的序号为

42~47.
的左、右眼部区域如图

根据眼部特征点的序号，提取

）所示的左、右长方形方框
（
b
1

区域

其定位计算规则如下：

W

，H

H

式中：W

= 1.6 ×

e
为人眼特征点

= 3 ×

e
到

）
（
1
之间的水平距离，H

e
为人眼特征点

到

37

41

36
之间和

39

到

38

40

e
之间垂直距离

的平均值，而 W 和 H 为定位的眼部区域的宽和高

.

W

_e

W

H

H

_e

）人脸特征点模型
（
a

）人眼定位示意图
（
b

图

基于特征点的人眼定位示意图

1

Fig.1 Eye location schemes based on feature points

1.2.1

为了能更为精准地识别人眼睁闭状态，使用两
个特征：人眼纵横比和人眼黑色像素累积差值作为
来识别图
支持向量机
SVM
像中人眼的状态
.

分类器的输入，使用

SVM

计算人眼纵横比

为了能准确快速识别眼睛的睁闭状态，我们计

算眼睛的高度和宽度之间的纵横比（

，

）
.

EAR

eye aspect ra⁃
睁眼时的纵横比在个体之间的差异基本
tio
上很小，并且对于图像的均匀缩放和面部的旋转是
完全不变的［
为左眼在睁开与闭合状态下检测
到的

］
8
.

图

个关键点，眼睛纵横比计算式为：
‖

‖

‖

P

P

P

2

6

EAR =

2 -

‖
P
6 +
‖
P

2

1 -

5

3 -
‖

4

P

）
（
2

P

1

P

2

P

6

P

3

P
P

5
5

P

4

）睁眼状态
（
a

图

2

）闭眼状态
（
b

个关键点示意图

人眼

6

Fig.2 Schemes of the six key points of human eyes

为了精确地识别眼部状态，取双眼

的平均

EAR

值作为眼睛睁闭识别的特征：

EAR = Mean(EAR left

，

EAR right)

）
（
3

计算视频图像连续

所示

帧左、右眼的纵横比，得
值迅速减
当发生眨眼时，
，然后慢慢增加至接近于正常情况下睁眼
0
值

EAR

到的结果如图
小接近于
时的

200

3

.

EAR
0.35

.

0.30

0.25
R
A
E
0.20

0.15

0.10

0.05

100

眨眼

120

图

140

帧数

160

180

200

均值结果图

3 EAR

Fig.3 EAR average results

1.2.2

基于自适应阈值计算人眼黑色像素累积差值

定位人眼区域，然后选取局部自适应阈值算法

对人眼图像进行二值化，经过形态学开闭操作和中

102

湖南大学学报（自然科学版）

年

2022

值滤波处理后，能较好地呈现眼睛轮廓及细节，表

为右眼不同情况下的二值图像

表 1 不同情况下的人眼二值图像

.

Tab.1 Binary images of human eyes

under different conditions

人眼状态

人眼图像 局部自适应图像 人眼二值图像

右睁眼

右半闭眼

右闭眼

1

值
差
积
累
素
像
色
黑

60

40

20

0

-20

-40

-60

-80

阈值

51

52

帧数

53

54

55

）黑色像素累积差值
（
b

图

黑色像素累积差值

4

Fig.4 Cumulative difference of black pixels

当人眼闭合时，尽管可能会受睫毛和眼睑等暗

差值大于

0

差值小于
差值小于
差值小于

0
0
0

差值小于 T（t）

区域的影响，但是最大暗部在瞳孔区域不会出现

所

以与睁眼相比，当眼睛闭合时，二值图像中的黑色像

素的数量会急剧减少

但是，由于黑色像素的数量会

随着人眼与摄像头之间距离的改变而改变，当距离

.

.

变大时，在图像中眼睛区域缩小，因此黑色像素的数

量减少

.

为了减少人眼与摄像头距离因素的影响，将人

眼图像归一为同一尺寸，计算连续两帧之间的黑色像

素差
动作，因此当连续两帧的差值小于

一般在两个以上的连续帧中可以观察到闭眼的
时，开始累计差

.

0

.
所示

值

人眼一次眨眼过程中，黑色像素数量变化如图

根据图

可以看到：第
（
而没有累积差值，导致其被错误地识别为睁眼状态

帧由于差值大于

54

a)

4

.

4

0

.

.

0

”和“状态

规定“状态

］提出的方法，使用自适应阈值的方
根据文献［
9
”两种状态，当

法累积差值
人眼区域二值化图像的黑色像素的差值小于
从“状态
阈值 T
等于阈值 T
参考图

”时，若差值小于
在“状态
”变为“状态
0
，累积差值并保持状态不变；若差值大于或
)

，不累积差值且状态变为“状态

”
.

”
.

请

1

1

1

0

0

(

(

t

)

t

时，

量
数
素
像
色
黑

5.
500
450
400
350
300
250
200
150
100
50
0

51

52

帧数

53

54

55

）黑色像素数值
（
a

状态
状态

0
0
（不累积
（不累积

差值）
差值）

状态

1
（累积

差值）

差值大于或等于 T（t）

自适应阈值黑色像素累积差值算法流程

图

5

Fig.5 Black pixel adaptive threshold cumulative

difference algorithm process

计算方法如下：

F

Δ

■
■
=
■
T ( t)
=
式中：N

∑Δ
α

N

状态

0 )
T ( )t

t
(
), (
N ( )t
≤
D( t
是第 t 帧的黑色像素数量，
Δ

N ( )t
[

状态
]

Δ
) ，α

, (
，
1
0

- 1

1)

×

∈

)

t

(
帧之间的差值，D

为“状态

N

t

(

）
（
4

）
（
5
为第

)
”中在

t 帧与第 t

-1

-1

第 t

帧的累积差值，α 为

t

1

0

(
到

- 1)
之间的恒定值，最优

1

α 值通过检测睁闭眼的准确性确定

由第 t

帧的累

积差值 D

t

得到第 t 帧的自适应阈值 T

使用

- 1)
自适应阈值可正确地将第

(

(
帧识别为闭眼

).
图

为

54

.

6

使用自适应阈值计算人眼二值图像的黑色像素累积

.

-1
t

差值的结果图，可以看出该方法能较好地识别闭眼

状态

.

1.2.3

睁闭眼状态测试

80
张；从

从

眨眼视频数据集［

］的

10

个视频中选取睁

ZJU

眼样本
2 000
劳检测视频数据集［

张，闭眼样本

700

］中选取睁眼样本

11

NTHU

驾驶员疲

张，闭眼

样本

本

1 300

4 000

张；同时自采集睁眼样本

张、闭眼样

张，总共采集睁、闭眼图像各

张

对人

2 000

2 000

6 000

.

眼纵横比、黑色像素累积差值这两类特征参数数据

进行归一化处理

.

在进行分类器训练前，需要选择合

第

期

4

胡峰松等：基于多特征融合的疲劳驾驶状态识别方法研究

103

适的核函数，当特征与分类标签之间的关系为非线

性时，选择

行模型训练

RBF

.

核函数，故本文采用

核函数进

RBF

60

40

20

0

-20

-40

阈值

值
差
积
累
素
像
色
黑
应
适
自

-60

-80

51

52

53

54

55

帧数

自适应黑色像素累积差值

图

6

Fig.6 Adaptive black pixel cumulative difference

左右

根据这一现象，本文选取最能表现疲劳状

0.2 s
态 的 三 个 眼 部 指 标 作 为 眼 部 疲 劳 特 征 参 数 ：基 于

.

准则［

］的

13

（闭眼帧数所占比）、

PERCLOS
（最长持续闭眼时间）和
1.4 眨眼检测

ECR

（眨眼频率）
.

BF

MECT

由图

的

值计算结果可知，一次眨眼过程

EAR

3
值先减小直至接近于零，然后逐渐增大至

中，

EAR

.

EAR

正常睁眼状态值

设 E 为

阈值，K 为判断眨眼的

.

EAR

帧数阈值

当

小于阈值 E 时，眼睛开始闭合；当

其值接近于正常睁眼状态值即大于 E 时，眼睛完全

睁开

.

我们统计该过程中

E 的连续帧数 F，当

EAR <
E 时，若 F 大于设定的连续帧数阈值 K，则记

EAR ≥
眨眼一次

.

为了寻找最优阈值 E 和 K，我们在

眨眼数据

ZJU

集上进行实验

中

个视频包含四种主题：未戴

. ZJU

80

眼镜的正面视频、戴薄边框眼镜的正面视频、戴黑框

从样本数据中选择

组数据进行训练，剩余

眼镜的正面视频及未戴眼镜向上仰角的视频，每个

的

组数据对睁闭眼状态进行测试，其测试结果

8 000

4 000

如表

所示

2

.

表 2 睁闭眼状态检测结果

20

主题

组视频，每个视频中眨眼次数

到

次不等，

数据集中总共包含

次眨眼

图

255

.

7

值 E 值与连续视频帧数阈值 K 值下眨眼检测结果的

1
6
为不同

阈

EAR

Tab. 2 Test results of open state and shut-down state

精确率

根据图

的结果，我们在提取眼睛疲劳参数

.

7

眨眼频率时，选择计算

小于阈值 E

时的

当

大于该阈值时，若连续帧数也大

EAR

= 0.24

连续帧数

于阈值 K

.

= 3

EAR
，则记一次眨眼

眨眼的次数，即为眨眼频率

.

计算一个时间周期内

.

眼睛

状态

睁眼

闭眼

样本

数量

识别状态

评估

睁眼

闭眼

准确

率

/%

精确

率

/%

召回

率

/%

2 000

1 907

93

2 000

36

1 964

96.78

95.48

98.2

从表

可以看出，提出的方法对睁闭眼状态识

表

3

.

为使用不同算法的识别结果

2

别的准确率较高

对比

.

表 3 不同算法识别结果对比

Tab. 3 Identified results comparison of different algorithms

100

K

=2

90
% K
80

/

=3

率
确
准

70

60

50

40

K
K

=4
=4

K

=5

0.22

0.23

算法

基于

融合方法

文献［

测试集）

SVM
］（

12

ZJU

闭眼识别

睁眼识别

平均准确

准确率

/%

准确率

/%

98.20

90.24

95.35

95.53

率

/%

96.78

94.21

以

0.24

0.25

阈值 E

EAR

阈值、帧数 K 值寻优结果

图

7 EAR

Fig. 7 The optimization results under different

EAR threshold and frame number

values

K

1.3 眼部疲劳信息提取

当人处于疲劳状态时，会出现眨眼频率增加、闭

眼时间增长、打哈欠等现象，严重时甚至会出现打瞌

睡的现象

次到

25

研究发现，人在正常情况下每分钟眨眼

10
次不等，眨眼一次眼睛闭合持续的时间约为

.

为一个时间周期，对周期内人眼状态进

60 s

行统计分析，得到眼部疲劳特征统计值

以

表示清

0
表示疲劳状态，记最长闭眼时间为

.

醒状态，
1
闭眼帧数所占比为

，

MECT

经实验及参

，眨眼次数为

BF.

ECR

考相关文献，得出三个眼部疲劳特征值之间的疲劳

）所示
阈值如式（
6

.

湖南大学学报（自然科学版）

年

2022

部状态

为了使

值更为精准，如图

所示，标记

要停车休息，不宜继续驾驶

104

MECT

MECT

MECT

={0
={0

，
，
1
，
，
1
，
■
0
=
■
，
■
1

MCT < 1.5
MCT ≥ 1.5

ECR < 0.2
ECR ≥ 0.2

10 ≤ BF < 25
BF < 10

或

BF ≥ 25

2 嘴部疲劳状态判断

嘴 部 检 测 定 位 的 方 法 很 多

（

）

6a

（

）

6b

（

）

6c

基 于 级 联 回 归 树

（

.

，

）算 法［

］的 人 脸

10

Ensemble of Regression Tress

ERT

关键点检测中，嘴部的位置序号为

48~67.
可以根据该序号来定位嘴部并识别其状态

因此，我们

本文主要通过计算嘴部高宽比（

）来判断嘴

.

MAR

.
P

MAR

的 P

用来计算

10

1~

MAR
）
计算公式可参照式（
7
.
，P
P
3

Mean(

Dis(
Mean(

10

Dis(

MAR =

8
个特征点，欧氏距离的

的

10

)

，

Dis(
)

，P
1

6

P

P

9

，P
4

Dis(

，

)

，

Dis(
)

，P
2

7

P

P

)

)

)

，P
5

8

）
（
7

P

3

P

4

P

5

P

2

P

1

P

6

P

7

P

10
嘴部

10

图

8

P

8

P

9

个关键点示意图

Fig.8 Diagram of the mouth

’

s ten key points

我们知道，正常驾驶情况下，嘴部处于闭合状

态；当与他人说话时，嘴唇处于开合不断变化状态，

且张开幅度不大；而当处于疲劳打哈欠状态时，嘴巴

张开幅度很大且持续时间较长［

14

为了判断嘴部状

］
.

态如讲话、打哈欠等，使用基于高宽比的方法在样本

上进行实验，实验结果如图

所示

时 ，嘴 巴 是 闭 合 的 ；当

9

MAR ≤ 0.4
时，为正常讲话状态；当

由图

.

9

可知：当

0.4 < MAR ≤ 0.8
时，处于打哈欠

状态

根据上述分析，可以使用

MAR > 0.8

.
别嘴部状态

1.4

1.2

1.0
R
A
M
0.8

0.6

0.4

0.2

0

打哈欠

说话

50

图

9

100

帧数

150

200

250

嘴部

MAR

检测结果图

Fig.9 MAR test results in the mouth

当驾驶者处于困倦状态时，会接连不断地打哈

欠，每次打哈欠嘴部持续张开时间约

，此时就需

6 s
根据该现象，我们可以

.

检测一个时间周期内司机打哈欠的次数，并据此来

评估其是否疲劳
数据集［

15

YawDD
和连续帧数值，寻找最优高宽比

为了正确识别打哈欠状态，我们在

.
］上进行实验，不断改变

的阈值
MAR
的阈值 M，并
值高于阈值 M 的连续帧数为打哈欠的阈
后，在数据集上检

MAR

和 K

定义
MAR
值 K
找到最优阈值 M
测打哈欠，准确率约为

.

=0.7

=15
当嘴部高宽比

连

MAR

续

帧大于

时，我们则记一次打哈欠

图

中的

15
到 t

0.7

的时间差即为一次哈欠时间，当嘴部张开程度

t
1
超过阈值时，我们检测是否打哈欠

表示正常状

以

4

.

10

95.6%.

）
表示疲劳状态，嘴部疲劳状态取值条件如式（
8

.

0

态，
1
所示：

YF =

0

，

N 且

YF <

■
■
■
YT >
表示打哈欠的次数，

YT ≤

YF ≥

N 或

，

1

t

t

）
（
8

为打一次哈欠持续

式中：
YF
的时间，阈值取 N

YT

，t

= 3

= 4 s.

最大最大

阈值

度
程
开
张
部
嘴

O

t

1

t

2

MAR

作为特征来识

图

10

.

Fig.10 The mouth state diagram

t

3

t

4

时间 t

/s
嘴部状态示意图

第

期

4

胡峰松等：基于多特征融合的疲劳驾驶状态识别方法研究

105

3 头部疲劳状态判断

率要比将多个疲劳特征融合进行识别的方法低［
］
.
因此，根据上述眼部、嘴部及头部的疲劳特征参数，

16

本文提出了基于多特征加权和的疲劳等级识别算

驾驶员驾驶过程中的点头频率的检测是对头部

法，算法具体步骤如下

.

运动分析的关键，也是疲劳驾驶检测的重要因素

当

将眼部、嘴部及头部的五个疲劳特征指标各自

.

一个时间周期内点头频率超过某个阈值时，可以认

为驾驶员处于疲劳状态

.

依据定位到的眼部特征点位置信息，从实时性

和准确性出发，本文提出了一种基于二维垂直方向

的点头频率特征分析算法

取定位的双眼的中心点

连线的中点作为头部位置检测点，根据该检测点在

.

取权重值，经实验，其权重取值如表

所示
表 4 各疲劳特征参数的权重取值

4

.

特征参数

Tab.4 The weight of each fatigue

characteristic parameter values

头部

NF

0.3

眼部

MECT

ECR

0.2

0.1

BF

0.2

嘴部

YF

0.2

垂直方向上坐标 y 随时间的变化情况，计算一个时间

权重 W i

周期内的点头频率

.
与帧数之间的关系图

图

为驾驶员打瞌睡时的 y 值

11

.

根据疲劳参数加权后值的不同，将状态分为三

y

标
坐
直
垂

160

180

200

220

240

0

25

50

75

100

帧数

125

150

175

200

图

11

头部运动分析图

Fig.11 Head motion analysis diagram

算法过程如下：当视频帧数较多时，图像可近似

个等级：清醒、疲劳、重度疲劳

特征参数加权和计算

.

如式（

）所示：
V i ×

10
= ∑

F

W i，i

(

=

，

，

，

，

ECR

MECT

BF

NF

)
YF
（

）

10

个特征参数值分别乘以其对应的权重值，求和

5

后便得到特征参数加权疲劳值 F

.

综合特征参数的权重值和疲劳等级，将特征参

数加权值与疲劳等级相对应，根据对应关系便能判

断出驾驶员的驾驶状态

对应关系如表

所示

5
表 5 疲劳值与疲劳等级对应关系表

.

.

Tab. 6 The relationship between the

values of fatigue and fatigue level

疲劳等级

清醒状态

疲劳状态

拟合为曲线，计算曲线极值点，极值点可将曲线分成

特征参数加权值 F

.

许多单调的曲线

经实验得出，统计一个时间周期内

单调递减段极小值点 y 值大于初始位置

像素的极

值点个数，即为点头次数

NF
则判断曲线是否单调递减，若为单调递减，则点头次

50
；若曲线没有极小值点，

4.2 实验结果分析

为了验证研究方法的性能，本文的实验在

不疲劳

疲劳

重度疲劳

F

< 0.3

0.3 ≤

F

< 0.7

F

≥ 0.7

数

则

NF

NF

1

为

，否则为
，
，

NF ={0

）所示：
取值如式（
9

）
（
9

0.NF
N
N

NF <
NF ≥

1

操作系统的

上进行，采用

编程语言，并结

PC

和

合

Opencv 2.4.13

测试数据来自

NTHU

python
函数库进行分析

Dlib18.17

驾驶员疲劳检测视频数据集的

若一个时间周期内点头次数

大于某个阈值，

部分数据

该测试数据中有

种不同场景：白天戴眼

.

5

疲劳特征参数值为

，否则为

经实验和相关

镜、戴太阳镜和不戴眼镜，晚上戴眼镜和不戴眼镜

NF

0.

1

.
组数据，每组数据包含清醒、疲劳

文献可知：取 N

时，疲劳状态检测准确率最高

=10

.

每个场景中选取

和重度疲劳状态

5

4 基于多特征加权和的疲劳状态识别

本文以

.
为一个时间周期检测驾驶员疲劳状

60 s

6

态，表

为在不同场景下疲劳识别的结果，表

为白

天戴眼镜情况下各特征参数的计算结果、疲劳值与

7

4.1 疲劳状态识别算法

依据单一的疲劳特征来评估疲劳状态，其准确

对应的疲劳识别结果

.

位

64

实验

.

106

湖南大学学报（自然科学版）

表 6 不同环境下疲劳识别结果

年

2022

Tab .6 Fatigue identification results under different environment

场景

真实状态

清醒

次

/

疲劳

次

/

重度疲劳

次

/

疲劳等级准确率

/%

白天戴眼镜

白天不戴眼镜

白天戴太阳镜

晚上不戴眼镜

晚上戴眼镜

清醒

疲劳

重度疲劳

清醒

疲劳

重度疲劳

清醒

疲劳

重度疲劳

清醒

疲劳

重度疲劳

清醒

疲劳

重度疲劳

5

0

0

5

0

0

5

3

2

5

0

0

5

0

0

0

5

0

0

5

0

0

2

2

0

5

1

0

5

2

0

0

5

0

0

5

0

0

1

0

0

4

0

0

3

100

100

53.3

93.3

86.7

表 7 白天戴眼镜疲劳识别结果

Tab .7 Fatigue recognition results with glasses in the daytime

组数

状态

眼部

嘴部

MECT/s

ECR

次

BF/

次

YF/

正常

疲劳

重度疲劳

正常

疲劳

重度疲劳

正常

疲劳

重度疲劳

正常

疲劳

重度疲劳

正常

疲劳

重度疲劳

0.121

0.622

5.976

0.143

1.731

2.637

0.089

0.067

1.478

0.096

0.117

0.160

0.102

0.153

2.238

0.127

0.236

0.413

0.214

0.164

0.381

0.126

0.181

0.345

0.094

0.132

0.229

0.127

0.204

0.327

23

32

8

24

17

9

34

27

9

23

28

31

22

37

24

3

3

4

0

2

0

1

1

4

2

3

3

0

5

2

1

2

3

4

5

由表

头部

次

NF/

疲劳值 F

识别结果

0

1

1

0

3

4

0

11

5

0

1

6

0

1

13

0.2

0.6

0.7

0.1

0.4

0.7

0.2

0.5

0.8

0.2

0.4

0.7

0

0.6

0.8

正常

疲劳

重度疲劳

正常

疲劳

重度疲劳

正常

疲劳

重度疲劳

正常

疲劳

重度疲劳

正常

疲劳

重度疲劳

YT/s

2.463

4.767

3.067

0

3.322

0

1.364

3.600

11.36

6.67

10.03

4.842

0

4.833

3.635

6

白天的识别准确率比夜晚要好，在戴太阳镜时识别

可以看出，本文提出的疲劳识别方法在

的精度较低，但是就整体而言，识别效果较好

.

效果较好

本文研究的算法，虽然在一定程度上能进

Electr. Eng. Czech Tech. Univ. Prague

2016

1-8.

胡峰松等：基于多特征融合的疲劳驾驶状态识别方法研究

107

第

期

4

5 结束语

本文提出了一种融合三类疲劳参数指标加权和

的疲劳识别方法，建立了疲劳识别系统，根据相应的

比重进行加权计算疲劳值来判断驾驶者的疲劳程

度

实验表明：本文的疲劳识别算法准确率较高，且

.

行疲劳识别，但在太阳光很强和夜晚时的识别率还

不理想

今后的研究可针对不同光照环境进行不同

的光照处理，将该识别方法扩展到适用于更多的驾

驶环境

另外，因为该识别方法只根据驾驶员的面部

.

.

.

研究方向

.

参考文献

］
［
1

LIANG Z M

．

IEEE International Conference on Systems

Man and Cybernetics

，

The Hague

：

，

：

．

2004

6451-6456

Netherlands
，

IEEE
．

KAZEMI V

SULLIVAN J

One millisecond face alignment with

，

．

an ensemble of regression trees

//2014 IEEE Conference on

Computer Vision and Pattern Recognition

Columbus

OH

USA

．

，

，

：

］
［
C

，

：

IEEE

2014

．

1867-1874
，

CECH J. Real-time eye blink detection using fa⁃
SOUKUPOVA T
］
［
J

// Cent. Mach. Perception

Dep. Cybern. Fac.

cial landmarks

，

LEE W O

PARK K R

Blink detection robust to vari⁃

Journal of Neuroscience Methods

2010

193

，

，

，

，

LEE E C
］．
［
J

，

：

．

］
［
7

］
［
8

］
［
9

ous facial poses
．
）：
（
2

356-372
，

，

［

］

10

］
［
C
．

］
［
C

PAN G

SUN L

WU Z H

Eyeblink-based anti-spoofing in

，et al．

face recognition from a generic web camera

//2007 IEEE 11th

，

：

Brazil

IEEE

2007

，

，

：

．

1-8
，

．

．

WENG C H

LAI Y H

LAI S H

Driver drowsiness detection via

a hierarchical temporal deep belief network

//Computer Vision

- ACCV 2016 Workshops. 2017

［

］ 黄洁媛，岑翼刚，张琳娜，等．基于卷积神经网络的人眼状态检

12

］．扬州大学学报（自然科学版），
测［
J

，

）：
（
3

21

25-29

．

HUANG J Y

CEN Y G

ZHANG L N

Eye state detection

，

，

2018
，et al．

based on convolutional neural network

Natural Science Edition

］．
［
J
），

2018

Journal of Yangzhou
，

．（

）：
（
3

21

25-29

In

特征进行疲劳识别，未能考虑车辆特征如车辆偏移、

International Conference on Computer Vision

Rio de Janeiro

车速、转达向盘转向等特征参数的影响，如何融合这

些特征参数进一步提高识别的准确率，是下一步的

［

］

11

A fatigue driving detection algorithm based on sup⁃

Review of Computer Engineering Stud⁃

port vector machine
）：
（
，
4
6

2019

ies

，

，

］．
［
J

．

87-92
，

（

University
）

Chinese
，

WU Q

］
［
2

］
［
3

，et al．

DUA M

SHAKSHI

SINGLA R

Deep CNN models-based

ensemble approach to driver drowsiness detection
，

，

puting and Applications

2021

3155-3168

）：
（
8

33

，

DOUDOU M

BOUABDALLAH A

BERGE-CHERFAOUI V

］
［
J
．

. Neural Com⁃

Driver drowsiness measurement technologies

current research

market solutions

and challenges

］．
［
J

International Journal of In⁃
） ：
（
2

2020

18

，

，

telligent Transportation Systems Research

：

，

，

［

］

13

SUN B X

，

XIE B

，et al．

recognition application for smart vehicle space

A PERCLOS-based driver fatigue
］
［
C

//2010 Third In⁃
，

ternational Symposium on Information Processing. Qingdao

．

，

［

］

14

China

：

，

：

．

2010

437-441

IEEE
，

ABTAHI S

SHIRMOHAMMADI S

，

HARIRI B

，et al．

A yawning
］
［
C

//2013

measurement method using embedded smart cameras

IEEE International Instrumentation and Measurement Technology

（

）

，

，

：

，

：

I2MTC

. Minneapolis

MN

USA

IEEE

2013

1605-

．

297-319

PAN C T
］．
［
J

．（

）

127

In Chinese

ABDULLAH M H

］
［
C

detection

．

2016

］．计算技术与
］ 潘陈听．深度学习在视频动作识别中的应用［
［
J
4

自动化，

，

）：
（
4

39

123-127

．

2020
．

Application of deep learning in video action recognition

Computing Technology and Automation

2020

，

，

）：
（
4

39

123-

］
［
5

］
［
6

，

RAMAN K J

，

AZMAN A

，et al．

//Information Science and Applications
．

：

，

：

Singapore
，

Springer Singapore
，

2016

269-278

．

BRANDT T

STEMMER R

RAKOTONIRAINY A

sual driver monitoring system for fatigue and monotony

Driver fatigue
）

（

ICISA

Affordable vi⁃
］
［
C

//2004

Conference
．

1608

ABTAHI S

：

24-28.

［

］

15

，

OMIDVEGANEH M

，

YawDD

a yawning detection dataset

SHIMOHAMMADI S
］
［
C

// Proceedings of the 5th

，et al

.

，

：

，

：

ACM Multimedia Systems Conference. MN

USA

IEEE

2014

［

］ 戴诗琪，曾智勇

16

］．计算
基于深度学习的疲劳驾驶检测算法［
J

.

机系统应用，

，

）：
（
7

27

2018

113-120

．

，

DAI S Q

ZENG Z Y. Fatigue driving detection algorithm based on

. Computer Systems & Applications

2018

27

，

，

deep learning
）：
（
7

113-120

］
［
J
．（

）

In Chinese

