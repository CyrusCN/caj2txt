第 39 卷第 Z1 期 
2018 年 9 月 

通    信    学    报 
Journal on Communications 

Vol.39    No.Z1 
September 2018 

基于面部多特征的疲劳驾驶预警系统的研究 

郭慧利，王恁，郭浩 
（太原理工大学信息与计算机学院，山西  晋中  030600） 

摘  要：如今汽车已成为人们出行的首选工具之一，疲劳驾驶便成了一项重大安全隐患。提出基于眼、嘴、头

等多种面部特征相结合的疲劳驾驶检测方法。该方法使用 CCD 摄像头采集图像信息，进行图像预处理，通过
基于 adaboost 算法的人脸检测方法，采用灰度积分投影定位眼、嘴区域，来监测局部状态。改进的 D-S 信息融
合算法形成综合疲劳判断指标，当指标达疲劳值时基于 IPv6 的预警平台会及时发出预警。将多种信号特征相
融合保证了系统的可靠性与高效性。 
关键词：疲劳驾驶；图像预处理；人脸检测；灰度积分投影；信息融合算法；IPv6 
中图分类号：TP391   
文献标识码：A 

doi: 10.11959/j.issn.1000−436x.2018184 

Research on fatigue driving early warning system 
based on multiple signal characteristics 

GUO Huili, WANG Nen, GUO Hao 

School of Information and Computer, Taiyuan University of Technology, Jinzhong 030600, China 

Abstract: Nowadays, automobiles have became one of the preferred travel tools for people, and then fatigue driving has 

became a major safety hazard. Summarizing the advantages and disadvantages of previous fatigue driving research, a fa-

tigue driving detection method based on the combination of various signal characteristics of eyes, mouth and head was 

proposed. CCD camera was used to collect image information and perform image preprocessing, through face detection 

based on adaboost algorithm, using gray integral projection to locate eye, mouth area, monitor local state, form compre-

hensive fatigue judgment index, when the indicator reaches a certain value. An early warning was issued. The integration 

of multiple signal features ensures the reliability and efficiency of the system. 
Key words: fatigue driving, image preprocessing, face detection, grayscale integral projection，information fusion algo-

rithm, IPv6 

1    引言 

随着全球经济的快速发展，汽车已成为绝大多
数人出行的首选工具，因此保障交通安全必不可
少。据统计，在各类交通事故中，因疲劳驾驶导致
的事故比例已达到 35%~40%。疲劳驾驶严重影响
驾驶员的警觉性、应变性及安全驾驶能力[1]。在各
类交通违法行为中，驾驶员疲劳驾驶也是难以解决
的问题之一。为了避免此类交通事故的发生，响应
科技强警的号召，研究一个高效、可靠的疲劳驾驶

收稿日期：2018−09−10 

预警系统具有重要的现实意义。 

近年来，国内外对疲劳驾驶方面的研究取得了
大量的成果。彭军强[2]通过检测驾驶员的脑电信号
和肌电信号等生理特征判定驾驶员的疲劳状态，但
该方法需驾驶员穿戴相应的设备，影响正常驾驶。
Jin[2]提出通过检测方向盘的状态来判定驾驶员的
疲劳程度，但是该方法没有确定的的判断标准，易
出现误判或是漏判的情况。王斐等[3]通过采集被试
者的脑电图信号和对应的方向盘操纵数据，将二者结
合检测驾驶员疲劳状态。该类方法虽不妨碍驾驶操

2018184-1 

 
第 Z1 期 

郭慧利等：基于面部多特征的疲劳驾驶预警系统的研究 

·23· 

作，也能达到一定检测精度，但根据个人操控习惯与
行车环境的不同，检测的健壮性会受到影响。 

许多关于疲劳驾驶的研究设备，比如脑电、心电、
肌点都需在驾驶员身上粘贴一些设备，给驾驶员所带
来的不适感是极其难耐的。这种接触式检测虽然可以
获得准确的驾驶员生理数据，但就整个监测过程而
言，其本身也在影响着驾驶员的驾驶及正常的驾驶疲
劳表现。而非接触式检测则克服了这种对驾驶员的影
响。传统的非接触式检测通过捕获人眼的眨眼状态或
者车辆行驶特征等进行疲劳判断，实时性欠佳及检测
指标的单一性造成了系统的可靠性低。本文提出基于
眼、嘴、头多种面部信特征相结合的疲劳驾驶检测方
法。以实时非接触的方式，设定必要的阈值，将通过
信息融合算法得到的数据与阈值作比较判断疲劳。该
方法一方面克服了前述所有缺陷，另一方面显著提高
了系统的稳定性与高效性。 

2    系统检测原理 

2.1    系统整体设计 

优 质 像 素 的 电 荷 耦 合 元 件 （ CCD,  charge- 
coupled device）摄像头采集驾驶员驾驶图像信息，
对获取图像进行灰度变换和二值化处理，增强图像
的对比度。利用基于 adaboost 算法的人脸分类器对
驾驶员的面部区域进行识别，在此基础上用灰度积
分投影法对眼睛进行定位与状态捕获，然后采用
PRECOLS（percentage  of  eyelid  closure  over  the 
pupil）算法与眼睛焦点位置信息进行疲劳判断。另
外，对嘴部区域建立坐标系，通过计算其在一定时
间内长宽比值不小于 1 的频率进行嘴部疲劳状态判
断，比值趋于特定值的频率进行点头判断。采用改
进的 D-S 证据理论合成算法综合分析各特征检测结

果，当综合疲劳指标达设定阈值时及时发出预警。 
本文基于 IPv6 搭建疲劳驾驶预警系统，它使用
更小的路由表，IPv6 的地址分配遵循聚类的原则，
这使得路由器能在路由表中用一条记录表示一片
子网，大大减小了路由器中路由表的长度，提高了
路由器转发数据包的速度，加速数据传输的速率[4-5]。
此特点能够使系统在检测出驾驶员疲劳状态时及
时发出疲劳预警，并提醒驾驶员尽快停车休息。IPv6
网络传输过程进行加密，数据更加安全，保护驾驶
员的个人信息。平台对驾驶员的驾驶状态进行实时
追踪，记录行车路线及历史驾车记录。系统的整体
设计如图 1 所示。 
2.2    基于 adaboost 算法的人脸检测 

为了实现最优质的驾驶员图像结果，本文采用
加权平均法对图像进行灰度化处理，由于人眼对绿
色敏感度高，蓝色敏感度低，因此按式(1)对分量进
行加权平均能得到较合理的灰度图像[6]。 

j
0.11
,


对所得到的灰度图像进行二值化处理，使图像
变得简单，而且数据减少，能凸显出感兴趣的目标
的轮廓。对灰度图像的再处理为之后的人脸检测带
来极大的帮助。 


G i


R i


B i

0.59

0.30













j

j

i

j

f

,

,

,

 (1) 

人脸检测即对录入图像进行判断，检测其中是
否包含人脸，若有则给出人脸区域。adaboost 是一
种迭代算法，核心思想是为同一训练集训练不同的
分类器（弱分类器），然后将这些弱分类器组合起
来形成更强的最终分类器（强分类器）[7]。adaboost
算法本身是通过改变数据分布来实现的。它根据每
个训练集中每个样本的分类是否正确以及最后整
体分类的准确性来确定每个样本的权重[8-9]。将修改
后的新数据集发送到下层分类器进行训练，最后将

图 1    系统整体流程 

2018184-2

 
 
·24· 

通    信    学    报 

第 39 卷 

每次训练得到的分类器最终合并为最终决策分类
器[10]。使用 adaboost 分类器可以消除不必要的训练
数据功能，并将其置于关键训练数据上。 

分类器首先对图像进行灰度化和二值化处理，
增强图像的对比度，然后对其进行网格标记，使用
Canny 算法提取边缘信息，识别出人脸感兴趣区域，
对其进行检测并用矩形框标示出脸部区域。人脸检
测如图 2 所示。 

由图 3(a)水平积分投影曲线可知，第一个波谷
为头发，眉毛区域的投影形成第二个波谷，第一个
波峰为额头区域，眉毛与上眼睑之间的肤色区域投
影形成第二个波峰，第三个波谷则是由人眼水平中
心线方向的投影形成，此时该坐标即为人眼中央所
在的横向坐标 y 值。 

由图 3(b)垂直积分投影曲线可知，对应于上述
定出的横向坐标区域，曲线中的 2 个最小值点为纵
穿人眼中央的 2 列像素点在垂直方向上的投影形
成，则其所对应的两个坐标值即为人眼中央所在的
纵向坐标 x 值。如此，结合获得的人眼中央 x, y 坐
标值，即可对人眼区域进行精准定位。 

图 2    人脸检测 

2.3    人脸局部区域检测 

灰度积分投影方法是用于提取图像特征信息的常
用方法。该方法的思想是在灰度图像或二值图像的水
平和垂直方向上累积像素的灰度值，以获得 2 个方向
上的像素灰度累积值曲线[11]。然后根据曲线中的峰谷
分布和面部特征的先验知识来校准人眼和嘴部区域。 
对图像进行水平积分投影和垂直积分投影，计

算式如式(2)和式(3)所示。   

H x
( )



x
1



x
2

I x y
( ,

)



V x
( )



y
1

y
2



I x y
( ,

)



x
2

1
 
x
1

x
1

y

2

1
 
y
1

y
1

x
2

y

2

I x y
( ,

)

(2) 

I x y
( ,

)

(3) 

其中，I(x,y)为图像上(x,y)像素点的灰度值，H(x)表示
(x1,x2)、(y1,y2)的水平积分投影函数，V(x)表示(x1,x2)、
(y1,y2)的垂直积分投影函数，由上式可知，当图像中
的某一行或某一列像素灰度值发生变化时，H(x)和
V(x)的值也会随之变化。图 3 为对驾驶员图像进行水
平垂直积分投影后所得到的积分投影曲线。 

观察人脸图像就可以注意到，眉眼区域包括眉
毛、上眼睑、瞳孔及下眼睑。眉眼区域内自上而下
灰度值变化较大，对应水平积分投影曲线呈现出来
的将是波谷到波峰，波峰再到波谷的一个波动状
态[12]。具体分析可知：眉眼区域的上边界为眉毛区
域投影成的波谷的垂直坐标，人眼水平中心线为瞳
孔区域水平投影成的波谷的垂直坐标，眉眼区域的
下边界为下眼睑区域水平投影成波峰的垂直坐标。
就此，得出眉眼的边界，划分出眉眼区域。 

图 3    积分投影曲线 

相对于人嘴部的定位，可以采取由右至左分析
投影曲线的方法，同人眼定位类似结合波峰波谷分
布及面部特征的先验知识来对嘴部区域进行划分
定位。图 4 为人脸眼睛区域定位，图 5 为人脸嘴部
区域定位。 

图 4    眼睛区域定位 

2018184-3

 
 
 
 
 
 
 
 
第 Z1 期 

郭慧利等：基于面部多特征的疲劳驾驶预警系统的研究 

·25· 

图 5    嘴部区域定位 

3    疲劳识别 

本文中所有实验的被试者，都被要求前一天睡
眠时间为 00:00—06:00，不允许使用提神类物品。
选择在人们最容易产生疲劳的 13:00—14:00 之间在
模拟驾驶仓进行直线行驶，这是因为长时间直线
行驶更容易产生疲劳。 
3.1    眨眼分析 

基于以上分析，在实现人脸检测和人眼定位之
后，分析人眼特征对眼睛的睁闭状态进行判断。
PERCLOS 算法的测量参数是指在特定的时间内眼睛
闭合程度超过某一阈值的时间所占总时间的百分率。
PERCLOS-P80 是指眼睛闭合超过 80%则认为是闭眼
状态[13]。Stern[14]通过对 20 名被测者不同阶段的眨眼
频率进行研究，指出在疲劳状态下，眨眼频率会发生
变化。当驾驶员处于疲劳状态时，眼睛的闭合时间会
变长，采用 PERCLOS 值 K 进行眼部疲劳识别，其值
越大驾驶疲劳程度越深，计算式如式(4)所示。 

K 

眼睛闭合图像帧数
待定时间内图像总帧数



100

(4) 

经前人的实验研究及实际应用证明 PERCOLS
算法能够实时地、准确地对驾驶员进行疲劳 判
定 [15]。实验中采用帧率均为 12  frame/s。本文通过
计算每分钟内 K 值得变化进行疲劳判断。选取被试
者进行模拟实验，在最容易疲劳的 13:00 开始在模
拟驾驶仓内连续直线行驶 1  h，统计 K 值并从中抽
出逐步到达疲劳状态的 11  min 数据，绘制 K 值折
线，如图 6 所示。 

图 6    K 值折线 

由图 6 可以看出从第 5 分钟起，K 值明显上升，
即开始出现疲劳状态，第 6 分钟以后上升速率增快，
疲劳程度越来越深。所以，当 K 值大于 15.98%时，
系统判定为眼部疲劳状态。 
3.2    嘴部分析 
3.2.1    哈欠判断指标 

基于上文中对人脸的嘴部进行检测与定位，采
取如下公式对嘴部坐标进行确定,其中 xface 和 facey
分别表示基于 adaboost 算法检测的人脸的矩形框的
左下方原点坐标值， faceW 与 faceH 分别为人脸区域即
矩形框的宽与高。 0
x y 表示嘴部矩形框的左上角
)
坐标， mouchW 与 mouchH 分别表示人嘴区域矩形框的宽
与高，计算式如式(5)所示。 

(

,

0

y
o

x
0








W




H



x
face





y
face



W
face
4
H
face
3


mouch

mouch





W

face
H
face
4

(5) 

x
0

2

采用嘴部的宽高比进行打哈欠判断，计算式如

式(6)所示。 

P



W
H

mouch

mouch

(6) 

当嘴部处于正常状态时，显然 P 值大于 1；当
处于打哈欠状态时，P 值显然逐渐变小，直至小于
1。本系统中对于打哈欠状态的识别，即当 P 值等
于 1 时检测算法作为打哈欠状态处理。通过计算在
一定时间内，P 值大于或等于 1 的频率，来对嘴部
进行疲劳状态识别，如式(7)所示。 

L 

1

p

≥ 的图像帧数
待定时间内图像总帧数



100%

(7) 

选取被试者 1 分钟内模拟打哈欠，记录每分钟
打哈欠次数为 1 次、2 次、3 次、4 次、5 次等对应
的 L 值，并由不同帧次对应 L 值制作相应的瀑布图，
具体如图 7 所示。 

本文通过计算每分钟内的 L 值进行疲劳判
断，由先验知识可知人们打一次哈欠需 5 s 左右。
由 L 值瀑布图可以看出当每分钟内打哈气次数为
3 次及之后增长幅度明显逐步增大，且说明驾驶
员疲劳程度逐步加深，即 L 值大于 25%时，判定
为疲劳状态。 

2018184-4

 
 
 
 
 
 
 
 
 
 
 
·26· 

通    信    学    报 

第 39 卷 

选取被试在模拟驾驶仓中道路环境单一的模式
下连续直行驾驶 1  h，并从中抽取发生眼睛焦点偏离
正常范围状态下的 1 min 散点图，如图 8 所示。 

图 7    1 min 内不同哈欠次数的瀑布图 

3.2.2    点头判断指标 

基 于 上 文 对 嘴 部 区 域 的 检 测 与 疲 劳 状 态 识
别，提出根据 P 值判断驾驶员的点头状态。当驾
驶员处于瞌睡状态时，会产生点头反应，驾驶员
点头时，是系统所检测到的驾驶员嘴部区域高度
变无穷小，并将未检测到嘴部的情况按打哈欠状
态判定，本系统中对于点头状态识别采用计算 P
值大于 P1 的频率进行，其中 P1 为驾驶员初始状
态值。 

U



p



的图像帧数
p
1

待定时间内图像总帧数



100%

(8) 

由常理可知，瞌睡状态点一次头所需时间为 2 s
左右，理论上每分钟内点头动作超过 10 次以上就
属于疲劳状态，即当图像帧数为 240 帧的 U 值大于
33.3%时，判定疲劳状态。 
3.3    眼动分析 

驾驶员驾车时眼睛需时常观察道路状况，视线
不断发生有规律的变化[16]。专注力会在道路上信息
意义最大的目标物所在区域内波动，眼睛焦点的运
动随驾驶的稳定会变得有规律[17]。相关研究表明，
若驾驶人连续 2  s 注视方向偏离正常道路前方，发
生交通事故的概率会增加 2 倍[18]。 

因此当驾驶人出现疲劳驾驶时眼睛会出现长
时间零摆动状态，也就是偏离了正常方向。所以
通过对眼睛焦点位置（eye focus position, EFP）移
动的相关信息的研究，分析注视方向和注视时间
的变化，可以对驾驶员的驾驶状态进行检测。采
用式(9)对疲劳进行判断，其中 1S 表示注视方向偏
离正常范围的图像帧数。 

图 8    眼睛焦点偏离不常状态的散点图 

由实验可知正常焦点范围为（2.5±1.8）mm，
当焦点位置存在连续 2  s 以上几乎零摆动时，说明
驾驶员开始出现目光呆滞现象。 

根据常理，若每分钟内出现 3 次及以上目光呆
滞现象，驾驶员有很大可能处于疲劳状态。由上表
可知每次偏离正常范围的图像帧数至少为 5 秒，即
当每分钟内注视方向偏离的帧数超过 180 帧时，S
大于 22.2%时，判断为疲劳状态。 

4    检测结果 

4.1    基于改进的 D-S 证据理论合成算法 

D-S 证 据 理 论 最 早 由 哈 佛 大 学 数 学 家 A.P. 
Dempster 首次提出，后由 Shafer 加以扩充和发展。
该方法可以在先验概率未知的情况下，通过简单的
证据合成准则，将多个信息进行合成，得出较好的
综合结果，但随着信息的增加该算法的计算复杂度
成指数增长[19]。因此，本文采用一种基于加权和矩
阵运算的改进的 D-S 证据理论合成算法，该算法可
成功克服上述缺陷。 
4.1.1    改进的 D-S 证据理论合成算法 

基于加权和矩阵运算的改进的 D-S 证据理论合

成算法的具体算法如下[19]。   

1)  定义 Θ 为识别框架记为： =

A   
,
2 ,
}nA ， 2  为 Θ 的幂集，对于任一个属于的 Ω 子
集 A，令它对应一个数 m， 
，且 m 满足 


m A 

1{ ,A

0,1



m



;

 



A






m A





1

(10) 

S

=

S
1
待定时间内图像总帧数



100%

(9) 

则称 m 为 2Θ 上定义基本概率赋值函数  BPA（basic 
probability assignment），m（A）称为 A  的基本可信数，

2018184-5

 
 
 
 
 
 
 
 
 
第 Z1 期 

郭慧利等：基于面部多特征的疲劳驾驶预警系统的研究 

·27· 

反映了支持命题 A 发生的程度。 
为证据的焦元或焦点元素。 

m A  的命题称
0



2)  计算各证据的平均值 

m m

2

1

m







m
n


n

(11) 

然后，计算各证据到平均证据的距离： 

就是采用 DS 组合式的分子部分），而矩阵中的所
有其他元素的和构成了证据的不确定因子，即 


m m p q
jp


  
m
,

1, 2,

(19) 

K







ip

,



p q


令 j
z

a ，则可得对应焦元的融合指标，即 

jj

m

j



z

1



j
K

(20) 


s m
i





d

i





e


m A m A






i







e


m B m B






i






,
i

1, 2,



,
m
(12) 

4.1.2    融合结果 

最后，计算各证据的可信度 


c m
i






s m
i
 

1,2,



n

i

,



s m
i



(13) 

,

i

n



1

1,2,

i



其 中 ， 
c m 作 为 证 据 mi 的 权 重 ， 满 足

 
。证据的权值反映了其他证据体
c m
i
对该证据的支持程度。如果支持程度较高，则相应
的权值高，对组合结果影响大；反之，相应的权值
低，对组合结果影响小。 

M c m c m
1
2





1

2

n





c m
n
n

(14) 

3)根据基本概率分配构建置信度矩阵 M n m

本文为计算方便将各个特征信息分离开，虚拟
的认为是由多个传感器得到的数据。通过上述实验
过程中对驾驶员各单信号特征疲劳阈值的确定，构
造出 D-S 证据理论中的基本概率赋值函数，利用
改进的 D-S 证据理论组合规则进行融合。选择 30
名被试者，13:00 开始在模拟驾驶仓内连续模拟驾
驶 1 小时，记录各单特征数据，为以后的融合做好
，K、S、L、U 分
准备。这里设 { ,
K S L U E
, }
,



,

别为上文中检测的单个特征指标的值，其中，E 为
其它特征状态所占比例极其微小影响可忽略不计。
按照改进的 D-S 证据理论算法进行融合，实验结
果如表 1 所示。 

维矩阵）[20]为 

M



M

1

M

2



M

n



















 
 

m m
11
12
m m
21


22






m
m
1
m
2

m



m m
1
n
n

2



m

nm









表 1 

状态 

清醒 

疲劳 

(15) 

疲劳结果 

m(K) 

m(S) 

m(L) 

m(U) 

( )m   

0.055 6 

0.156 8 

0.184 2 

0.226 9 

0.072 8 

0.159 8 

0.222 3 

0.251 3 

0.333 3 

0.198 3 

重度疲劳 0.196 7 

0.254 8 

0.261 9 

0.350 6 

0.265 9 

其中	

m m

1
i
i

2







m

im



1,

i



1, 2,

  
,
n

(16) 

将矩阵 M 中的某一行 i 进行转置，然后与矩阵

的另一行 j 相乘，即 

M M

i

j



[

m m
i
i
1

2



m

nm

T
]



[

m m
1

j

j

2



展开得到一个新的 m m 维矩阵 A 

m

]

jm
(17) 

A




 




i


j

1
i



m m m m
1
j
m m m m
1
j







1
i

2

2

i

2

j

2





m m

1
i

jm
m m

2

i

jm




m

im



m m
1

j

im



m

j

2



m

nm



m

nm

  (18) 









从式(17)可以看出，主对角线的元素即为传感
器 i 与传感器 j 对目标基本概率分配的乘积（实际

将所得的各特征信号的疲劳阈值进行证据理
论合成，得到综合疲劳指标 ( )m  ，将超过阈值 20%
的值进行证据理论合成，得到重度疲劳指标 ( )m  ，

如表 1 所示。 

对 单 个 特 征 信 号 使 用 相 同 的 方 法 进 行 数 据
处理并通过该结果判断驾驶员的疲劳状态，结果
表面单特征准确率很低，而对于 D-S 数据融合处
理后的结果判断驾驶员的疲劳状态，结果所示误
判率明显降低。本文将每次实验分为 6 组，共进
行 50 次实验，分别对 PERCOLS、嘴部、眼动和
点头数据进行处理，然后对这 4 个特征采用传
统 D-S 证据理论合成处理，最后对驾驶员上述 4
个特征信号采用改进的 D-S 证据理论合成方法
进行融合处理，最终判断结果的准确率如 表 2
所示。 

2018184-6

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
·28· 

通    信    学    报 

第 39 卷 

表 2 

各疲劳种类比较结果 

疲劳种类 

准确判断次数 误判次数 

准确率 

PERCOLS(K) 

嘴部状态(L) 

眼动(S) 

点头(U) 

传统 D-S 

融合 

37 

34 

26 

27 

43 

46 

13 

16 

24 

23 

7 

4 

74% 

68% 

52% 

54% 

86% 

92% 

由上表可知，该系统在融合了多种面部特征之
后，准确率明显提高，且该系统在单个特征值超过
规定疲劳值 20%时直接判定驾驶员处于疲劳状态，
并通过基于 IPv6 的网络预警系统发出预警，及时提
醒驾驶员尽快停车休息。与传统 D-S 融合算法相比
准确率也有所提升，并且运行速率大幅提高。由此
可知，在驾驶员疲劳驾驶检测方法上，本文所提出
的多种面部特征融合后的结果优于单特征和传统
D-S 证据合成。 

5    结束语 

本文通过优质像素的 CCD 摄像头采集驾驶员
驾驶图像信息，对获取图像进行灰度变换和二值化
处理，增强图像的对比度更有利于图像感兴趣区域
的识别[21]。利用基于 adaboost 算法的人脸分类器对
驾驶员的面部区域进行识别。在此基础上用灰度积
分投影法对眼睛进行定位与状态捕获，然后采用
PRECOLS 算法与眼睛焦点位置信息进行疲劳判
断。另外，对嘴部区域建立坐标系，通过计算其在
一定时间内长宽比值不小于 1 的频率进行嘴部打哈
气疲劳状态判断，比值趋于特定值的频率进行点头
判断。通过改进的 D-S 证据理论合成算法得到综合
疲劳指标，当综合疲劳指标达 0.198  3 时基于 IPv6
的网络预警系统会及时发出预警，并提醒驾驶员尽
快停车休息。该方法以不影响驾驶员驾驶的方式对
所采集到的信息进行有效的处理，与传统疲劳检测
相比本文将多种信号特征相融合的方法结果更加
稳定高效，并且确保了系统的可靠性与高效性。 

参考文献： 

[1]  孙超.  基于人眼状态的疲劳驾驶检测技术的研究与实现[D].大连：

大连理工大学, 2014. 

SUN  C.  Research  and  implementation  of  fatigue  driving  detection 

technology  based  on  human  eyes[D].  Dalian:  Dalian  University  of 

[2]  毛须伟,  景文博,  王晓曼,  等.  一种基于眼部状态的疲劳驾驶检测
方法[J].  长春理工大学学报(自然科学版), 2016, 39(2): 125-130. 

MAO X W, JING W B, WANG X M, et al. A fatigue driving test me-

thod  based  on  eye  state  [J].  Journal  of  Changchun  University  of 

Science  and  Technology  (Natural  Science  Edition),  2016,39(2): 

125-130. 

[3]  王斐,  王少楠,  王惜慧,  等.  基于脑电图识别结合操纵特征的驾驶

疲劳检测[J].  仪器仪表学报, 2014,35(2): 398-404. 

WANG  F,  WANG  S  N,  WANG  X  H,  et  al.  Driving  fatigue  detection 

based on eeg recognition combined with operating characteristics [J]. 

Journal of Instrumentation, 2014,35(2): 398-404. 

[4]  朱莹莹.  下一代 IP 技术——IPv6[J].  民营科技, 2009(5): 38. 

ZHU Y Y. Next generation IP technology:IPv6[J]. Private Technology, 

2009(5): 38. 

[5]  陆强,  朱亚进.  中职学校新校区校园网 IPv6 方案的设计原则[J].  信

息与电脑(理论版), 2018(9). 

LU Q, ZHU Y J. Design principles of IPv6 scheme for the new cam-

pus  network  of  secondary  vocational  schools  [J].  Information  and 

computers (Theoretical Edition), 2018(9). 

[6]  朱聪.  光学镜片表面疵病检测算法研究[D].  成都:  西南交通大学, 

2014. 

ZHU  C.  Study  on  detection  algorithm  for  surface  defects  of  optical 

lenses [D]. Chengdu:Southwest Jiaotong University, 2014. 

[7]  李娥.  人脸检测方法综述[J].  信息技术与信息化, 2018(4). 

LI E. Overview of face detection methods [J]. Information Technology 

and Informatization, 2018(4). 

[8] 

JIANG L, WANG H, GAO S, et al. Research of the automotive driver 

fatigue driving early warning system[J]. 2011, 226: 383-391. 

[9]  孙为民,  王晖,  高涛,  等.  将人工神经网络和 Adaboost 相结合提高

绝缘子图像识别的准确率[J].  电子世界, 2017(24): 27-28. 

SUN W M, WANG H, GAO T, et al. The combination of artificial neu 

ral network and adaboost to improve the accuracy of insulator image 

recognition [J]. Electronic world, 2017(24): 27-28. 

[10]  耿利川,  成运,  苏松志,  等.  RBFD:一种鲁棒的图像局部二值特征
描述子[J].  计算机辅助设计与图形学学报, 2015. 27(5): p. 815-823. 

GENG  L  C,  CHENG  Y,  SU  S  Z,  et  al.  RBFD:  a  robust  local  binary 

feature  description  of  images  [J].  Journal  of  Computer-Aided  Design 

and Graphics, 2015, 27(5): 815-823. 

[11]  亢洁,  李静.  基于积分投影和模板匹配的人眼定位算法研究[J].  陕

西科技大学学报, 2017,35(1): 174-177. 

QI  J,  LI  J.  Research  on  human  eye  localization  algorithm  based  on 

integral projection and template matching[J]. Journal of Shaanxi Uni-

versity of Science and Technology, 2017,35(1): 174-177. 

[12]  YOU F,LI  Y  H,HUANG L, et al.,Monitoring drivers' sleepy status at 

night  based  on  machine  vision[J].  Multimedia  Tools  &  Applications, 

2017,76(13): 14869-14886. 

[13]  吴天翔.  基于视频人脸图像的警觉度估计研究[D].上海:上海交通

大学, 2013. 

WU  T  X.  Research  on  alertness  estimation  based  on  video  face  im-

age[D]. Shanghai: Shanghai Jiaotong University, 2013. 

[14]  STEM  J  A,BOYER  D,SCHROEDER  D.  Blink  rate  ss  a  measure  of 
fatigue:  a  review[J].  Blink  Rate  As  A  Measure  of  Fatigue  A  Review, 
1994. 

[15]  CARROLL  R 

J.  Ocular-based  measures  of  driver 

alert-

ness[C]//International  Truck  and  Bus  Safety  Symposium,  2nd,  1999, 

Technology, 2014. 

Knoxville, Tennessee, USA. 1999. 

2018184-7

 
 
第 Z1 期 

郭慧利等：基于面部多特征的疲劳驾驶预警系统的研究 

·29· 

[16]  SUN X. Driver fatigue alarm based on eye detection and gaze estima-

[作者简介] 

tion[C]//International  Symposium  on  Multispectral  Image  Processing 

and Pattem Recognition. International Society for Optics and Photon-

ics, 2007, 6786: 678612-678612-6. 

[17]  FRIDERICHS  F，YANG  B.  Camera-based  drowsiness  reference  for 

driver state classification under real driving conditions[C]// Intelligent 

Vehicles Symposium, IEEE, 2010:101-106. 

[18]  牛清宁,  周志强,  金立生,  等.  基于眼动特征的疲劳驾驶检测

方法[J].  哈尔滨工程大学学报, 2015(3): p. 394-398. 

NIU Q N, ZHOU Z Q, JIN L S, et al. Fatigue driving detection method 

based  on  eye  movement  characteristics  [J].  Journal  of  Harbin  engi-

neering university, 2015(3): 394-398 

[19]  杨靖,林益,洪露,等.  一种改进的 D-S 证据理论合成方法[J].  计算机

工程与应用, 2012, 48(20): 150-153. 

YANG J, LIN Y, HONG L, et al. An improved method of d-s evidence 

theory  synthesis[J].  Computer  Engineering  and  Application,  2012. 

48(20): 150-153. 

[20]  宿陆,  李全龙,  徐晓飞,  等.  基于 D-S 证据理论的传感器网络数据

融合算法[J].  小型微型计算机系统, 2006. 27(7): 1321-1325. 

SU  L,  LI  Q  L,  XU  X  F,  et  al.  Sensor  network  data  fusion  algorithm 

based  on  D-S  evidence  theory[J].  Small  Micro-Computer  System, 

2006, 27(7): 1321-1325. 

[21]  ANDRADE  E  L,  FISHER  R  B.  Simulation  of  crowd  problems  for 

computer vision[J]. First International Workshop on Crowd Simulation, 

2005. 

郭慧利（1996−），女，山西临汾人，太原
理工大学硕士生，主要研究方向为人工智
能、智能信息处理。 

王恁（1991−），男，山西太原人，太原
理工大学硕士生，主要研究方向为脑信
息科学。 

郭浩（1981−），男，山西太原人，博士，
太原理工大学副教授，主要研究方向为脑
信息学、智能信息处理、脑网络组学研究。

2018184-8

 
 
 
 
 
 
 
