学校代码：10289分类号：TP391密级：公开学号：202070017江苏科技大学硕士学位论文基于多特征融合的船舶驾驶人员疲劳检测研究研究生姓名张博熠导师姓名刘庆华申请学位类别全日制学术型硕士学位授予单位江苏科技大学学科专业计算机科学与技术论文提交日期2023年4月22日研究方向计算机视觉论文答辩日期2023年5月29日答辩委员会主席俞孟蕻评阅人盲审盲审2023年06月05日分类号：TP391密级：公开学号：202070017工学硕士学位论文基于多特征融合的船舶驾驶人员疲劳检测研究学生姓名张博熠指导教师刘庆华教授江苏科技大学二O二三年六月ResearchonFatigueDetectionofShipDriversBasedonMulti-featureFusionSubmittedbyZhangBoYiSupervisedbyLiuQing-huaJiangsuUniversityofScienceandTechnologyJune,2023摘要I摘要现如今各地内河货物的流通率提高，我国内河范围内船舶的数量也越来越多，虽然现阶段船舶的导助航系统也比较完善，但是近3年来由于船舶驾驶值班船员疲劳驾驶所导致的船舶触礁碰撞事故也时有发生。因此研究一种针对于船舶驾驶人员的疲劳检测方法具有十分重要的意义。在常用的疲劳检测方法中，存在驾驶员抵触、检测模型大、时延高和误判率高等问题，因此本文首先对YOLOv5s进行改进，保证准确度的前提下，减小了模型大小且降低了人脸检测的时延；其次基于眼嘴多特征融合设计了一种新的疲劳判定模型，降低了疲劳检测的误判率；最后通过设计开发疲劳驾驶监测预警系统，实现人机交互和检测结果可视化。本文主要研究工作如下：(1)针对现有的人脸识别在边缘设备上检测准确率和速度都较低的情况，提出一种基于YOLOv5s的人脸及关键点检测与定位的方法，首先优化原有Mosaic数据增强的方法，让其更加适用于人脸检测并提升检测性能；其次使用GhostBottleNeck构建CSPNet-G代替原有的CSPNet主干网络，使检测模型更加轻量化，将原有Focus块替换为Stem块，降低了计算复杂度，提高了网络的泛化能力，改进网络PAN结构，提高对大人脸的检测效果，同时根据当前帧和前一帧差别，缩小检测范围，确定ROI，降低了同一镜头下多名驾驶员对检测的干扰；最后采用Wing-Loss作为人脸关键点回归的损失函数，提高了模型的回归精度和收敛速度。(2)针对现有疲劳判定模型时延高和误判率高等问题，首先对YawDD、CEW和NTHU-DDD进行整合，实现疲劳判定模型对眼部和嘴部多特征融合的训练；其次采用截取并校正眼部和嘴部图像，对眼睛睁闭，嘴部开闭进行识别，降低了背景对眼嘴状态识别的干扰，解决了船舶驾驶时驾驶员头部运动幅度较大的问题，以Ghost模块为基础构建了眼嘴状态分类网络EMSD-Net，并加入ECA注意力模块，实现模型轻量化及加快对眼嘴状态的识别，提出了一种新的判定方法用于区分嘴部的正常打开和打哈欠的状态，以减少将嘴部正常说话误判为打哈欠，进而降低整体疲劳检测的误判率；最后融合眼部和嘴部特征，根据PERCLOS、CCT和SYT，实现对是否疲劳进行判定。(3)设计开发了船舶驾驶员疲劳驾驶监测预警系统。该系统主要实现对输入的图片或视频流进行检测，输出视频检测结果图和疲劳特征结果，并在识别出疲劳状态时，发出警示。为实现检测便携性，将该系统部署至JetsonTX2中；针对部署后出现的视频卡顿问题，利用TensorRT对模型进行加速，最终实现检测结果可视化。关键词船舶疲劳驾驶检测；多特征融合；YOLOv5；Ghost模块；人脸检测AbstractIIIAbstractNowadays,thecirculationrateofinlandgoodsaroundthecountryisconstantlyincreasing,thenumberofshipswithinthescopeofinlandriversinChinaisalsoincreasing.Althoughthenavigationassistancesystemofshipsisalsorelativelycomplete,inthepastthreeyears,shipcollisionaccidentscausedbyfatiguedrivingofshipdriversondutyhavealsocomeupattimes.Therefore,itisofgreatsignificancetostudyafatiguedetectionmethodforshipdrivers.Incommonlyusedfatiguedetectionmethods,thereareissuessuchasdriverresistance,largedetectionmodels,hightimedelay,andhighmisjudgmentrates.Therefore,thisarticlefirstimprovesYOLOv5storeducemodelsizeanddelayinfacedetectionwhileensuringaccuracy;Secondly,anewfatiguedetectionmodelwasdesignedbasedonmultifeaturefusionoftheeyesandmouth,whichreducedthemisjudgmentrateoffatiguedetection;Finally,bydesigninganddevelopingafatiguedrivingmonitoringandwarningsystem,human-computerinteractionandvisualizationofdetectionresultsareachieved.Themainresearchandworkofthisthesisareasfollows:(1)InviewofthelowdetectionaccuracyandspeedofexistingfacerecognitiononEdgedevice,amethodoffaceandkeypointdetectionandlocationbasedonYOLOv5sisproposed.First,theoriginalMosaicdataenhancementmethodisoptimizedtomakeitmoresuitableforfacedetectionandimprovethedetectionperformance;Secondly,usingGhostBottleNecktoconstructCSPNet-GinsteadoftheoriginalCSPNetbackbonenetworkmakesthedetectionmodelmorelightweight,replacingtheoriginalFocusblockwiththeStemblock,reducingcomputationalcomplexity,improvingthenetwork'sgeneralizationability,improvingthenetworkPANstructure,andimprovingthedetectioneffectonadultfaces.Atthesametime,basedonthedifferencebetweenthecurrentframeandthepreviousframe,thedetectionrangeisreducedandtheROIisdetermined,Reducedinterferencefrommultipledriversinthesamelensfordetection;Finally,WingLossisusedasthelossfunctionoffacekeypointregressiontoimprovetheregressionaccuracyandconvergencespeedofthemodel.(2)Toaddresstheissuesofhighlatencyandhighmisjudgmentrateinexistingfatiguejudgmentmodels,YawDD,CEW,andNTHU-DDDareintegratedtoachievethetrainingoffatiguejudgmentmodelsformultifeaturefusionofeyesandmouth;Secondly,byinterceptingandcorrectingeyeandmouthimages,therecognitionofeyeopeningandmouthopeningandclosingisachieved,whichreducestheinterferenceofbackgroundoneyeandmouthstaterecognitionandsolvestheproblemoflargeheadmovementduringshipdriving.BasedontheGhostmodule,aneyeandmouthstateclassificationnetworkEMSD-Netisconstructed,andanECAattentionmoduleisaddedtoachievemodellightweightandacceleraterecognitionofeyeandmouthstates,Anewjudgmentmethodhasbeenproposedtodistinguishthenormalopeningandyawningstatesofthemouth,inordertoreducethemisjudgmentofnormalspeakingasyawningandtherebyreducetheoverallmisjudgmentrateoffatiguedetection;Finally,byintegratingeyeandmouthfeaturesand江苏科技大学工学硕士学位论文IVbasedonPERCLOS,CCT,andSYT,itispossibletodeterminewhetherfatigueispresent.(3)Afatiguedrivingmonitoringandwarningsystemforshipdrivershasbeendesignedanddeveloped.Thesystemmainlydetectsinputimagesorvideostreams,outputsvideodetectionresultmapsandfatiguefeatureresults,andissueswarningswhenfatiguestatusisrecognized.Toachievedetectionportability,deploythesystemtotheJetsonTX2;Toaddresstheissueofvideolagafterdeployment,TensorRTwasusedtoacceleratethemodelandultimatelyachievevisualizationofdetectionresults.KeywordsShipfatiguedrivingdetection;multi-featurefusion;YOLOv5;GhostModule;Facedetection目  录 第1章 绪论............................................................................................... 1 1.1 研究背景 ........................................................................................... 1 1.2 国内外研究现状 ............................................................................... 2 1.2.1 基于驾驶人的生理特征参数的检测方法 ................................ 3 1.2.2 基于驾驶人行为和船舶行为特征的检测方法 ........................ 5 1.2.3 基于驾驶人面部特征的疲劳驾驶检测方法 ............................ 5 1.3 研究内容和结构 ............................................................................... 6 第2章 相关理论与方法 .......................................................................... 9 2.1 目标检测 ........................................................................................... 9 2.2 轻量级网络 Mobile Net ................................................................ 11 2.2.1 深度可分离卷积 ....................................................................... 12 2.2.2 线性瓶颈和倒残差结构 ........................................................... 13 2.2.3 激活函数 Re LU6 和 h-swish ............................................... 14 2.3 人脸及关键点检测 ......................................................................... 16 2.3.1 Adaboost 算法 ........................................................................... 17 2.3.2 基于深度学习的方法MTCNN ............................................... 18 2.3.3 基于 Retina Net 的 Retina Face 算法 .................................. 19 2.4 YOLOv5 算法 ................................................................................. 21 2.5 本章小结 ......................................................................................... 21 第3章 基于 YOLOv5s Face 的人脸定位方法 ................................... 23 3.1 YOLOv5s 人脸及关键点检测的改进 ........................................... 23 3.1.1 YOLOv5s 检测算法 ................................................................. 23 3.1.2 轻量级主干网络 Shuffe Net V2 ............................................. 25 3.1.3 YOLOv5s 的网络优化 ............................................................. 25 3.2 实验仿真验证 ................................................................................. 28 3.2.1 数据集准备 ............................................................................... 28 3.2.2 模型训练 ................................................................................... 29 3.2.3 评价指标 ................................................................................... 30 3.2.4 实验结果与分析 ....................................................................... 30 3.3 本章小结 ......................................................................................... 34 第4章 基于 EMSD-Net 的疲劳状态判定 .......................................... 36 4.1 疲劳状态判定 ................................................................................. 36 4.1.1 眼部和嘴部区域提取 ............................................................... 36 4.1.2 疲劳状态识别网络 ................................................................... 38 4.1.3 多特征融合疲劳判定模型 ....................................................... 41 4.2 实验仿真验证 ................................................................................. 42 4.2.1 数据集建立 ............................................................................... 42 4.2.2 评价指标 ................................................................................... 44 4.2.3 实验结果与分析 ....................................................................... 45 4.3 本章小结 ......................................................................................... 49 第5章 疲劳驾驶监测预警系统的设计与实现 .................................... 51 5.1 系统总体设计 ................................................................................. 51 5.1.1 系统架构设计 ........................................................................... 51 5.1.2 系统功能模块设计 ................................................................... 52 5.1.3 系统整体工作流程 ................................................................... 52 5.2 Jetson TX2 疲劳驾驶检测系统搭建 ............................................. 53 5.2.1 Jetson TX2 深度学习嵌入式设备 ........................................... 53 5.2.2 Jetson TX2 疲劳驾驶检测系统整体框架 ............................... 55 5.3 疲劳驾驶监测预警系统演示 ........................................................ 55 5.3.1 系统可视化界面设计 ............................................................... 55 5.3.2 系统运行结果 ........................................................................... 56 5.4 本章小结 ......................................................................................... 60 总结和展望 ............................................................................................... 61 参考文献 ................................................................................................... 63 第1章绪论1第1章绪论1.1研究背景目前，我国内河的船舶发展在稳定推进。虽然内河水上交通安全持续稳定，但仍然不能完全避免水上事故的产生，而水上交通事故相比于公路事故，造成的影响更为巨大，不仅是轮船的经济损失，更是有可能导致大量人员的失踪，例如在“十三五”期间，广东海事局辖区内就发生了213起较大水上交通事故，造成了227人失踪及337亿元的经济损失。事故的类型分布如图1.1所示。图1.1水上事故发生类型Fig.1.1Typesofmaritimeaccidents在上述发生的事故中，由于船舶驾驶员疲劳所引起的事故也越来越多，疲劳已经成为海上事故的重点调查区域，已被列入NTSB的运输安全方面最需要改进的方面。例如2018年，一艘载着110名乘客的渡轮在水路行驶过程中，因驾驶员长时间工作，从凌晨5点就开始在船上工作，因发困无法集中注意力而撞上了浮桥，致使两名乘客和两名船员受伤。2021年4月21日凌晨4点，某运输1944吨油品的汽油船舶触礁后自行脱困，后调查发现是由于当班船员疲劳过度后睡着，导致航行期间船舶偏离轨道[1]。由于各大海上公司的竞争也日渐激烈，船舶驾驶室操控员在工作上也面临着巨大的竞争压力，再加上家庭等方面的影响，船舶驾驶员的疲劳驾驶问题也日益凸出。虽然在现阶段的船舶驾驶舱设置了每隔一段时间提醒的装置，但是如果有一个在驾驶员疲劳江苏科技大学工学硕士学位论文2状态产生初期就能发出警告的设备，这就可以有效地降低这类事故的发生率，减少人员伤亡和降低经济损失。因此，研究船舶驾驶员疲劳驾驶监测预警的方法对提高船舶驾驶安全性具有重要意义。通过对大量船舶事故的深入研究分析，此类事故的发生主要受三个因素的影响：人为因素、轮船因素和外部环境因素(包括天气、水路状况等)，其中引起水上交通事故最大的人为因素就是值班人员处于疲劳状态。如今的船舶驾驶越来越先进，虽然不需要船员时时刻刻对轮船进行操控，但是这也提高了对船舶驾驶员的操作要求，面对繁多的键位以及复杂的特殊情况需要值班人员在行船期间更加谨慎，身体控制更是要快速，再加上行船时间和空气环境的原因，驾驶人员的体力消耗的更快，也更容易进入疲劳状态，因此内河船舶的值班疲劳已然成为一个回避不了的难题[1]。当船舶驾驶员经过一段漫长的工作时间后，身体机能的下降，让其无法从容地对发生的特殊情况做出相对正确的判断，轻微情况下，可能还能瞬间清醒，对转舵快速旋转，避免事故的发生；而若是处于深度疲劳状态下，船舶驾驶员可能在事故发生后或者发现时已经没有多余时间进行挽救，进而造成事故[2]，这是一种正常的生理现象，而引起船舶驾驶员疲劳的因素也有很多方面。根据IMO专题研究，船员值班疲劳主要与以下因素紧密相关[1]：(1)睡眠不足或质量差。(2)频繁的港口访问和相关货物运输工作[1]。(3)工作环境，噪音大同时还伴随振动，船舶航行期间还会有横倾、纵倾，工作之余也不能好好休息。(4)在船时间较长，容易导致慢性疲劳。1.2国内外研究现状在汽车疲劳驾驶领域，国内外学者早在上世纪80年代就已经开始着手研究，但当时由于技术的局限，一些处于疲劳状态下不稳定的生理指标不能够被直观表现出来[3]，如今随着计算机技术的不断发展，尤其是深度学习技术的不断完善，从技术层面，为疲劳驾驶提供新的解决方案。而专门针对内河船舶驾驶员疲劳状态判定的研究仍然较少，与汽车驾驶员疲劳判定相比，船舶驾驶员由于无需时刻操控船舵，更容易分心乃至疲劳；船舶驾驶台需要操控的设备较多，船舶驾驶员的操控范围和运动幅度与汽车驾驶员相比也更大，进而导致脸部采集更容易出现翻转和倾斜等状态；部分船舶还会配备前后一高一低两个驾驶位，这种情况下，前方摄像头极容易捕捉到两位驾驶员的脸部特征，进而导致误判率升高。本节首先总结了内河船舶驾驶员疲劳监测的重要意义，再对寻常汽车驾驶员疲劳研究现状进行分析，为参数优选与判别模型搭建提供研第1章绪论3究思路。目前，疲劳驾驶的检测方法可分为主观和客观两种[4]，其中主观方法是基于问卷调查的方法，借助比较著名的问卷，例如斯坦福睡眠量表、驾驶记录表和皮尔逊疲劳量表等，问卷方法主要是根据司机的主观思维回答问卷中的问题，因主观性过强，不适合作为疲劳驾驶检测的标准方法；客观法是通过对驾驶员或者船舶的行驶信息来检测是否处于疲劳状态，国内外对疲劳驾驶常用的客观检测方法及比较如表1.1所示：表1.1疲劳驾驶检测常用方法比较Table1.1ComparisonofCommonMethodsforDetectingFatigueDriving检测依据特征参数具体描述准确性可扩展性实用性生理信号检测脑电图、心电图、肌电图等生理信号的变化很好一般差操作与船舶行为检测驾驶员的操作与船舶的行驶情况的变化一般很好好面部特征检测驾驶员面部状态变化很好很好很好1.2.1基于驾驶人的生理特征参数的检测方法当人的精神状态发生变化时，其身体技能也会发生相应变化，在生理特征上，会因疲劳程度的加深，相应指标也会逐渐异于正常值[5]，由于这些生理数据值都是固有的、自发的，因此，可以根据驾驶员生理特征的变化来判断疲劳程度，并保证其准确性，进而保证更加及时地给出警示，预防事故的发生。同时又因为采集数据的过程可以连续进行，也为实时监测驾驶员状态提供了条件。常见生理特征包括脑电（EEG[6]）、眼电（EOG[7]）、心电（ECG[8]）、肌电（EMG[9]）等。EEG被认为是这几种方法中，最为“靠谱”的检测方法。(1)脑电检测方法鉴于脑神经活动可以有效地反映疲劳这一特性，脑电信号在各类代表驾驶员疲劳状态的生理信号中被公认为“金标准”，并且是最具潜力、最可靠的。脑电图通常采用附着在头皮上的平面电极来提取。Borghini等人所提出的借助侦测EEG的方式在实验过程中的用户准确性方面有所局限[10]。此外，在微电子技术快速发展的背景下，国外已经出现了一种可穿戴脑电采集设备，因小体积和便捷性完美胜过传统采集设备，如图1.2所示。江苏科技大学工学硕士学位论文4图1.2可穿戴脑电采集设备Fig.1.2WearableEEGacquisitionequipment(2)眼电检测方法EOG所测量的是眼球前后的角膜与视网膜电位差，主要是通过在眼睛周围布置电极来对眼睛的运动进行测量。研究表明，人的眼动模式会在清醒到入睡的过程中逐渐变化。Zhu等人通过对22名志愿者的研究，在其眼睛周边精确放置电极，使用CNN从原始的EOG中提取特征，测量了疲劳响应的正确性，并推导出响应误差随疲劳程度的增加而增加的结论。但是电极的安装位置，很大程度上会对驾驶员产生干扰[11]，Zhang等人提出的通过放置在驾驶员前额的电极测量方法，很有前景。但是基于EOG的检测方法依然会受到实时性要求的限制[12]。(3)心电检测方法尽管ECG和PPG等心电信号被认为疲劳状态的准确检测方法，但是由于心电信号传感器具有侵入性，因此再实施过程中的可行性收到限制，近些年来，随着非侵入式传感器的进步，如今的传感器能够嵌入在方向盘或者安全带中，这类疲劳检测方法也因此得到普及[13]。起初，非侵入式的心电传感器被放置在驾驶员的座椅下，但是由于织物厚度的原因，这种方式容易出错，在此基础上，Jung等人利用驾驶员双手碰到电极所产生的心率参数，完成了研究，结果表明心率HR会随着疲劳程度的加深而上升[14]。Li等人提出了一种基于PPG的驾驶员检测方法，也是将PPG传感器放置于转舵上，借助其提取心率变异性参数HRV，并训练支持向量机分类驾驶员的状态[15]。(4)肌电检测方法肌电信号是由电极测量肌肉细胞产生的电势获得，例如表面肌电信号就是记录皮肤表面肌肉产生的电势，而肌肉疲劳就可以用这些从肌电信号中提取出来的特征来预测。Adalarasu等人使用15~30Hz的信号功率对肌肉疲劳进行检测。通过在驾驶员身体各个部位，包括手腕、肩部等放置表面肌电电极，在模拟环境中提取表面肌电，根据对11位参与者的研究，得出了15-30Hz的信号功率随着疲劳而增加的结论，由于表面肌电信号传感器的侵入性会引起驾驶员的不适，因此在实时驾驶疲劳检测应用中具有较高的局限性[16]。第1章绪论51.2.2基于驾驶人行为和船舶行为特征的检测方法在驾驶员出现疲劳之后，会影响其驾驶的能力。而航道交叉和舵转向角度异常等特征也可以作为驾驶员操控能力下降的表现。因此可以从间接角度，用船舶工作人员对船只的操控来衡量驾驶员的驾驶状态。疲劳与清醒之间状态的不同，可以借助传感器来测量转舵的旋转角度、船只的行进速度或者行驶线道来进一步研究分析。Mumford等人通过研究不同状态下功率谱分布，发现了其转角的功率在驾驶员疲劳情况下有明显增加的趋势[17]。McDonald等人使用方向盘角度与随机森林算法来检测汽车驾驶车道是否偏离[18]。李仁杰等人对方向盘的旋转角度进一步研究探索，最后借助相似熵和繁杂度研发了识别驾驶员疲劳等级的检测模型[19]。该类方法非侵入、实时性也较高，因此具有一定优势，但是实际使用这种方式的话，驾驶员的习惯方式会从一定程度上对识别造成影响。除此之外，由于睡意直接关系到驾驶员的驾驶状态和姿态，因此驾驶员的姿态变化也被许多学者用来作为疲劳检测的特征。Furugori等人采用将压力传感器安装在驾驶员的座位上，研究证明，压力分布会因时间从整个座椅到背部的某一点[20]。1.2.3基于驾驶人面部特征的疲劳驾驶检测方法驾驶员的面部和头部表现出来的变化是疲劳的最明显特征，该方法使用摄像头采集驾驶员的眼部、头部和嘴部等基础身体特征进而实现最终的疲劳识别判定。目前，国外已经有基于面部特征疲劳检测的商用产品，该疲劳检测系统就是根据上述三个基础因素实现驾驶状态的疲劳程度的检测，同时保证了准确和稳定[21]。(1)基于眼睛状态的实现闭眼频率、眼脸距离和睁眼百分比等特征都被证明为疲劳判定的适合指标，Sigari等人使用Haar-like特征检测器在图像中检测出人脸，再采用模板匹配和水平投影的方法来提取人脸特征，以客观评价为基础，对疲劳特征进行分类，但是这类方法人脸跟踪不准确且计算量大，在低光条件下精度会大大降低[22]。Mandal等人专门为公交车司机设计了一种通过公交车圆顶摄像头监控驾驶行为的疲劳检测系统，该系统首先用OpenCV对人脸和眼睛进行检测，其次用线性回归和谱回归对眼睛开合程度进行计算，最后通过梯度直方图(HOG)对头部和肩部进行检测，该技术虽已在真实的驾驶环境中对23名司机进行了测试，但由于其是针对公共汽车而设计的，缺乏普适性[23]。(2)基于头部位置的实现Murohy等人通过使用头部姿态估计来定位驾驶人员头部位置情况对其是否处于疲劳驾驶状态做出判定，头部姿态也是姿态的一种[24]。ASCI公司研制的一种传感器，用来检测头部的位移，实时记录各时间段头部位置的变化对驾驶员疲劳程度作出判断。江苏科技大学工学硕士学位论文6李勇达等人通过计算头部旋转角速度和头部倾斜角度等信息来综合判断疲劳状态[25]。(3)基于嘴部状态的实现Alioua等人将打哈欠用于疲劳驾驶识别，通过支持向量机检测到视频帧中的人脸，再用梯度边缘检测定位嘴部位置，最后使用圆形霍夫变换识别出嘴巴是否处于打哈欠状态[26]。童兵亮等人将驾驶员驾驶过程中嘴巴的张开度数作为输入，采用BP神经网络对输入进行识别，并对哈欠情况进行记录，最后以此判定是否处于疲劳的驾驶状态[27]。(4)基于混合特征的实现为提高检测精度，现阶段通常都将多个特征进行混合进行疲劳判定。Bergasa等人将Perclos、闭眼持续时间、眨眼频率、点头频率和面部位置等作为输入，进行疲劳检测[28]。Zhang等通过肤色分割确定人脸矩形框，再使用哈尔特征(Haar)定位眼睛，最后利用虹膜来计算眼睛闭合百分比。深度学习方法因准确性和适用性使其优于生物视觉和传统的机器视觉方法[29]。Wang等使用RetinaFace检测人脸，搭建并改进ShuffleNetV2，自动识别出眼嘴的相应状态[30]。Zhao等使用单次多盒检测器（SSD）检测人脸区域，并用VGG-16网络对人脸状态进行分类[31]。随着深度学习地发展，注意力机制也被证明是一种提高分类准确度的有效模块[32]。在文献[33]中总结了三种面部特征提取的方法，其中基于形状的特征提取方法的速度较快，但是对于人脸关键点的标注要求也较高，复杂的结构也让这种方式的实时性较差；基于手工提取特征的方法速度稍慢于基于形状的方法，但是这种方法对图片质量要求较高，也更容易受到光照的影响；基于深度学习的特征提取方法对于图片质量要求并不高，一些基于CNN的方法提取效果也较好，但由于网络结构的深度原因，实时性并不高，在实际使用中，可通过轻量化的网络增强检测的实时性。1.3研究内容和结构现有的疲劳驾驶检测中，由于面部特征检测的不接触性与设备要求不高等优势，通过这类方式对于船舶驾驶员的疲劳状态进行检测比较火热。研究的出发点，一方面是提高面部疲劳特征提取的精度，从而提升疲劳识别的准确度，减少错误识别的概率；另一方面是不断减少判别疲劳的时间，从实时性入手，提高检测效率，更有效地减少事故的发生。然而，目前针对该问题的实时性和准确性难以兼顾，无法准确判断驾驶员是否存在疲劳，并及时预警，提示驾驶员及时调整状态，以免引发重大事故。针对因疲劳驾驶而导致的频发事故，给人们造成了巨额的财产损失和严重人身伤害的现状，因此在本文中，采用了将多个疲劳特征进行融合来对疲劳进行识别，首先通过改进后的YOLOv5s算法实时检测驾驶员的面部区域及相关人脸关键点，再对第1章绪论7YOLOv5s网络结构进行优化改进，在最大程度上降低了对面部特征和特征点的提取速度，从而提升了算法的实时性能。再根据人脸关键点，确定出眼嘴的对应区域，针对性的进行疲劳特征的识别，以降低疲劳判定的误判率，尤其是在之前的研究中，张嘴说话较容易被识别为疲劳。最后利用多种疲劳特性识别方法，实现对驾驶员驾驶状况的精确判断，进而对其进行针对性的早期预警，降低交通事故的几率。将优化改进后的YOLOv5s模型与EMSD-Net相结合，可以同时满足疲劳驾驶检测对检测精度的要求和对疲劳预警的及时性的要求。本文在原有的网络模型上提出了改进方案，提升了检测的速度和精度，并采用多特征疲劳判别模型实现对驾驶员疲劳程度的进一步判断。本文的方法下，驾驶员但凡有疲劳的一部分特征都可以及时发出预警，更好地避免因疲劳驾驶引发的事故，减少船舶经济损失和人员的伤亡。本文立足于船舶驾驶人员疲劳驾驶危险行为的检测问题，以计算机视觉为基础，充分发挥面部检测不接触与对设备要求不高等优势，着重研究与解决现阶段疲劳驾驶检测过程中误判率高，检测时效性低的关键问题，通过结合眼嘴两部分的状态识别对船舶驾驶员疲劳检测与预警系统进行设计与开发，实现对驾驶员疲劳驾驶的监测与警示功能。本文结构安排如图1.3所示，主要研究工作如下：图1.3论文整体结构图Fig.1.3Overallstructurediagramofthethesis江苏科技大学工学硕士学位论文8第1章绪论。介绍研究背景和意义，结合近几年海上事故的数据分析表明对船舶驾驶员驾驶状态进行监测与预警的必要性与价值性；总结分析当前国内外对疲劳驾驶等危险行为检测的研究现状，进而引出在疲劳驾驶监测领域的关键性难题。第2章相关理论与方法。主要对深度学习领域的目标监测方法进行讲述，简单介绍目标检测的理论知识；对轻量级网络MobileNet的各个版本的区别以及运用的一些优化点进行阐述；最后介绍了一些常用的人脸与关键点检测方法以及YOLOv5算法。第3章基于YOLOv5sFace的人脸定位方法。在YOLOv5s的基础上进行改进，从整张图片中识别定位到人脸和关键点位置；为降低整体计算复杂度，提高网络的泛化能力，使用Stem块代替原有的Focus层；对原有的主干网络CSPNet进行改进，提高对大人脸的检测准确率，实现最终检测速度的提升；在数据集WiderFace上进行训练，采取Mosaic方法对数据进行增强，针对人脸的检测对上下翻转方式删除以提高训练效果；通过前后视频帧的特性，缩小检测区域，加快检测速度。第4章基于EMSD-Net的疲劳状态判定。根据检测到的人脸及关键点的位置坐标，对驾驶员眼部和嘴部按一定比例进行截取与旋转，以便后续分类；以Ghost模块为基础构建状态判定网络EMSD-Net，并引入注意力模块ECA，在尽可能维持精度的基础上，降低时延；对眼部状态实现开闭的判定，对嘴部的打哈欠状态进行判定，减少了驾驶员在正常说话时被判为打哈欠的情况，降低了误判率；最后结合PERCLOS、持续闭眼时间和持续哈欠时间等指标实现驾驶状态的判定。第5章疲劳驾驶监测预警系统的设计与实现。在YOLOv5sFace+EMSD-Net的基础上，设计出总体架构，在高性能设备JetsonTx2上进行部署，连接摄像头实时获取驾驶员的视频流，并对其状态进行检测判定，在发现驾驶员处于疲劳状态时，系统会及时发出声音，起到警示作用。总结和展望。主要总结了本文所涉及到疲劳检测算法的具体工作内容，同时指出在本文研究过程中发现的问题和不足，阐述在将来研究方向上的拓展。第2章相关理论与方法9第2章相关理论与方法2.1目标检测在现实环境中存在不同类型的对象，在机器的帮助下识别这些物体是项复杂的任务，计算机视觉让机器能够从图片或者视频帧中看到并识别物体。目标检测和图片分类任务是构建神经网络需要解决的两类主要问题，在目标检测训练过程中，使用对象分类定义图片中存在的一个或多个对象的类别，并为这些对象分配了标签[34]，物体定位时通过边界框[34]定位图像或视频中一个或多个物体位置的过程。目标检测任务要求我们不仅要利用算法判断图片中出现的物体是属于哪个类别，还要在图中找到他的位置和大小，用红框对其进行框示赋上相应标签及被识别对象的类概率，即置信度。由于图片中的物体不尽相同，即使相同的物体的摆放姿态也有所不同，再加上采集图片时外部环境的复杂性，例如光照强度，存在遮挡物等因素，更是为得到一个准确的目标检测结果增加了难度，这也是计算机视觉需要不断突破改进的方向。如图2.1所示，在目标的数量上，可分为单目标和多目标，从任务上来看，具有分类、定位和分割等。图2.1目标检测Fig.2.1objectdetection检测方法主要的三个步骤为：(1)信息区域：图像中出现的物体在大小和纵横比上可能有所不同，目标检测模型对整个图像会进行不同尺度的扫描，以检测目标并找到可识别的模式。这样的方法可以找到物体可能存在的位置，但也存在一定的不足，那就是需要高计算能力的处理过程中会产生多个候选窗口，代价较高。(2)特征提取：特征是一个图像中较为重要的因素，用于对物体进行分类和识别，然后特征提取的效果，会受到上文所说的背景、光照条件、天气等外在环境因素的影响。江苏科技大学工学硕士学位论文10(3)分类：分类用于从给定的类别数据中进行预测。在此过程中，将相关特征结合起来表示对象，并与训练后的模型进行比较，对于视觉识别，需要靠分类来区分目标对象与其他对象。深度学习中，深度神经网络被用来实现对图像的深度特征表示，更有效地实现了目标检测，降低了检测的错误率。但由于深度神经架构有大量用于训练的数据，因此，他需要大量的时间，例如AlexNet、VGGNet、GoogleNet等被主干网路被用于检测对象。从阶段步骤数来看，深度学习检测存在两阶段和单阶段[35]。两阶段的检测方法通常采用先识别出所有物体的区域，再通过深度学习模型进行分类两步骤来检测图像中的物体，这类方法可以在数据集上体现更好的结果和更高的精确度，常见的两阶段检测有RCNN、SPP、FastRCNN等；但与单阶段检测方法相比，它的推理速度较慢。对于倾向于实时检测的项目，更多地采用单阶段检测方法，可以有效地降低延迟，常见的单阶段检测有YOLO、SSD、RetinaNet等。考虑到之前的单阶段检测器的精度较低，RetinaNet应运而生，它的运行速度快，对密集和小尺度物体都能提供一个较高的精度，它的网络结构中存在一个主干网络和两个子网络，用于在多个尺度上进行目标检测。主干网络可以接收任何大小的输入图像，并计算输入的卷积特征映射。第一个子网络对主干网络结构输出实现分类，而第二个则实现边框，这两个子网络有利于提高单阶段检测器的性能。其网络结构如图2.2所示。图2.2RetinaNet网络结构Fig.2.2ThenetworkstructureofRetinaNetRetinaNet可分为四部分，结构为自底向上的主干网络、自顶向下的FPN、分类、回归子网络。第一部分是自底向上路径，选择ResNet作为主干结构来计算不同图像尺度下的特征映射；第二部分中的FPN(FeaturePyramidNet)用于横向连接和自顶向下的下采样，这有利于从任何大小的单一分辨率图像构建多尺度和丰富的特征金字塔；RetinaNet的分类子网络主要用来预测每个检测到的对象类别和锚框的概率，而第四部分的回归子网络主要获得目标边界框的各项参数。该网络中的损失函数(FocalLoss)确保检测速度的前提下，稳定了检测的精度。对于每一个anchor和事先标注好的box进行一一比对，将交并比(IOU)大于0.5的视作正第2章相关理论与方法11样本，将交并比小于0.4的视作负样本，而在这两者之间的，全部舍弃。FL独特的点在于正负样本都用来计算分类损失，然后仅对正样本进行回归损失的计算，这也有效缓解了之前单阶段检测器模型中的前景与背景类不平衡的问题。目标检测算法中的多阶段目标检测，主要采用的是先定位后分类，首先对输入图像定位识别ROI(ResionofInterest)，确定候选区域，再根据提取到的特征进行分类及检测框的回归。如RCNN就使用SS(SelectiveSearch)，通过计算图像中每个像素的纹理并不断合并相似组，进而得到候选区域，候选框相比于传统穷举法明显减少，为后续分类节省了许多计算资源；在回归步骤中，每个目标都会得到两到三个候选框，每个候选框都标有目标概率值。与之不同的单阶段目标检测有着检测速度快而且结构简单的优点，Tsung-YiLin等提出的RetinaNet就是一种典型的速度和精度都达标的单阶段目标检测算法，在此之前，YOLO、SSD等单阶段代表虽然在速度上已达标，但是在精度方面仍然不如FasterRCNN等多阶段代表。2.2轻量级网络MobileNet深度卷积神经网络普及以来，在计算机视觉领域，卷积神经网络尤为重要，为了追求更高的精度，通常都是采用构建更深、更复杂网络的方法，深度残差网络ResNet就是一个典型例子，它的深度最多已经达到152层，这固然能够提升其精确度，但是这也不是适用于所有应用，在例如自动驾驶、机器人等对时效性更敏感的应用中，如果使用ResNet类复杂网络，可能会因为计算量的增加，从而导致运行期间内存不足，因此，针对需要在计算力有限的平台上及时完成识别任务的应用场景中，轻量级网络MobileNet更为适合。MobileNet作为小模型、低延迟的代表性轻量级网络，它主要是利用一种高效的网络结构以及一对超参数，降低了网络的整体的参数、计算量，且具有高精度，从边缘设备设计需求层面完美地达到要求。MobileNet中主要的亮点在于深度可分离卷积的结构设计以及缩减模型宽度和减小输入图像分辨率这两个超参数。然而MobileNetV1存在Depthwise部分卷积核参数大量为0的问题，谷歌团队在2018年提出了MobileNetV2，它的精度更高，模型更小，主要是引入了倒残差结构(InvertedResiduals)和改进了线性瓶颈(LinearBottlenecks)[36]，并通过全卷积网络，适应不同尺寸的图像，为追求更强的鲁棒性，使用Relu6作为激活函数。在之后的MobileNetV3中，主要是对V2版本中的倒残差结构进行简单改进，更新为bneck，使用了NAS(NeuralArchitectureSearch)搜索函数，并加入了SE注意力机制模块，将激活函数Relu6更新为h-switch函数。江苏科技大学工学硕士学位论文122.2.1深度可分离卷积深度可分离是MobileNet的核心思想，它由深度卷积和点卷积组成，如图2.3所示，标准卷积分解为逐深度卷积和1x1逐点卷积的，对于MobileNet，深度卷积对每个输入通道应用一个过滤器，1x1卷积被用来组合深度卷积[36]。深度可分离卷积将标准卷积分成两层，一个用于过滤，另一个单独的层用于组合，这种方式起到了降低计算量和模型大小的作用。图2.3标准卷积和深度可分离卷积Fig.2.3Standardconvolutionanddepthseparableconvolution深度可分离卷积与传统的标准卷积的结构对比如图2.4所示。图2.4标准卷积和深度可分离卷积结构区别Fig.2.4Differencebetweenstandardconvolutionanddepthseparableconvolutionstructures假设输入的图像大小为FFDDM，其中FD表示特征图的宽和高，选取N个KKDD大小的卷积核，则传统卷积见式(2.1)。,,,,,1,1,,,ijmnklnkiljmijmGKK(2.1)一层网络的计算量见式(2.2)：第2章相关理论与方法13ortFFKKCDDDDMN(2.2)对于深度可分离卷积，它的表达式见式(2.3)。,.,,,1,1,ˆˆklnijijnkiljmGKF(2.3)它对应的计算量主要由DW卷积和PW卷积两部分构成，见式(2.4)。depdwpwFFKKFFCCCDDDDMDDMN(2.4)如式(2.5)所示，在深度可分离卷积作用下，较之传统卷积计算量有着明显的减少。211depFFKKFFrateoriFFKKKCDDDDMDDMNCCDDDDMNND(2.5)可以看出，标准卷积的参数量和计算量与深度可分离卷积的比值，随着kD的数值上升，而逐渐增大，证明了此结构具有良好的网络精简效果[36]。2.2.2线性瓶颈和倒残差结构MobileNetV2主要就是在MobileNetV1的基础上加入了残差思想。在通常的残差结构中，先是利用1x1卷积压缩输入通道，进而减少后续特征提取的计算量；再利用3x3卷积进一步提取特征；最后再次利用1x1卷积将特征的通道数恢复到和输入特征相同的数量。在通过“压缩—>提取特征—>扩张”这一过程，可以发现，形成了输入和输出的特征通道数要比中间通道数多的瓶颈结构。然而因为在MobileNet中使用了深度可分离卷积，它不会改变通道数，特征提取从而会被输入输出的通道数所限制，同时由于输入特征信息较少的原因，如果使用残差结构进行特征处理，会获得更少的有效特征信息，残差结构因此也不能直接加以使用。在MobileNetV2中，采用倒残差结构(InvertedResiduals)，通过先扩展维度结合卷积，更好地保留了特征，再压缩维度结合卷积，将模型压缩至可接受的范围内。由于ReLU非线性激活函数在维度较低时会造成过多的信息损失，因此在残差块的深度可分离卷积层之后的1x1卷积层用线性激活函数来代替ReLU，可以解决MobileNetV1中深度可分离卷积部分存在部分卷积核训练失效的问题。ReLU这一类激活函数，在使用时，以损失少量特征信息为代价，提高了图像的非线性特性，然而，在低维空间中，运行非线性激活函数不但会导致特征信息的损失，还会对输入的特征信息进行破坏[36]。因此，在MobileNetV2的网络结构中，加入了线性瓶颈，如图2.6所示，在经过第二次PW卷积后，为保证特征信息的完整性，将不再使用激活函数对信息进行非线性映射。江苏科技大学工学硕士学位论文14图2.5MobileNetV2网络结构图Fig.2.5TheNetworkstructurediagramofMobileNetV22.2.3激活函数ReLU6和h-swishReLU激活函数是目前使用率较高的一个函数之一，其公式见式(2.6)：()max(0,)agxz(2.6)ReLU函数相比于普通的sigmoid函数，它的使用，学习周期有较为明显的缩短效果。它的收敛速度要比sigmoid和tanh快很多，计算量小也是它速度快的一个原因；同时它也能避免梯度爆炸和梯度消失的问题；对神经网络也能使用稀疏表达。ReLU、tanh和sigmoid三种激活函数的示例图如图2.6所示。图2.6三种激活函数示例图Fig.2.6Examplediagramofthreeactivationfunction在MobileNetV3中，主要是对最后和一些早期的层进行改进以及使用h-swish代替了之前MobileNetV2中使用的激活函数ReLU6，它在Google[37]提出的swish函数的第2章相关理论与方法15基础上做出了改进。由于在网络结构中，往往最后和一些早期的层要比其他层更加昂贵，而要想保持准确性的基础上，减少这些层的延迟。通过去除之前瓶颈结构中的投影层和滤波层，使计算复杂度得到进一步降低，结构优化如图2.7所示。另一个昂贵的层在于初始的那组滤波器，为了进行边缘检测，同时为了有效地降低延迟，将构建滤波器组的数量减少一半至16个，同时使用ReLU或swish保持与32个过滤器一样的精度。图2.7原始最后阶段和高效最后阶段的比较Fig.2.7Comparisonbetweentheoriginalfinalstageandtheefficientfinalstage非线性函数swish被用作ReLU的代替品，它显著提高了神经网络的准确性，但是虽然swish提高了一定的精度，但是如果需要使用到移动设备的话，其计算sigmoid函数的代价较高，最终，用6(3)6RELUx来代替sigmoid函数，这个做法在精度方面并没有非常显著的差异，但在部署方面相比于原来的sigmoid函数具有很大的优势。ReLU6几乎适用于全体框架，也解决了潜在数值损失的问题首先，在实践中，h-swish也可以作为分段函数实现，减少内存访问数量，从而大幅降低延迟成本。Swish公式见式(2.7)，h-swish公式见式(2.8)，swish和h-swish的示例图如图2.8所示。s[]()wishxxsigmoidx(2.7)6(3)[]6RELUxhswishxx(2.8)江苏科技大学工学硕士学位论文16图2.8h-swish和swish的对比示例图Fig.2.8Comparativeexamplediagramofh-swishandswish2.3人脸及关键点检测基于面部状态判别驾驶员疲劳基本可分为人脸位置及关键点的检测、状态的特征识别和最终的疲劳评估三个步骤[38]。据研究表明，驾驶员面部状态的特征识别往往可以基于生物视觉[39]、传统机器视觉以及深度学习三种方式。在疲劳检测中，人脸状态识别主要对人眼和嘴巴的开合进行研究。作为一项经典研究方向，人脸检测近年来得到了广泛研究，起初的人脸检测器是基于滑动窗口和人工设定的特征，用来提取图像的局部二值模式，并使用贝叶斯分类器完成人脸识别任务[40]。另一种传统人脸检测方法是使用CNN作为人脸特征的提取器，再使用模糊感知和双通道进一步进行人脸与非人脸的分类。随着深度学习的发展，人脸检测取得了较大成果，而对于人脸检测，可以分为基于锚框和无锚框两类，基于锚框的检测方法继承了滑动窗口的概念，再输入图像的每个单元都使用多尺度锚点替换不同的滑动窗口，同时对候选区域进行预测，现在的研究人员关注如何有效设计并更好使用锚框来提高人脸检测的精度和召回率[41]，FaceBoxes使不同尺度的锚点再输入图像上拥有相同的密度，来提高对小人脸的检测效果[42]。人脸关键点检测是在人脸检测后，获得关键区域的位置坐标，包括眼睛、嘴巴或者人脸轮廓等。人脸检测的目的是定位和预测人脸的边界，也是人脸识别[43]-[44]、活力检测[45]和人脸年龄估计[46]-[47]等重要应用的关键步骤。第2章相关理论与方法172.3.1Adaboost算法Adaboost算法是2010年Viola和Jones基于haar-like特征和级联结构所提出的一种人脸检测算法，成功在模式识别领域所应用，实现了对人脸的实时性检测，在该领域也获得了较大的突破。Adaboost算法的核心思想是选择一个基础估量，在一些数据上拟合出相应的弱估量，以这些估量的精度为依据，为每个估量赋值一个权重，再将所有估量与各自的权重相乘并相加[48]，得出最后的预测结果。其基本原理图如图2.9所示。图2.9Adaboost算法基本原理Fig.2.9BasicprinciplesofAdaboostalgorithm在Adaboost算法人脸检测过程中，作者考虑到检测过程重背景的复杂性，提出将肤色等人脸特征加入到检测依据中，借助色彩空间的特性，降低了光照对人脸检测的影响，通过灰度值的差别，大致确定眼睛的坐标和眼睛的区域大小。嘴部区域的检测与眼部区域类似，利用Cb值比Cr值高出很多的特点，更容易检测到嘴部区域。最后根据检测出的眼嘴区域，能够较为容易地确定人脸的候选区域。Adaboost人脸检测示意图如2.10所示。Adaboost算法可以使用较为简单的弱分类器，不需要对特征进行筛选，也不易出现过拟合的情况；由于它的精度完全取决于弱分类器，因此在人工或自然数据上都能够很好地提升准确率；Adaboost在接收到下级分类器的反馈后能够进一步调整假定的错误率，执行效率较高。但是该算法对于异常样本较为敏感，会使得异常样本的权重较大，从而影响预测结果，导致准确率的降低。江苏科技大学工学硕士学位论文18图2.10Adaboost人脸检测示意图Fig.2.10FaceDetectionSketchMapofAdaboost2.3.2基于深度学习的方法MTCNN2016年，Zhang等人依靠人脸和人脸关键点之间潜在的联系，提出了一种多任务级联卷积神经网络(MTCNN)，在该算法中，同时解决了人脸边界框定位和面部五个关键点定位的问题，将两个检测任务同时进行。在MTCNN中，包含了三个级联的多任务卷积神经网络，每个神经网络都有三个学习任务，分别针对人脸类别、边界框和关键点位置。(1)第一层为ProposalNetwork(P-Net)，是一个全连接网络，先是粗略获取人脸候选窗口及其边界框的回归向量，再用推测边界回归来校准候选对象，并使采用非极大抑制(NMS)的方法消除重合度较高的候选框。P-Net网络结构如图2.11所示。图2.11P-Net网络架构Fig.2.11ThenetworkframeworkofP-Net(2)第二层为RefineNetwork(R-Net)，以上一层P-Net得出的候选框作为输入，进一步筛除大量虚假的候选对象，并使用边界框回归进行校准，同时使用NMS合并候第2章相关理论与方法19选对象，得到更为准确的候选框。R-Net网络结构如图2.12所示。图2.12R-Net网络架构Fig.2.12ThenetworkframeworkofR-Net(3)第三层为OutputNetwork(O-Net)，这一层和上一层类似，但是这一层对目标会更加详细地描述，更为关键的是会输出五个面部特征的坐标。O-Net网络结构如图2.13所示。图2.13O-Net网络架构Fig.2.13ThenetworkframeworkofO-Net虽然MTCNN采用了级联的思想，将一个大网络拆分成三个小网络，使参数量有所减少；大卷积核由小卷积核所代替，让其感受野一致的基础上，减少了参数的体量，但是其中的P-Net需要经过图像金字塔再传入网络进行计算，导致需要的时间较长，因此，考虑到更好的实时性，本文并不采用MTCNN进行人脸检测。2.3.3基于RetinaNet的RetinaFace算法2019年，Insightface团队在RetinaNet的基础上提出了RetinaFace人脸检测模型，使其对小目标人脸的检测效果也有所提升。RetinaFace模型的实现过程，首先将图像江苏科技大学工学硕士学位论文20输入主干网络，然后选取最后三个特征层作为输出，再构建FPN特征金字塔，最后使用SSH模块增强感受野，获得三个预测结果，分别是分类预测(是否为人脸)，人脸框回归(bbox)以及人脸关键点回归(landmarks)，针对同一物体出现多个候选框的情况，可利用NMS来抑制这些冗余的框。通过上述描述，不难看出RetinaFace在人脸检测过程中无需寻找人脸，利用回归可以直接对其位置和人脸关键点进行预测。如图2.14所示，RetinaFace的网络结构中存在P2至P6五层特征金字塔，其中经过主干网络特征提取后得到的C2至C5自顶向下融合相加得到P2至P5，而P6则由C5上步长为2的3x3卷积计算得到。其还在特征金字塔的不同层级上应用了5个独立的上下文模块，以达到增加感受野以及增强上下文建模能力的目的。图2.14RetinaFace网络结构图Fig.2.14TheNetworkstructurediagramofRetinaFaceRetinaFace的多任务损失函数定义为：=,∗+1∗,∗+2∗,∗+3∗(2.9)其中，,∗为人脸分类损失函数，则为锚点为面部的预测概率，∗的值（1/0）分别代表正锚点和负锚点;,∗为检测框回归损失函数，=,,,ℎ和∗=∗,∗,∗,ℎ∗分别表示与正负锚点相关联的预测框的坐标信息;,∗为面部标志回归损失函数，为面部聚点回归损失，=1,1.⋯,5,5表示预测到的关键点和∗=1∗,1∗,⋯,5∗,5∗标注的关键点。损失平衡权值参数1~3分别设置为0.25，0.1，0.01，如此一来，可以更好的从监督信号中，关注到预测框和人脸标志点的信息。但是在疲劳检测任务中与多人脸检测有所不同，疲劳驾驶检测对单个人脸区域定位的准确度要求更高，RetinaFace即使在复杂情况下，也可以准确输出面部的五个标志点：左右嘴角、鼻子中心、左右眼睛中心点。由于它综合了MTCNN和自监督的长处，可以实现定位到像素级，即使人脸的输入尺度并不相同[49]。因此，就算在驾驶员与视频采集设备相隔较远时，也可以准确地定位到人脸的5个标志点。MobileNetV1-0.25和ResNet50是其主流的两种主干网络，ResNet网络更加注重于检测精度，但是相对地，耗时也会随着精度的提高适当增加，而MobileNetV1-0.25是一种适合于移动端或嵌入式的轻量级主干网络，它是MobileNetV1-1通道数压缩为1/4的网络，MobileNet的主干网络相比于传统的神经网络大大降低了模型的参数量和第2章相关理论与方法21运算量，而准确率只存在小幅降低。2.4YOLOv5算法人脸检测的的正确率在一定程度上决定着疲劳驾驶检测的正确率，因此，正确且高效地检测到视频或图片中的人脸，获取到人脸关键点的位置成了疲劳驾驶检测算法中的关键任务。例如Viola和Jones所提出来的Adaboost这种传统算法，通过对图像的提取出来的数据进行多个弱分类器训练，再通过级联的方式得到一个强分类器，从而完成人脸的检测任务，虽然这类方式仍在使用，但是不断创新下，人脸识别也得到了较大的突破性进展，现如今对人脸检测分割出现了更好的方法。例如基于滑动窗口的MTCNN和基于锚框的RetinaFace，相比于传统的检测方法，基于CNN的人脸检测避免了人工提取特征，在当前大数据以及算力设备的技术支持下，获得了巨大的提升。虽然RetinaFace在人脸检测领域具有很好的效果，但是，它所针对的更多是多人脸的检测，在人脸数量越多，小目标越多的情况下，它才会有更加突出的表现，针对于疲劳驾驶中摄像头内出现人脸较少的情况，RetinaFace并不是非常的适配于疲劳驾驶的人脸检测。YOLO模型是一种端到端的卷积神经网络，主要采用回归的思想，可以快速地完成目标检测任务，该算法主要是用滑动窗口来代替传统地目标检测，这样可以降低外部因素对特征提取任务地影响。在第一代YOLO中借助了不止一个下采样层，使得网络学习到的特征并不精准；对于小物体的检测，也会因为大小物体的IOU训练时Loss值相近而降低物体检测定位的准确性。YOLOv5是近年来所提出的YOLO模型的改进版，相比于YOLOv4，拥有更高的精度和更快的速度，其主要的思路是将图像规划成多个网格，然后预测出每个网络内的物体的种类和位置信息，再根据预测框与真实框之间的IOU对目标框进行筛选，最终得到预测框的类别和位置信息。YOLOv5具有YOLOv5s、YOLOv5m、YOLOv5l、YOLOv5x和YOLOv5nano五种版本，分别应对对于实时性和精准度不同需求的任务，其中YOLOv5s是其中深度最浅、特征图宽度最小的一个版本，考虑到本文较高实时性的需求，因此采用特点为精度高、检测速度快和参数量较少的YOLOv5s为基础，在下文中对于人脸检测针对性改进。2.5本章小结本章首先介绍了目标检测的一些相关算法，其次对目标检测算法RetinaNet的网络结构及特点进行了阐述，由于轻量级网络MobileNet和疲劳驾驶检测所需要的时效性比较契合，因此引入MobileNet系列的网络和常见的激活函数ReLU6和h-swish，江苏科技大学工学硕士学位论文22解释了MobileNet系列在模型大小和精度上的优点。最后对于人脸关键点检测的不同种类的典型算法进行了介绍，从传统的分类器到现在的MTCNN算法和RetinaFace算法，为下一节改进的人脸检测算法YOLOv5sFace的实验提供了参考。第3章基于YOLOv5sFace的人脸定位方法23第3章基于YOLOv5sFace的人脸定位方法在2.1节中，已经对目标检测做出了简单解释，不管是对于船舶驾驶员还是车辆驾驶员，检测其是否处于疲劳状态的前提是能够准确、快速地检测到驾驶员人脸的所处位置，再根据检测到的人眼和嘴巴位置进行识别，但是往往会出现漏检或误检的情况，导致其检测效率降低，也不利于实际使用，对疲劳驾驶判定中人脸检测针对性分析，本章通过对YOLOv5s进行改进，从准确率与时延两方面分析，实现快速准确检测人脸位置，并将其运用到实际场景中，更好地验证方法的可行性。3.1YOLOv5s人脸及关键点检测的改进3.1.1YOLOv5s检测算法YOLOv5的结构与YOLOv4较为相似在YOLOv5s的网络结构中，可以分为输入端、Backbone、Neck、输出端四个部分。(1)输入端：在这一部分中，首先采用了Mosaic，这是在YOLOv4出现过的一种数据增强方法，通过对图片随机处理之后再进行拼接，增强了数据的丰富性，有利于真正使用中更好地检测到小目标；同时也会加入自适应锚框计算，用于输出预测框与真实框进行对比，得到两者差距，从而迭代网络参数；最后图片会经过一个自适应缩放的过程，这是因为在目标检测算法中，输入的图片长宽尺寸并不一致，而直接将图片统一缩放到一个标准尺寸，又会影响推理速度，因此在缩放后自适应添加尽可能少的黑边，得到最后的输入图片。(2)主干网络Backbone：YOLOv5中与之前版本有所不同的是在于加入了Focus切片操作，其与下采样类似，具体取值方法为对图片进行像素级一个隔一个操作，这样既保证了信息不丢失，又能获得四张互补的图片，这样的话，输入通道就被扩充了4倍，再将得到的图片进行卷积，获得为丢失信息情况下的二倍采样特征图。切片过程如图3-1所示。在进行了三层的下采样卷积改进后，降低了参数量，也达到了加快速度的效果；YOLOv5中涉及了两种CSP结构，CSP1_X和CSP2_X，在YOLOv5s网络中，前者应用于主干网络中，而后者则应用在颈部网络中。(3)颈部网络Neck：YOLO目标检测的主干存在许多层，层数的不断扩充，特征图的空间分辨率也因下采样而不断降低，为保留这些特征，主要采用FPN+PAN的结构，通过在FPN自顶向下传达强语义特征后面添加一个自底向上的特征金字塔PAN江苏科技大学工学硕士学位论文24传达强定位特征，主要是利用感兴趣区域(ROI)对齐和元素最大化操作的全连接层对自底向上的输出特征图进行融合，起到了对不同检测层进行参数聚合的效果；在Neck部分的CSP2_X结构，有效地加强了网络的特征融合能力。图3.1Focus切片过程Fig.3.1TheslicingprocessofFocus(4)输出端：YOLOv5中使用_CIOULoss作为Boundingbox的损失函数；在后处理中，使用DIOU_NMS对多个检测框进行筛选，在重叠目标的检测中，效果要好于普通的NMS。损失函数_CIOULoss由公式(3.1)可得：222_11()(1)vCIOULossCIOUIOUcIOUv(3.1)其中表示真实框中心点和预测框中心点之间的距离，c表示最小包围两个框的矩形对角线长度，v表示两个框的宽高比相似度，v的表达式见(3.2)。gtp22gtp4ww(arctanarctan)hhv(3.2)YOLOv5目标检测结果好坏的衡量标准主要有，首先图像中存在目标的位置需要被检测到，漏检和误检的目标越少越好；其次模型检测到的检测矩形框对目标包围地越契合越好；最后是对检测到的目标地识别分类越精确越好。因此，YOLOv5的损失函数也可以由预测框损失(rectLoss)、置信度(objLoss)和类别概率(clsLoss)所构成。预测框代表检测目标的大小和准确位置、置信度代表预测到的框的可信程度，取值范围在0到1之间，值越大越代表可能存在目标。因此整体的损失函数见式(3.3)。**OrectobjclsLossaLossbLosscLoss(3.3)其中,,abc分别是上述三个损失各自的权重，通常情况置信度的损失权重取最大，另外两个的权重次之。上文也讲述了YOLOv5中的预测框损失由_CIOULoss求得，而置信度和类别的损失则由_BCELoss进行求解，过程见式(3.4)。''_log()(1)log(1)iiiiBCELossCCCC(3.4)第3章基于YOLOv5sFace的人脸定位方法25其中',iiCC分别是置信度的标签和预测的矩阵。3.1.2轻量级主干网络ShuffeNetV2考虑到船舶疲劳检测系统将应用至嵌入式设备中，而ShuffleNetv2是针对移动设备的一个主干网络，其网络结构如表3.1所示。表3.1ShuffleNetv2网络结构Table3.1ThenetworkstructureofShuffleNetv2层输出尺寸K尺寸步长重复次数输出通道数224x224---3Conv1MaxPool112x11256x563x33x322112424Conv2MaxPool28x2828x283x33x32113116116Conv3MaxPool14x1414x143x33x32117232232Conv4MaxPool7x77x73x33x32113464464Conv57x71x1111024GlobaPool1x17x1--1024FC----1000FLOPs----146M3.1.3YOLOv5s的网络优化在YOLOv5中采用CSPNet作为主干网络，颈部使用SPP和FPN对特征进行聚合，头部则是采用了回归和分类。为达到计算复杂度低，网络泛化能力强的目标，同时保证网络的性能，使用Stem块结构代替之前的Focus层，在输入图像后的第一次下采样中设置步长为2，并扩大通道数，以获取更强的表示能力。Stem块的结构如图3.2所示。图3.2Stem结构图Fig.3.2TheStructurediagramofStem江苏科技大学工学硕士学位论文26为YOLOv5更加方便地部署，计算量需要尽可能减少，GhostNet是华为所提出的一种轻量级网络，其主要思想是用线性变换代替一部分传统卷积，推理计算量有相应的减少，相比其他相关网络，GhostNet[50]能更好地利用特征与特征间的相关性，同时兼顾冗余性。而组成GhostNet的最基本元件称为Ghost模块(GhostModule,GM)，其结构如图3.3所示，该模块首先通过传统卷积特征提取输入图，再对得到的中间特征图的各个通道进行线性变换，最后将两种特征图进行堆叠。图3.3Ghost模块结构图Fig.3.2TheStructurediagramofGhostModule本文采用Ghost模块构建的GhostBottleNeck替换YOLOv5中原有的CSPNet中的BottleNeck得到CSPNet-G，其中组成部件CGM，如图3.4所示，GhostBottleNeck由输入经过两次GBS与输入相加所得；再由GBN组成网络结构中的重要结构。图3.4CGM模块的结构组成Fig.3.4TheStructuralcompositionofCGM在传输到颈部的特征聚合块之前，将主干网络的输出特征传输到SPP块中，起到分离重要特征的作用，SPP模块的作用在于能够不受输入图像的尺寸影响，能够生成固定大小的输出，不用考虑输入图像的尺寸问题，而且能够集中多尺度版本提取重要的特征。为检测到更小的人脸，提高人脸检测性能，将原本的13x13、9x9和5x5的内核替换成7x7、5x5和3x3的内核。SPP模块图如图3.5所示。在原本的YOLOv5中，PAN输出特征图中有三个输出块，分别是P3(80x80x16)、P4(40x40x16)和P5(20x20x16)，其步长分别为8、16、32。由于在疲劳驾驶检测过程中，大部分时间船舶驾驶员的面部在摄像头中的占比称得上是大目标，因此，为提高对大第3章基于YOLOv5sFace的人脸定位方法27目标人脸的检测效率，额外增加一个P6(10x10x16)输出，步长为64。图3.5SPP模块结构图Fig.3.5ThestructurediagramofSPP最终的网络结构如图3.6所示。图3.6YOLOv5sFace网络结构图Fig.3.6TheNetworkstructurediagramofYOLOv5sFace人脸关键点的坐标是人脸检测中的一个重要特征，在MTCNN中将传统的68个人脸关键点简化成5个，而现在5个关键点在人脸检测中广泛被应用，坐标的准确度也影响着人脸对齐及人脸识别等应用的效果。一般的目标检测方法中不包含关键点的坐标，因此，将它作为回归中的一部分添加到YOLOv5中。人脸关键点回归头如图3.7所示。图3.7人脸关键点回归头Fig.3.7TheRegressionHeadofFaceKeyPoint江苏科技大学工学硕士学位论文28坐标回归损失通常采用L1、L2或者smooth-L1，但是这些这些损失函数对小误差都并不敏感，因此在本文中，采用Wing-Loss作为人脸关键点回归的损失函数，Wing-Loss可以很好地将增强小误差影响的对数函数与极端姿势下定位大误差的L1函数相结合，对于小误差表现为具有偏移量的对数函数，而对于大的误差则表现为L1函数。Wing-Loss函数见式(3.5)。ln(1),,()xwifxwexCotherwiseWingx(3.5)其中w是非负数，并将非线性部分的范围限制在(-w,w)，e限制了非线性区域的曲率，ln(1||)Cwwxe是一个常数。关键点的向量iss与真实的向量'iss的损失函数见式(3.6)。'()()LiiiLossswingss(3.6)其中i=1，2，…，10。从上文中可知YOLOv5的通用目标检测损失函数为OLoss，因此加入关键点损失后的总损失函数见式(3.7)。()OLLLosssLossLoss(3.7)其中L为关键点回归损失函数的权重因子。3.2实验仿真验证3.2.1数据集准备本文采用的数据集是目前比较人脸检测比较常用的数据集WiderFace，通过它对人脸检测模型进行训练和测试，WiderFace作为人脸检测数据集最大规模的存在，包含了32203张图像和393703张人脸，它的尺度、姿势情况、是否遮挡、表情以及光照强度等方面变化很大，比较接近现实，在具有挑战性的同时，也能很好地增强训练模型的鲁棒性。其中的部分样本如图3.8所示。图3.8WiderFace数据集部分样本图Fig.3.8ThedatasetpartialsamplegraphofWiderFace第3章基于YOLOv5sFace的人脸定位方法29WiderFace数据集中按照EdgeBox的检测结果将检测人脸的难度分为简单、中等和困难三种，在模型训练过程中，根据人脸检测的难度将整个数据集中60%作为训练集、10%作为验证集、30%作为测试集。考虑到真实应用场景中，船舶驾驶员在视频中的人脸一般情况下是较大的，而WiderFace数据集中很少有大的人脸图像，因此选择从Multi-task-facial数据集中添加一些大人脸图像到YOLOv5sface的训练数据集中。在YOLOv4中提出了一种数据增强的方法Mosaic，它核心操作是将四张图片随机裁剪后再拼接，得到一张新的图作为训练数据。这样能够起到丰富图片背景的作用，更好地增强模型的鲁棒性。Mosaic数据增强是CutMix数据增强的改进，在获得新的一张图片后，同时也会获得这张图片对应的框，再将这样一张新的图片传入到模型种训练学习，相当于一次性传入四张图片进行学习，也相当于提高了batch_size，在进行BN操作时也会计算四张图片，并不依赖于本身batch_size，对GPU的依赖也有所降低，更好地为之后在嵌入式设备上部署做准备。Mosaic方法如图3.9所示。图3.9Mosaic数据增强方法Fig.3.9MosaicDataEnhancementMethod但是在实验过程中，发现一些用于寻常目标检测的数据增强并不完全适用于人脸检测，尤其是上下翻转，因此在数据增强中选择删除上下翻转以提高性能；而Mosaic增强对于检测小人脸图像时，效果不佳，容易降低性能，而忽略小人脸后，随机裁剪有助于提高检测的性能。考虑到上述情况，以及Mosaic数据增强也会带来很多不准确的框，因此在本文中对模型训练时仅对最初的80%使用Mosaic数据增强。3.2.2模型训练本章将YOLOv5s作为基础，在Tensorflow框架上搭建了人脸检测的网络模型，设置好部分训练参数的值，便于在训练的过程中能够不断被优化，使用Adam优化器。Adam优化器能够记录梯度的一阶矩，使得每次更新后，上一次更新的梯度和本次的不会相差过大，即起到梯度平滑和稳定的效果，可以更好地适应不稳定的目标函数；与此同时，它也记录了梯度的二阶矩，这能够提供自适应学习率给到不同的参数。江苏科技大学工学硕士学位论文30在本文的模型训练过程中，参考迁移学习中的思想，将训练过程分为冻结和解冻两个环节，由于在人脸检测模型中，主干特征提取所得到的特征是通用的，因此所谓的冻结环节就是将主干特征网络先冻结起来，加快训练的速率，同时也能够防止权值损坏。在冻结的情况下，特征提取网络不会发生变化，它所占用的显存也会更少；之后的解冻环节中，主干特征网络也会发生改变，此时所需要的显存就会增大。在模型训练之前需要对以下三个参数进行初始化设置，分别是一次性抓取样本数量(batch_size)、学习率(learning_rate)和训练轮数(epoch)。而这三个初始值的设定也需要衡量，例如batch_size设的越大，一次性需要训练的样本也会越多，训练效果也会更好，但也会可能因为显存不足而导致训练中断，考虑到设备的显存情况，本章在解冻环节将batch_size设置为4，在冻结环节设置为8。学习率这个参数主要用来控制网络梯度的更新，随着训练的不断进行，要将学习率不断调小，因为在训练后期，如果学习率过大的话，就不容易或者错失最优解，只有不断降低模型训练的波动幅度，才能更进一步地贴近局部最优解。本章训练过程中初始学习率设置为1e-2，最终的学习率为1e-5，权重的衰减为5e-3。训练的次数是冻结环节的50次和解冻环节的100次。3.2.3评价指标对于人脸检测而言，需要通过相应的评价指标来衡量和评估模型的效果，一般的目标检测算法中评价指标有：精准率、召回率、精度和平均精度等。精准率：在模型预测为正样本的结果中，真正是正样本所占的百分比，见式(3.8)。PPrecisionTPTPF(3.8)召回率：在实际为正样本中，被预测为正样本所占的百分比，见式(3.9)。ReTPcallTPFN(3.9)精度(AP)：是PR曲线下的面积，面积越大即代表该类别的精度越高，见式(3.10)。10()APPRdR(3.10)平均精度(mAP)：顾名思义，mAP是各个类别AP的平均值，用来评估目标检测的性能，见式(3.11)。本章所使用的mAP0.5是指以IOU>0.5为依据来区分正样本。1()NnAPnmAPN(3.11)3.2.4实验结果与分析为尽可能加快人脸检测的速度，首先将输入图像的尺寸缩放至原图的0.5倍，即第3章基于YOLOv5sFace的人脸定位方法31320x240，此时，既保证了图像不会过于模糊而无法进行下一步判定，又可以加快检测的速度。再考虑到正常情况下，驾驶员在视频中的位置基本变动不大，因此可以对一段视频流进行人脸检测的同时，多一部检测上一帧是否存在人脸的步骤，若检测到人脸，则记录上一帧中人脸的位置并将其适当放大，作为下一帧的人脸检测范围，若是上一帧没有检测到人脸的情况下，再对整个输入图像进行检测，这样一来也能缩短人脸检测的时间开销，具体的判定流程如图3.10所示。图3.10YOLOv5sface优化流程图Fig.3.10TheoptimizationflowchartofYOLOv5sface为避免真实船舶驾驶过程中，镜头中的其他工作人员被检测到影响后续判定的情况，对传入的视频帧确定感兴趣区域（ROI），同时也可以为缩短检测时间起到一定作江苏科技大学工学硕士学位论文32用，图3.11展示了设立ROI后的YOLOv5sface对于模拟船舶驾驶环境中驾驶员和其他工作人员同时出现在镜头中时，有效过滤后排人脸的检测结果。图3.11优化后的多人脸检测结果Fig.3.11Theresultofoptimizedmultifacedetection本章使用处理过的测试集对训练后的人脸检测模型进行测试，在平均准确度和检测速度两个评价标准上，将优化改进后的YOLOv5s与原算法进行比较，对比情况如表3.2所示。表3.2YOLOv5s改进前后比较Table3.2ComparisonofYOLOv5sbeforeandafterimprovement操作方式平均准确率(%)平均检测速度(帧/s)修改SPP内核原内核(13,9,5)89.0647更改内核(7,5,3)90.3647数据增强原Mosaic增强88.3647删除上下翻转88.6747加入随机裁剪91.0347主干网络改进CSPNet89.2147CSPNet-G90.7654可以看到缩小SPP内核大小能为准确率的提升做出一定贡献；在数据增强中，随机裁剪的效果较为明显，将准确率提升了近2%；将主干网络换成CSPNet-G之后，有效地提高网络的轻量性，准确率相比原CSPNet提升了1.7%，帧率提升了14%，有效地改善了对船舶驾驶员疲劳检测的效果。YOLOv5sFace的训练结果如图3.12所示。其中图3.12(a)是训练过程中训练集和验证集的损失函数图，图3.12(b)是以改进后的网络作为主干网络的YOLOv5sFace和RetinaFace的PR曲线对比图。第3章基于YOLOv5sFace的人脸定位方法33图3.12YOLOv5sFace模型训练损失图和PR曲线对比图Fig.3.12ThetraininglossgraphofYOLOv5sFaceandthecomparisonGraphofPRcurve本章对测试集进行相应处理后，用其来测试上述训练后的人脸检测模型的性能，通过对于不同模型在WiderFace上的测试情况进行对比，其中对于本章使用的YOLOv5sFace，采用三种主干网络，CSPNet是作为原本的主干网络进行训练，CSPNet-G是在CSPNet基础上加以改进的版本，而ShuffleNetv2和ShuffleNetv2-0.5则是针对于之后部署嵌入式设备进行训练以及与以MobileNet0.25为主干网络的RetinaFace进行比较，显然使用YOLOv5sFace+P6+CSPNet-G在简单和中等难度类别中能够取得更好的效果。对比情况如表3.3所示。表3.3各个模型在WiderFace数据集上的对比Table3.3ComparisonofvariousmodelsontheWiderFacedataset模型主干网络Easy(%)Medium(%)Hard(%)MTCNN-65.365.240.3RetinaFaceResNet5093.6992.2869.12RetinaFaceMobileNet0.2588.6786.5657.64YOLOv5sFaceCSPNet92.9592.4282.25YOLOv5sFace+P6CSPNet93.4793.3981.03YOLOv5sFaceCSPNet-G94.5693.8783.85YOLOv5sFace+P6CSPNet-G93.9693.9482.84YOLOv5sFaceShuffleNetv291.6489.5379.32YOLOv5sFaceShuffleNetv2-0.587.4586.6172.53可以看出，在整体性能上，针对人脸和关键点检测改进后的YOLOv5s相较于老牌人脸检测器MTCNN有着比较大的优势。对于RetinaFace而言，主干网络都较大时，例如RetinaFace+ResNet50和YOLOv5sFace+P6+CSPNet-G，两者在Widerface数据集中简单部分都能取得一个比较不错的准确率，但是在中等和难的两个数据集部分，YOLOv5sFace+P6+CSPNet-G均高于RetinaFace；在主干网络都偏向于更小时，例如江苏科技大学工学硕士学位论文34RetinaFace+MobileNet0.25和YOLOv5sFace+ShuffleNetv2，在WiderFace的三个难度中，改进后的YOLOv5s都比RetinaFace效果更好。与此同时，在模型YOLOv5sFace未添加P6层时，改进后的主干网络CSPNet-G在三个类别上的检测准确率比原始CSPNet分别提升了1.7%、1.6%和1.9%；在添加P6层之后，分别提升了0.5%、0.6%和2.2%。在具体检测的结果中，如图3.13所示，RetinaFace在较大姿态的人脸上的检测效果并不佳，而使用YOLOv5sFace对于人脸关键点的定位在这类情况下更加准确。图3.13RetinaFace和YOLOv5sFace的人脸和关键点检测示例Fig.3.13ExamplesoffaceandkeypointsdetectionforRetinaFaceandYOLOv5sFace3.3本章小结本章首先在上一章YOLOv5算法的基础上介绍了YOLOv5s版本在网络结构上的一些特点，然后具体阐述了将普通目标检测算法改进为人脸检测算法的一些原理和依据，改进算法在数据预处理阶段删除了原有数据增强方式中常见的上下翻转，加入了更适合于人脸检测的随机裁剪；对检测网络进行改进，包括替换Focus层、CSPNet中的BottleNeck和减小原SPP中的内核大小，使其在适用于人脸检测的同时检测速度更快；在损失计算阶段，增加Wing-Loss函数作为人脸关键点回归损失函数；最后通过NMS后处理得到检测结果。并且在此基础使用ShuffleNetv2与CSPNet进行对比测试，虽然在实验中对检测的平均准确度稍有降低，但是对检测的帧数有一个较为明显的提高。通过对不同检测模型之间的比较，可以发现本章所使用的方法，与常用的MTCNN和RetinaFace两个算法相比，存在一定的优势。这比较符合我们对船舶疲劳驾驶检测低时延的预期，也为下一章中依据人脸和关键点检测结果进一步进行疲劳判第3章基于YOLOv5sFace的人脸定位方法35定奠定了基础。江苏科技大学工学硕士学位论文36第4章基于EMSD-Net的疲劳状态判定依据第三章所得到的驾驶员的双眼、嘴角以及鼻尖五个人脸关键点的位置，对双眼及嘴部区域分别截取并旋转至水平，对现有的数据集进行重新构建分类用来训练以Ghost模块为基础的眼嘴状态判别网络(EMSD-Net)，再对双眼开合及嘴部是否哈欠进行识别，最后再根据眼嘴状态，使用瞳孔随时间闭合百分比PERCLOS、持续闭眼时间CCT和持续哈欠时间SYT进行疲劳判断，并得出相应的疲劳程度，从而能够起到更有效的预警效果。本文的疲劳驾驶检测流程如图4.1所示。图4.1疲劳驾驶检测流程图Fig.4.1Theflowchartoffatiguedrivingdetection4.1疲劳状态判定由于分析驾驶员脸部特征来检测是否疲劳驾驶对实时性的要求较高，同时为降低疲劳判定的误判率，使用一种新的疲劳驾驶检测方法，通过对眼嘴状态从简单的开合分类改进为正常特征合疲劳特征进行分类，最后结合闭眼百分比、持续闭眼时间和持续哈欠时间判定疲劳状态。4.1.1眼部和嘴部区域提取在经过YOLOv5sFace获取到船舶驾驶员的人脸部分位置以及嘴角两端、眼睛中心和鼻尖五个关键点后，需要通过这五个关键点的坐标来确定划分眼睛和嘴部的区域，然而在真正的驾驶过程中，船舶驾驶员头部可能会因为疲劳发生一系列倾斜或者因为与同事沟通发生偏转，这是不可避免的[51]。由于缺少船舶领域的疲劳数据集，而疲劳驾驶检测在船舶和汽车领域的大体相关性，因此使用较为常用的疲劳数据集YawDD[56]等作为演示数据图。图4.2(a)~4.2(c)展示了在真实驾驶环境下使用上节改进得到的YOLOv5sFace进行人脸检测获得的人脸框，图4.2(d)~4.2(f)是使用如LOU等方法到截取眼嘴区域得到的局部图像。如图4.2(a)和4.2(b)所示，当船舶驾驶员正视摄像头时，获得的人脸框比头部倾斜时更加规整，从中获取到的眼部区域也有一定角度的倾第4章基于EMSD-Net的疲劳状态判定37斜，这也许也加大了判别网络的分类难度，因此考虑在送入判定网络前，将眼部图像旋转至水平。在驾驶员头部发生偏转时，很容易出现如图4.2(c)的检测结果，此时截取到的眼部图像可能是如图4.2(f)的右眼的不完整状态，这就会增加最终的状态误判几率。考虑到人在一般情况下，双眼都是以同样方式进行开闭的，所以选择截取人的双眼图像进行眼部状态的判断，同时双眼图像也能提供更丰富的特征，这样也能为识别眼睛状态提供更好的条件。图4.2实际驾驶过程中人脸和眼睛区域的检测结果Fig.4.2Detectionresultsoffaceandeyeregionsduringactualdriving在本文中，通过YOLOv5Face网络可以检测到两个眼睛坐标，通过这两个坐标求得眼睛图像中心点的坐标，再根据头部倾斜的角度和以下的宽高比例，可以截取到需要的眼部区域图像。YOLOv5Face检测到的右眼中心位置为111(,)Pxy，左眼的中心位置为222(,)Pxy，双眼中心距离为d，眼部图像的宽度为，长度为h，相应的关系见式(4.1)。22121212=dxxyywkdh=kd（-）（-）(4.1)如图4.3所示，已知双眼中心点坐标以及眼部长宽和倾斜角度，就可以由公式(4.2)的比例关系获得边界点1T的坐标。其余三个边界点同理可得。112cossinONhQNONaQOONaONOQQNTNSNST(4.2)江苏科技大学工学硕士学位论文38图4.3眼部区域示意图Fig.4.3EyeAreaSchematic其中11,,,,,ONQNQOTNSNST均表示示意图中相应线段长度。根据最后求到的四个边界点坐标，可以将眼睛区域确定，并在旋转原图像至水平后对其进行截取，可以提高状态识别的准确性；在嘴巴区域的识别过程中，YOLOv5sFace可以检测到左右嘴角的关键点，可以使用类似眼部区域选取的过程，通过左右嘴角的坐标得出嘴部区域图像的四个边界点。但是嘴部区域又和眼部区域有些许不同，在正常闭嘴，张开幅度较小的说话，张开幅度较大的打哈欠或者大笑时，左右嘴角之间的距离也许会发生变化，而且嘴巴区域的上下高度也会随之发生变化，因此，嘴部区域的宽度1和高度1h与嘴角间距离1d的比例关系就尤为重要，本文采用的比例关系见式(4.3)。22112121111()()10953dxxyywdhd(4.3)最终眼部和嘴部区域图像如图4.4所示。图4.4最终眼部和嘴部区域图像Fig.4.4Finaleyeandmouthregionimages4.1.2疲劳状态识别网络在获得所需要的眼部和嘴部区域后，接下来一个重要步骤就是去判定眼嘴的开闭状态，本文构建了一个判定眼嘴状态的卷积神经网络，即眼嘴状态识别网络(EMSD)。在该网络中使用到了ECA-Net[52]中的注意力机制，如图4.5所示，它也属于通道注意力机制，可以将其看作是SE-Net[53]中SE模块的改进，SE模块在对输入的特征层平均第4章基于EMSD-Net的疲劳状态判定39池化后，使用了两次全连接，获取全部通道的信息，这过程其实是不必要的，所以ECA模块中采用了1D卷积代替了SE模块中的两个全连接层对特征层进行学习，1D卷积具有良好的跨通道获取信息的能力，而且ECA模块的参数量很小，对网络结构大小几乎没有影响，之后再经过sigmoid激活函数与输入进行相乘得到最后的输出结果。图4.5SE模块与ECA模块的结构Fig.4.5ThestructureofSEmoduleandECAmodule在真实驾驶的过程中，获取到的驾驶员眼睛部分图像的大小并不一致，因此以统一尺寸的标准调整输入的图像尺寸大小，经实验，将图像大小调至56x56对于模型的大小及准确率都能有更好的表现，然后传入网络，如图4.6所示，首先使用一个传统5x5和3x3卷积提取全局特征，步长均设为1,为避免图像大小经卷积后发生缩减，图像填充padding设为same，这也可以减少由于图像边缘信息丢失引起的误差。之后通过轻量化模块ghost模块对传统3x3卷积进行代替，ghost模块是在Ghostnet中的一个基础模块，该模块先对输入进行较少通道数输出的点卷积，再通过得到的进一步逐层完成3x3的深度卷积（DepthwiseConv2D）,最后将两者进行堆叠处理，这样的处理方式比传统卷积更加的轻量化，最终得到的模型大小仅为0.84MB，在此期间插入一定的最大池化，步长均为2。该网络的最终分类结果只有四类，所以只设置一个全连接层，用以继承前层提取江苏科技大学工学硕士学位论文40到的特征，经过实验，全连接层设置为32时，在减少参数量的同时，也能保证不错的准确率，最后通过softmax层输出样本属于不同眼嘴状态的概率。激活函数选用了relu函数，其收敛速度相比于hard-swish较快，并且能降低反向传播途中梯度消失现象导致的不利影响。此外，EMSD-Net还加入了批量归一化(BN)层来标准化输入数据以及加快网络的学习速度。在损失函数的选取上，选择了交叉熵损失函数，来衡量模型的质量，其表达式见式(4.4)。221=[log()(1)log(1)]NiiiiiLypyp(4.4)其中，表示样本的标签，正类为1，负类为0；ip表示样本预测为正类的概率。图4.6眼嘴状态判别网络结构图Fig.4.6ThestructureofEMSD-Net第4章基于EMSD-Net的疲劳状态判定414.1.3多特征融合疲劳判定模型当一个驾驶员处于疲劳状态下，频繁地打哈欠，不断地眨眼或持续闭眼都是会出现的现象。因此，眼镜和嘴巴状态是判断是否疲劳的两个最有效又明显的面部特征。上述识别算法可以确定眼睛和嘴巴的状态，然后通过两部分的行为特征建立疲劳确定模型用以识别驾驶员的疲劳状态。(a)闭眼百分比（PERCLOS）标准PERCLOS[54]是一种国际公认的疲劳判断标准，研究表明，人在正常情况下，每分钟大约眨眼15次，也就是平均4s眨一次眼。PERCLOS标准指的是每单位时间闭眼时间与总时间的占比大小。在实际驾驶过程中，摄像机采集设备将视频流转换为帧图像进行处理，因此PERCLOS标准也可以理解为每单位时间眼睛闭合帧数与总帧数之比，见式(4.5)。eyePeye100%nFN(4.5)其中，pF表示PERCLOS值，eyen表示单位时间闭眼帧数的总和，eyeN表示单位时间内视频总帧数。(b)持续闭眼时间CCT在操控驾驶船舶过程中，疲劳会使驾驶员出现长时间闭眼的情况，这属于一种疲劳特征，同时这也属于一种危险行为，驾驶员在这种情况下应该被预警。在本文中，每帧图像都可以被识别出眼睛的开合情况，从驾驶员眼睛闭合的那一时刻开始，计算持续关闭帧的数量，由式(4.6)得到连续闭合时间tF。tendstart0()FNNT(4.6)其中startN表示视频流中闭眼的开始帧序列，endN表示视频流中闭眼状态的结束帧序列，0T表示每帧图像间的时间间隔。上述的两个眼部指标被用来判断驾驶员眼睛是否疲劳。为了确定PF的阈值，对收集的视频序列进行了相关实验，并计算单位时间驾驶员的PERCLOS值。实验表明，由于计算整段视频的PERCLOS值很容易因为总帧数过大的问题导致错误判断，因此本文采用每2s计算一次PF，得到最大的PF，当PF有达到0.5以上的情况，那么该驾驶员存在疲劳的可能性；当CCT超过2s，驾驶员处于极度危险驾驶状态下，应该对其发出警告或者人性化地提醒注意休息。(c)持续哈欠时间SYT除了眼部的特征，驾驶员在疲劳驾驶时的另一面部特征就是开始频繁打哈欠了。在正常情况下，一个人打哈欠时，嘴巴会张开并且保持数秒，通过上一节的步骤，可以检测到嘴巴处于闭合、正常张开或打哈欠的状态。研究表明，在正常情况下，一个江苏科技大学工学硕士学位论文42人的打哈欠时间大约为6s，当然在驾驶员大笑的情况下，可能会误判为打哈欠，但是这种情况也应当提醒驾驶员安全驾驶，因此，本文由公式(4.7)计算判定打哈欠的持续时间确定判断驾驶员是否安全驾驶。y0()endstartFYYT(4.7)其中，startY表示视频帧中判定为打哈欠的开始序列号，endY表示下一次判定为正常张开的序列号，0T同样表示采集每帧图像的时间间隔。在实验中，数据集中的视频以平均每秒23帧的速率采样来获得一组图片，因此每一帧的图像的时间间隔为43ms。当CCT2s，即tF超过46帧时，驾驶员处于危险中；当驾驶员的SYT4s，即yF超过92帧时，需要给驾驶员发出警告提醒注意安全驾驶。根据以上三个指标，建立疲劳判定模型，将驾驶员的状态分为眼部疲劳（EF），哈欠疲劳（YF）和清醒状态三种状态情况。判断的条件见式(4.8)。PyEF ,(2)(0.5)YF ,(4)Awake ,tFsFFsothers(4.8)在本文中，当驾驶员持续闭眼时间超过2s或者每2s检测的闭眼百分比有超过0.5的情况，即tP(2)(0.5)FsF时，可以判定为驾驶员处于打瞌睡状态；当驾驶员出现打哈欠症状，即(4)yFs时，可以判定驾驶员当时的状态是打哈欠，这两种情况都应当提醒驾驶员集中精神，注意安全。最后就是驾驶员处于清醒状态行驶。4.2实验仿真验证4.2.1数据集建立在对EMSD-Net训练之前，我们需要大量的训练样本。其中EMSD-Net的训练样本主要来自于三个数据集：CEW[55]、YawDD[56]和NTHU-DDD[57]，并且对训练中划分出来的测试集进行准确率的最终测试。对于后两个数据集而言，由于最初是视频形式，因此首先要将其转换为帧图像，并将图像进行预处理和分类，以此来创建训练数据集，在4.1.1中的1k和2k的选取过程中，参考了文献[58]中提出的153k，而2k的选取,在过低的情况下可能会导致截取某些图像时容易将眼部部分漏截，通过实验比较，最终选择了279k[58]。比较结果如图4.7所示。第4章基于EMSD-Net的疲劳状态判定43图4.7不同参数下的眼部图像Fig.4.7Eyeimagesunderdifferentparameters本网络的训练过程中，对所使用到的数据集划分为训练集、验证集、测试集，比例为7:2:1，本文中眼部数据集简要分布如表4.1所示。嘴部数据集简要分布如表4.2所示。用于训练的数据集示例如图4.8所示。表4.1眼部数据集的简要分布Table4.1BriefdistributionoftheeyedatasetsDatasetStateTrainValTesttotalCEWOpen8622461231231Close8362391171192Total16974842422423YawDDOpen9062581291293Close41212060592Total1318378189701NHTU-DDDOpen10352981491482Close56216080802Total15974582292282表4.2嘴部数据集的简要分布Table4.2BriefdistributionofthemouthdatasetsDatasetStateTrainValTesttotalYawDDNormal63518291908Yawning47113467672total11063161581580NHTU-DDDNormal7252471231235Yawning55716080797total12824072032032江苏科技大学工学硕士学位论文44图4.8EMSD网络训练集中的样本示例Fig.4.8TheSampleExampleofEMSD-Net4.2.2评价指标衡量疲劳驾驶的评价指标主要有准确率(Accuarcy)、精准率(Precision)、召回率(Recall)、F1Score和时延。对于一个二分类测试，即可将实例分成正类或负类，而在实际实验测试中会出现四种情况：真正类TP：正类被预测为正类；假负类FN：正类被预测为负类；假正类FP：负类被预测为正类；真负类TN：负类被预测为负类。准确率：预测正确的样本数量占总量的百分比，见式(4.9)。ATPTNccuarcyTPFNFPTN(4.9)精准率：在模型预测为正样本的结果中，真正正样本所占比重，见式(4.10)。PPrecisionTPTPF(4.10)召回率：在实际为正样本中，被预测为正样本所占比重，见式(4.11)。ReTPcallTPFN(4.11)F1分数：针对精准率和召回率各自存在缺点，若阈值较高，则精准率提高，却会遗漏过多数据；若阈值较低，则召回率提高，但预测会很不准确。因此，为兼顾二者，精准率和召回率的调和平均数，也被称为F1Score，见式(4.12)。第4章基于EMSD-Net的疲劳状态判定4521PRFPR(4.12)4.2.3实验结果与分析本实验在完成数据集准备的前提下，在深度学习的框架上搭建了一个神经网络模型，并通过Tensorflow所提供的多线程输入数据框架将数据批量组合并破坏数据原序列，从而提高模型训练效率[59]。在训练过程中，batch大小设置为100，利用keras的提前停止（EarlyStopping）避免epoch过高导致过拟合，具体原理就是在每个epoch结束后，从验证集中获取测试结果，随着epoch的增加，验证集上的测试误差如果上升，那么提前停止训练，将停止后的权重作为网络的最终参数。采用Adam优化算法进行反向传播，并设置回调函数来监测验证集的损失。训练及验证的结果，如图4.9所示，图4.9(a)和图4.9(c)是未加入ECA模块前的损失和精度曲线，图4.9(b)和图4.9(d)是加入ECA模块后的损失和精度曲线，可以看出，加入ECA模块后训练轮次提早了5个epoch结束，而且曲线的收敛要比之前更快，这也证明了其有利于加速模型的训练以及模型的收敛。图4.9加入ECA前后模型在训练集和测试集上的损失和精度Fig.4.9LossandaccuracyofmodelsintrainingandtestingsetsbeforeandafterECAaddition本文分类网络在257张闭眼图片，338张正常睁眼图片，214张正常嘴部图片以及145张哈欠图片，总共954张测试集下测试准确率达到97.9%。由表4.3中可知，本文的分类网络，对于眼嘴的分类的错误率为0，由于将人为感觉清醒时的半开眼状态和江苏科技大学工学硕士学位论文46人为认为疲劳的半开眼状态均放入训练集中进行训练，但这类数据集严重不足，因此该网络对于眼睛闭合以及正常的分类判断还有待提高，但是在嘴部哈欠的识别判定准确率均达到了99%以上。表4.3EMSD-Net的检测分类结果Table4.3TheclassificationresultsofEMSD-Net图片类别检测正确数目误判类别单类准确率眼睛闭合247眼睛正常96.1%眼睛正常331眼睛闭合97.9%嘴巴正常212嘴巴哈欠99.1%嘴巴哈欠144嘴巴正常99.3%平均准确率97.9%验证集和测试集用于测试训练后的模型，为验证EMSD-Net的优势，在同一数据集上将其与常见的几种网络，如GhostNet、ResNet50[60]、ResNet50V2[61]、MobileNet[62]、MobileNetV2[63]和InceptionV3[64]以及文献[58]和文献[59]提出的网络进行了对比，最终在不同分类网络上的检测准确率和平均时间开销如表4.4所示，EMSD-Net的分类准确率达到97.9%，是比较网络中最高的，模型大小也是除了未加入ECA时最小的0.84MB，平均单帧预测时间降低至7.8ms，虽然在预测时间上要高于文献[59]和文献[58]的网络平均检测时间，但是精度更高，而且模型大小更小，在时间上也可以通过一些策略比如每2帧检测一次，这样不仅能使得单位时间内传输的图像更多，让视频看上去更流畅，同时也保证了检测的精度。而使用现有一些网络，由于该分类任务较小，因此现有的网络精度虽然不低，但是针对性不强，对该任务而言，网路结构过于复杂。表4.4基于不同网络分类准确度与时间开销Table4.4Classificationaccuracyandtimecostbasedondifferentnetworks分类网络平均时间开销（ms）模型大小（MB）平均准确度(%)GhostNet38.160.996.8ResNet5019.890.380.2ResNet50V221.790.296.1MobileNet10.912.596.2MobileNetV217.98.9694.4InceptionV330.183.792.7JI1.166192.8LOU5.22.4195.5EMSD-Net（noECA）7.10.8396.7EMSD-Net7.80.8497.9如图4.10(a)~图4.10(d)所示，其分别是驾驶员在模拟驾驶船舶时处于正常驾驶，第4章基于EMSD-Net的疲劳状态判定47正常谈话，眼部瞌睡以及打哈欠状态下的疲劳检测实例；图4.11(a)~图4.11(d)通过记录视频帧的形式，更加形象地展示了图4.10中的四种驾驶状态下，眼部和嘴部被检测到的变化过程，根据PERCLOS和CCT来判定眼部是否疲劳，而SYT则用来判定驾驶员是否有打哈欠的行为。由图4.11(a)可知，上文的分类网络对于睁眼以及嘴巴的闭合判断很准确，因此对正常驾驶状态的判定结果很好；由图4.11(b)和图4.11(c)的嘴部结果图可知，仍然存在嘴巴正常张开被误判为打哈欠的情况，但由于持续帧数很低，达不到设定的哈欠阈值，因此在最后的疲劳判定中，基本不影响后续的疲劳判断；从图4.11(c)的眼部图像可看出，测试者的闭眼百分比并未达到判断阈值，但是在一段1分钟左右的视频中，最高持续闭眼时间高达6.2秒，仍然可以判定为驾驶员处于疲劳状态，所以使用闭眼百分比和持续闭眼时间双重标准可以提高最终疲劳判定的准确率。如图4.11(d)的嘴部状态图像所示，驾驶员在哈欠状态下的图像很明显的可以看出该状态下的哈欠的持续帧数要比正常说话下的误判哈欠持续帧数大的多，该测试者的最大持续哈欠时间达到了6.8s，因此这两种情况就可以判定其为疲劳状态。图4.10四种状态下的疲劳检测实例Fig.4.10Examplesoffatiguetestinginfourstates江苏科技大学工学硕士学位论文48图4.11四种驾驶状态下的眼嘴状态显示Fig.4.11Eyeandmouthstatesunderfourdrivingstates最后，为证明所提出的疲劳判定模型的优越性，从数据集中筛选出未参与训练的一共325段平均30s的眼部疲劳视频片段以及平均10s的其余三种状态的视频片段，使用文献[58]和文献[59]。的分类网络以及疲劳判定模型与本文提出的方法进行疲劳检测准确度的对比测试，最后的实验比较结果如表4.5所示。很明显，文献[58]的疲劳判第4章基于EMSD-Net的疲劳状态判定49定模型对正常驾驶状态下的判断准确率并不高，而在哈欠视频中，更是做出了很多将疲劳状态误判为正常状态的错误判断，而且使用原始的MTCNN的耗时也更加的高；文献[59]中使用PMOT进行哈欠判断，很容易造成将正常说话判定为哈欠的误判，这也是本文主要针对的一个问题。本文的方法对嘴部的疲劳检测准确度很高，正常说话时的误判也是判定为眼部疲劳，这是由于测试者是否戴眼镜或者光照条件是否良好都可能会影响眼部状态的判断，因此对于正常驾驶的两种状态下都有被误判为眼部疲劳的情况出现，相比上述两种方法，本文方法在保证了检测准确率的前提下也尽可能保证了实时性。表4.5不同疲劳检测方法对比Table4.5Comparisonofdifferentfatiguetestingmethods4.3本章小结本章为解决目前疲劳驾驶检测存在误判率高和实时性差的问题，提出了一种结合轻量级卷积神经网络和多特征判定模型的疲劳检测方法。引入Ghost模块和ECA注意力模块构造出EMSD-Net用于眼嘴状态分类，使网络的参数量和训练收敛的所需时间进一步降低。同时在疲劳判定模型中，采用对检测视频每2s计算一次PERCLOS的方法，大大减少了由于视频总时太长导致检测不准确的情况，对嘴部疲劳的检测也从以往的检测嘴巴开闭特征转变为检测嘴部是否在哈欠状态，有效地降低了疲劳检测的误判率。所提出方法在公共数据集NHTU-DDD和YawDD的组合视频上进行了评估，结果表明，该方法能在保证较低网络参数量和平均时延的前提下达到较高的检测准确方法视频类别数量分布正确检测数错误类别准确率平均准确率平均时间开销文献[58]正常状态11067均有60.9%62.6%44.3ms正常说话10097哈欠+眼部疲劳97%眼睛瞌睡3323正常69.6%哈欠状态8219正常23.1%文献[59]正常状态11098眼部疲劳89.1%68.1%38.8ms正常说话10020哈欠+眼部疲劳20%眼睛瞌睡3321正常63.6%哈欠状态8282--100%本文方法正常状态110103眼部疲劳93.6%95.3%32.6ms正常说话10094眼部疲劳94%眼睛瞌睡3331正常93.9%哈欠状态8282--100%江苏科技大学工学硕士学位论文50率。第5章疲劳驾驶监测预警系统的设计与实现51第5章疲劳驾驶监测预警系统的设计与实现本章重点描述了如何构建该疲劳驾驶监测预警系统，在对Jetson系列深度学习嵌入式设备高速计算能力与强大性能的认知与理解的基础上，系统选择了JetsonTX2深度学习嵌入式设备作为主控核心。利用与摄像机相结合的方式，可以对其进行图像采集，还可以与扬声器设备相结合，从而对疲劳驾驶的驾驶员展开提醒。最后，经过实验验证，所搭建的机器视觉疲劳驾驶检测系统可以正常运转与准确检测。5.1系统总体设计5.1.1系统架构设计本文的疲劳驾驶监测预警系统是对船舶驾驶员面部特征进行提取并分析，该系统的总体框架图如图5.1所示。其中主要包括物理环境、开发平台、图像读取与预处理、数据分析层和应用层五个模块。图5.1系统总架构图Fig.5.1Overallsystemarchitecturediagram(1)应用层，其中包括了疲劳驾驶预警系统中的主要模块，分别对船舶驾驶员人脸及面部关键点进行检测，再对其疲劳状态进行分析。江苏科技大学工学硕士学位论文52(2)数据分析层，其中包括本系统中所使用到的相关模型，并对相关模型进行调度以完成任务，在一次检测完成后，为保证下次正常运行，会对产生的数据进行初始化处理。(3)图像采集与预处理层，主要实现对传入的视频或图像进行检测前预处理工作。5.1.2系统功能模块设计对于船舶驾驶员疲劳监测预警系统可以分为三个模块，分别是：(1)视频显示模块，负责显示摄像头采集到的视频信息，包括人脸框和置信度等；(2)疲劳状态信息显示模块，负责将检测到的人脸及判定的最终疲劳相关信息显示在设备上，包括持续闭眼时间、打哈欠次数等；(3)实时监测预警模块，负责对船舶驾驶员工作时的面部进行检测监督，在判定其为疲劳驾驶时及时发出警示，避免意外的发生。具体功能模块设计图如图5.2所示。图5.2疲劳驾驶检测预警系统功能模块图Fig.5.2Functionalmodulediagramoffatiguedrivingdetectionandearlywarningsystem5.1.3系统整体工作流程系统整体的工作流程如图5.3所示：(1)在疲劳检测预警系统之初，需要预加载YOLOv5sFace并且对其进行初始化处理，其中包括人脸检测和人脸关键点定位。(2)之后获取视频序列帧，可供选择摄像头实时获取或者上传视频流文件。(3)使用数据分析层中预加载完成的YOLOv5sFace模块，对输入的视频流文件进行扫描，首先实现对驾驶员人脸的检测及定位，其次在该基础上，获得眼嘴鼻5个关键点坐标并标注。(4)获得人脸关键点坐标信息后，经过眼部嘴部裁剪选取，送入疲劳驾驶状态判定第5章疲劳驾驶监测预警系统的设计与实现53模块，根据每帧的眼睛开闭和嘴巴张合的情况，计算得出驾驶员的眨眼频率、闭眼时长、PERCLOS值、打哈欠次数等疲劳指标，再将这些实时提取到的疲劳指标进行归一化处理，分析对比后得出疲劳级别，并按照不同的等级对在行车过程中的驾驶员发出相应的预警提示。图5.3系统整体的工作流程Fig.5.3Overallworkflowofthesystem5.2JetsonTX2疲劳驾驶检测系统搭建5.2.1JetsonTX2深度学习嵌入式设备本文在JetsonTX2深度学习嵌入式平台基础上，对疲劳驾驶检测预警系统进行研发，该嵌入式系统为一款具备强大功能的小型计算机，专为支持入门级边缘AI设备而设计[65]，如图5.4所示，其JetPackSDK中支持BSP、计算机视觉和GPU计算等众多功能，同时包含如Pytorch、TensorFlow等主流框架。具体配置参数如表5.1所示。江苏科技大学工学硕士学位论文54通过JetsonTX2上所搭载的拓展接口，可以外接多个传感器组件，可以连接USB摄像头对视频图像进行采集，通过GPIO接口连接蜂鸣器组件实现驾驶员在驾驶过程中，出现疲劳状态后，发出预警。表5.1JetsonTX2嵌入式设备相关参数Table5.1JetsonTX2embeddeddevicerelatedparameters配置参数GPU256-corePascalCPUHMPDualDenver2/2MBL2QuadARMA57/2MBL2内存8GB128-bitLPDDR458.3GB/s存储32GBeMMC5.1视频编码2x4K@30|HEVC|视频解码2x4K@30，12位支持摄像头12通道MIPI，CSI-2，D-PHY1.2(30Gb/s)显示DSI、DP、HDMI连接一千兆以太网、802.11acWLAN、蓝牙USBUSB3.0+USB2.0通过JetsonTX2上所搭载的拓展接口，可以外接多个传感器组件，可以连接USB摄像头对视频图像进行采集，通过音响等发声组件实现驾驶员在驾驶过程中，出现疲劳状态后，发出预警[64]。图5.4JetsonTX2开发套件Fig.5.4JetsonTX2developmentkit第5章疲劳驾驶监测预警系统的设计与实现555.2.2JetsonTX2疲劳驾驶检测系统整体框架本文使用JetsonTX2深度学习嵌入式系统为主控核心，使用DS-E12摄像头进行视频采集，外接模块有显示屏显示以及通过连接蜂鸣器对处于疲劳状态的驾驶员发出警告提醒等功能，供电模块统一给硬件设备供电。疲劳驾驶检测系统框架图如图5.5所示。图5.5整体硬件系统框图Fig.5.5Overallhardwaresystemdiagram5.3疲劳驾驶监测预警系统演示5.3.1系统可视化界面设计本文使用Qt来进行疲劳驾驶检测系统图形界面的绘制及模拟，系统的初始界面如图5.6所示。在本系统中，用户可通过点击图片或视频两个按钮来选择需要识别的对象；对于需要识别的内容，可以自行选择选择文件中的视频流或者直接调用摄像头进行实时检测，对于疲劳检测的权重暂且提供了改进后训练得到的CSPNet-G以及适用于小型移动设备的ShuffeNetV2两种，可针对不同需求进行选择。本文中持续闭眼时间和持续哈欠时间的阈值分别设定为2s和4s，也可以自行调节。除此以外，还提供了疲劳指标显示窗口，可以在检测过程中，观测到PERCLOS、持续闭眼时间、持续哈欠时间以及疲劳判定结果窗口中的最长持续闭眼时间、最长持续哈欠时间和最终的驾驶状态是否疲劳。江苏科技大学工学硕士学位论文56图5.6船舶驾驶员疲劳驾驶监测预警系统初始界面Fig.5.6Initialinterfaceoffatiguedrivingmonitoringandwarningsystemforshipdrivers5.3.2系统运行结果(1)单张图片检测此功能下，可从文件夹中选择某一图片，若其中存在人脸，则输出检测识别到的眼嘴状态，如图5.7所示，当传入的图像中并不存在人脸时，系统将在检测结果栏提示“未检测到人脸！请重新选择图片！”。图5.7单张图片疲劳特征检测示例Fig.5.7Exampleoffatiguefeaturedetectionforasingleimage(2)图片批量检测此功能主要实现快速对某一文件夹中多张图片批量化检测，并在检测结果栏给出每张图片的检测结果，如图5.8所示。第5章疲劳驾驶监测预警系统的设计与实现57图5.8批量图片疲劳特征检测示例Fig.5.7Exampleoffatiguefeaturedetectioninbatchimages(3)视频检测视频流检测主要实现对上文中提到的正常驾驶、说话交谈驾驶、打瞌睡和打哈欠四种常见驾驶状态进行了检测，由于真实驾驶场景进行疲劳测试具有一定危险性和不确定性，因此借助船舶模拟驾驶台采集到驾驶过程中的四种状态，并将四段视频输入至检测系统，得到相应检测结果。如图5.9所示，对传入的视频流进行检测，系统会根据第四章中提到的PERCLOS、CCT和SYT的计算方法对当前帧下的参数值进行计算，由于该视频中的PERCLOS值为0.024，CCT的最大值为0.4s，都未达到眼部疲劳的情况，SYT的最大值未0s，表明未有打哈欠的情况，因此给出的最终结果为清醒状态。图5.9正常状态下模拟操控船舶检测结果Fig.5.9Testresultsofsimulatedmaneuveringofshipsundernormalconditions江苏科技大学工学硕士学位论文58如图5.10所示，传入视频播放至最新帧时，PERCLOS值为0.023，CCT的最大值为0.367s，并未超过所设定的2s，表明此时被测试者的眼部状态为正常，并未出现疲劳特征，SYT的最大值为0.129s，并未超过所设定的4s，因此给出的判定结果为清醒状态。图5.10正常说话状态下模拟操控船舶检测结果Fig.5.10Simulatedmaneuveringshipdetectionresultsundernormalspeechstate如图5.11所示，传入视频播放至最新帧时，PERCLOS值为0.615，超过了所设定的0.5，CCT的最大值为0.367s，超过了所设定的2s，这两种参数满足其中任一项均可判定其为打瞌睡，表明此时被测试者的眼部状态为疲劳，SYT的最大值为0.132s，并未超过所设定的4s，表明嘴部属于正常状态，因此给出的判定结果为打瞌睡状态，并发出警示。图5.11打瞌睡状态疲劳下模拟操控船舶检测结果Fig.5.11Simulatedmaneuveringshipdetectionresultsunderdozingstate第5章疲劳驾驶监测预警系统的设计与实现59如图5.11所示，传入视频播放至最新帧时，PERCLOS值为0.112，未超过所设定的0.5，CCT的最大值为1.642s，未超过所设定的2s，因此表明此时被测试者的眼部状态为正常，SYT的最大值为6.723s，超过了所设定的4s，表明嘴部属于打哈欠状态，因此给出的判定结果为打哈欠疲劳状态，并发出警示。图5.12打哈欠状态疲劳下模拟操控船舶检测结果Fig.5.12Simulatedmaneuveringshipdetectionresultsunderyawningstate(4)摄像头检测如图5.13所示，在实时检测下，Fps可达到60，可以满足实时检测的要求，在测试者模拟打瞌睡状态时，PERCLOS的值达到0.615，超过了0.5，CCT的最大值也随之上升到2.236，最后判定为测试者为打瞌睡状态，并发出警示。图5.13摄像头下模拟操控船舶检测结果Fig.5.13Simulatedmaneuveringofshipsundercameradetectionresults江苏科技大学工学硕士学位论文605.4本章小结本章主要介绍了本文所搭载的JetsonTX2嵌入式平台、相关软件设计以及可视化的应用界面，根据对船舶驾驶员疲劳检测的具体需求，设计了可视化界面，主要包括参数设置区域、视频检测区域、状态输出区域。实验结果表明算法在系统中能够正常运行，也能够满足实时性和准确性的要求。总结和展望61总结和展望通过疲劳检测预警系统，可以在船舶驾驶员疲劳状态下，提供警示效果，现阶段具有的疲劳监测方法包括基于生理信号、船舶行驶行为和驾驶员面部特征等方式，在实际检测过程中，仍各有缺陷。因此本文对疲劳检测算法的实时性与准确性进行针对性研究，在YOLOv5s基础上改进出适用于人脸检测的方法，并对人脸、眼部和嘴部进行特征提取，通过改进后的疲劳判定算法，降低了整体的误判率，在保证精度降低可接受的情况下，进一步提高了检测的速度，本文的主要工作总结如下：(1)由于现有的疲劳相关图片类型数据集CEW中，只包含了眼睛开闭两类，未找到适用的嘴部疲劳特征的数据集，而模型的训练效果与数据集的好坏又息息相关，因此，本文在YawDD和NTHU-DDD这两个视频数据集的基础上，人工对视频帧的收集、筛选和分类，构建了专门判定眼部嘴部状态的数据集，该数据集包含了5406张眼部开闭状态图片和3612张嘴部不同状态图片。在人脸检测的过程中使用WiderFace来判定检测的效果。(2)根据人脸检测任务的特点，改进YOLOv5s模型，为提高对大人脸的检测准确率，在网络结构中增加了一层和减小了SPP的内核大小；在数据增强的方法中，删去了不适合人脸检测的上下翻转和马赛克增强；采用更加轻量化的网络CSPNet-G作为整个网络结构的主干网络，减少模型的参数，提升模型的检测速度，并与常见的人脸检测算法MTCNN和RetinaFace进行比较，在WiderFace数据集的三个类别中分别取得了1%、1.6%和0.7%的提升；通过根据上一帧的人脸位置，预判当前帧的人脸位置，减少模型对人脸的检测时耗，提高模型的检测能力。(3)以人脸关键点作为依据得到眼嘴部图像，以Ghost模块为基础设计眼嘴状态判别网络EMSD-Net，并加入注意力机制ECA让网路更快收敛，用EMSD-Net判定眼睛开闭和嘴巴正常说话或者打哈欠，由此得到PERCLOS、持续闭眼时间和持续哈欠时间等特征相结合，作为判定疲劳的依据。实验表明，与现有的两种疲劳检测方法相比，准确率上升了39.9%，时耗方面也降低了16%，得出更为准确的判定结果。(4)对疲劳驾驶监测预警系统进行设计与实现。使用Qt对系统运行界面进行编写设计，为更好地在设备JetsonTx2中实现该系统，将Python转TensorRT模型，并用C++进行重写，最后根据需求，实现了图片检测、视频检测和摄像头实时检测的功能，并为用户提供了CSPNet-G和ShuffeNetv2两种权重文件，以及对持续闭眼时间和持续哈欠时间阈值的控制，可以以此来调节系统对不同疲劳程度的监测；连接发声模块，在检测到船舶驾驶员疲劳时，及时发出声音，起到警示作用。江苏科技大学工学硕士学位论文62本文通过对人脸中眼嘴部位的特征信息的提取以及对网络模型的改进，提升了疲劳驾驶检测的性能，也为后续进一步提升算法能力提供了新的思路，但在研究过程重对于出现的一部分问题仍需进一步分析与研究：(1)现实情况中，驾驶员在夜间更容易处于疲劳状态，但是目前对于船舶驾驶员夜间驾驶的疲劳数据寥寥无几，因此在夜间的情况下，对疲劳状态的识别能力有限，后期的研究可以对夜间光照弱的问题进一步解决。(2)在对于人脸图像存在噪声的情况下，模型是否能够发现人脸特征还有待考证，后续可以在该基础上，进行研究，同时也需要考虑到姿势、遮挡等问题。(3)在研究过程中，也发现最理想的情况是驾驶员正面面向摄像头时，而当驾驶员头部低至摄像头检测不到面部时，对疲劳的检测将出现困难，因此，为进一步提升整个检测模型的鲁棒性，准确率以及最终的应用实现，未来的研究将在人体关键点检测的基础上引入驾驶员头颈部的姿态检测以及继续优化模型以求更高的实时性，最终在边缘设备上达到更好的效果。参考文献63参考文献[1]徐碧苑,谭志荣,高兴,等.内河船舶驾驶台值班船员疲劳机理与预防[J].中国海事,2021(12):46-49.DOI:10.16831/j.cnki.issn1673-2278.2021.12.012.[2]张堃.船舶机舱值班人员眼部视觉识别及疲劳状态监测[D].大连:大连海事大学,2019.DOI:10.26989/d.cnki.gdlhu.2019.001834.[3]陈燕达,屠彦,王莉莉,等.视觉疲劳状态下的生理指标研究[J].电子器件,2015(6):1245-1248.DOI:10.3969/j.issn.1005-9490.2015.06.007.[4]MolliconeD,KanK,MottC,etal.Predictingperformanceandsafetybasedondriverfatigue[J].AccidentAnalysis&Prevention,2019,126:142-145.[5]沈英超.基于眼部特征的疲劳驾驶检测系统的研究与实现[D].桂林:桂林电子科技大学,2019.[6]徐礼胜,张闻勖,庞宇轩,等.基于短时心电信号的疲劳驾驶检测算法[J].东北大学学报:自然科学版,2019,040(007):937-941.[7]GHARAGOZLOU,FARAMARZ,SARAJI,GEBRAEILNASL,MAZLOUMI,ADEL,etal.DetectingDriverMentalFatigueBasedonEEGAlphaPowerChangesduringSimulatedDriving[J].Iranianjournalofpublichealth,2015,44(12):1693-1700.[8]WangL,LiJ,WangY.ModelingandrecognitionofdrivingfatiguestatebasedonRRintervalsofECGdata[J].IeeeAccess,2019,7:175584-175593.[9]ArtantoD,SulistyantoMP,PranowoID,etal.Drowsinessdetectionsystembasedoneye-closureusingalow-costEMGandESP8266[C]//20172ndInternationalconferencesonInformationTechnology,InformationSystemsandElectricalEngineering(ICITISEE).2017.[10]BorghiniG,VecchiatoG,ToppiJ,etal.AssessmentofmentalfatigueduringcardrivingbyusinghighresolutionEEGactivityandneurophysiologicindices[C]//2012annualinternationalconferenceoftheIEEEengineeringinmedicineandbiologysociety.IEEE,2012:6442-6445.[11]ZhuX,ZhengWL,LuBL,etal.EOG-baseddrowsinessdetectionusingconvolutionalneuralnetworks[C]//2014InternationalJointConferenceonNeuralNetworks(IJCNN).IEEE,2014:128-134.[12]ZhangYF,GaoXY,ZhuJY,etal.AnovelapproachtodrivingfatiguedetectionusingforeheadEOG[C]//20157thInternationalIEEE/EMBSConferenceonNeuralEngineering(NER).IEEE,2015:707-710.[13]何艳清.基于深度学习的疲劳检测方法研究[D].北京:北京建筑大学,2021.DOI:10.26943/d.cnki.gbjzc.2021.000201.[14]JungSJ,ShinHS,ChungWY.Driverfatigueanddrowsinessmonitoringsystemwithembeddedelectrocardiogramsensoronsteeringwheel[J].IETIntelligentTransportSystems,2014,8(1):43-50.[15]LiG,ChungWY.Detectionofdriverdrowsinessusingwaveletanalysisofheartratevariabilityandasupportvectormachineclassifier[J].Sensors,2013,13(12):16494-16511.[16]BalasubramanianV,AdalarasuK.EMG-basedanalysisofchangeinmuscleactivityduringsimulateddriving[J].JournalofBodyworkandMovementTherapies,2007,11(2):151-158.[17]KingDJ,MumfordDK,SiegmundGP.Analgorithmfordetectingheavy-truckdriverfatiguefrom江苏科技大学工学硕士学位论文64steeringwheelmotion[C]//The16thESVConferenceProceedings.1998.[18]McDonaldAD,SchwarzC,LeeJD,etal.Real-timedetectionofdrowsinessrelatedlanedeparturesusingsteeringwheelangle[C]//ProceedingsoftheHumanFactorsandErgonomicsSocietyAnnualMeeting.SageCA:LosAngeles,CA:SagePublications,2012,56(1):2201-2205.[19]李作进,李仁杰,李升波,等.基于方向盘转角近似熵与复杂度的驾驶人疲劳状态识别[J].汽车安全与节能学报,2016,7(3):279-284.[20]FurugoriS,YoshizawaN,InameC,etal.Estimationofdriverfatiguebypressuredistributiononseatinlongtermdriving[J].Reviewofautomotiveengineering,2005,26(1):053-058.[21]兰振东.基于脑电与车辆运动信息融合疲劳检测研究[D].大连:大连理工大学,2021.DOI:10.26991/d.cnki.gdllu.2021.002862.[22]SigariMH,FathyM,SoryaniM.Adriverfacemonitoringsystemforfatigueanddistractiondetection[J].Internationaljournalofvehiculartechnology,2013,2013:1-11.[23]MandalB,LiL,WangGS,etal.Towardsdetectionofbusdriverfatiguebasedonrobustvisualanalysisofeyestate[J].IEEETransactionsonIntelligentTransportationSystems,2016,18(3):545-557.[24]Murphy-ChutorianE,TrivediMM.Headposeestimationincomputervision:Asurvey[J].IEEEtransactionsonpatternanalysisandmachineintelligence,2008,31(4):607-626.[25]李勇达,张超,孟令君.基于头部姿态特征的列车司机疲劳驾驶检测系统研究[J].交通信息与安全,2014,32(5):114-119.[26]AliouaN,AmineA,RzizaM.Driver’sfatiguedetectionbasedonyawningextraction[J].Internationaljournalofvehiculartechnology,2014,2014.[27]童兵亮.基于嘴部状态的疲劳驾驶和精神分散状态监测方法研究[D].长春:吉林大学,2004.[28]BergasaLM,NuevoJ,SoteloMA,etal.Real-timesystemformonitoringdrivervigilance[J].IEEETransactionsonintelligenttransportationsystems,2006,7(1):63-77.[29]ZhangZ,ChenY,YangY.Driverfatiguedetectionsystembasedonmachinevision[C]//20087thWorldCongressonIntelligentControlandAutomation.IEEE,2008:3979-3984.[30]王鹏,神和龙,尹勇,等.基于深度学习的船舶驾驶员疲劳检测算法[J].交通信息与安全,2022,40(1):1-9.[31]ZhaoG,HeY,YangH,etal.Researchonfatiguedetectionbasedonvisualfeatures[J].IETImageProcessing,2022,16(4):1044-1053.[32]HuJ,ShenL,SunG.Squeeze-and-excitationnetworks[C]//ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2018:7132-7141.[33]徐松,王敬晖,隋英楠,许文利.疲劳驾驶检测技术研究综述[J].运输经理世界,2022(24):162-165.[34]HarzallahH,JurieF,SchmidC.Combiningefficientobjectlocalizationandimageclassification[C]//2009IEEE12thinternationalconferenceoncomputervision.IEEE,2009:237-244.[35]夷德.基于YOLO的目标检测优化算法研究[D].江苏:南京邮电大学,2021.[36]王舒磊.基于面部特征的疲劳驾驶检测技术研究[D].沈阳:沈阳工业大学,2022.DOI:10.27322/d.cnki.gsgyu.2022.001178.[37]RamachandranP,ZophB,LeQV.Searchingforactivationfunctions[J].arXivpreprintarXiv:1710.05941,2017.[38]LinTY,GoyalP,GirshickR,etal.Focallossfordenseobjectdetection[C]//Proceedingsofthe参考文献65IEEEinternationalconferenceoncomputervision.2017:2980-2988.[39]BenoitA,CaplierA.Fusingbio-inspiredvisiondataforsimplifiedhighlevelsceneinterpretation:Applicationtofacemotionanalysis[J].ComputerVisionandImageUnderstanding,2010,114(7):774-789.[40]ChouKY,ChenYP.Real-timeandlow-memorymulti-facesdetectionsystemdesignwithnaiveBayesclassifierimplementedonFPGA[J].IEEETransactionsonCircuitsandSystemsforVideoTechnology,2019,30(11):4380-4389.[41]DengJ,GuoJ,VerverasE,etal.Retinaface:Single-shotmulti-levelfacelocalisationinthewild[C]//ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.2020:5203-5212.[42]ZhangS,ZhuX,LeiZ,etal.Faceboxes:ACPUreal-timefacedetectorwithhighaccuracy[C]//2017IEEEInternationalJointConferenceonBiometrics(IJCB).IEEE,2017:1-9.[43]WangH,WangY,ZhouZ,etal.Cosface:Largemargincosinelossfordeepfacerecognition[C]//ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2018:5265-5274.[44]GeS,LiC,ZhaoS,etal.Occludedfacerecognitioninthewildbyidentity-diversityinpainting[J].IEEETransactionsonCircuitsandSystemsforVideoTechnology,2020,30(10):3387-3397.[45]SONG,XIAO,ZHAO,XU,FANG,LIANGJI,etal.Discriminativerepresentationcombinationsforaccuratefacespoofingdetection[J].PatternRecognition:TheJournalofthePatternRecognitionSociety,2019,85220-231.DOI:10.1016/j.patcog.2018.08.019.[46]AkbariA,AwaisM,FengZH,etal.Distributioncognisantlossforcross-databasefacialageestimationwithsensitivityanalysis[J].IEEETransactionsonPatternAnalysisandMachineIntelligence,2020,44(4):1869-1887.[47]DornaikaF,Arganda-CarrerasI,BelverC.Ageestimationinfacialimagesthroughtransferlearning[J].MachineVisionandApplications,2019,30:177-187.[48]李京徽.基于神经网络的疲劳驾驶检测算法[D].长春:长春工业大学,2022.DOI:10.27805/d.cnki.gccgy.2022.000307.[49]牛作东,覃涛,李捍东,陈进军.改进RetinaFace的自然场景口罩佩戴检测算法[J].计算机工程与应用,2020,56(12):1-7.[50]HanK,WangY,TianQ,etal.Ghostnet:Morefeaturesfromcheapoperations[C]//ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.2020:1580-1589.[51]郑文倩.基于深度学习的疲劳驾驶检测[D].辽宁:辽宁科技大学,2020.DOI:10.26923/d.cnki.gasgc.2020.000212.[52]WangQ,WuB,ZhuP,etal.ECA-Net:Efficientchannelattentionfordeepconvolutionalneuralnetworks[C]//ProceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition.2020:11534-11542.[53]JinX,XieY,WeiXS,etal.Delvingdeepintospatialpoolingforsqueeze-and-excitationnetworks[J].PatternRecognition,2022,121:108159.[54]AcıoğluA,ErcelebiE.RealtimeeyedetectionalgorithmforPERCLOScalculation[C]//201624thSignalProcessingandCommunicationApplicationConference(SIU).IEEE,2016:1641-1644.[55]SongF,TanX,LiuX,etal.Eyesclosenessdetectionfromstillimageswithmulti-scalehistogramsofprincipalorientedgradients[J].PatternRecognition,2014,47(9):2825-2838.江苏科技大学工学硕士学位论文66[56]AbtahiS,OmidyeganehM,ShirmohammadiS,etal.YawDD:Ayawningdetectiondataset[C]//Proceedingsofthe5thACMmultimediasystemsconference.2014:24-28.[57]WengCH,LaiYH,LaiSH.Driverdrowsinessdetectionviaahierarchicaltemporaldeepbeliefnetwork[C]//AsianConferenceonComputerVision.Springer,Cham,2016:117-133.[58]JiY,WangS,ZhaoY,etal.Fatiguestatedetectionbasedonmulti-indexfusionandstaterecognitionnetwork[J].IEEEAccess,2019,7:64136-64147.[59]娄平,杨欣,胡辑伟,等.基于边缘计算的疲劳驾驶检测方法[J].计算机工程,2021,47(7):13-20.[60]HeK,ZhangX,RenS,etal.Deepresiduallearningforimagerecognition[C]//ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2016:770-778.[61]HeK,ZhangX,RenS,etal.Identitymappingsindeepresidualnetworks[C]//Europeanconferenceoncomputervision.Springer,Cham,2016:630-645.[62]HowardAG,ZhuM,ChenB,etal.Mobilenets:Efficientconvolutionalneuralnetworksformobilevisionapplications[J].arXivpreprintarXiv:1704.04861,2017.[63]SandlerM,HowardA,ZhuM,etal.Mobilenetv2:Invertedresidualsandlinearbottlenecks[C]//ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2018:4510-4520.[64]SzegedyC,VanhouckeV,IoffeS,etal.Rethinkingtheinceptionarchitectureforcomputervision[C]//ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2016:2818-2826.[65]宋晓敏.基于机器视觉疲劳驾驶检测系统的研发[D].浙江:浙江科技学院,2022.DOI:10.27840/d.cnki.gzjkj.2022.000003.