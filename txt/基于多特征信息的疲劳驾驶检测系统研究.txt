．

分类号  密 级 

Ｕ Ｄ Ｃ

硕 壬 学 位 论 文

基于 多特征信息 的疲劳鸾驶 检测 系 统 研究



；－占 －

。 麵

．

？ …卿



－＊Ｆ

＇

 …

’娜

．

一— －

－

。作 者 姓 名 ：王 勤／ ？ ：

；

学 科 、 专 业 ：车 辆 工 程這边 ？ 含

一

：

掉 ，

■ 学号 ：

２ １ ２ ０ １ ２ ０ ８ ０ ２ ０ ４ ０ １ ５

指 导 教 师 ：唐 就 教 授 ￣

完 成 日 期 ． ：

＿？￣

〇 １ ５年 ５ 月

，

Ｘ＾

＾Ｂ＾ｓ＾＾ ＾＾＾Ｂ ｌＢＢ＾Ｂ Ｉ＾＾ ｎｕ

ｉ

，

，

— －■ ￡



  

 

＊

Classified Index:
UDC:

Xihua University

Master Degree Dissertation

Fatigue driving detection system research
based on multi-feature information

Candidate:
Major
Student ID: 212012080204015
Supervisor:

: Vehicle Engineering

May, 2015

西华大学硕士学位论文

摘

要

疲劳驾驶已成为交通安全的“头号杀手”，及疲劳驾驶预警系统平民化，迫切需要

我们不断改进疲劳驾驶检测技术。为改善单一传感器在疲劳检测中的不足,本文通过综

合分析疲劳时驾驶员眼睛、嘴部状态和车辆行驶轨迹这三个疲劳特征来提高疲劳驾驶检

测率。

首先在车里和车前部安装摄像头采集驾驶人员面部和道路图像来获得驾驶人员的

眼睛、嘴部和道路特征数据，采用辅助红外光源的图像采集方案来保证本系统的全天时

可用性和自然光的影响；然后采用基于纹理分析的红外检测方法来提取眼睛特征，使用

智能的ADABOOST算法来检测并定位目标区域，并分别采用左右眼分类器来检测眼睛图

片；通过先定位鼻子，再根据鼻子和嘴巴的几何位置关系定位嘴巴的方式来提高嘴巴的

检测率，提出基于自适应方法来检测嘴巴开度，再根据区域的尺寸来计算嘴巴的开度；

采用一种简单的直线车道模型来计算道路图像中的车道线，并使用鲁棒性较好的概率霍

夫变换来求解直线车道模型的参数，计算出偏航率。

文中使用改进PRECLOS、闭眼时长率的方法来分析眼睛特征，把检测到的闭眼时

长和正常闭眼时长的比值作为分析疲劳的标准；提出双阈值哈欠分析方法来分析嘴巴特

征，疲劳和区分非哈欠的情况；文中提出偏航率的方法检测车道偏离，偏航率定义为左

右车道线和图像横轴夹角的比值。最后以改进PRECLOS、闭眼时长、哈欠时长和车道

偏航率作为特征值，采用加权平均做融合分析，实验证明其基于多特征信息融合的疲劳

驾驶检测准确率有较大提高。

关键词:汽车主动安全;疲劳驾驶检测;信息融合；特征提取；图像采集

基于多特征信息的疲劳驾驶检测系统研究

Abstract

As we know，fatigue driving has become "the number one killer" of traffic safety，and

with the popularization of driver fatigue warning system, the continuous development and

improvement of fatigue driving detection system technology is imminent. To overcome the

limitations of a single sensor in fatigue detection, we improve the fatigue driving detection

rate through comprehensive analysis these three features of the driver’s eyes and mouth status,
and the vehicle traveling trajectories.

First of all, this paper obtain the driver's eyes, mouth and the road feature data from the

driver’s facial image and road image through installing cameras in the car and the front of the

car，using image acquisition program of the infrared light auxiliary sources to ensure the

all-time availability of the system and filter out the effect of natural light；extracting the eye

fatigue characteristic by texture analysis infrared detection method，and then detect and locate

the eyes and mouth area by the intelligent ADABOOST algorithm; we first locate the nose,

and then enhance the mouth detection rate through the geometric position relationship of nose

and mouse，then calculate the opening degree of the mouth according to the area the size;

calculating lane of road image using a simple linear lane model, and obtain the parametric of

the linear lane model using the better robustness probability Hough transform, so calculate the

yaw rate.

This paper propose the eyes closed time rate to analyze eye feature, on the basis of

PERCLOS algorithm, this method let the ratio of the detected eyes closed time and normal

eyes closed time as the standard of fatigue analysis, for the mouth fatigue Characteristic

Analysis, we use the dual-threshold yawn analysis methods to analyze fatigue and distinguish

non-yawn; this paper detects lane deviation using the yaw rate, which is defined as the ratio of

the left and right lane lines and the image horizontal axis angle. Finally, do fusion analysis

using the weighted average, with select the PRECLOS, the eyes closed time, yawn time and

the lane yaw rate as the features value, experiment show that the accuracy rate has greatly

improved.

Keywords: Automobile Active safety; fatigue driving detection; information fusion;

feature extraction; image acquisition

西华大学硕士学位论文

目

录

摘

要............................................................................................................................. I

Abstract.............................................................................................................................. II
1 绪论.............................................................................................................................. 5

1.1 课题研究背景....................................................................................................5

1.2 疲劳驾驶检测系统的研究现状...........................................................................5

1.2.1 疲劳驾驶检测国外研究现状....................................................................5

1.2.2 疲劳驾驶检测国内研究现状....................................................................6

1.3 研究内容............................................................................................................6

1.4 本章小结............................................................................................................7

2 疲劳驾驶检测系统简介.............................................................................................. 8

2.1 疲劳驾驶的定义及危害....................................................................................8

2.2 疲劳驾驶检测系统基本组成..............................................................................9

2.3 疲劳驾驶检测方法的分类..............................................................................10

2.3.1 基于生理和行为的检测方法..................................................................10

2.3.2 基于视觉的检测方法..............................................................................11

2.3.3 基于信息融合的检测方法........................................................................1

2.4 本章小结............................................................................................................2

3 驾驶员面部图像及道路图像采集................................................................................. 3

3.1 全天时驾驶人员面部图像采集...........................................................................3

3.2 眼睛及嘴巴图片提取..........................................................................................4

3.2.1 ADABOOST 算法原理.............................................................................5

3.2.2 眼睛检测...................................................................................................7

3.2.3 嘴巴检测...................................................................................................8

3.3 道路图像采集....................................................................................................10

3.4 实验结果及分析................................................................................................10

3.4.1 眼睛检测实验与分析..............................................................................10

3.4.2 嘴巴检测实验与分析.............................................................................12

3.5 本章小结............................................................................................................13

4 关键疲劳特征计算...................................................................................................... 14

4.1 LBP 理论............................................................................................................ 17

基于多特征信息的疲劳驾驶检测系统研究

4.2 计算眼睛开闭特征............................................................................................19

4.2.1 计算纹理特征滤波阈值.........................................................................19

4.2.2 计算特征矩阵描述向量.........................................................................22

4.2.3 支持向量机做开闭检测.........................................................................24

4.3 计算嘴巴开度特征............................................................................................26

4.3.1 计算二值化阈值.....................................................................................26

4.3.2 嘴巴开度计算.........................................................................................28

4.4 本章小结............................................................................................................28

5 车道偏离特征计算...................................................................................................... 30

5.1 道路图像特征分析............................................................................................31

5.2 基于边缘的车道特征计算................................................................................34

5.3 车道建模与车道识别........................................................................................38

5.3.1 图像平面中的道路模型.........................................................................39

5.3.2 车道模型参数计算.................................................................................39

5.4 本章小结............................................................................................................40

6 多特征疲劳分析........................................................................................................ 42

6.1 基于 PERCLOS 原理的疲劳分析.................................................................... 42

6.2 持续闭眼时长分析............................................................................................44

6.3 哈欠分析............................................................................................................44

6.4 偏道分析............................................................................................................46
6.(cid:24) 疲劳特征融合分析............................................................................................49
6.5.1 多特征数据融合方法.............................................................................49

6.5.2 眼睛疲劳特征融合分析..........................................................................50

6.5.3 融合多特征权重分配及计算模型.........................................................53
6.(cid:25) 疲劳预警............................................................................................................56
6.(cid:26) 本章小结............................................................................................................57
论.......................................................................................................................... 59

结

参考文献.......................................................................................................................... 61

攻读硕士学位期间发表的论文及科研成果.................................................................. 64

致

谢.......................................................................................................................... 64

西华大学硕士学位论文

1 绪论

1.1 课题研究背景

据最新数据统计，若驾驶员在 3s 时间内出现注意力不集中，会造成大约 80%的交通

事故，主要有车道偏离和追尾事故, 大量交通事故的发生严重影响了我们的和谐生活[1]。

研究显示，若在公路交通事故发生前的 1.5s 给驾驶员发出预警，则可避免 90%的这类事

故。所有这些都道出“疲劳驾驶猛于虎”[2]。所以疲劳驾驶除了合理安排行车时间，还

需要有效的科技预警装置，才能最大程度减少疲劳驾驶事故的发生[2]。

心理学家提出，在人们的交流中通过面部表情传递的信息量达到了 55％，由于人脸

表情包含丰富的行为信息，因此对人脸表情进行识别有利于了解人类的情感等心理状

态，并且可以进行有效的人机交互[3]。一项调查结果显示 70％的受调查者承认在高速路

上驾车时有打瞌睡的经历，疲劳驾驶发生时有 60％以上的汽车的行驶速度是超过 80km/h

的[3]。《中华人民共和国道路交通安全法实施条例》第六十二条规定：连续驾驶机动车

超过 4 小时未停车休息或者停车休息时间少于 20 分钟。也就是说，凡驾驶人连续驾驶

机动车超过 4 小时未停车休息或者停车休息时间少于 20 分钟的，都属于过度疲劳驾驶

车辆，都是违法行为。因此，疲劳检测系统中加入对于驾驶员面部的识别，来判断他是

否是开车超过四个小时未休息，从而判定他是疲劳驾驶是非常重要的。

据检测分析可知，疲劳特征越简单明显，对其进行识别和提取的算法实效性越好，

抗干扰性越强[4]。同时基于机器视觉的检测方法发展迅速，其非接触式检测范围广、可

扩展性强。而车载检测系统的主流也由基于多传感器信息融合技术的疲劳驾驶智能检测

系统替代了眼部检测装置。所以本文提出基于驾驶员面部特征（眼睛、嘴巴特征）、车

道行驶轨迹特征信息进行综合分析的研究方法。

1.2 疲劳驾驶检测系统的研究现状

1.2.1 疲劳驾驶检测国外研究现状

国外较早就对疲劳驾驶检测与预防进行了研究，在理论和实际应用中都有不错的成

绩。如日本先锋公司在 1994 年开发的通过检测驾驶员心跳速度来防止驾驶员开车打瞌

睡的“心跳检测仪”；在 1995 年澳大利亚研发了通过检测驾驶员在行驶过程中头部运

动情况来判断打瞌睡的“预警系统”；在 1998 年美国卡内基.梅隆大学研发了检测单位

时间内眼睛闭合程度来提醒驾驶员注意行车安全的“PERCLOS 系统”。近年来，近年来，

美国 Electronic Safety Products 公司开发出了“转向盘检测系统 S.A.M”；美国 Ellison

Research Labs 研究出通过对车道标志线进行实时检测、当车辆偏离道路中线或车道标

1

基于多特征信息的疲劳驾驶检测系统研究

志线时向驾驶员发出警告的“车道偏离报警系统 DAS2000”[4]；欧盟研发出利用图像、

压力等多种传感器对疲劳驾驶行为进行较为全面检测和评价的“AWAKE 系统”[5-6]。

国外预防疲劳驾驶的产品：（1）美国 ATTENTION 公司的 DD850，已经通过美国交通

运输部在全美进行推广，在国内成都也有代理，售价 2 万多;（2）美国 DSS 公司的疲劳

检测和分析系统，在北京有代理，售价 20 万;（3）奔驰、沃而沃等的高端系列产品有

瞌睡提醒装置[7]。

1.2.2 疲劳驾驶检测国内研究现状

紧随其后，国内多所著名高校也开始了对疲劳驾驶检测这一课题进行了不同程度的

研究，并在疲劳驾驶检测的理论和算法上取得了一些基础性的成果。近年来，江苏大学

的刘志强教授通过已有的 PERCLOS 算法研究了疲劳驾驶检测系统；吉林大学利用车辆的

动力学状态参数、车辆前方道路的几何特征研发出了确定车辆的当前位置和方向是否会

导致车辆发生车道偏离的“车道偏离警告系统”，还有重庆大学的导航与直道实验室，

他们采用模式识别、特征提取和信息融合开发出了“高速公路智能汽车行驶主动安全预

警系统”[6], 清华大学和东南大学的几位博士组建的中国单片机公共实验室南京研发中

心联合南京远驱科技有限公司研究出来的 gogo850 是国内唯一已经商业化的疲劳驾驶预

警系统[7]。如 BMW-X5 配套车道偏离预警和 HUD 抬头显示系统；新（奔驰-E350）带车道

偏离预警和主动夜视系统上市[8]。

1.3 研究内容

本文主要集中通过机器视觉的方法获得驾驶员疲劳时的面部疲劳特征和车辆偏航

率等来研究单特征及多特征疲劳分析方法，在文章中通过分别分析不同的疲劳特征及综

合分析这些疲劳特征来提高疲劳检测精确度。

首先，在查阅了大量的与主动安全、疲劳驾驶检测及预警方法、特征提取分析相关

文献的基础上，从研究意义和国内外研究现状等方面分析现在疲劳驾驶检测技术的优缺

点后，从中分析得出本文的研究重心和研究方向——运用机器视觉的方法来完成基于多

特征的疲劳驾驶检测分析。其主要工作如下：

1、采集前端人脸视频数据和道路视频数据，求取目标图像。针对自然光照易变且

在夜晚无自然光等条件，提出使用主动红外成像技术来解决车内人脸视频数据全天时采

集问题。在采集到稳定的人脸视频数据和车道数据后，使用智能的 ADABOOST 算法来做

人眼和嘴巴的定位工作，并从这些图像中提取眼睛和嘴巴图片。为了更加精确的提取眼

睛和嘴巴，本文采取分别对左右眼使用左右眼分类器的方法来提高眼睛检测的精度，在

2西华大学硕士学位论文

检测嘴巴时本文提出通过检测特征比较明显且检测精度的鼻子检测分类器来优先检测

鼻子，在通过鼻子和嘴巴的几何位置关系来计算出嘴巴的位置。

2、眼睛及嘴巴开度检测。运用纹理分析方法来检测眼睛的开闭，并提出一种自适

应阈值的嘴巴开度检测方法。眼睛开闭检测是利用眼睛在睁眼和闭眼时它们的纹理信息

在纹理特征矩阵中有不同的分布来检测眼睛的开闭，该方法检测速度快精度高。嘴巴开

度检测，首先根据嘴巴的纹理分布来分割原嘴巴图像，并对分割后等到的皮肤图像求其

灰度分布的期望，把此值作为对原图像二值化的标准来二值化原图像。最终检测出嘴巴

区域并计算其开度。

3、提出车道线检测方法，检测出行驶车道线偏航率。提出使用直线车道模型来解

决高速路车道线检测问题，针对高速路的直线车道模型，使用概率霍夫变换来求解模型

参数，以达到车道线检测的目的。

4、对上述使用和提出的算法做实验得到本文所需的分析疲劳的特征数据。分 5 节

分别研究基于眼睛的疲劳分析方法、基于嘴巴的疲劳分析方法、基于车道疲劳分析方法

及疲劳特征融合分析方法。

5、最后本文根据三特征的特点选用改进 PRECLOS、闭眼时长、哈欠时长和车道偏

航率作为特征值，采用加权平均法做融合三疲劳特征分析，实验证明其检测准确率有较

大提高。

1.4 本章小结

本章阐述了疲劳驾驶检测技术的研究背景及发展现状，最后提出了本文的主要内

容。

3基于多特征信息的疲劳驾驶检测系统研究

2 疲劳驾驶检测系统简介

2.1 疲劳驾驶的定义及危害

疲劳驾驶是指驾驶员因长时间行车、睡眠不足或身体不适等因素而引起的视线模

糊、反应迟钝、注意力分散、动作僵硬等现象，或者说驾驶人在长时间连续行车后，产

生生理机能和心理机能的失调，出现驾驶技能下降的现象[12]。驾驶人没有休息好或长时

间驾驶，容易出现疲劳，一旦疲劳后会使驾驶人的注意、判断、决定和运动意识减弱等，

若再继续驾驶车辆，出现动作迟误或过早，操作停顿或修正时间不当等错误操作，极易

导致交通事故，为保障安全应严禁疲劳驾驶。

当驾驶人轻微疲劳时，会出现换档不及时、不准确；驾驶人中度疲劳时，会出现操

作动作呆滞，有时甚至会忘记操作；驾驶人处于重度疲劳时，往往会下意识操作或出现

短时间睡眠现象，严重时会失去对车辆的控制能力, 车辆出现“S”型前进等状况[13]。

若驾驶员在疲劳时仍驾驶车辆极易导致交通事故。

疲劳驾驶预警系统作为汽车主动安全系统里的一员，下面对汽车主动安全性及部分

工作方式同于疲劳驾驶检测系统的主动安全系统做简单介绍。汽车主动安全性，是指汽

车本身防止或减少道路交通事故发生的性能，无论是直线上的制动与加速还是左右打方

向都应该尽量平稳，不至于偏离既定的行进路线，而且不影响司机的视野与舒适性[9]。

主动安全系主要包括有：AWS、TCS、ESP、VSA、ABS、EBD、LCA、ASR、SAS[10]，部分介

绍如下表 2.1 所示：

4西华大学硕士学位论文

表 2.1 部分主动安全系介绍

Tab 2.1 Part of the active safety system introduced

名称

主要内容

(Advance Warning System)意外事故预防和缓和的驾驶辅助系统，通过在汽

车上安装汽车碰撞预警系统，利用技术手段分析车道、周围车辆的状况等驾驶环

AWS

境信息，一旦当驾驶员发生疲劳及精神分散、汽车出现无意识的车道偏离及汽车

间车距过近或存在追尾可能时，及时给予驾驶主动预警[10]。

（ lane change assist）变道辅助系统，同 BSD 车辆盲点检测系统，采用

LCA

24Ghz 雷达传感器检测后面盲区接近的车辆，并通过前方后视镜旁的指示灯报警提

示[10]。

座椅震动预警

将以往汽车的安全警示由视觉和听觉延伸到触觉。当传感器感知潜在的事故

（SAS）

威胁时，驾驶座会根据状况发出一侧或双侧的震动，配合图标和声音的警示，以

清晰而直观的方式告诉驾驶者潜在的危险即将发生，甚至是危险的来源方向，以

做出及时而正确的应对措施[10]。

LDWS 车道偏离

当车在无意识（驾驶员未打转向灯）偏离原车道时，能在偏离车道 0.5 秒之

预警

前发出警报，为驾驶员提供更多的反应时间，大大减少了因车道偏离引发的碰撞

事故[10]。

自动感应大灯

自动感应大灯随车辆周边环境光线影响，系统会自动识别判断。雨雾天气光

线不够，大灯会自动亮起给驾驶者提供更安全的行车环境[10]。

2.2 疲劳驾驶检测系统基本组成

本文所研究的疲劳驾驶检测系统结构框图如图 2.1 所示,包括目标图像信息采集模
块、疲劳特征提取模块、单个疲劳特征分析模块、多特征信息融合分析模块及预警模块
五部分。

目标图像信息采集模块使用主动红外成像技术来全天时采集车内人脸视频数据及

道路图像；疲劳特征提取模块对精确定位的目标图像计算出疲劳特征；单个疲劳特征分
析模块使用线性判别模型对疲劳特征进行分析，划分出疲劳区间所对应的疲劳度，进行
一级融合；多特征信息融合分析模块，对多个特征值使用加权平均法进行融合分析；及
预警模块从视觉、听觉、触觉、嗅觉等预警手段中选取适宜的方式对驾驶人进行预警。

5基于多特征信息的疲劳驾驶检测系统研究

图 2.1 疲劳驾驶检测系统结构框图

Fig2.1 Fatigue driving detection system structure diagram

2.3 疲劳驾驶检测方法的分类

据有关数据表明，由疲劳驾驶导致的重特大公路交通事故占所有公路交通事故的

50%左右[6]，正因为如此，国内外大量专家和学者在疲劳驾驶检测预警这块做出了广泛的

探索和研究，也提出了许多方法。

2.3.1 基于生理和行为的检测方法

基于生理和行为的检测方法主要有脑电图（ EEG ）信号检测、 心电图（ ECG ）

信号检测、脉搏跳动检测以及肌电图（ EMG ）信号检测等[13]，具体介绍如表 2.2 所示：

表 2.2 基于生理和行为的检测方法

Tab 2.2 Detection method based on physiology and behavior

检测方法

主要内容

通过采集提取不同驾驶员不同波段的 EEG 信号，利用神经网络、采样熵和二

脑电图（ EEG ）

阶差分结构等方法对 EEG 信号进行非线性分析和处理，疲劳出现时会自动发出警

信号检测

报[13]。

对 ECG 信号的心率变化情况进行分析来确定驾驶员是否发生疲劳。该装置结

心电图（ ECG ）

构简单易于实现，成本低，但由于个体心率变化规律的差异较大，误判率稍高，

信号检测

且接触式的不方便适用，只能作为疲劳判断的辅助装置[13]。

脉搏跳动检测

在转向盘或手腕上安置探测装置检测脉搏跳动情况，利用软件实时分析并判

断驾驶员是否疲劳。脉搏跳动检测其可靠性和灵敏度也很好，但其是接触式的，

易对驾驶员产生干扰，不易被人接受[13]。

肌电图（ EMG ）

一般采用诱发电位的方法，在肌肉表面固定好表面电极，肌电信号经表面电

信号检测

极传至肌电图记录仪[13]。

6西华大学硕士学位论文

2.3.2 基于视觉的检测方法

基于机器视觉的方法是通过机器视觉来获得车辆在行驶过程中的显著特点和驾驶

人员的行为和状态来评估驾驶人员的疲劳状况，如车轮的运动状态及驾驶人员的持续眨

眼等。目前大致有以下几种，如表 2.3 所示：

表 2.3 基于视觉的检测方法

Tab 2.3 Detection method based on the visual

检测方法

主要内容

PERCLOS 检

在相同照度下分析眼睛的大小和位置，最后根据眼睛区域的图像高度判断眼睛的

测

睁闭。南京远驱科技有限公司研究出的 gogo850，该系统运用“PERCLOS”检测技术。

“PERCLOS”检测可靠性和实时性都比较好，是市面上运用最广的检测技术[13-15]。

头部位置检

它是对驾驶员安装头部位置传感器，通过人这个高导体，改变电极之间的电容，

测

进而通过测量电压计算头部与传感器之间的距离[15]。

视线方向检

首先在人脸肤色区域内定位双眼，根据瞳孔处图像比周围像素暗来确定瞳孔的位

测

置，最后根据瞳孔和眼角的相对位置关系确定视线方向，若人眼视线偏离正前方向，

则驾驶员可能因疲劳而注意力不集中[13]。

嘴部状态检

提取嘴部形状的几何特征并将其作为特征值，根据 BP 神经网络等方法来识别驾

测

驶员的疲劳状态[14]。

对采集到的转向盘转角信号，利用快速傅立叶和小波变换提取转向盘转角信号特

转向盘转动

征，通过对信号的分析来评价驾驶员是否疲劳。此方法实时性好、成本低，但是其抗

情况检测

干扰性差，可靠系数不大[14]。

车辆行驶速

通过实时监测车辆的行驶速度，判断车辆是处于有效控制状态还是处于失控状

度检测

态，从而间接反映驾驶员是否疲劳驾驶，但速度的大小很难准确的反映疲劳状况[15]。

车道偏离检

通过一个朝向道路前方的 CCD 摄像头检测驾驶员的行车轨迹，对车道标志线进

测

行实时检测，当驾驶员因疲劳而导致无意识偏离车道时（如转向灯不开）及时向驾驶

员发出警告。优点是非接触检测，信号易提取，缺点是容易受车型、路况、天气及个

人驾驶习惯的影响较大[15]。

7西华大学硕士学位论文

2.3.3 基于信息融合的检测方法

下面表 2.4 是对几种常用的疲劳驾驶检测技术的准确性、实用性和可扩展性的一个

比较。

表 2.4 常用疲劳驾驶检测技术性能比较

Tab 2.4 Common fatigue driving detecting technology performance comparison

检测技术

描述

准确性

实用性 可扩展性

基于生理参数的检测

主要检测脑电波、心率、脉搏频率以及

方法

皮肤电压等变化

基于驾驶

员行为特

征的检测

方法

身体反应

驾驶行为

头部运动、眼皮运动、眼睛闭合频率、

凝视方向、打哈欠频率

检测各种操控器（方向盘、加速器、刹

车踏板、档位等）的变换

基于交通工具行为特

检测汽车本身的行为（速度、侧向加速

征的检测方法

度、偏行速率、侧向位移等）的变化

基于行驶条件的检测

检测行驶时间和行驶条件（如白天或者

方法

晚上、行驶速度等）

很好

很差

一般

很好

一般

好

好

很好

很差

好

很好

很差

很差

好

很好

从表 2.4 可以看出任何一种疲劳预警方法都有自身的优缺点，其中基于驾驶员行为

特征的方法，对眼睛、嘴巴的检测各指标都较好，而采用多种方法对驾驶员疲劳状态进

行综合监测是非常有效和有前途的方法。目前有以下几种：

（1） 欧盟启动的 “ AWAKE ”驾驶行为综合监控系统。该系统利用图像、压力等

多种传感器，对驾驶员眼睑运动、视线方向、转向盘握紧力等驾驶状态进行综合，做出

较为全面的监测和评价[17]。

（2）Seeing Machines 公司研发的 Face LAB 系统。 通过检测驾驶员头部姿态、

眼睑运动、凝视方向、瞳孔直径等面部特征参量，进行多特征信息融合，实现对驾驶员

疲劳状态的实时监测[17]。

（3）奔驰公司开发的“疲劳识别”辅助系统，通过识别驾驶员的疲劳状态然后及

时给予警告。其中眨眼监控系统模块利用红外线摄像机持续地记录驾驶者的眨眼频率以

及每次闭眼的时长，一旦发现闭眼超时就给予警告信号。此外，他也利用生理监测如 EEG

来获取疲劳时的客观指标，并且该系统融合行驶时动态数据分析，如转向和制动行为，

若驾驶员较长时间没有操纵转向设备系统也会发出警告[18]。

8基于多特征信息的疲劳驾驶检测系统研究

2.4 本章小结

本章介绍了与疲劳驾驶研究相关的疲劳驾驶定义、危害及主动安全技术简介，并对

现有的疲劳驾驶检测方法做了详细介绍，为后面本文工作的开展奠定基础。然后从基于

生理和行为特征检测方法、基于机器视觉的检测方法以及基于信息融合的检测方法这三

方面来阐述了目前的疲劳驾驶检测方法。

9西华大学硕士学位论文

3 驾驶员面部图像及道路图像采集

在传统的疲劳检测检测技术的基础上，提出使用包括驾驶人员的眼睛、嘴巴和车辆

的行驶轨迹等特征来综合分析预警的方法。而提取这些特征最有效和廉价的方法就是使

用驾驶人员的面部视频数据以及道路视频数据。并采取相应的算法从中提取上述三种特

征。针对于此，本文在本节主要介绍采集全天时的驾驶人员面部视频和道路视频的方法，

以及从驾驶人员面部视频中提取眼睛图片和嘴巴图片的方法和设备。

3.1 全天时驾驶人员面部图像采集

由于驾驶环境复杂多变，影响驾驶人员面部图像质量的因数有很多，包括车身抖动、

驾驶员头部运动和环境光照等。在这些因数中尤其是环境光照的变化对采集图像质量影

响最大。本文针对夜晚光照弱或无光照以及自然光照强度随环境变化等问题，提出采用

主动红外成像技术来解决全天时图像或视频的采集问题。

主动红外成像技术是指：在普通的基于 CCD 感光芯片的摄像机的基础上，加一个

主动红外补光模块和红外滤光模块。使得加入这两个模块的摄像机能过滤掉自然光的影

响而采集近红外图像。有了这两个模块的加入使得整个前端采集系统能在全天时使用，

并且能通过红外滤光片过滤掉自然光的影响，有效的提高采集图像的质量。本文所使用

的硬件如图 3.1 所示。

图 3.1 采集驾驶人员面部图像设备

Fig 3.1 The driver face image acquisition equipment

本文使用上述设备在车内采集红外图像的原理如下：

1）安装在车辆的 A 柱上的发光波长为 850nm 的 LED 红外补光阵列发出红外光，

其红外光照在驾驶员面部产生漫反射。

10基于多特征信息的疲劳驾驶检测系统研究

2）反射的红外光进入安装在驾驶台上的加装了滤光片的林柏视高清摄像头内，并

在其内部的 CCD 芯片上产生视频信号。

3）林柏视高清摄像头通过 USB 和计算机连接并向计算机发送视频帧。

从图 3.1 中可以看到本文所使用的硬件设备，在实验采集驾驶人员面部图像时，高

清摄像头被安装在车辆方向盘后方的平台上，在竖直方向上正对驾驶人员头部，在横向

为了配合辅助红外光源，摄像头向上有一定的向上的倾角，红外滤光片安装在摄像头的

机盖上，红外辅助光源安装在车辆的 A 柱上。这样就构成一个完整的采集近红外图像的

系统。在实际的车上采集的驾驶人员的白天和夜晚的面部图像如图 3.2 所示。

图 3.2 红外摄像头采集白天和黑夜面部图像

Fig 3.2 Infrared camera to capture the facial image during the day and night

本文所使用的主动红外采集系统能完全满足在白天和黑夜采集驾驶人员面部图像

的需求，能有效的抑制自然光对采集图像质量的影响，能保证全天时的图像采集任务。

3.2 眼睛及嘴巴图片提取

在基于多特征的疲劳检测技术中，眼睛的特征和嘴巴的特征是较为重要的特征，同

时也是表征疲劳最直接的特征，眼睛和嘴巴的定位作为疲劳判断的前提显的尤为重要。

在人脸图像中定位眼睛和嘴巴的方法有很多，但是针对近红外图像和在驾驶车辆这样的

特殊环境。国内外的学者大都采用鲁棒性较好的 ADABOOST（adaptive boosting）算

法来解决在这个特殊环境下的眼睛和嘴巴检测问题[20]。主要原因在于，近红外图像中眼

睛和嘴巴的特征和自然光照下眼睛和嘴巴的特征在图像灰度上有不同表现，造成许多针

对自然光提出的眼睛和嘴巴检测算法失效；另外在驾驶车辆的环境中，驾驶人员的头部

往往会做不规则的运动，主要是由于道路不平或驾驶习惯等导致，这样使得一些非智能

算法在检测眼睛和嘴巴时鲁棒性较差。然而 ADABOOST 智能算法被用来做驾驶环境下

的眼睛和嘴巴检测，能有效的提高检测眼睛以及嘴巴的鲁棒性。保证高效和高质量的眼

睛和嘴巴图片的检出。下面将简单介绍 ADABOOST 算法，和详细描述本文训练眼睛和

嘴巴检测分类的具体过程。

11西华大学硕士学位论文

3.2.1 ADABOOST 算法原理

在机器学习理论中，通常从可学习性角度出发把机器学习的算法分为强学习算法和

弱学习算法。即针对一个学习算法通过在一组样本上的学习训练，能达到较为理想的识

别率，称该学习算法为强学习算法；相反，如果学习结果的识别率与随机猜测相当，称

该学习算法为弱学习算法[21]。1996年，Freund和Schapire改进了boosting算法，提出

ADABOOST算法[20-21]，该算法在保证原有的boosting算法效率的同时，它不需要任何弱学

习算法的先验知识，所以该算法更容易运用到实践的应用中。

ADABOOST算法的基本思想是将一组弱学习算法结合大量的样本训练得到一个识别

率较好的强学习算法，根据ADABOOST算法的思想，识别率的好坏与样本的数量有关，如

果样本的数量接近无穷那么训练所得的分类器的识别率能接近100%。但是这只是假设的

情况，在实际的应用中考虑到训练成本问题，往往选择区分度高和数量足够大的样本作

为训练样本。Adaboost算法流程如图3.3所示。

1D

2D

iD

1tD 

tD

1S

1h

2S

2h

w h x
1 1( )

w h x
2 2 ( )

...

...

tw h

1


t

1tS 

1th 

tS

th

x
1( )



tw h x
( )

t

)H X
(

图3.3 ADABOOST算法流程图

Fig 3.3 ADABOOST algorithm flowchart

在图3.3中， 1
S



{(

x y
,
1
1

),...(

x y
,
i
i

),...(

x y
,
n

n

)}

是初始训练集，其中 ix

X 样本集，

iy

Y 类标集。具体的ADABOOST算法训练过程如下所示：

弱分类器 ( )h x ，初始假设样本权重为均匀分布且 ( ) 1

首先选取 m 个特征（基于Haar特征的ADABOOST算法选取 m 个Haar矩形特征[21]）组成
tD i 表示在第 t 次迭代中
x y 的权重，并假设训练迭代次数为T 次。那么ADABOOST算法循环执行以下
i

n ， ( )

赋给样本 (

tD i

)

,

i

步骤：

12基于多特征信息的疲劳驾驶检测系统研究

（1）在训练集 tS 上训练分类器 ( )

th x ，并用该分类器对训练集 tS 中的样本 x 进行分
th x 的分类误差，其分类误差的计算公式如公式(3.1)所示。

类，由此得到本次分类器 ( )


t



n



i

1


D i h x
( )
i

(

i

t

)



y
i

(3.1)

在公式(3.1)中如果 1 2

t  ，那么减少循环次数既是

T T  ，否则继续循环。

1

（2）设


 
t

t

1

 ，并从新计算权重向量。计算权重向量的公式如公式(3.2)所


t

示。

D i
(
t


1)
  


,  



t

if h x
(
i
i

D i
)
( )
t
D i
( ),                     
t

(

)
y

i
other

(3.2)

（3）经过T 轮训练后，得到强分类器 ( )H x ， ( )H x 的输出公式如公式(3.3所示：

( )
H x



sign

(

T



t

1


log(1


t

)



h x
t

( ))

(3.3)

( )

按照以上ADABOOST算法能使用 m 个特征经过T 次的迭代运算来确定T 个弱分类器
th x ，并把这T 个弱分类器组成一个识别率较好的强分类器 ( )H x 。在基于扩展Haar特
征的ADABOOST算法中，即是用Haar矩形特征来作为所选的 m 个特征来组成最初的弱分类
器[22]。Haar特征是指一些由矩形构成的特征。具体的模板如图3.4所示。

图3.4 Haar特征模板图

图3.5 Haar特征模板匹配图

Fig 3.4 Haar feature template

Fig3.5 Haar feature template matching graph

在人脸图像中眼睛和嘴巴及其周围邻域的灰度分布和图3.4的模板刚好能匹配，

Haar特征检测的示意图如图3.5所示，在计算时Haar特征是尺寸可变的模板，通过不同

尺寸的模板在人脸图像中搜索满足要求的特征。Haar特征值的计算是在模板中黑色区域

13西华大学硕士学位论文

的像素和和白色区域的像素和的差值，在收索过程中这个差值即Haar特征值满足要求就

作为可选特征输出。

本文在训练用于眼睛和嘴巴分类的分类器时主要选用的Haar特征是如图3.4所示的

线形特征和中心特征，这两种特征从其形状上来看，在脸部图像中最符合眼睛和嘴巴的

灰度分布特性（如图3.5所示），即眼球部分灰度较暗周边灰度较亮的特性，嘴唇灰度

叫其邻域灰度分布较暗。而在线性特征和中心特征中都包含 45 角模板特征，使得所训

练的分类器在检测眼睛和嘴巴时对驾驶人员头部的倾斜有一定的鲁棒性，并因此提高眼

睛和嘴巴检测的精度和检出率。

3.2.2 眼睛检测

本文在了解和学习 Adaboost 算法的基础上，提出使用 Adaboost 算法的开源库在红
外人脸图像中来检测嘴巴和眼睛，这个开源库是 OpenCv 提供的。在 OpenCv 库（是一种
数字图像处理和计算机视觉的函数库）中提供了相应的 Adaboost 算法接口函数和训练
好的一些分类器[22]。其中接口函数是：

DetectHaarCascade





HaarCascade haarObj double scaleFactor
HAAR DETECTION TYPE flag Size minSize
_

，

_

，

，

int minNeighbors

,





其中第一参数是引入已经训练好的基于Haar特征的分类器。后面几个参数是规定该

分类器中Haar特征的收索范围和尺寸等条件。在检测眼睛时，后面几个参数的确定有赖

于做大量的实验，因为这几个参数是经验值，对于不同的样本有不同适应值。在本文中

做眼睛检测时，所选用的分类器是OpenCv库所提供的左右眼分类器，该分类器分别是：

haarcascade_mcs_lefteye.xml左眼分类器和haarcascade_mcs_righteye.xml右眼分类

器。对左右眼选择不同的分类器原因在于，在驾驶过程中驾驶人员可能由于观察后视镜

或其他一些原因，使得在图像中面部在水平方向有较大倾角，这样可能在图像中只出现

左眼或者是右眼。在这种情况下，分别使用左右眼检测分类器能有效的检测出眼睛，避

免在这种极端条件下，检测不到眼睛的情况。并且为了提高眼睛检测的鲁棒性，该分类

器在训练时把左右眼眉也作为训练特征来训练分类器，因为人在闭眼时，往往眼睛部分

的灰度和其邻域的灰度区分度不高，但是无论是在闭眼或是在睁眼时，眼眉的灰度特征

是比较稳定的。能够形成稳定的分类特征。眼睛检测算法的流程图如图3.6所示。

14 
 
 
 
 
基于多特征信息的疲劳驾驶检测系统研究

图3.6 眼睛检测算法流程图

Fig 3.6 Eye detection algorithm flow chart

在图3.6中，当每帧人脸图像输入时，想做直方图均衡化消除部分光照的影响，在

使用上述的左右眼分类器和 DetectHaarCascade 函数计算检测出眼睛图片，从算法的流程可

以看出，首先检测的是左眼，无论左眼检测是否成功，都会进入右眼的检测，当算法结

束时保证至少能检测到一只眼睛（一些特殊情况除外）。当遇到图像中没有眼睛的情况，

算法检测失败，进入下一帧的处理检测。在这些改进的基础下，使得本文所使用眼睛检

测算法能有效的保证为后续眼睛疲劳特征检测提供可靠的数据来源，这就是本文所使用

的眼睛检测算法的流程。

3.2.3 嘴巴检测

嘴巴的检测和眼睛的检测基本相同，都使用的是OpenCv的开源库中的函数，不同的

在于分类器使用不同。但在检测嘴巴时，当嘴巴张开时特征比较明显，且检测精度较高。

但是在红外图像中当嘴巴闭合时，嘴巴和其邻域的在灰度上区分不明显。所以在用Haar

特征做检测时会导致检测失败。

在本文中为了能在各种情况下鲁棒的检测出嘴巴，综合分析鼻子和嘴巴的位置关

系，提出从找鼻子出发来定位嘴巴的方法。鼻子和嘴巴在面部图像的几何位置关系如图

3.7所示。

15西华大学硕士学位论文

w

x y
,
1
1

(

)

(

x y
,
2


2

)

h

图3.7 鼻子和嘴巴位置关系图

Fig 3.7 The nose and mouth position diagram

在图3.7中红色的矩形是运用ADABOOST算法检测的鼻子的结果，这个矩形由两个点

来确定，这两个点是该矩形的对角点，分别是点 1
形的下方，根据人脸器官的大小比例和分布情况，本文定义嘴巴区域如公式（3.4）所

 ，嘴巴的位置在该矩
)
2

 和点 2
)

x y
,
1

x y
,

(

(

示：


x
x
1
2


y w
y


1
1

x

2

y w

2

x
2





h

y

2

（3.4）

通过公式（3.4）能方便的确定嘴巴区域矩形，分别通过对角点 1

x y 和点 2

x y 确
)
2

(

)

(

,

,

1

定。在本文的算法中，首先使用OpenCv开源库中的一个比较稳定的检测鼻子的分类器

haarcascade_mcs_nose.xml，在红外人脸图像中检测鼻子的位置，在每一帧图像中检测

到鼻子后在使用公式（3.4）来计算出嘴巴的位置。并按照该位置提取嘴巴图片。具体

的嘴巴检测算法流程图如图3.8所示。

16            
基于多特征信息的疲劳驾驶检测系统研究

图3.8 嘴巴检测流程图

Fig 3.8 Mouth detection flow chart

在图3.8中详细介绍了本文做嘴巴检测的流程，通过特征稳定和检测率较高的鼻子

来间接的检测嘴巴，在保证检测时间效率的同时，又能避免闭嘴时检测不到嘴巴的情况。

提高检测的准确度和准确率。在此基础上做嘴巴的疲劳特征计算相对直接找嘴巴的方法

有更好的效果。

3.3 道路图像采集

在采集道路图像时，与采集驾驶人员面部图像不同的是，由于道路环境比较开阔，

不能使用有效的补光手段，并且白天车辆行驶在道路上有足够的自然光照，可以采集到

有效的道路图像。在夜间行车时，车辆的前照灯也能提供相应的光线来采集道路图像，

所以采集道路图像时从硬件上的改进比较微弱。然而在行车的过程中往往可能遇到大

雾、大雪或者阴雨天气。针对这些天气做图像预处理能提高道路图像的质量。

在本文中采集的道路图像的设备主要包括一台高清摄像头和采集主机。高清摄像头

白安装在车辆中央后视镜的正前方，与道路路面有一定的夹角。并与采集主机相连。用

于实时的采集道路图像。

17西华大学硕士学位论文

3.4 实验结果及分析

3.4.1 眼睛检测实验与分析

本文在ADABOOST算法原理基础上，考虑到驾驶人员在驾驶车辆的过程中可能由于车

辆的抖动或者是驾驶员左顾右盼，使得摄像头采集到的人脸图像不全，如可能有的帧中

出现不包含左眼或者不包含右眼的情况。同时由于在红外图像中当眼睛处于闭眼状态

时，这时眼睛处的灰度和周围皮肤的灰度区分度不高，即局部灰度差异不大，不满足所

选用的Haar特征模板，以至于检测闭眼目标失败。针对这两种情况，本文提出一种分别

使用左右眼睛和眼眉训练的各自分类器来检测眼睛的方法。分别使用左右眼睛分类器来

检测眼睛是为了保证头部运动幅度较大时，仍然能在倾斜的人脸图像中检测到眼睛。根

据本文提出的眼睛检测的算法分别在实验室环境和车内环境采集的视频数据做眼睛检

测实验，实验结果如图2.9所示，该实验结果是使用上文所述左右眼分类,在实验人员面

部存在左右倾斜（小于15 度）和正常情况下的眼睛检测结果。

图 3.9 眼睛检测结果图

Fig 3.9 Eye detection results

大量实验表明，由于本文采取针对左右眼睛分别训练各自分类器的方法。并在检测

时对一张红外人脸图像同时检测左右眼睛。该方法在提高眼睛检测率的同时还能允许驾

驶人员面部有上下或左右存在15 度左右的倾斜。表3.1是在实验室和行车两种环境对眼

睛检测结果的统计情况分析。

表 3.1 眼睛检测统计分析结果

Tab 3.1 Eye test statistical analysis results

视频源

图像帧 正确检测帧 检测失败帧 错检帧 正确率

实验室

环境

行车环境

525

525

498

487

27

31

5

6

94.9%

92.8%

18基于多特征信息的疲劳驾驶检测系统研究

表3.1的结果表明，本文所提出的针对左右眼睛分别训练分类器的方法能有效的提高

眼睛检测的准确率，能适应行车环境下眼睛检测的需求。但同时也存在检测失效的情况。

经过分析导致检测失效的主要因数有：

（1）车辆颠簸或驾驶员自身引起的头部运动幅度过大

在实际驾车时，道路上有减速带或者有坑洼地段以及驾驶员要左右观察交通情况等

因数都会导致诸如眼睛区域出镜或面部倾斜角过大等问题。本文训练的分类器虽然能适

应15 度左右的面部倾斜，但当倾斜角度超过15 度时就会导致检测失效。

（2）驾驶舱背景图像干扰

在实验室或车内环境中，当背景图像出现符合人眼特征的目标时，该算法会把该错

误目标误检为眼睛。在室内如墙上或书上的黑色字体等都是误检的目标，在车内主要是

后配的乘车人员的眼睛会被误检。这些情况的存在目前本文提出的方法还不能很好的解

决。

（3）夜间行车时来自对面车强灯光的影响

在实际夜间驾车时，对面来车的灯光照在人脸上，会导致采集图像成全白色，这时

在采集的图像中失去眼睛目标导致本文算法检测不到眼睛。这情况本文才采取的主动红

外成像技术能在采集图像时过滤掉一些非红外灯光，但是当对面来车灯光有较强的红外

成份时该系统将失效，这也是要加强研究和改进的地方。

3.4.2 嘴巴检测实验与分析

在ADABOOST算法基础上。嘴巴的检测与眼睛的检测有所不同，嘴巴的检测在本文中

不是直接检测嘴巴，而是通过检测鼻子来计算出嘴巴的位置，这样能提高嘴巴检测的效

率。本文在实验时分别针对直接检测嘴巴和通过先检测鼻子在计算嘴巴的方法做对比实

验。实验结果如表3.2所示：

表3.2 不同方法检测嘴巴实验对比

方法

直接检测嘴巴

间接检测嘴巴

Tab 3.2 The comparison of different mouth detection methods
错检针

检测失败帧

正确检测帧

图像帧

500

500

313

497

134

3

53

0

正确率

62.6%

99.4%

从表3.2的结果可以看出采用检测鼻子来计算嘴巴的方法能有效的提高检测效率。

并且检测失败的情况很少。在表中检测失败的情况主要是由于驾驶人员的面部图像区域

19西华大学硕士学位论文

不包含鼻子（偏头角度过大）。当嘴巴超出图像区域时虽然能检测出鼻子，但是计算的

嘴巴结果不正确，不能作为正确检测结果输出。本文方法的检测结果例图如图2.10所示。

图 3.10 嘴巴检测结果图

Fig 3.10 Mouth test result figure

从图3.10是嘴巴从闭到开的全过程。从这个检测结果可以看出，本文提出的检测嘴

巴的方法能较准确的检测出嘴巴。接下来的工作就是检测嘴巴的疲劳特征。

3.5 本章小结

本章从驾驶人员面部图像和道路图像采集入手，通过主动红外成像技术有效地解决

了普通摄像头不能适应夜晚无自然光照的问题，并能保证采集的白天和黑夜驾驶人员面

部图像的质量。此外针对驾车环境颠簸等因数的存在，使得驾驶人员面部倾斜，导致普

通的已有的眼睛检测分类器不能有效检出眼睛的问题，在本章提出分别采用左右眼睛分

类器来检测眼睛的方法有效的解决了此问题。另外从本章的实验结构来看，虽然诸如上

述提到的问题得以解决，但在面部倾斜角过大和环境红外太强导致的眼睛检测失败等问

题还有待解决。

20基于多特征信息的疲劳驾驶检测系统研究

4 关键疲劳特征计算

在第 3 章通过在摄像头硬件设备上的改进，使用主动红外成像技术能稳定的在白天

和黑夜采集驾驶员面部图像，并通过具有较好鲁棒性的 ADABOOST 算法，在红外人脸

图像中较为精确的定位到了眼睛及嘴巴区域，在此基础上提取出了有效的眼睛及嘴巴图

像。在这章使用一些已有的算法来计算眼睛和嘴巴的疲劳特征，即是眼睛的开闭特征和

嘴巴打哈欠的特征，在疲劳分析中这两个特征是驾驶员是否疲劳的最为直接的特征。所

以本文先计算眼睛及嘴巴的开闭特征，之后再做眼睛和哈欠的疲劳分析。

本文针对眼睛开闭检测问题，使用对光照具有较强鲁棒性的纹理分析检测方法来检

测眼睛的开闭[24]。该方法选择有光照鲁棒性和旋转不变性的纹理检测算子即局部二值模

式 LBP（Local Binary Patterns）[25-27]来提取眼睛区的纹理，并在此基础上提取眼睛区域

的统计特征，最后运用支持向量机 SVM（Support Vector Machine）[28]来判断眼睛开闭

状态。并且由于 LBP 算子计算简单，这样使得该算法具有较好的实时性。该算法主要

分为眼睛区域精确提取、眼睛部位特征提取和特征分类三个环节。提取眼睛区域后，计

算其 LBP 纹理描述，然后以 LBP 描述的统计特征作为眼睛区域的特征向量，最后使用

SVM 对特征向量分类。该算法的具体的流程图如图 4.1。

图 4.1 眼睛开闭检测算法流程图

Fig 4.1 Eyes open and close detection algorithm flow chart

为了提高眼睛区域纹理特征在后续描述向量中的影响，本节在也有的眼睛图片的基

础上研究出一种自适应的眼眉剪除算法，相对于根据眼眉在图像中的位置剪除眼眉的方

21西华大学硕士学位论文

法，本文的算法能更准确的定位眼睛的位置同时保证提取眼睛的完整性。初步提取的眼

睛图片如图 4.2 所示，

图4.2 初步提取包含眼眉的眼睛图片

Fig 4.2 Initial extraction eyes pictures contained the eyebrows

通过观察与分析初步定位的眼睛图片以及结合人眼的生物学特征可以得出，无论是

睁眼或是闭眼在眼睛与眼眉之间存在一个在灰度上有明显变化的过度区域（特殊情况除

外），在此基础上，本文提出通过对投影曲线求极值的方法来自适应的精确提取眼睛区

域，该算法的具体过程是，首先对初步提取的包含眼眉的图像做 Y 方向的投影计算，其

公式如公式(4.1)所示，

Y j
( )



M



i

j
( , )
I i

，
j




1,

N



(4.1)

在公式(4.1)中 ( , )

I i

j 是在图像中 i 行和 j 列所对应的像素点灰度值，其中的 M 和 N

分别是图像宽和高。

在运用公式(4.1)做投影后所对应的曲线如图 4.3 投影曲线所示。由于投影计算只是

简单的对每行像素的累加，所以投影曲线是非平滑曲线。对于非平滑曲线求极值具有一

定的随机性，受噪声点的影响太大。所以本文对初步求得的投影曲线做一维高斯平滑处

理以消除噪声点的影响。处理结果如图 4.3 平滑曲线所示，在平滑曲线的基础上采用从
区间中点向两边收索的策略来计算局部极大值 maxy 以及取得局部极大值 maxy 时的横坐
标 j 。所取得的 j 即为眼眉和眼睛之间的过度区域中最能切分这两个目标的横坐标。其

计算公式如公式(4.2)，按照公式(4.2)切分初步定位的眼睛区域图像以剪切眉毛区域，

i
得到精确的眼睛图像 (
ROI

I



2,

j

  ，整个处理过程如图 4.3 所示。

)

j

I

ROI

(

i



2,

j

)
j
  

( , )
j
I i


i
M
2,3...


  
j
j
j



  

2
N

(4.2)

22基于多特征信息的疲劳驾驶检测系统研究

图4.3 投影处理过程中的图片和曲线

Fig 4.3 The images and curves during projection process

从图 4.3 的结果得出本文算法能精确地去裁剪眉毛区域和一部份鼻梁区域，有效的

排除这两部分区域对后续提取的纹理特征的影响，使得提取的纹理特征能充分的描述眼

睛。

针对嘴巴开度检测问题，由于嘴巴在闭合和张开时，嘴巴部分的灰度变化很大，通

过简单的二值化处理即能准确的定位出张开的嘴巴。但是光照强度在每帧图像中有所不

同等因数的存在，使得该二值化阈值的确定存在难度，在本文中主要研究该阈值的自适

应计算方法，在本文的方法中，首先从嘴巴的纹理特征出发初步定位出属于嘴巴的像素

在整个嘴巴图像中的位置，在通过该位置特征来分割出嘴巴和皮肤图像，最后计算分割

后的皮肤图像的灰度直方图来获得其灰度的期望，并把该期望作为二值化阈值。算法流

程如图 4.4 所示。

图 4.4 嘴巴开度检测流程图

Fig 4.4 Mouth opening detection flow chart

23西华大学硕士学位论文

4.1 LBP 理论

局部二值模式（Local Binary Pattern, LBP）是一种纹理分析算子，它能快捷且有效

的分析图像的局部纹理信息[25]。所谓的局部是指某个像素点和其邻近的其他像素点组成

的邻域，LBP纹理分析即是在该邻域内做计算。完整的图像是由这样的一个一个细小的

邻域组成，对每个细小的局部纹理做分析，正好组成整个图像的纹理特征信息。LBP纹

理分析算子使得对整幅图像的纹理纹理分析变得简单可行，并且能通过简单的计算获得

较好的纹理分析结果。而LBP做纹理分析依赖于所取局部的大小，一般方法是先确定一

个局部的中心像素，在根据中心像素的位置取其邻近像素构成一个领域即局部，在具体

的计算过程中，常用的邻域大小有4邻域、8邻域和16邻域等，做纹理分析时对邻域大小

的选择尤为重要，具体分析时邻域的大小不是越大越好也不是越小越好，要根据提取的

纹理类型和应用的场景来确定邻域的大小。但一般情况是小邻域能更好的描述图像中的

细小的纹理对粗糙的纹理不敏感，而大邻域则刚好相反。但无论如何选择合适的邻域大

小有助于感兴趣纹理特征的提取，能为后续的纹理分析提供可靠保障。

本文选择常用的传统的8邻域作为例子，详细介绍LBP算子做纹理分析的具体过程。

首先8邻域结构如图4.5所示；

图4.5 8邻域结构图

Fig 4.5 8 Neighborhood structure

在图4.5中领域中心像素是空白的像素。而其邻域内的8个黑色的像素即构成中心像

素的8邻域结构。8邻域大小的LBP算子做纹理分析的计算过程即是用图4.6的结构在整个

图像中扫描计算的结果。其具体过程如图4.6所示：

4

5

4

6

3

4

5

5

7
(a)

0

1

0

1

0

0

1

1
(b)

4

8

16

1

2

128

64

32
(c)

1

2

0

0 43 8
32
0
(d)

0

图4.6 8邻域LBP计算过程示意图

Fig 4.6 Neighborhood LBP calculation process diagram

24基于多特征信息的疲劳驾驶检测系统研究

图4.6（a）是在整个图像中取出的8邻域的局部像素，其中的值表示其对应的像素值，

并把每一个像素值和其中心像素值做减法，得到的数大于等于“0”则该领域像素值计

算的结果为“1”。否则计算的结果为“0”。这样对邻域内的8个像素分别作这样的计

算得到如图4.6（b）所示的一个矩阵。在LBP的理论中对8邻域的计算特征矩阵如图4.6

（c）所示，从左上角开始每个位置的值都是“2”的方幂，具体值的大小与该像素在领

域中的位置有关。传统的LBP规定从左上角开始顺时针计算“2”的方幂得到特征矩阵。

再把先前计算得到的矩阵（b）和特征矩阵（c）按像素所在位置做与运算。其结果如图

4.6（d），在图（d）中只保留在图（b）中对应像素位置为“1”的点的值。最后把矩阵

（d）8领域的值求和即得到该8领域的LBP特征值，在图（d）中LBP特征值是“43”。

上述过程即是单个8邻域LBP纹理特征的计算过程，对整幅图像重复以上过程可以求出

全图的LBP纹理特征矩阵。传统的LBP纹理算子能检测出图像中存在的所有纹理，但它

缺乏针对某些感兴趣纹理单独检测的能力。所以Guo, Z和Zhang, L在传统LBP的基础上

提出了完全二值模式CLBP（Completed Local Binary Pattern）[29]，该文在传统的LBP纹
理算子中加入了滤波的阈值T ，使得可以针对性的检出一部分感兴趣的纹理信息来生成
特征矩阵。设中心像素为 cg ，它的所有的 p 个邻点设为 pg , 运用公式（4.3）来二值化
像素点纹理单元。

s x
( )



 


1,
0,

x T

x T


（4.3）

其中

x



g

c



g

p

, (

p



0...

p



1)

像素点的 CLBP 特征值计算公式如（4.4）。

CLBP

_M



P R
,

p

1



(g
S

c

p



0

p

g )2
p

（4.4）

其中不同 (

)P R 取值对应的纹理单元如图 4.7 所示：

,

25西华大学硕士学位论文

图 4.7 不同的 ( ,

)P R 取值对应的纹理单元

Fig 4.7 Different values corresponding to texture units

在纹理计算过程中想要获得感兴趣的纹理特征。阈值T 的选取很重要。选择一个合

适的阈值对精确提取眼部纹理至关重要。在本文的实际应用中，由于不同的人在眼部皮

肤颜色和眼睛颜色上存在差异，同时在行车过程中环境光照的变化使得每张图片的亮暗

程度也不尽相同，固定阈值来做眼部纹理特征的提取虽然简单，但是固定阈值很难确定，

且不能适应所有的光照条件以及皮肤颜色。针对这一情况，为了提高算法的鲁棒性，本

文根据眼部图像在灰度分布上的特点，提出一种自适应计算阈值T 的方法。在此基础上

CLBP M 算子提取眼部图像的局部纹理信息并最终生成描述眼部特征的特征向

_

P R
,

采用

量。

4.2 计算眼睛开闭特征

眼睛的疲劳特征即是眼睛的开闭特征，在连续的视频帧中，检测每帧图像中眼睛的

开闭，在时间域上就能计算出在一段时间内闭眼的时长。根据该时长可以估计出驾驶人

员所处于的状态。这个状态包括，正常驾驶状态、精神不振状态和疲劳驾驶状态。

4.2.1 计算纹理特征滤波阈值

为了克服肤色变化和光照变化带来的影响，并使得纹理算子能精确提取眼睛区域

纹理和增强算法的鲁棒性，那么有效自适应的确定

键。

CLBP M 纹理算子中的阈值T 是关

_

P R
,

首先要精确提取眼睛区域的纹理信息，相对而言就是要屏蔽掉皮肤表面的纹理信

息。根据

CLBP M 纹理分析原理可知，屏蔽皮肤表面纹理就是在作特征计算时让属于
皮肤的纹理单元特征值的计算结果均为“0”，但在眼睛图片中，某个像素是否属于皮

P R
,

_

肤的像素很难确定，但是通过原始的眼睛图像可以大概求出皮肤像素所在灰度的一个分

部范围。具体过程如下。图 4.8 为一幅眼睛区域图像和相对应的直方图，从（a）和（b）

可以看出图中大部分区域为皮肤区域并且总体灰度值偏大，那么可以假设直方图（b）

26基于多特征信息的疲劳驾驶检测系统研究

中在分割线 r 左边[0,x]的灰度分布主要为眼睛部分的灰度，那么对图像增强使得灰度分

布集中于[x,255]之间，那么整幅图像将接近于人脸皮肤图像，这样即可以大概求出皮肤

灰度所在的范围。然后对增强后的图像求其主要像素灰度所在的区间，那么这个区间长

度即是

CLBP M 纹理算子中的阈值T 。

_

P R
,

（a）眼睛区域图

（b）对应的直方图

图 4.8 眼睛区域图和与其对应的直方图

(a) Eye region image

(b) Corresponding histogram

Fig 4.8 Eye area diagram and corresponding histogram

经过以上论述，自适应求阈值T 的算法主要分为求原图灰度分布的期望、确定增强

函数参数、积分增强后图像的直方图得到阈值T 三个部分。其中求原图灰度分布的期望

是为了确定眼睛灰度和皮肤灰度的分界线。并根据求取的期望确定增强函数的参数，对

原图像增强，增强后的图像接近于皮肤图像。具体的公式和过程如下所示：设 ( ,
图像灰度级为


1L  。

0,

ROI

I

x y

)

a）计算 ( ,

x y 灰度级概率密度函数如公式（4.5）：

)

I

ROI

P r
(
k

)



n
k
M N


（4.5）

其中 kr 是第 k 级灰度； kn 是 ( ,

x y 中灰度级为 kr 的像素个数； M 和 N 分别是

ROI

I

)

图像 ( ,
I

x y 的宽和高。

)

ROI
b）计算灰度分布的期望如公式（4.6）：

E

(r)

L

1


 

i



0

r P r
(
k
k

)

（4.6）

根据求得的期望 (

)kE r 来估计 ( ,

ROI

I

x y 图像中某个像素点的灰度是在皮肤灰度范

)

围还是在眼睛的灰度范围，从而定义分段变换函数如公式（4.7）对图像进行增强。

c）基于分段变换函数如公式（4.7）的图像增强：

c

log

s


 


r E r
( )

)

(1



r

,


,
r other

（4.7）

27西华大学硕士学位论文

其中 r 为输入灰度级；s 为输出灰度级；系数 c 由 ( )E r 决定。该函数能把 ( ,

x y

I

ROI

)

中原本属于眼睛的灰度范围的灰度变换到皮肤灰度范围的灰度。增强前后图片及其直方

图如图 4.9 所示。

图 4.9 增强前后图片及直方图对比图

Fig 4.9 Image and histogram contrast diagram before and after enhancement

对增强后的 ( ,

x y 求得图像的灰度直方图如图 4.9 所示，从增强后的直方图可以

I

)

ROI

看出增强后的图片的灰度主要集中于
即为眼部图像中肤色分布范围，本文将该区间长度作为提取



,x x 这一小段区间，这段区间所包含的灰度范围
1

2

CLBP M 纹理特征的阈值

_

P R
,

T 。

估算区间长度 1
x 的具体步骤如下：
x
设在增强后的直方图中当灰度值取 kr 时得到最大值 (

2

)kg r ，那么从 kr 开始向左右两

边搜索，如公式（4.8）所示。

x
1



i

,

x
2



j

,






r
k i


g

if



if g r
k



j






ACC



ACC

（4.8）

j

i

k

其中

1,

1,

k
 

k
 

2,...1;


区间的精度。搜索结束得到的区间长度 1
x
给出了使用固定阈值
取结果。

18

T 



k

n
2,... ;

ACC 为结束条件。ACC 控制着搜索的次数和

x 即为
2

CLBP M 的自适应阈值T 。如图 4.10

_

P R
,

和自适应阈值对不同光照图片的

CLBP M 纹理特征提

_

P R
,

28基于多特征信息的疲劳驾驶检测系统研究

（a）

（b）固定阈值

T 

18

（b）Fixed threshold

T 

18



T 

11



T 

16



T 

11



9T 

（c）

图 4.10 固定阈值和自适应阈值对比图

Fig 4.10 Fixed threshold and adaptive threshold comparison chart

在图 4.10 中（a）图像序列为原始光照不均匀眼睛图像，（b）图像序列为固定阈值

CLBP M 纹理检测的结果，（c）图像序列为自适应阈值的

CLBP M 处纹理
18T  时

检测结果。由实验结果可以得出，对明暗变化的图片，自适应阈值的方法能较好的提取

P R
,

P R
,

_

_

出眼睛部分的纹理，但固定阈值的方法在对较亮和暗的图像时提取的效果不是很好，甚

至检测不到纹理信息。运用自适应阈值的

CLBP M 纹理检测算子可稳定提取眼部区域

_

P R
,

的纹理特征，能较好的克服因光照等因素带来的检测不到纹理的问题。

该节通过对眼睛图片中皮肤部分的灰度值做分析，按照公式（4.8）对眼睛图像作增

强，使得增强后的图像整体的灰度分布接近于皮肤灰度，可以认为增强后的图像是一幅

皮肤图像，要在做

CLBP M 纹理检测时过滤掉皮肤的纹理，那么可能属于皮肤的像素
点的差值要小于所求阈值T 。那么也就是要求阈值T 能包含皮肤的灰度分布范围。对于

P R
,

_

增强后的眼睛图片来讲，计算该图像的灰度直方图能求出图中灰度分布范围。而这个范

围正是滤波阈值T 的值。该阈值的确定使得自适应的计算眼睛的纹理特征成为可能，并

提高了本算法对光照的鲁棒性。

4.2.2 计算特征矩阵描述向量

上面基于自适应阈值提取的

CLBP M 纹理特征矩阵依然是一幅与原始精确眼部

_

P R
,

区域尺寸一致的图像，为了便于后续纹理分析和眼睛开闭检测。通常需要对原始的纹理

特征矩阵作统计分析，并把统计分析的结果作为描述向量来完成纹理分析。考虑到睁眼

29西华大学硕士学位论文

和闭眼时眼睛有不同的纹理分布，如图 4.11 所示，其中图（a）和图（d）分别是原始睁

眼和闭眼图片，图（b）和图（e）是用

CLBP M 作纹理检测所构成的纹理特征矩阵，
图（c）和图（d）是对纹理特征矩阵二值化结果。从二值化后的图（c）和图（d）可以

P R
,

_

看出，睁眼时眼部区域纹理分布的区域广而且纹理像素占总像素比重较大，而闭眼时纹

理分布的区域狭窄而且纹理像素占总像素比重较小。本文对

CLBP M 特征图像先做二
值化，见图 4.11 的（c）和（d）所示，然后统计纹理像素点在特征矩阵中的空间分布作

P R
,

_

为判断眼睛开闭的特征矢量。

（a） （b） （c）

（d） （e） （d）

图 4.11 自适应阈值

CLBP M 纹理特征图像及其二值化结果

_

P R
,

Fig 4.11 The adaptive threshold image texture feature and the binary results

首先对二值化图片分块，以方便后续算法计算纹理特征在特征矩阵中的离散化程

度。设二值化图片大小为 M N ，块大小为

block 



2, 4, 6,8

，对每个块统计白点（即眼

部纹理特征点，该点携带眼睛的轮廓信息）出现的频率

,


F i

,p i

j

i



1, 2,...

 
,

j ，如公式（4.9）所示：

M block j



/

,

1, 2,...

N block

/



，并对其归一化，得到归一化概率分布


p i

,

j





j



,


F i
R

（4.9）

其中 R 是纹理特征矩阵中纹理特征点个数。
最后计算 

j 的二阶矩、熵、边际分布二阶距等统计特征作为最终的特征向量。
,p i
具体计算公式如下：

二阶矩（ASM）

k

ASM

m

k

n

 

i

j




p i

,

j



2

（4.10）

30基于多特征信息的疲劳驾驶检测系统研究



N block

/

。当纹理特征点分布比较散乱时 ASM 的值会很小，

n

其中

k M block k
/
m



;

反之则会很大。该特征的物理意义在于，它能描述纹理特征值在特征矩阵中分布的离散

程度。

熵 ENT

k

ENT

m

k

n

 

i

j


p i

,

j



log


p i

,
j

（4.11）

其中

k M block k
/
m



;



N block

/

。当纹理特征点个数较多时 ENT 的值会比较小，

n

反之则会很大。该特征的物理意义在于，它能反应出在纹理特征矩阵中纹理特征数的数

量及其分布区域。

边际分布二阶矩 MDASM

k

 
p j




p i

,

j



m



i



0

MDASM



k

n



j

2

 
p j

（4.12）

其中  

p j 是 
,p i

k M block k
/
m
点在 Y 轴方向分布比较散乱时 MDASM 的值较小反之则很大。边际分布二阶矩主要表


j 的一个边际分布；

。当在纹理特征

N block





;

/

n

示纹理特征在 Y 方向上的离散化程度。

ASM，ENT 和 MDASM 这三种统计特征能准确描述眼睛区域纹理特征的分布特性，

与简单的使用特征直方图所产生的描述向量有所不同，主要表现在，特征直方图所生产

的描述向量只包含某特征在数量上的统计特性信息；而本文所生产的特征向量既包含某

特征在数量上的统计特性信息，同时把某特征在特征矩阵中分布位置信息也包含在描述

向量中。并且本文的描述向量较特征直方图而言，在向量的维度上大大较少，这样在训

练和分类时能有效的提高分类器的分类精度和计算分类的时间效率。并且这样的描述向

量更加适合描述眼睛纹理的分布特性，同时配合不同的 block 块大小能更好的生成具有

高区分性的特征向量。

4.2.3 支持向量机做开闭检测

本文第二章中详细介绍本文在人脸图像中检测眼睛图片的方法，并把检测结果即左

眼或右眼眼睛图片作为本章的输入数据。所以本章的输入数据中只有眼睛图片，本文选

择的 SVM 训练样本中包含有左右眼睛图片各数张。这些样本取自不同的人，并且包含
有不同红外光照强度的眼睛图片，同时眼睛的左右倾斜角度在15 范围内。

31西华大学硕士学位论文

在众多机器学习方法中，支持向量机（SVM）是一种普遍适用且易于训练的机器学

习方法[43] ，其基本思想是：由前端输入低维度的样本特征描述向量，在支持向量机内

部在把输入的向量转换到一个高维度的特征空间中，并通过最优化计算在此空间中构造

最优分类平面。通过支持向量机理论证明，只要能选择恰当的从低维度到高维度的映射

函数，会使得一般情况下在低维度空间线性不可分问题，转化到相应的高维度特征空间

变为线性可分问题。为了解决增维后可能带来的维度灾难问题，支持向量机巧妙的引入

核函数（Kernel Function）。部分训练样本如图 4.12 所示。

图 4.12 部分训练样本图

Fig 4.12 Part of the training sample diagram

本文把训练样本中的开眼和闭眼互相作为正负样本来训练 SVM，因为开眼和闭眼

在特征上具有较高的区分度。在此样本上训练的分类器在分类时具有较好的鲁棒性。

样本选择好以后，训练 SVM 的关键因素在于确定核函数及其参数。本文选择普遍

使用的 LibSVM[45]开源库来对开闭眼睛样本进行训练并实现分类，在开始训练前，本文

为了排除所生成的三维向量中可能出现的大数严重影响训练结果的情况，首先对所有的

特征向量包括训练样本和检测样本做归一化处理，减少在训练时大数吃小数的情况。在

核函数的选择方面，由于本文中生成的特征向量是三维的比较简单，所以本文选择的核

函数是 LINEAR 线性核函数，线性核函数不会将本文中描述向量所在的三维空间映射到

另一个高维空间去，而是在特征向量所在的三维空间寻找最优的分类平面，能加快训练

的速度。LINEAR 中的未知参数惩罚因子 C 和在最初训练时并不知道，只能凭经验设

定。为了寻找参数 C 和在本文环境下的最优值，本文使用交叉验证法在训练中寻找适

合本文环境的最优 C 和值[28]。

32基于多特征信息的疲劳驾驶检测系统研究

4.3 计算嘴巴开度特征

在驾车过程中，由于驾驶人员精神高度集中，并出于自身安全考虑驾驶人员一般不

会和车乘人员交谈。所以在基础上，本文可以假设当驾驶人员嘴巴张开时很大概率是驾

驶人员在打哈欠。但也有例外的情况，如驾驶人员在和乘客交谈或者在唱歌时嘴巴也会

张开。但是和打哈欠不同的是，这时嘴巴的开度不会太大，因为正常讲话时嘴巴的开度

没有打哈欠时大，同时当人疲劳打哈欠时往往都伴有闭眼的发生。所以在通过嘴巴的开

度特征来分析疲劳时，要综合考虑以上因数，以便准确的检测到哈欠，而不是误检。在

此分析的基础上，具体的哈欠检测如下文所示。

4.3.1 计算二值化阈值

本文通过详细地分析第二章采集到的嘴巴图像，发现无论嘴巴时张开还是闭合，嘴

巴区域的灰度和其周边的皮肤的灰度有差别。这个差别主要是在嘴巴区域的灰度与皮肤

的灰度相比较要深一些。所以本文为了提高计算的时间效率考虑找个合适的阈值对嘴巴

图像做二值化处理，已达到开度检测的目的。但是针对不同光照强度的嘴巴图像，要确

定此阈值并不是一件容易的事。在嘴巴图像中，虽然直接精确定位嘴唇是比较繁琐和耗

时的工作，但是粗略的在嘴巴图像中找到那些像素是嘴唇像素却比较简单。设原始的嘴

巴图像为 ( ,

I x y ，计算该阈值的过程和公式如下：

)

1)使用本章 4.1 节所介绍的 LBP 算子来计算图像 ( ,

I x y 的纹理特征矩阵，并把该特

)

征矩阵表示为

LBP M x y ,计算
( ,

_

)

LBP M x y 的 LBP 算子的主要参数是：纹理单元大

( ,

_

)

小选择基本的 8 邻域纹理单元，其中的阈值T 由 4.2.1 的方法计算。计算出的纹理特征

矩阵转换成图像如图 4.13 所示。

图 4.13 嘴巴 LBP 特征图

Fig 4.13 Mouth LBP feature maps

图 4.13 中的图（a）到图（c）分别是从闭嘴到张度最大时的 LBP 计算结果。在图

4.13 中可以清晰地看出嘴唇的大概轮廓。由此便能初步定位到属于嘴巴的像素。因为在

特征矩阵中，不属于嘴巴的区域特征值均为零。

33西华大学硕士学位论文

2）根据

LBP M x y 特征图来分割图像。设分割后的图像为 _

skin RoI x y ，具体
( ,

( ,

_

)

)

的计算公式是：

skin RoI x y

( ,

_

)


 


I x y
( ,

(

if LBP M x y
),   
_
0,                      other

( ,

) 0)


（4.13）

按照公式（4.13）计算得出的图像是一幅只包含皮肤像素的图像。对此图像计算其

直方图便可得到皮肤在原图中的一个灰度分布。

3）计算 _

skin RoI x y 的灰度直方图，用 (

( ,

)

)kh r 来表示，其中 kr 是第 k 级灰度的亮度。

在此基础上定义灰度级概率模型为：

p r
(
k

)



h r
)
(
k
Count

（4.14）

在公式（4.14）中，Count 表示在图像 _

在第二步分割时由满足公式（4.14）的点计数所得。 (

skin RoI x y 中的皮肤点的个数，这个参数
( ,
)kp r 表示皮肤灰度级的概率分布。

)

4）计算皮肤灰度级 (

)kp r 的期望，以确定二值化阈值，公式如下：

E r
( )

L

1


 

k



0

r P r
(
k
k

)

（4.15）

在公式（4.15）中计算所得是 _

skin RoI x y 直方图的期望，直观上分析，也就是

( ,

)

皮肤灰度的均值，用来作为二值化的阈值，意义在于：这个值能代表图像中皮肤灰度所

在范围，大于或等于此值的都是皮肤像素，而小于此值的是嘴巴像素。

按照上述四个步骤求得的二值化后的图像如图 4.14 所示：

图 4.14 嘴巴原图及二值化图对比

Fig 4.14 Mouth picture and binary figure compares

从图 4.14 的结果可以看出本文采取的方法在做二值化时，能有效的区分开嘴巴和其

周围的皮肤区域。并且能看到在闭嘴到张嘴的过程中对嘴巴的检测效果很好。

34基于多特征信息的疲劳驾驶检测系统研究

4.3.2 嘴巴开度计算

嘴巴开度是指嘴巴的张开程度，在计算时考虑使用上下嘴唇之间的距离来作为衡量

开度的标准。用嘴巴的特征的疲劳分析，也就是分析哈欠，特殊情况除外，打哈欠一般

会伴随这嘴巴张度的变化，而在非驾驶环境时，当人们打哈欠时往往会用手遮挡嘴部，

但是在驾车这种特殊的环境下，驾驶人员的双手一般会去完成驾车等相关操作，所以可

以不考虑有手遮挡嘴巴的情况。那么在本文中做哈欠分析，也就是在于完成嘴巴开度的

测量。首先开度测量的示意图如图 4.15 所示。

wH

图 4.15 开度测量示意图

Fig 4.15 Opening measurement schematic diagram

在图 4.15 中，通过嘴唇来定义的开度是一个准确的开度，但在本文实验中考虑到算

法的鲁棒性和时间效率问题，并不能精确的计算出嘴唇的位置，但是本文可以在源图像

中找出嘴巴的精确位置，所以把嘴巴开度的测量转而测量嘴巴区域的高度，如图 4.15
中的 wH 。在数学的定义中 wH 同样具有开度的特征，即是在嘴巴张开时 wH 的值逐渐增
大，当嘴巴闭合时 wH 值逐渐减少直至嘴巴完全闭上，这是 wH 值不发生变化。所以可以
用 wH 来代替开度值做哈欠分析。

在计算时设二值化后的图像为 ( ,

)

bI x y ，计算 wH 公式如下：
y
y
,

i
i
y

if I x
(
b

if I x
(
b


,    

,   

0)

0)







y

)

)

(

(

,

j

j

y
u
y

d







H

w



y
u



y

d

（4.16）

在公式（4.16）中的 x 是指在 x 的行像素上的连续  个像素。公式的意义在于当在 x

的行像素上首次出现连续  个像素不为零时，这个行像素值就是嘴巴的边界。

4.4 本章小结

本章从对红外眼睛图像的纹理分析入手提出一种新颖眼睛开闭检测方法。该算法采

用

CLBP M 纹理检测算子精确提取眼部图像纹理特征。为了增强

_

P R
,

CLBP M 算子对光

_

P R
,

照和皮肤颜色差异的鲁棒性，提出一种根据眼部图像的肤色分布自适应确定纹理算子

CLBP M 中阈值T 的方法。该方法在有效增强算子对光照和肤色鲁棒性的同时能精确

_

P R
,

35西华大学硕士学位论文

的检测出眼睛部分纹理。在纹理分析部分，考虑到睁眼和闭眼时眼睛纹理在纹理特征矩

阵中有不同的分布，为了便于计算纹理特征，本文对纹理特征矩阵先做二值化处理突出

眼睛部分的纹理。在对二值化后的特征矩阵作分块处理来提高统计计算的速度。并利用

统计学中的二阶矩、熵和边际分布二阶矩来构建纹理特征矩阵的描述向量，最后使用大

量的睁眼和闭眼的眼睛样本训练 SVM 得到眼睛开闭的分类器。本章算法在红外光和自

然光两种数据集上的大量实验表明，提出的算法有较高的检测精度和优良的时间效率，

完全能满足实时应用的要求。同时在本章也完成嘴巴开度的检测。提出的自适应阈值算

法，能有效的完成嘴巴图像的二值化，并准确的求出嘴巴的开度。

36基于多特征信息的疲劳驾驶检测系统研究

5 车道偏离特征计算

根据 GB/T 26773-2011 智能运输系统及车道偏离报警系统的性能要求与检测方法中

对报警临界线及其设置区域的相关要求的示意图如下，在后文中所检测的道路车道线即

图中 1 所示的车道边界，由于研究方法不同和研究能力有限，其他标志线仅供参考，在

后文研究中没有涉及。

1——车道边界（由可见车道标识确定，在无可见车道标识的情况下由其他提示性的可见道路特征或
者由其他方式如 GPS、磁道钉等确定的车道边界线）；
2——报警临界线设置区域（最早报警线与最迟报警线之间的区域，报警临界线设置于该区域内）；
3——最早报警线（报警临界线变化范围的最内侧界线）；
4——最迟报警线（报警临界线变化范围的最外侧界线）；
5——非报警区域（两条最早报警线之间的区域）；
6——报警临界线（发出报警时车辆在道路上的位置，对应于系统内部设置的报警触发点）。

图 5.1 报警临界线及其设置区域的概念示意图

Fig 5.1 The warning critical line and concept schematic diagram of set area

道路车道线检测技术是提高汽车主动安全性能和减少公路交通事故的一个关键

技术。具体的诸如车道偏离预警系统以及车道保持系统等都是以该技术作为基础。这些

系统是在此基础上增加预警或控制模块来构成完整的系统。目前由于使用硬件的方法来

做车道线的检测不仅成本较高而且实用面较窄。所以近年来针对道路车道检测技术方法

的研究主要集中在基于机器视觉和模式识别的方法研究上。但是目前的研究成果并不是

放之四海而皆准的方法。针对不同的道路类型和不同的使用环境都有其具体的方法。大

体上，简单的方法，针对复杂的道路结构或者是有大部分车道线被车辆或阴影遮挡时检

测效果不佳；复杂的道路车道线识别检测方法针对弯曲或路面环境较为复杂的道路一般

能有较好的识别结果，但是这些算法中普遍存在的大量复杂的计算使得其实时性不好。

37西华大学硕士学位论文

不能满足高速路车道线识别与检测任务，本文在研究和总结前人提出的方法的基础上，

针对高速公路特殊的分道线结构和路面环境，提出了一种高效且实时性较强的高速路车

道线识别检测方法，算法流程如图 5.2 所示。

图 5.2 车道线检测算法流程图

Fig 5.2 The lane line detection algorithm flow chart

5.1 道路图像特征分析

国家高速公路的建设与一般的城市公路或省道乡道公路有所不同，主要考虑车辆能

在路面高速安全行驶的指标而修建，所以在高速路上小型载客汽车的时速一般在

100km/h 到 120km/h 之间是比较合适的速度。有的汽车可能有更高的时速，这样的高速

度要求高速路车道线检测系统一秒钟能处理多张图片。如按照小型汽车时速为 120km/h

来计算，单位时间内车辆的行驶路程有 33m。采用目前流行的一秒钟能采集 30 帧的图

像采集系统，那么要求车道线检测算法大约在 33ms 内完成车道线的检测才能满足实时

应用的要求。这里可能采取降低帧率的方法，来降低车道线检测时间的要求。但是针对

高速公路车道线检测，以每秒 30 帧的帧率来采集道路图像，可能造成每帧大约有 1m 的

道路图像没有采集到，即在采集的高速路道路图像序列中，每帧道路图像之间大约丢失

了 1m 的道路环境信息。在这 1m 的路程里车辆完全可能行驶切线或发生其他的突发情

况。所以针对高速公路的车道检测算法的研究，主要工作集中于在保证算法实时性的同

时不失车道线检测正确率。由于国家高速公路在建设时有其严格的行业标准[30]，如：

（1）高速公路车道宽度为 3.75m；

（2）高速路车道线的宽度为 0.21m；

38基于多特征信息的疲劳驾驶检测系统研究

（3）对于设计速度为 120km/h 的高速公路，极限的转弯半径为 650m 但是一般在

设计修建时的转弯半径为 1000m；

（4）高速公路上坡和下坡坡度小于 4 度；

（5）高速公路为封闭公路等。

（a）

（b）

图 5.3 高速公路直线车道线与弯道车道线例图
Fig 5.3 The straight lane highway and bend Lane case diagram

在高速公路严格的行业标准和封闭道路行车的保障下，本文针对高速公路车道线的

检测提出新的方法。从大量高速路实验图片和实际驾驶经验总结得出，高速公路行车时

车道线呈现的特点是：按照以上高速公路的建设标准以及高速路在转弯时的转弯半径一

般为 1000m，因此如图 5.3 所示，在图 5.3 中（a）为直线车道线，（b）为弯曲车道线。

在（a）与（b）中无论是直线车道线还是弯曲车道线，在红线分割线下边区域（本文称

之为近视场区域）的车道线都呈现为直线车道线，而在红线分割线上边的区域，离车辆

的位置较远使得图像中车道线的像素个数较少，且车道线快速的集中于消失点，在这种

车道线特征点较少且受环境景物影响较大的情况下提取车道线特征较为复杂且耗时。为

了尽量满足实际的实时性需求，本文在做车道线检测时对红线上边的区域不做车道线检

测。

在提出车道模型前，本文在高速公路修建标准的基础上提出两点假设：

39西华大学硕士学位论文

（1）假设高速公路路面均是水平路面与摄像机光轴的夹角保持不变。此假设基于

高速公路在设计时上坡和下坡的坡度小于 4 度，且在近视场区域道路平面可以不考虑地

球曲率的影响。

（2）假设高速公路车道线在近视场区域呈直线[31-33]。此假设基于高速公路在转弯

时转弯半径大于 650m，一般在 1000m 左右，这样在近视场区域转弯曲率可以忽略不计。

本文针对以上两点假设及高速公路道路特点，提出首先计算道路图像的边缘特征，

并在该特征中找到属于车道线的特征点，最后在使用该特征点计算车道模型中的参数来

求解车道线方程。如何在大量的边缘特征中确定车道线的特征是本节研究的重点之一。

图 5.4 感兴趣区域示意图

Fig 5.4 Sketch map of the interest region

本文采集道路图像的前端系统包括一台普通计算机和一个高清摄像头，高清摄像头

被安装在汽车中央后视镜的前部，距离路面的高度大约等于汽车的高度，并且正好处于

汽车两前轮轴线的中间位置。采集的道路图像如图 5.3 所示，当车辆正常行驶时车道线

在图像平面中出现的区域相对固定，本文根据该先验知识和相机参数在原始道路图像中

设置感兴趣区域，该感兴趣区域是包含当前车道线的最小区域能排除绝大部分环境景物

的影响。其示意图如图 5.4 所示。

在图 5.4 中左右两个分界线以外区域中检测出的边缘不包含车道线的边缘特征，而

车道线的边缘特征包含在感兴趣区域内，感兴趣区域的确定依赖于相机位置等先验知

识。确定感兴趣区域后能有效减少非车道边缘特征的影响，同时减少计算量。确定感兴

趣前后边缘特征提取图如图 5.45 所示，图 5.5（a）是在全图像范围内做车道检测，而（b）

是在感兴趣区域内做边缘检测。

40基于多特征信息的疲劳驾驶检测系统研究

（a） 全图边缘检测

（b） 感兴趣区域边缘检测

图 5.5 感兴趣区域确定前后车道边缘检测图

(a) Full map edge detection (b) The region of interest edge detection

Fig 5.5 The interest region determine the before and after lane edge

从图 5.5 可以看出，感兴趣区域中完全包含当前车道线，并且从两幅图的对比可知

感兴趣区域只是原图中很小的一部分，在感兴趣区域内计算道路的边缘特征不仅能提高

时间效率，同时可以排除其它一些非车道线边缘特征对有效车道线边缘特征的影响。

5.2 基于边缘的车道特征计算

在道路图像中确定合适的感兴趣区域能提高有效边缘特征的检测精度，在上节中按

照摄像机的位置参数和内部参数等先验知识，较好的解决了该区域的位置问题，在本节

中选择合适的边缘检测算子，计算感兴趣区域内道路图像的边缘特征，以及做恰当的边

缘连接成为研究的重点。

在图像处理过程中，边缘存在于灰度变化较为明显的区域，与实际生活中的边缘有

所不同。假设图像是一个有界的连续二元函数 ( ,

f x y ，在函数 ( ,

f x y 中寻找函数值变

)

)

化明显的区域即边缘存在区域。从数学的角度看，边缘会出现在函数 ( ,

f x y 的极值点或

)

间断点处，求函数 ( ,

f x y 的极值点或者是间断点，在数学中常用的方法是求其一阶或者

)

是二阶导数。但是对于离散的图像来说求导往往是作某个邻域内对应像素的差分，所以

推导一种较好的求导差分算子是能否有效计算图像边缘的核心，其中梯度算子就是众多

边缘检测算子中比较实用和典型的一种,如 Roberts算子 、 Prewitt算子 、 Sobel算子 、

Canny算子 等梯度算子都是常用的边缘检测算子[34]。

由 以 上 对 图 像 边 缘 的 论 述 可 知 ， 边缘的强度可以由梯度的大小表示 , 在 该

边缘处灰度变化最快的方向可以由梯度方向指出。在连续的情况下计算函数 ( ,

f x y 的

)

梯度、梯度幅值和梯度方向的方程分别如下：

41西华大学硕士学位论文

梯度：

f
 

[
,
G G
x

y

T
]



[

df df
,
dx dy

T
]

梯度幅值：

f
 

2
[
G G

x

2 1/2
]
y



[(

df
dx

2

)



(

df
dy

2 1/2
) ]

梯度方向角： arctan









G

G

y

x





（5.1）

（5.2）

（5.3）

在计算离散图像的梯度幅值 时 ，如果按照连续的计算公式（5.2）计算，计算

f

量比较大，所以在实际计算时往往将公式（5.2）转化成如下公式（5.4），来计算梯度

幅值。

 

2
f G G
x



2
y



G

x



G

y

（5.4）

在公式（5.4）中用绝对值求和的方式来近似代替平方和并开方的值，该近

似值仍然具有一阶导数的性质，既该值在亮度不变区域中的值仍然为零 ，而该

值与亮度变化区域中的亮度变化程度成比例 。从公式（5.3）和公式（5.4）可以得出计

算梯度幅值 f 和梯度方向角的关键在于怎样计算 xG 和 yG 。对于连续的情况计算函
f x y 的偏导数能方便地得到 xG 和 yG 。但是对于离散的情况计算 xG 和 yG 的算子有
数 ( ,
多种，并且这些算子各有各的优势能应用于不同需求下边缘的计算，下面将重点介绍几

)

种常用的梯度算子，在介绍具体梯度算子前本文先定义一个 3 3 图像邻域如图 5.6 所示：

图 5.6 3 3 的图像邻域

Fig5.5 3 3 image neighber area

42基于多特征信息的疲劳驾驶检测系统研究

表 5.1 常用梯度算子介绍

Tab 5.1 Commonly used gradient operators

Roberts

边缘检

测算子

Prewitt

边缘检

测算子

使用两个 2 2 的差分模板从 x 方向和 y 方向分别计算 xG 和 yG 的值，在

2 2 的区域内使用局部差分的计算方式查找强边缘，能取得较好的边缘定位

精度，但是受到算子本身尺寸的影响，使得该算子对噪声比较敏感，所以

Roberts 边缘检测算子对低噪声且存在陡峭边缘的图像检测效果最好[34]。

使用两个 3 3 的差分模板分别计算 xG 和 yG ，与 Roberts 边缘检测算子

不同的是，Prewitt 边缘检测算子使用的是 x 方向和 y 方向上的差分来查找边

缘且模板尺寸比 Roberts 算子大，对噪声有一定的抑制能力，该算子数字化

地近似一阶导数 xG 和 yG [34]。

Sobel 边

在 Prewitt 边缘检测算子的基础上增加模板中心邻近点对该处边缘检测

缘检测

的贡献。该算子在保证对边缘检测有高效响应的基础上，同时能更好的平滑

算子

噪声的影响[34]。

Canny 算

Canny 算子整合滤波、增强和检测等多个过程，并且该算子对这几个过程做

子

相应的优化，能在噪声抑制和边缘检测之间取得较好的平衡[34]。

（1）Roberts 边缘检测算子的具体计算过程和卷积模板如下：

Roberts 边缘检测算子的计算公式如公式（5.5）所示：

G z


x

G




9
z
8

y





z
5
z

6

（5.5）

由公式（5.5）可以计算出 Roberts 边缘检测算子的卷积模板如图 5.7 所示：

图 5.7 Roberts 边缘检测算子的卷积模板

Fig 5.7 Roberts edge detection operator convolution template

43西华大学硕士学位论文

（2）Prewitt 边缘检测算子的计算过程和卷积模板如下所示：

Prewitt 边缘检测算子的计算公式如（5.6）所示：










z
9

z
8















z

z

z
9

z
3

6

7

x

y

G


G


z
1



z



z
3

2

z
1



z



z

7

4




（5.6）

由公式（5.6）可计算出 Prewitt 边缘检测算子的卷积模板如图 5.8 所示：

图 5.8 Prewitt 边缘检测算子的卷积模板

Fig 5.8 Prewitt edge detection operator convolution template

（3）Sobel 边缘检测算子的计算过程和卷积模板如下所示：

Sobel 边缘检测算子的计算公式 （5.7）所示：








2

z

z
8

z
9

7

x

G


G







y

z
3



2

z

6



z

9









z
1

z
1



2

z



z

3

2



2

z



z

7

4




（5.7）

由公式（5.7）可计算出 Sobel 边缘检测算子的卷积模板如图 5.9 所示：

图 5.9 Sobel 边缘检测算子的卷积模板

Fig 5.9 Sobel edge detection operator convolution template

（4）Canny 边缘检测算子

其基本思想是：首先选择合适的高斯核对待检测的图像做高斯滤波来减少噪声点对

边缘检测的影响；然后使用一阶偏导算子计算图像在每一点的梯度幅值和梯度方向；第

44基于多特征信息的疲劳驾驶检测系统研究

三部是对梯度幅值做非极大值抑制，在梯度幅值矩阵中元素的值越大既是这点的梯度幅

值大，但是不能说明梯度幅值大的点就是边缘点，所以做非极大值抑制既是图像增强的

过程又是抑制噪声的过程； Canny 算子做边缘检测一个重要的过程就是确定双阈值的

大小[34]。

在本文中，为了有效的检测出边缘特征点，本文选择 Canny 算子来计算边缘特征，

对于 Canny 算子中双阈值的选取，本文从大量的实验经验中来确定 Canny 算子的阈值并

取得较好的检测效果。用以上算子做车道线边缘检测的结果如图 5.10 所示，在图 5.10

中，Canny 算子求取的边缘特征中在车道线的线条连接上要不其他三种算子的效果好，

有利于后期精确的检测出车道直线。

图 5.10 各种边缘检测算子检测结果对比图

Fig 5.10 A variety of edge detection operator test results comparison chart

5.3 车道建模与车道识别

在感兴趣区域内提取到有效的车道线边缘特征后，怎样使用这些边缘特征计算车道

线方程是本节将解决的重要问题，本节在 5.1 节的两个假设的基础上，提出本文针对高

速公路做快速车道线检测的车道模型。并在此模型的基础上初探和本模型保持一致的车

道偏离预警模型。

45西华大学硕士学位论文

5.3.1 图像平面中的道路模型

在大量的研究中，多种车道模型被相继提出，如比较简单的分段直线模型、抛物线

模型和主动轮廓模型等，这些模型在车速不高（小于 70km/h）的城市路段的车道线检

测算法中能有较好的检测效果。但对于高速公路车道线的检测，这些模型在计算时间上

并不能满足实时的要求。为了提高高速公路车道线检测的时间效率和精度，本文结合在

近视场区域车道线成直线的假设，提出简单的直线模型来实现高速公路车道线的检测。

本文在世界坐标平面中使用直线模型来表示左右两条车道线。并使用透视变换将车

道线模型变换到图像平面。直线车道模型最早被使用来实现车道线检测，但是由于直线

模型简单且不能拟合车道线存在曲线的情况，所以后来被更为复杂的曲线模型所代替。

但作为直线模型有表示简单且容易计算等优点。在本文的车道线检测中直线模型既能在

近视场区域有效的拟合车道线，同时在时间效率上完全满足实时的要求。该直线模型如

公式（5.8）所示。

x
l
x
r





(
k y
l
(
k y
r







)
vpm b
l
)
vpm b
r



(5.8)

在公式（5.8）中模型 lx 和 rx 分别表示左右车道线，其中 lk 和 rk 表示车道线的斜率，

lb 和 rb 表示车道线的截距， vpm 是近视场区域在图像中的位置。在公式（5.8）中有 5
个参数，这些参数的确定能精确快速的拟合车道线。在本文的假设条件下，在世界坐标

k ，使得模型中的参数由 5 个减少
平面中左右两条车道线是平行的关系，所以参数 l
k
到 4 个。参数 k 、 lb 和 rb 的确定依赖于对车道线特征的提取，而参数 vpm 是在本文实验
的基础之上确定，在本文中 vpm =280（本文中所采用的图像大小为 720 480）。简单的

r

直线车道模型在符合本文对高速公路车道线提出的假设，但是能否精确的拟合车道线还

依赖于精确的车道线特征的提取。

5.3.2 车道模型参数计算

在已经存在的车道线检测方法中，对车道模型参数的估计采用最大后验概率（MAP）

的方法，该方法能较好的解决比较复杂的车道模型参数的估计。但是该方法是建立在有

丰富的先验信息和恰当的似然函数基础上的最优化解决方法，在计算当前样本的概率时

无疑增加计算成本。本文在 5.2 节的基础上结合所建立的直线车道模型，考虑采用曲线

拟合的方式来求解车道模型参数。

目前在诸多曲线拟合方法中，最小二乘法是比较常用且易于实现的方法之一[29]。在

本文中通过 5.2 节的边缘提取算法提取的车道线边缘特征中，仍然存在大量的非正态噪

46基于多特征信息的疲劳驾驶检测系统研究

声。若使用最小二乘法拟合车道模型，拟合结果将受到噪声的影响使得检测效果不佳。

然而基于在不同参数空间求解点—线对偶性的 Hough 变换却成为一种可选的车道模型

求解方法。

Hough 变换由 Paul Hough 在 1962 年首次提出，该变换的思想是将一个空间中的曲

线变换到所对应的参数空间中的点上，通过在参数空间中统计点的极大值来确定曲线的

参数[30]。该方法的优点在于它具有一定的抗噪能力。在传统 Hough 变换的基础上提出

概率 Hough 变换（PHT），该方法在曲线空间随机的选取一些点投影到参数空间，并且

在参数空间并不把所有的可能的点累加，而只是累加其中一部分，这样在小部分时间中

就能寻找到极值点并求出曲线的参数。该方法可以实质性的减少变换的计算时间和空

间。本文在概率霍夫变换的基础上对变换后的参数引入直线车道线结构的约束，车道线

结构的约束是指在图像平面中，左侧车道线的斜率将在 0.5 到 1 的范围内，而右侧车道

线的斜率将在-0.5 到 1 的范围内。结合 5.2 节中 Canny 边缘检测结果做进一步的概率霍
夫变换，能更加精确的确定直线车道模型的参数 lk 、 rk 、 rb 和 lb 的值。图 5.11 是 Canny
边缘检测（a）和 PHT 直线检测结果（b）对比图。

（a）Canny 边缘检测结果

（b）PHT 检测结果

图 5.11 PHT 直线检测结果

Fig 5.11 PHT straight line test results

从图 5.11 的结果可以看出 PHT 在边缘检测和车道线结构约束的条件下能精确的检

测车道线。完全能屏蔽掉车内挡风玻璃或雨刷的影响。

5.4 本章小结

本章重点研究基于机器视觉的高速公路车道线检测方法和预警决策，从高速公路独

特的道路结构入手，通过科学的假设提出高速公路车道线在近视场区域呈直线理论，并

47西华大学硕士学位论文

在此基础上建立针对左右车道线的直线车道模型。针对车道线特征检测方法，充分利用

车道线在道路图像中边缘信息突出的优点，利用边缘检测效果突出的 Canny 算子做图像

边缘检测。但是由于道路图像中还存在周边景物或车辆，这些物体的边缘特征会影响道

路边缘特征的检测，所以在此基础上集合车道线在图像中出现的物理位置，设置感兴趣

区域来约束检测出的车道线以提高检测的正确率。车道线特征的精确提取是车道模型参

数能否正确解析的关键，本文中使用概率霍夫变换在边缘特征矩阵中寻找车道模型参

数。实验证明本方法能鲁棒的检测车道线并建立车道线的直线方程。

48基于多特征信息的疲劳驾驶检测系统研究

6 多特征疲劳分析

本文在第 3 章解决了眼睛和嘴巴的精确定位并成功的提取到了眼睛和嘴巴图片；在

第 4 章中运用一些图像处理算法高效的实现了眼睛开闭检测和嘴巴开度测量；在第 5 章

根据高速路道路图像的特点使用简单且鲁棒性较强的直线车道模型，实现了高速路车道

线的检测，并找到一种适合此道路模型的偏航决策。在这三章中，本文分别从不同的角

度探讨和解决了疲劳特征数据提取问题。有了这些疲劳特征数据，接下来的工作就是对

这些数据做分析，找到单个特征判断疲劳的标准，再对这三个特征做融合分析，以提高

疲劳预警的效率和抑制虚警率。使得疲劳预警更加准确。

6.1 基于 PERCLOS 原理的疲劳分析

一般情况下，人在疲劳时会伴有眼睛闭合的现象，并且这种情况下的眼睛闭合和正

常的眨眼在闭合时间上有较大的差异，在本文已经完成的眼睛开闭检测的基础上，选择

一种合适的方法来测量眨眼时间是通过眼睛分析疲劳的关键。本文选择在疲劳分析中有

重要地位的 PERCLOS(percentage of eyelid closure over the pupil over time)判定原理来做

眼睛开闭特征的疲劳分析[35]。

PERCLOS 判定方法是指使用单位时间内闭眼时长所占比例来作为疲劳分析标准。

该方法的判断原理图如图 6.1 所示。

图 6.1 PERCLOS 测量疲劳原理

Fig 6.1 PERCLOS measurement principle of fatigue

如图 6.1，应用 PERCLOS 方法，需要测量的时间点主要有四个，在图中分别是 1
t

t 。
4

有了这些时间点的值，计算 PERCLOS 值的方法如公式 6.1 所示：

49西华大学硕士学位论文

f



t
3
t

4




t
2
t
1



100%

（6.1）

在公式（6.1）中， f 为计算所得的眼睛闭合时间比。表示的物理意义是，在一次闭

眼中，眼睛的闭眼程度在整个闭眼过程中所占的时间比，这个比值越大，疲劳程度也就

越大。

在 PERCLOS 判断准则中，认为当 f 的值大于等于 80%时即为疲劳。结合本文所使

用的眼睛开闭检测方法，不能准确的测量在一次闭眼过程中公式（6.1）中的四个时间点，

所以换一种测量方式。根据在正常情况下人的一次眨眼平均时间 300ms 左右，按照

PERCLOS 准则，在疲劳时在一次闭眼中完全闭眼的时间长度会增加 80%，为了方便计

算，可以认为疲劳眨眼时间长度比正常眨眼长度要高出 80%。根据这个转换，本文中设

正常眨眼时间长度为 t ，在一次闭眼测量中测量到的闭眼时间长度为 t 。本文计算疲

劳的公式如公式（6.2）。

f



t

  
t
t


（6.2）

所以在 f 的原理基础上定义了如下疲劳判断规则：

1）当 f 值大于等于 0.8 时，认为驾驶员处于疲劳状态。

2）当 f 值小于 0.8 且大于等于 0.5 时，并且在一分钟内出现大于三次。这时认为驾

驶人员轻度疲劳。

3）当 f 值小于 0.5 且大于 0.2 时，认为处于精神不佳状态，可能进入疲劳状态。

4）当 f 值小于 0.2 时，认为处于清醒状态。

本文中使用如下步骤计算 f 值：

1）在眼睛开闭检测算法提供的数据基础上，使用一些简单的滤波方法，使得提高

数据的可靠性。

2）算法在检测到某两帧的状态从“1”变到“0”时。开始帧计数。

3）在第二步的基础上，当算法检测到某两帧状态从“0”变到“1”时停止帧计数。

4）在第三步的基础上，使用帧数来乘帧间隔时间，得到这段的闭眼时间。

5）使用公式（6.2）计算时间比例，并集合本文判断疲劳规则得出实验人员所处状

态。

6）重置帧计数，并进入步骤（1）。

50基于多特征信息的疲劳驾驶检测系统研究

6.2 持续闭眼时长分析

驾驶人员在疲劳时，闭眼时长会有明显的延长，本文中以检测到闭眼的帧作为开始

计时点 st （眼睛状态由“1”变到“0”的帧），并把接下来再次检测到睁眼作为计时结
束点 et （眼睛状态由“0”变到“1”的帧），并定义持续闭眼时长 TC 如公式（6.3）:
 
e

（6.3）

TC t

t

s

如同上述规则在定于持续时长的基础上，在本节也将 TC 分为 4 个等级，具体的规

则如下：

1） 当 TC 值大于 1.5s 时认为处于严重疲劳状态。

2） 当 TC 值小于 1.5s 且大于 1 秒时认为处于中度疲劳状态。

3） 当 TC 值小于 1s 且大于 0.5s 时认为处于轻度疲劳状态。

4） 当 TC 值小于 0.5s 时处于精神良好状态。

在程序中计算 TC 的方法和上述计算闭眼时长比 f 值的方法的一样。

6.3 哈欠分析

第 4 章详细阐述了通过精确定位鼻子以找到嘴巴的方法，本方法的准确度较高，能

有效的从红外人脸图像中找到嘴巴，保证后续哈欠分析的数据可靠性。根据相关研究表

明，人在疲劳、紧张或从沉睡中醒来都会有打哈欠的表现，并且研究发现打哈欠时通过

嘴巴的深度张开，使得吸入的氧气量增减以增强大脑的供氧量。所以在人处于疲劳时打

哈欠是对抗疲劳的表现。无论是在什么情况下，人打哈欠的平均时长是 5s 左右，并且

该时间的长度也因人而异，但总的来说，针对疲劳引起的哈欠，哈欠时间越长说明疲劳

程度越大。本文针对这个情况，定义持续哈欠时长（YT），在引出（YT）之前，本文

先介绍本文的哈欠检查方法。本节针对第四章计算所得到的嘴巴开度来做哈欠分析，首

先本文的实验人员处于疲劳时和处于正常状态时的嘴巴开度曲线如图 6.3 所示。在图 6.3

中上部分的蓝色曲线是实验人员在疲劳时测量的到的嘴巴的开度曲线，下部分的红色曲

线是实验人员在正常闭嘴和开口讲话时的嘴巴开度曲线。其中的是一个哈欠门限阈

值，在本文中，只有当嘴巴的开度值大于，并在大于的范围内持续一段时间，才把

此次张嘴分析为哈欠。这是由于在正常情况下人们讲话时的嘴巴开度较小并且每次张开

的时间长度比较短，在一段连续的时间段里张嘴的频率较快。和打哈欠有着本质上的区

别，但是也不能排除一些特殊的情况。为了本文哈欠分析的准确性和鲁棒性，本文引入

了哈欠分析门限值。

51西华大学硕士学位论文





图 6.3 嘴巴开度曲线图

Fig 6.3 Mouth opening curve

但是引入此阈值也相应的带来一些技术上的问题，这便是此哈欠分析门限值怎么

确定，和在此值持续的时间长度 t 又应该怎么确定等问题，在本文中是采取大量的实验

来逐渐的验证逼近取得在本文环境下最好的和 t 值，通过本文的实验，在能有效区分

讲话和哈欠的开度范围的原则上，

本文实验所得的哈欠门限阈值 85 ，哈欠持续时间阀值

如下：

  。具体的判断步骤

3

s

t

1）在原始检测计算所得的开度曲线上做一维高斯滤波。目的在于平滑掉一些噪声

点的影响。使得曲线变得更加平滑和容易处理。

2）在曲线中把当前开度值和值比较，当出现开度值大于值时，开启帧计数。

直到开度值小于值时停止帧计数。

3）计算帧计数所得的时间，并把该时间和 t 时间做比较。同时重置帧计数。

4）当计算所得的时间大于或等于

哈欠的时间。

  时，算法认为这是一次哈欠。并记录此次

3

s

t

5）计算单位时间内的哈欠频率，并根据此频率的大小给出疲劳指标。

6）回到第（1）步开始新一轮的检测。

本文在上述基础上定义持续哈欠时长（YT），具体定义如下：检测到开始打哈欠
的时间为 sY ，定义结束打哈欠的时长为 eY 。那么定义一次张嘴为哈欠的公式如（6.4）所
示：

Y

e
在公式（6.4）中 tY 为哈欠，且计算得到的哈欠 tY 为持续哈欠时长。

(
if Y
t

t
 

,   

Y
s

Y
t



)

（6.4）

52基于多特征信息的疲劳驾驶检测系统研究

在此基础上本文分析哈欠主要分为四个等级，具体如下：

1） 当 tY 值大于等于 7s 时，认为处于严重疲劳状态。
2） 当 tY 值小于 7s 大于等于 5.5s 时，认为处于中度疲劳状态。
3） 当 tY 值小于 5.5s 大于等于 4.5s 时，认为处于精神不佳状态。
4） 当 tY 值小于 4.5s 时，认为处于清晰状态。

6.4 偏道分析

在第 5 章中通过使用概率霍夫变换精确的求解直线车道模型中的未知参数，并求得

左右车道线的直线方程，然而一个完整的车道偏离预警系统在车道检测的基础上还需具

备优化偏航决策和预警模型。目前针对基于计算机视觉的车道偏航决策主要可以划分为

两大类：一类是需要标定摄像机，使用摄像机的位置参数和车道线的几何关系来做偏航

决策，该方法决策精度较高，但是对车身抖动比较敏感；另一类方法是不需要标定摄像

机的方法，该方法主要使用左右车道线的几何关系做决策，相对第一类方法来说该方法

对偏航的反应比较迟钝，但车身抖动不会影响偏航决策。在高速路行车时由于车速较高，

正常情况下驾驶人员不会猛烈转动方向盘，所以车辆在横向上可以认为是匀速切线，基

于这个假设本文选择第二类方法来实现偏航决策。

本文在直线车道模型的基础上，考虑设计适合直线车道模型且时间效率高和灵敏度

能满足偏航计算的预警决策，首先直线车道线在图像平面中加上图像的横轴标会形成一

个三角形，当车辆在横轴不同位置时，这时这个三角形的内角有比较明显的变化，基于

此本文定义偏航率 [53]来描述车辆偏离车道的程度，此偏航率能有效的反应三角角度的

变化，并且在车辆位置发生变化时能比较灵敏的反应其变化。该策略下的预警模型如图

6.4 所示。

图 6.4 偏航决策模型图

Fig 6.4 Yaw decision model diagram

53西华大学硕士学位论文

在图 6.4 中，偏航率

  
r

/l

平面横坐标的夹角。其中 arctan(

 
l

lk

r
当车辆在左右车道线中间行驶时的值接近常数 1，当车辆向左偏航行驶时的值将增

，其中 l 和 r 分别是左侧车道线与右侧车道线和图像
。由偏航率的定义可知，

  

arctan(

，

)

)

rk

大，与之相反当车辆向右边偏航行驶时的值将减少。所以通过值在一段时间内的变

化能准确的反应车辆是否偏航。

如上所述偏航率能准确反应当前帧中车辆与左右车道线的位置关系，但与实际的驾

驶情况相似，仅仅根据单帧计算所得偏航率的值尚不能判断车辆是否偏航行驶。在实际

情况中偏航行驶是车辆逐渐靠近某一条车道线的过程，根据该结论，本文定义偏航函数

 
t

f

( )
t

，在函数 ( )

f

t 中 t 作为自变量表示偏航率对应的帧时间， t 是帧时间 t 的函数。

分析车辆偏航行驶的过程可知偏航函数曲线的一般规律，其示意图如图 6.5 所示。

图 6.5 偏航函数曲线示意图

Fig 6.4 Yaw function curve schematic diagram

在图 6.5 中车辆从 0 时刻到 6t 时刻的行驶可分为 5 个状态具体如下：

（1）从 0— 1t 、 3t — 4t 和 6t 时刻后， t 的值均接近于 1，这时认为车辆行驶在车道

中央，是正常的行驶状态。

（2）从 1t — 2t 时间段， t 从正常值不断增加，根据偏航率的定义可知，车辆正在

向左偏航行驶，处于向左偏行行驶状态。

（3）从 2t — 3t 时间段，由于在 2t 时刻驾驶人员受到干预，所以驾驶人员调整方向盘，

这时 t 值不断减少，说明车辆在向右行驶，回归正常驾驶状态。

（4）从 4t — 5t 时间段， t 从正常值不断减少，说明车辆正在向右偏航行驶，处于向

右偏航行驶状态。

54基于多特征信息的疲劳驾驶检测系统研究

（5）从 5t — 6t 时间段，由于在 5t 时刻驾驶人员受到干预，所以驾驶人员调整方向盘，

这时 t 值不断增加，说明车辆在向左行驶，回归正常驾驶状态。

从对偏航函数所包含的一般情况分析可知，车道偏离预警应该在 1t — 2t 或者 4t — 5t

时间段。

根据上述理论，在实际情况中根据驾驶员个人驾驶习惯的不同，在实际开车时往往

偏航率不会保持是“1”或者在“1”周围波动，往往是会保持一个特定的值而在这个值
周围波动，本文设某个车辆正常行驶时保持的偏航率为 c 。但是在这个过程中对于任何
一辆行驶的车辆来说，在发生偏航时有同一的表现，那就是发生偏航时实际的偏航率 t
和 c 之间的差值相对来说是比较稳定的特征。 根据本文中实际测定的偏航率如图 6.6
所示。

图 6.6 偏航率曲线图

Fig 6.6 Yaw rate graph

在图中当车辆在一条车道线中正常行驶时，这时的 t 值在 1 的附近波动，而当车辆
分别向左右变道时，这时 t 值开始变化，向左变道时 t 值先减少再增大；向右变道时 t

值先增大再减少。这两个过程虽然 t 值得变化方向不一样，但是 t

c  的变化方向是

一样的，都是先增大再减少。所以本文使用

 

  
t
c

 来定义偏航程度，但使用  来

定义偏航的弊端是本文从  直接看出偏航的方向。在偏航预警中我们要关注的是什么
时候发生偏航，所以  也满足本文应用的要求。在这上述分析的基础上本文将偏航程
度分为四级，具体的如下：

1） 当  值大于等于 0.8 时，严重偏航。

55西华大学硕士学位论文

2） 当  小于 0.8 且大于等于 0.5 时，中度偏航。
3） 当  小于 0.5 且大于等于 0.2 时，轻度偏航。
4） 当  小于 0.2 时，正常行驶，不做计算。

6.5 疲劳特征融合分析

驾驶员疲劳时会有很多特征，包括眼睛闭合时间变长、嘴巴打哈欠及无意识车辆跑

偏等。这些特征中有的很强的反应了驾驶员的疲劳状态，以及密切关系人身及车辆安全，

例如眼睛的状态，有的则是作为疲劳状态的辅助判断，例如嘴巴状态等。并不是所有的

疲劳特征都具有同等的重要性，也不能因此忽略掉辅助的信息，所以综合多个疲劳特征

对疲劳的正确判断很有意义。虽然眼睛的状态透露出了很多疲劳的信息，但是由于佩戴

墨镜、有的人眼睛比较小或者说有的人本身眨眼频率就大等原因，检测到的眼睛状态甚

至眼睛区域是错误的，得出的结果也是错误的，甚至有时由于车身抖动等没有检测到驾

驶员的面部信息，因此依靠单一的疲劳特征来判断疲劳有很大的局限性。为了尽可能的

提高准确性，一方面需要提高各个疲劳特征检测的准确性，另一方面需要设计一个良好

的算法结合多种特征，给出综合判断的结果。

文中采用信息融合中的特征级融合，利用从各个传感器的原始信息中提取的特征信

息进行综合分析和处理，通过对像素级融合数据的处理提取出驾驶员的面部特征信息，

然后通过加权平均法对所有信息进行相关分析和处理。

6.5.1 多特征数据融合方法

多传感器数据融合的常用方法大致分为随机和人工智能两大类,随机类算法有加权

平均法、卡尔曼滤波法、多贝叶斯估计法、证据推理、产生式规则等；而人工智能类则

有模糊逻辑理论、神经网络、专家系统等[36]。其中，加权平均法是利用样本的对某个变

量的观测值来预测未来某个时刻该变量的值的方法。加权平均法最简单、最直观，该方

法，它将一组传感器提供的冗余信息进行加权平均，结果作为融合值，该方法是一种直

接对数据源进行操作的方法[36]。

在本文中所采样本是上述的包括眼睛、哈欠和车道偏航这三个特征值在时间序列上

的变化，需要预测的是在接下来某个时刻或计算当前时刻驾驶人员的疲劳状态。具体的

操作是给每个特征按照特征的重要性，对每个特征的等级赋予不同的权重。在利用此权

重加权平均得到当前的疲劳等级。

56

基于多特征信息的疲劳驾驶检测系统研究

6.5.2 眼睛疲劳特征融合分析

对眼睛的两个疲劳特征采用加权平均方法来融合分析，首先对上述两个参数特征做

出疲劳等级的划分，具体的等级如表 6.1。

表6.1 眼睛疲劳参数等级划分

Tab 6.1 Classification of eyestrain parameters

疲劳等级

改进 PERCLOS

0w

1w

2w

3w

小于 0.2

0.2-0.5

0.5-0.8

大于 0.8

TC

小于 0.5

0.5-1

1-1.5

大于 1.5

根据自己的经验和对各项评价指标重要程度的认识，针对表 6.1 中的疲劳等级的权

重划分如表 6.2

表6.2 疲劳等级权重划分

Tab 6.2 Fatigue level weights classification

疲劳等级

权重

0w

0

1w

0.4

2w

0.7

3w

1

根据上述表格的一系列的规定，本文计算疲劳的方法是：首先根据眼睛开闭检测的

结果计算出改进 PERCLOS 特征和持续闭眼时长（TC）特征。并按照表格 6.1 和 6.2 对

疲劳特征做加权计算得到疲劳度 Fatigue ，如公式（6.5）。

（6.5）
Fatigue Perclos w TC w
i
公式（6.5）中 iw 表示疲劳等级权重，i 的取值为 0,1,2,3。分别对应 0w 、 1w 、 2w 和 3w 。









i

按照公式（6.5）计算的结果作表 6.3 的划分。

57

西华大学硕士学位论文

表6.3 疲劳程度划分

Tab 6.3 Fatigue level division

疲劳程度

Fatigue 值

精神良好

精神不佳

轻度疲劳

严重疲劳

Fatigue 

0.28

0.28



Fatigue



1.05

1.05



Fatigue



2.3

Fatigue 

2.3

根据提出的眼睛开闭检测算法，在采集的数据集上对输入的眼睛图片做开闭检测。

当检测到眼睛为开时输出的结果是“1”；当检测到闭时输出的结果为“0”。在一段时

间内输出的结果是一段方形波。具体眼睛开闭检测实验结果如图 6.7 所示。

图 6.7 眼睛开闭曲线

Fig 6.7 Eye opening and closing curve

58

基于多特征信息的疲劳驾驶检测系统研究

图6.8 眼睛疲劳检测结果

Fig 6.8 eyestrain test results

在图 6.7 中做眼睛开闭检测均是使用的 30fps 的视频，在假设没有漏帧的情况下能

用这个帧率来计算某帧之间的时间间隔。如对于 30fps 帧率的视频，每帧图像之间的时

间间隔大约为 33ms。那么 10 帧图像之间的时间间隔为 9 33 ms。所以本文以此类推来

计算时间。在图 6.7 中实验都使用 900 帧连续的图像，其中上面蓝色曲线是正常所测得

的眨眼曲线；而下面红色曲线是实验人员在疲劳时所测得的眨眼曲线。从该曲线结果可

以定性的分析出，在实验人员疲劳时眼睛闭合的时间明显比清醒时的时长有所增加。本

文在上述疲劳数据的基础上对前面提出的疲劳分析方法做实验验证，其疲劳检测结果如

图 6.8 所示。其上边是与疲劳驾驶时所对应的眨眼图，下边是对这段曲线做疲劳分析得

到的疲劳检测结果，其中的红点表示检测到的疲劳值，横线是本文提出的疲劳分析的门

限值。虚线是为了方便对照标出来的对照线。那么从图 6.8 中可以得出：

1）按照前面的判断规则，分别在 100 到 200 和 400 到 500 帧时检测到轻度疲劳，

并且有具体的 Fatigue 值均满足轻度疲劳的要求。与上边的眨眼曲线对照可以发现符合

实际的情况。

2）在 200 到 300 之间检测到一次严重疲劳，其 Fatigue 值为 2.4496 明显大于门限值

2.3，与眨眼曲线对照可以看出，与其它的点相比较闭眼的时间确实比较长。

3）在除去上述所述的 5 个疲劳点，在其他点均没有检测到疲劳。

59

西华大学硕士学位论文

最后本文通过大量的实验计算本文算法做眼睛开闭检测和疲劳分析的时耗，其平均

用时在 6ms 左右。分析处理用时较少的原因在于，本文所使用的纹理分析方法在计算上

比较有优势，同时最后提取的描述向量是一个线性可分的三维向量，在做分类处理时也

能提高分类的效率。并且本文最后产生的开闭数据是由“0”和“1”组成的方波，容易

处理。所以综上所述本文提出基于纹理的眼睛开闭检测方法和疲劳分析方法能满足实时

性要求，并且提出的方法已在实验室的疲劳检测系统中得到应用，有一定的实用价值。

6.5.3 融合多特征权重分配及计算模型

由前面的分析可以知道，眼睛闭合度、嘴部开度、车道偏航率等特征都是对驾驶员

的疲劳程度有反应。当然并不是所有的疲劳特征都能够直接准确的指示疲劳的状态。但

有时候一个特征就可以判断出驾驶员处于危险驾驶状态，例如长时间眼睛闭合。通常需

要我们同时检测到多个特征来判断疲劳能有较高的准确率。例如同时检测到点头、打哈

欠等。事实上，每个特征都对驾驶员的疲劳清醒有一定关联，但是有的特征并不只是疲

劳时出现，在非疲劳状态时也会出现。为了表述这种情况，本文采用上述加权平均法来

计算疲劳的程度。

1）疲劳程度权重分配

对每个疲劳等级的划分是由前面 6.1-6.4 节的分析得来。现在分配疲劳等级如表 6.4

所示：

表 6.4 疲劳等级划分表

Tab 6.4 Fatigue grade classification table

疲劳等级

改进 PERCLOS

YT

TC



0w

1w

2w

3w

小于 0.2

0.2-0.5

0.5-0.8

大于 0.8

小于 4.5

小于 0.5

小于 0.2

4.5-5.5

5.5-7

大于 7

0.5-1

1-1.5

大于 1.5

0.2-0.5

0.5-0.8

大于 0.8

疲劳等级 0w 、 1w 、 2w 及 3w 分别代表各关键特征处于精神良好、精神不佳、轻度疲劳

及严重疲劳的情况。再对各疲劳值进行归一化，如下表所示：

60

基于多特征信息的疲劳驾驶检测系统研究

表 6.5 归一化后疲劳等级表

Tab 6.5 The normalized Fatigue grade classification table

疲劳等级

改进 PERCLOS

0w

1w

2w

3w

0.25

0.25-0.625

0.625-1

1

YT

0.643

TC

0.33



0.25

0.64-0.79

0.33-0.67

0.25-0.625

0.79-1

1

0.67-1

1

0.625-1

1

然后每个信息对疲劳影响的关联度不同来对每个疲劳特征信息的权重分配如下表

所示，因为权重是根据自己的经验和对各项评价指标重要程度的认识来确定的，所以在

这里取了两组不同的权重分配来分析，最后选出最优权重分配，如表 6.6 所示：

表 6.6 各疲劳特征信息权重分配表

Tab 6.6 Each fatigue feature information weights allocation table

疲劳等级

权重 1

权重 2

а0

0.6

0.65

а1

0.6

0.68

а2

0.7

0.70

а3

0.6

0.60

根据表 6.4 和 6.6，针对使用改进 PERCLOS、持续哈欠时长（YT）、持续闭眼时长

（TC）和车道偏航率差  加权计算疲劳的方法如下：首先定义疲劳度为 Fatigue ，定

义计算新的疲劳度 Fatigue 的公式如公式（6.6）所示：

Fatigue=PRECLOS×а0+ YT×а1+TC×а2+  ×а3
公式（6.6）中аi 表示疲劳等级权重， i 的取值为 0,1,2,3。分别对应а0、а1、а2
和а3。该公式是对所有疲劳特征的加权平均，并最终能计算得到相应的疲劳度。在融

（6.6）

合分析后再次对疲劳度做了等级的划分如表 6.7 所示：

表6.7 多特征融合后疲劳程度划分

Tab 6.7 The fatigue degree division after multi-feature fusion

疲劳程度

精神良好

精神不佳

轻度疲劳

Fatigue 值

Fatigue﹤0.7

0.7≤Fatigue﹤

0.925≤Fatigue﹤

0.925

1.425

严重疲劳

Fatigue≥

1.425

61

西华大学硕士学位论文

当单个疲劳特征度已确定时，通过多特征融合计算方法疲劳特征结合疲劳关联度计

算疲劳度，根据疲劳度初步得到疲劳状态，给出报警，驾驶员打瞌睡时的综合疲劳度如

表 6.8 所示。

表 6.8 驾驶员某时的单特征和融合后疲劳度

Tab 6.8 The fatigue of a single feature and after integrate

疲劳特征

权重 1

权重 2

单特征疲劳度 多特征疲劳度 1 多特征疲劳度 2

改进 PERCLOS

YT

TC



0.6

0.6

0.7

0.6

0.65

0.68

0.7

0.6

0.2

0.5

0.4

0.3

0.88

0.93

由上表可以知道，驾驶员同时出现眼睛闭合时间长，打哈欠及车偏航行驶这三个特

征时，由公式根据权重系数 1 和权重 2 计算出的疲劳度为 0.88 和 0.93，而权重系数 2

精确度更高，综合分析的疲劳度在多特征融合后疲劳程度划分的范围内更高，已属于轻

度疲劳，提高了检测精度。下面将权重系数 2 用于融合分析，取一段时间各疲劳特征的

疲劳值进行融合分析后的结果对比图如图 6.9 所示，由图可知融合分析后疲劳特征区分

度更高且融合后的疲劳值在新的疲劳判定等级范围内更能准确检测疲劳。

图 6.9 各疲劳值及融合后疲劳值对比图

Fig 6.9 Comparison chart of each fatigue value and fatigue value after integration

62

基于多特征信息的疲劳驾驶检测系统研究

通过对比分析以下两种情况，一种是结合多特征的方法，另外一种是以单个特征中

准确度最高的眼睛开度做单个特征疲劳检测，对比结果如表 6.9 所示：

表 6.9 疲劳检测对比结果

Tab 6.9 The fatigue detection result

检测方法

实际次数

检测总次数

正确次数 错误次数 灵敏性

眼睛疲劳度

多特征融合

525

500

525

500

487

497

37

3

0.927

0.994

通过表 6.9 中的数据可以看到，多特征融合在灵敏性上比通过单个特征（眼睛疲

劳度）表现要好，这主要是由于在眼睛疲劳特征不明显时，检测到了其他疲劳特征，判

断出了疲劳状态。综上所述，融合多特征的方法表现比基于单个特征的检测更加优秀。

6.6 疲劳预警

目前在基于单特征的疲劳分析系统中，有效精确的预警和抑制虚警是比较困难的工

作。本文针对这部分提出基于多特征分析的方法来提高预警的精度和抑制虚警。特征的

引入，使得这些特征能相互制约和相互补充。在本文中，主要引入了三个在疲劳分析时

比较重要和便于判断分析的疲劳特征—眼睛特征、嘴巴特征和车道特征。此三特征有着

怎样的关系呢？

1）分析疲劳首先会考虑和分析的眼睛特征，是驾驶人员是否疲劳最直接的考量特

征。该特征在整个疲劳分析中处于重要地位，如检测到长时间的闭眼，无论是否有其他

表征疲劳的特征出现，这时都应该给予预警，因为驾车时长时间的闭眼时反常现象，并

且很容易照成交通事故。但是上述情况可能是在驾驶人员确实太过于疲劳时才可能出现

的情况，一般在驾驶时由于驾驶人员心理对安全的重视，会强制自己在疲劳时不会长时

间闭眼。但不能控制的睡意会改变驾驶员的眨眼频率，但是这种表现出来的疲劳没法单

单通过计算眼睛的特征得到一个准确的判断。这时就需要诸如嘴巴和车道这些特征的加

入来综合分析。

2）嘴巴的特征，在第一种情况中出现的仅仅由眼睛不能判断疲劳的情况，通过加

入嘴巴特征可能得到解决。在一般情况下，当人有睡意时，出于某种原因也许可以控制

眼睛长期出于睁开状态，但是打哈欠是不由自主的行为，不能控制。所以当检测到驾驶

人员眨眼频率变化时，这时可以加入嘴巴的状态来综合分析。如果嘴巴有打哈欠的特征

出现，这时即可以认为驾驶人员处于精神不佳的状态，可以给予相应的提醒。

63

西华大学硕士学位论文

3）车道偏行特征，由于在本文所研究的技术中并不能做道路全景分析，所以只能

假设车辆在高速行驶时，最佳的状态是在一条车道中间位置行驶。把车辆的偏道行为分

为两种:第一种是有意识的切线；第二种是无意识的偏航。对于第一种情况，可能是在驾

驶人员超车或让障碍物时可能发生，这种情况往往伴随着车辆信号灯的改变，并表现出

来的车辆行驶轨迹是迅速的切线变道。但是对于第二种情况，往往并没有信号灯的变化，

和在偏道上不会出现正常切线的规律性。所以对于偏道的检测情况比较复杂。单单使用

这一种数据并不能区分各种复杂的情况。但是已知的是无论车辆出于什么原因偏道，这

都是驾驶人员操作行为的表现。那么我们综合驾驶人的一些疲劳特征的分析能比较准确

的判断出偏道出于何种原因，并做出相应的预警。在本文中，只要检测到车道偏离，并

在嘴巴和眼睛特征上有疲劳表征，便做出相应的预警。

综上所述本文使用上述三个特征综合预警方案如下：

1）疲劳预警，当检测到眼睛长时间（超过 1s）处于闭眼状态时，作为最高优先级

做疲劳预警。

2）注意休息预警，做此预警的情况是，当检查到眨眼频率改变、哈欠和车道偏航

这三个特征中的两个特征满足时，做出注意休息预警。

3）请注意驾驶预警，此项预警主要是检测出驾驶人员有一些不正常的驾驶行为。

在本文中主要包括如下：检测到嘴巴长时间处于说话状态；在红外人脸图像中不能检测

到驾驶人员眼睛和嘴巴（这是可能头偏的程度较大，视线不在车辆前方）；车道发生偏

离等。任一情况发生时，做出请注意驾驶预警。

同时，经过多信息融合分析后，做出如下预警方案：

1)一级警告：在测到疲劳程度为精神不佳时，启动车内语音提示，告诫驾驶员不能

疲劳驾驶；

2)二级警告：在测到疲劳程度为轻度疲劳时，启动车内语音提示，警告驾驶员正处

于危险驾驶过程中；同时，启动车外语音警戒，并对外发射遇危提示红灯闪烁的危险防

撞信号。

3)三级警告：在测到疲劳程度为重度疲劳时，启动车内语音提示，命令驾驶员立即

靠边停车，20 秒后将自动关闭发动机；同时，启动车外语音和灯光警告系统。

6.7(cid:0) 本章小结

在本章中主要提出四种预警方案，其中包括基于眼睛的疲劳预警方案、基于嘴巴的

预警方案、基于车道的预警方案和以上三种特征融合的预警方案。对于眼睛开闭检测的

64

基于多特征信息的疲劳驾驶检测系统研究

结果提出闭眼时间比的方法来判断疲劳；对于嘴巴开度疲劳分析，本文引入开度阈值和

时长阈值来区分讲话和疲劳这两种情况；对于车道偏航预警本文提出偏航率来做偏航

率；最后对三特征做融合分析，提出多特征数据融合方法以及融合多特征信息的加权平

均分析法。并在本章中用提出的方法对采集到图像数据做分析，实验结果表明提出融合

方案的可行性。

65

西华大学硕士学位论文

结

论

本文研究的课题是“基于多特征信息的疲劳驾驶检测系统研究”，与传统的基于单

特征的疲劳预警技术相比较，在疲劳预警上能更有效的抑制虚警的发生。本文使用三个

特征来做预警分析，其中包括眼睛特征、嘴巴特征和车道偏离特征。在这些特征做单个

疲劳分析的基础上引入三特征融合分析，并提出三特征融合分析的预警方案，其中包括

疲劳预警、精神不佳预警和专心驾驶预警。本文具体的成果和创新点如下：

1）本文在绪论部分详细的分析现阶段也有的疲劳预警系统研究现状和发展趋势，

并在此基础上引出了本文的研究课题和研究方案。采用三特征融合分析预警。

2）为了设计保证疲劳驾驶检测系统在全天时的可用性。本文在驾驶人员面部数据

采集和车道数据采集模块做相应的改进，主要是引入红外成像系统。在此系统中采用红

外辅助光源和红外滤光片来保证为全天时的疲劳检测提供可靠的人脸面部数据。

3）要检测眼睛的开闭和测量嘴巴的开度，首先要解决的问题就是从人脸红外图像

中定位并提取眼睛和嘴巴图片。本文在分析也有的系统的基础上，使用智能算法——

ADABOOST 算法来在人脸图像中定位眼睛和嘴巴。针对采集的人脸图像有时可能只包

含左眼或右眼的情况，提出使用左右眼分开的分类器来检测驾驶人员的眼睛，以提高眼

睛的检测率。并且在做嘴巴检测实验时，发现直接检测嘴巴，实验效果不好检测率较低。

针对此情况，本文提出首先在人脸图像中检测鼻子，因为在人脸图像中鼻子是比较稳定

的特征，并且在实验中鼻子的检测率较高，再通过鼻子和嘴巴的几何位置关系来定位嘴

巴，最终达到检测嘴巴的目的。

4）针对眼睛开闭检测和嘴巴开度测量问题。首先红外图像中眼睛的开闭检测是比

较麻烦的工作，本文设计的疲劳检测系统需要考虑的一个重要指标便是时间效率问题。

所以找到一个高效的针对红外图像的眼睛开闭检测检测方法是本文的系统能否实现的

关键。在本文中使用高效的基于纹理的眼睛开闭检测方法来检测眼睛的开闭。在保证眼

睛开闭检测效率的同时，准确率也较高。另外针对嘴巴开度测量问题，本文提出自适应

二值化阈值的开度测量方法，对于不同的光照强度的嘴巴图像自适应的生成二值化阈值

并做二值化，最后在二值化后嘴巴的开度。

5）为了保证车道线检测的时间效率，本文使用直线车道模型来检测车道线，能很

好的满足和适应高速路的车道线检测问题。在本方法中，主要是使用 PHT 来求解直线

模型的参数。并求出左右车道线模型，最后针对本文的高速路车道线模型提出一种适合

本文的车道偏离预警策略。

66基于多特征信息的疲劳驾驶检测系统研究

6）针对上述的三种疲劳特征分别做实验验证特征检测和提取方法的正确可行性。

并提出单个特征的疲劳分析方法。最后本文根据三特征的特点选用 PRECLOS、闭眼时

长、哈欠时长和车道偏航率作为特征值，采用加权平均法做融合三疲劳特征分析，实验

证明其检测准确率有较大提高，且实验表明提出的预警方法能很好的适应驾车的环境。

本文在特征的数据的采集、疲劳特征提取和疲劳特征分析上都做了相应的工作，并

得到了相应的成果。但是伴随着技术的不断发展，和保证车辆安全的要求越来越高，接

下来本文还有很多工作需要改进，具体如下：

1）在车道数据采集上需要下功夫，本文采集的车道数据并没做一些相应的预处理，

但是在实际的情况中，可能会遇到诸如雨雪等复杂的天气，这时对采集的车道图像做预

处理是必须的，做了预处理能提高算法的鲁棒性和系统的健壮性。

2）本文中眼睛的检测和眼睛的开闭检测都有较好的精度，但是总有一些特征情况

导致检测失败的情况，对于失败时本文采取的方法是不做处理。但是在应用中这些数据

往往可能更加的关键，所以在眼睛的疲劳判断模块，有必要研究一种滤波算法，在输入

眼睛开闭检测失败的结果时，能通过此滤波算法做出来从中找到可用的信息来判断眼睛

的开闭。

3）本文的车道偏离预警中，并没有加入一些车辆的车身数据作为判断的标准，这

需要改进，加入车辆车身数据的分析能有效的提高偏航分析的准确率。

4）对驾驶员疲劳驾驶检测系统而言，系统的实时性、准确性以及对驾驶行为的非

约束性是在设计系统过程中需要考虑的几个重要因素，尤其是实时性，它是衡量该系统

性能好坏的一个重要指标。而提出的三特征融合的预警方案，在实时性上还需要做特别

多工作，才能尽最大可能的满足实际要求，提升检测率。

67西华大学硕士学位论文

参考文献

[1]杜勇. 基于面部信息的驾驶者疲劳状态分类方法研究[D]. 哈尔滨工业大学,2012.

[2]崔坚.基于眼部识别的驾驶员疲劳检测方法研究[D]. 大连海事大学电子科学与技术，2013

[3]李树娟.基于 LBP 特征的人脸表情分析[D]. 中国石油大学信息与通信工程,2010.

[4]戴军,张进,姚洪略等.基于信息融合技术的驾驶员疲劳度实时监控系统[D]. 广东技术师范学院工业

中心,2006.

[5]吴雅萱,李文书,施国生等.疲劳驾驶检测技术研究综述[D]. 浙江理工大学，2010.

[6] 刘洪榛.基于机器视觉的疲劳驾驶检测算法研究[D]. 哈尔滨工业大学,2012.

[7] Ji Q, Yang X. Real-time eye, gaze, and face pose tracking for monitoring driver vigilance [J]. Real-Time

Imaging, 2002, 8(5): 357-77.

[8] 李凤芝, 李昌吉, 龙云芳, et al. 汽车驾驶员攻击性驾驶行为的心理因素分析 [J]. 四川大学学报:

医学版, 2004, 35(4): 568-70.

[9]黄瀚敏.基于汽车驾驶员疲劳状态监测技术的汽车主动安全系统研究[D]. 重庆大学控制理论与控

制工程,2007.

[10] 宋健, 王伟玮, 李亮, et al. 汽车安全技术的研究现状和展望 [J]. 汽车安全与节能学报, 2010,

1(2): 98-106.

[11] Ji Q, Yang X. Real-time eye, gaze, and face pose tracking for monitoring driver vigilance [J].

Real-Time Imaging, 2002, 8(5): 357-77.

[12] 黄仁, 田源, 杨吉云, et al. 基于人眼状态识别的驾驶员疲劳检测方法研究　 [J]. 世界科技研究

与发展, 2011, 33(1): 125r7.

[13] 朱婧.基于视频图像信息提取的疲劳驾驶检测技术研究[D]. 控制理论与控制工程,2009.

[14] 顾征远.面向驾驶员的疲劳监测系统研究[D]. 浙江大学电路与系统,2013.

[15] 曹海燕 ,方志辉 ,李晓明,疲劳驾驶状态数据融合技术研究[D], 太原理工大学电气与动力工程学

院,2011.11

[16] 李旭, 张为公. 基于视觉的车道偏离报警系统的研究 [J]. 仪器仪表学报, 2008, 29(7): 1554-8.

[17] 杨万海，多传感器数据融合及其应用[M]，西安电子科技大学出版社，2004.4

[18]赵小川等，传感器信息融合 MATLAB 程序实现[M]，机械工业出版社，2014.6

[19] 彭冬亮，文成林，薛安克等，多传感器多源信息融合理论及应用[M].科学出版社，2010

68基于多特征信息的疲劳驾驶检测系统研究

[20] 朱振华.基于多特征融合的驾驶员疲劳检测算法研究[D]. 通信与信息系统,2008.

[21] 甘玲, 朱江, 苗东. 扩展 Haar 特征检测人眼的方法 [J]. 电子科技大学学报, 2010, 39(2):

247-50.

[22]黄仁, 田源, 杨吉云, 等. 基于人眼状态识别的驾驶员疲劳检测方法研究[J]. 世界科技研究与发

展, 2011, 33(1): 125r127.

[23] 孙明，数字图像处理与分析基础-MATLAB 和 VC++实现[M]，电子工业出版社，2013.10

[24]张昌明,童卫青,王燕群.一种高性能近红外光人脸检测和眼睛定位算法[M].华东师范大学计算机

科学技术系,2011.

[25] 黄仁, 田源, 杨吉云, 等. 基于人眼状态识别的驾驶员疲劳检测方法研究[J]. 世界科技研究与发

展, 2011, 33(1): 125r127.

[26] 宋爱国，刘文波，王爱民，测试信号分析与处理[M]，机械工业出版社，2011.1

[27] 刘卫国，MATLAB 程序设计与应用(第二版) [M]，高等教育出版社，2006.7

[28] 黄仁, 田源, 杨吉云, et al. 基于人眼状态识别的驾驶员疲劳检测方法研究[J]. 世界科技研究与

发展, 2011, 33(1): 125r7.

[29]周振超，张健，王立红等.容错控制理论综述与展望[J].自动化博览，2007（7）：7-9.

[30] 胡友好. 山区高速公路总体设计探析 [J]. 交通标准化, 2009, 24(052.

[31] 董因平. 高速汽车车道偏离预警系统的算法研究 [J]. 长春: 吉林大学汽车工程学院, 2004,

[32] 耿静静. 基于单目视觉的车道线检测与识别 [D]; 哈尔滨工业大学, 2007.

[33] 刘涛, 黄席樾, 周欣, et al. 高速公路弯道识别算法 [J]. 重庆大学学报: 自然科学版, 2003, 26(7):

24-7.

[34] 刘加海, 白洪欢, 黄微凹. 基于彩色和边缘信息融合的道路分割算法[J]. 浙江大学学报: 工学版,

2006, 40(1): 29-32.

[35] GuoYi Jin, Driver Fatigue Monitoring System and Achievement Based on Face Detectionon face

Detectlon[D]. School of Informat．ion Engineering,2013.

[36] 何友，王国宏，彭应宁等著，多传感器信息融合及应用（第二版）[M].电子工业出版社，2007.12

[37] 蒋友毅,基于多特征的疲劳驾驶检测系统的设计与实现[D].计算机应用技术，2013.

[38] 孙仁云，付百学.汽车电器与电子技术[M].北京：机械工业出版社，2011..

[39]臧杰，阎岩，汽车构造（下册）[M]，机械工业出版社，2010.1

[40] Ronald P.S Mahler，范红旗，卢大威，刘本源等，多源多目标统计信息融合[M]，国防工业出版

社，2013.8

[41]David L. Hall James Llinas.多传感器数据融合手册[M].海军新军事变革丛书，电子工业出版社，

69西华大学硕士学位论文

2008.5

[42]Evaluations of Physical Fatigue during Long-term driving with a New Driving Posture[R], Jilin

University,2014.

[43]Se Jin Park, Sun Woong Kim. A Study on the Assessment of Driver’s Fatigue[R]. SAE International by

Jilin University,2002.

[44]Nanae Michida, Hiroshi Okiyama etc. A Study of Drivers’ Fatigue Mechanisms during Long Hour

Driving[R]. SAE International by Jilin University,2001.

[45]Leandro L. Di Stasi, Rebekka Renner. Towards a driver fatigue test based on the saccadic main

sequence:A partial validation by subjective report data[R].Transportation Research Part C21 (2012)

122–133

[46]Sarah Jay, Drew Dawson, Sally Ferguson and Nicole Lamond. Driver fatigue during extended rail

operations[R]. The Centre for Sleep Research, University of South Australia, City East Campus,

Level 7, Playford Building, Frome Road, Adelaide 5000, South Australia, Applied Ergonomics 39

(2008) 623–629

[47]Masrullizam Mat

Ibrahim, John Soraghan. Yawn analysis with mouth occlusion detection[R].

Department of Electronic and Electrical Engineering, University of Strathclyde, Biomedical Signal

Processing and Control 18 (2015) 360–369.

[48] Knipling R R, Wang J S. Crashes and fatalities related to driver drowsiness/fatigue. Washington, DC:

US Department of Transportation, National Highway Traffic Safety Administration; 1994[J]. ntl. bts.

gov/lib/jpodocs/repts_ te/1004. pdf. Accessed January, 2013,

[49] Chambayil B, Singla R, Jha R. EEG Eye Blink Classification using neural network[C]//Proceedings of

the World Congress on Engineering. 2010, 1: 2-5.

[50] Yang J H, Mao Z H, Tijerina L, et al. Detection of driver fatigue caused by sleep deprivation[J].

Systems, Man and Cybernetics, Part A: Systems and Humans, IEEE Transactions on, 2009, 39(4):

694-705.

[51] Vural E, Cetin M, Ercil A, et al. Drowsy driver detection through facial movement

analysis[M]//Human–Computer Interaction. Springer Berlin Heidelberg, 2007: 6-18.

[52] Ortega A, Sukno F, Lleida E, et al. AV@ CAR: A Spanish Multichannel Multimodal Corpus for

In-Vehicle Automatic Audio-Visual Speech Recognition[C]//LREC. 2004.

[53] Laws, K.I. Textured image segmentation. Report 940,Image Processing Institute[R], Univ. of Southern

California,1980.

70基于多特征信息的疲劳驾驶检测系统研究

攻读硕士学位期间发表的论文及科研成果

1 Qin Wang, Lan Tang etc. Driver fatigue detection algorithm research based on the
characteristics of eyes, Applied mechanics and materials. vols.701-702(2015) pp30-35.

致

谢

首先诚挚地感谢我的指导老师唐岚教授，三年里不懂事的我在生活中和学习上出过

很多错，但是她都能包容我并给我正确的指导，指明学习和人生的方向。在唐老师的耐

心指导下，我终于完成论文，她在百忙中抽出宝贵的时间来指导我的学习，关心我的生

活，审查并修改我的论文。她严谨仔细、一丝不苟的学术作风和和蔼可亲、风趣幽默、

胸怀宽广的人格魅力一直深深感染着我，也一直是我的学习榜样。在此，谨向我尊敬的

老师表示最诚挚的敬意和衷心的感谢！

论文能够顺利的完成，我要感谢指导和帮助我的老师们，他们让我学习到做技术就

是要肯专研，在自己摸索过程中学习的不仅仅是技术更是一种解决任何问题的都能使用

方法。同时还要感谢我的同学及师弟们，在各种关键的时候提醒我，通知我各种学业上

的事，并在我需要帮助时给与我无私的帮助。在我苦闷的时候能开导我，给我最大的鼓

励。在此，我深深的感谢您们。同时感谢母校对我多年的培养。

最后我要特别感谢我的家人，在我这么多年的求学期间，您们都一直默默的无私的

支持我，给我无微不至的关爱，让我专心于学习，同时也恳请你们原谅我的任性和不懂

事，让你们操心了。我感谢我的朋友，感谢他们为我提出的建议和意见，给我支持和鼓

励，我很欣慰和感激认识了你们。

71简ｉ

《 是 明 德 幸 據１

Ｉ

心 诗ｉ点 ；

己； 早 叫 叶

． 苦 苗
叩苗 ； 式 Ｓ常苗； 扣變邢

；

ｉ

ｒ ，

．

．

．

、

＊

４

Ｉ

 ＊

３

達 ＇

山 ！甚 冬

賊 １
款若 点 雜１

 ：

＇



＾

１

■

＇

ｈ

■

 —

一

ｉ－

．

．．

． ．

 ｒ

－ ． －

：：

。＾
／ｊ

Ｊ

：

强乾如 ！ ：實 端 乃
聲 宗黏 ；站路扣 ＞ ：

． Ｖ 扣 帛扣

－  ＇

 ，

－ ？



；

■ ＇

：

＇ 〇

；

 －

Ｍ

寒 皆 古

；蠻萬

苗點麗雜柏

Ｉ

苗苗 Ｉ鮮 ：巧？ 婚 誓诗 ．

：邱 与

 ． 

：

．

  ■  

，   ｊ

■■

 ＇ ， －！

？

 －

 － 

＂ １  ＂

．

：

 ． ｉ 

，

ｉ

 







 ＾ 

． 

＇

 Ｖ

．

 ■

 ■

．

．

：

．

：

－

－ ；  －   ．

 

 

．  ？ ：

＇

－  ■

■  ■

； 

？

誦誦議議議議賴 穀

’ ＼ ：

：

＇

＇

；

百 ： 心

 ： 占 心 巧

： 么

与

乐 ■

Ｉ

ｉ

＇

；

／

：  ＾

＼

＾

如 ：Ｔ Ｖ

：

：占



■

■

 ．品Ｊ

．

出

—边

，

－

－

＇

Ｖ

＇Ｖ．  －Ｊ

 ‘

— 产

冥 革 Ｓ 甲可 ‘點 ． －

－

心 ；

－ 矣－

； 魏 ：

ＶＪ

